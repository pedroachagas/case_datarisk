2023-02-14 20:00:26,173:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-14 20:00:26,173:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-14 20:00:26,173:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-14 20:00:26,173:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-14 20:00:27,754:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-14 20:07:12,759:INFO:PyCaret ClassificationExperiment
2023-02-14 20:07:12,759:INFO:Logging name: clf-default-name
2023-02-14 20:07:12,759:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-14 20:07:12,759:INFO:version 3.0.0.rc9
2023-02-14 20:07:12,759:INFO:Initializing setup()
2023-02-14 20:07:12,759:INFO:self.USI: 3884
2023-02-14 20:07:12,759:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'pipeline', 'seed', 'X', 'logging_param', 'X_train', 'data', 'fold_shuffle_param', 'log_plots_param', 'memory', '_available_plots', '_ml_usecase', 'html_param', 'fold_groups_param', 'USI', 'gpu_n_jobs_param', 'y_train', 'y', 'y_test', 'fix_imbalance', 'is_multiclass', 'fold_generator', 'target_param', 'exp_name_log', 'n_jobs_param', 'idx', 'X_test'}
2023-02-14 20:07:12,759:INFO:Checking environment
2023-02-14 20:07:12,759:INFO:python_version: 3.9.15
2023-02-14 20:07:12,760:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-14 20:07:12,760:INFO:machine: AMD64
2023-02-14 20:07:12,760:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-14 20:07:12,760:INFO:Memory: svmem(total=8469581824, available=1662853120, percent=80.4, used=6806728704, free=1662853120)
2023-02-14 20:07:12,760:INFO:Physical Core: 4
2023-02-14 20:07:12,760:INFO:Logical Core: 4
2023-02-14 20:07:12,760:INFO:Checking libraries
2023-02-14 20:07:12,760:INFO:System:
2023-02-14 20:07:12,760:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-14 20:07:12,760:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-14 20:07:12,760:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-14 20:07:12,760:INFO:PyCaret required dependencies:
2023-02-14 20:07:12,760:INFO:                 pip: 22.3.1
2023-02-14 20:07:12,760:INFO:          setuptools: 60.10.0
2023-02-14 20:07:12,761:INFO:             pycaret: 3.0.0rc9
2023-02-14 20:07:12,761:INFO:             IPython: 7.31.1
2023-02-14 20:07:12,761:INFO:          ipywidgets: 7.6.5
2023-02-14 20:07:12,761:INFO:                tqdm: 4.64.1
2023-02-14 20:07:12,761:INFO:               numpy: 1.21.5
2023-02-14 20:07:12,761:INFO:              pandas: 1.4.4
2023-02-14 20:07:12,761:INFO:              jinja2: 2.11.3
2023-02-14 20:07:12,761:INFO:               scipy: 1.9.3
2023-02-14 20:07:12,761:INFO:              joblib: 1.2.0
2023-02-14 20:07:12,761:INFO:             sklearn: 1.0.2
2023-02-14 20:07:12,761:INFO:                pyod: 1.0.7
2023-02-14 20:07:12,761:INFO:            imblearn: 0.10.1
2023-02-14 20:07:12,761:INFO:   category_encoders: 2.6.0
2023-02-14 20:07:12,761:INFO:            lightgbm: 3.3.5
2023-02-14 20:07:12,761:INFO:               numba: 0.56.4
2023-02-14 20:07:12,761:INFO:            requests: 2.28.1
2023-02-14 20:07:12,761:INFO:          matplotlib: 3.6.2
2023-02-14 20:07:12,762:INFO:          scikitplot: 0.3.7
2023-02-14 20:07:12,762:INFO:         yellowbrick: 1.5
2023-02-14 20:07:12,762:INFO:              plotly: 5.9.0
2023-02-14 20:07:12,762:INFO:             kaleido: 0.2.1
2023-02-14 20:07:12,762:INFO:         statsmodels: 0.13.2
2023-02-14 20:07:12,762:INFO:              sktime: 0.16.1
2023-02-14 20:07:12,762:INFO:               tbats: 1.1.2
2023-02-14 20:07:12,762:INFO:            pmdarima: 2.0.2
2023-02-14 20:07:12,762:INFO:              psutil: 5.9.0
2023-02-14 20:07:12,762:INFO:PyCaret optional dependencies:
2023-02-14 20:07:12,781:INFO:                shap: 0.41.0
2023-02-14 20:07:12,781:INFO:           interpret: Not installed
2023-02-14 20:07:12,781:INFO:                umap: Not installed
2023-02-14 20:07:12,782:INFO:    pandas_profiling: 4.0.0
2023-02-14 20:07:12,782:INFO:  explainerdashboard: 0.3.6.2
2023-02-14 20:07:12,782:INFO:             autoviz: 0.1.58
2023-02-14 20:07:12,782:INFO:           fairlearn: Not installed
2023-02-14 20:07:12,782:INFO:             xgboost: 1.7.3
2023-02-14 20:07:12,782:INFO:            catboost: Not installed
2023-02-14 20:07:12,782:INFO:              kmodes: Not installed
2023-02-14 20:07:12,782:INFO:             mlxtend: Not installed
2023-02-14 20:07:12,782:INFO:       statsforecast: Not installed
2023-02-14 20:07:12,782:INFO:        tune_sklearn: Not installed
2023-02-14 20:07:12,782:INFO:                 ray: Not installed
2023-02-14 20:07:12,782:INFO:            hyperopt: Not installed
2023-02-14 20:07:12,782:INFO:              optuna: 2.10.1
2023-02-14 20:07:12,782:INFO:               skopt: Not installed
2023-02-14 20:07:12,782:INFO:              mlflow: Not installed
2023-02-14 20:07:12,782:INFO:              gradio: Not installed
2023-02-14 20:07:12,783:INFO:             fastapi: Not installed
2023-02-14 20:07:12,783:INFO:             uvicorn: Not installed
2023-02-14 20:07:12,783:INFO:              m2cgen: Not installed
2023-02-14 20:07:12,783:INFO:           evidently: Not installed
2023-02-14 20:07:12,783:INFO:               fugue: Not installed
2023-02-14 20:07:12,783:INFO:           streamlit: Not installed
2023-02-14 20:07:12,783:INFO:             prophet: Not installed
2023-02-14 20:07:12,783:INFO:None
2023-02-14 20:07:12,783:INFO:Set up data.
2023-02-14 20:07:12,818:INFO:Set up train/test split.
2023-02-14 20:07:12,915:INFO:Set up index.
2023-02-14 20:07:12,929:INFO:Set up folding strategy.
2023-02-14 20:07:12,929:INFO:Assigning column types.
2023-02-14 20:07:12,949:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-14 20:07:13,008:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-14 20:07:13,011:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-14 20:07:13,054:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 20:07:13,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 20:07:13,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-14 20:07:13,644:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-14 20:07:13,675:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 20:07:13,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 20:07:13,678:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-14 20:07:13,731:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-14 20:07:13,766:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 20:07:13,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 20:07:13,839:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-14 20:07:13,876:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 20:07:13,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 20:07:13,879:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-14 20:07:13,964:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 20:07:13,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 20:07:14,057:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 20:07:14,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 20:07:14,064:INFO:Preparing preprocessing pipeline...
2023-02-14 20:07:14,078:INFO:Set up simple imputation.
2023-02-14 20:07:14,143:INFO:Finished creating preprocessing pipeline.
2023-02-14 20:07:14,150:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                             'numero_de_dependentes'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-02-14 20:07:14,150:INFO:Creating final display dataframe.
2023-02-14 20:07:14,443:INFO:Setup _display_container:                     Description             Value
0                    Session id              4016
1                        Target      inadimplente
2                   Target type            Binary
3           Original data shape      (110000, 11)
4        Transformed data shape      (110000, 11)
5   Transformed train set shape       (77000, 11)
6    Transformed test set shape       (33000, 11)
7              Numeric features                10
8      Rows with missing values             19.8%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              3884
2023-02-14 20:07:14,565:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 20:07:14,568:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 20:07:14,664:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 20:07:14,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 20:07:14,668:INFO:setup() successfully completed in 1.91s...............
2023-02-14 20:07:37,472:INFO:Initializing compare_models()
2023-02-14 20:07:37,472:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-14 20:07:37,472:INFO:Checking exceptions
2023-02-14 20:07:37,501:INFO:Preparing display monitor
2023-02-14 20:07:37,540:INFO:Initializing Logistic Regression
2023-02-14 20:07:37,540:INFO:Total runtime is 0.0 minutes
2023-02-14 20:07:37,544:INFO:SubProcess create_model() called ==================================
2023-02-14 20:07:37,546:INFO:Initializing create_model()
2023-02-14 20:07:37,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:07:37,546:INFO:Checking exceptions
2023-02-14 20:07:37,546:INFO:Importing libraries
2023-02-14 20:07:37,546:INFO:Copying training dataset
2023-02-14 20:07:37,598:INFO:Defining folds
2023-02-14 20:07:37,599:INFO:Declaring metric variables
2023-02-14 20:07:37,605:INFO:Importing untrained model
2023-02-14 20:07:37,613:INFO:Logistic Regression Imported successfully
2023-02-14 20:07:37,623:INFO:Starting cross validation
2023-02-14 20:07:37,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:07:52,242:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-02-14 20:07:57,172:INFO:Calculating mean and std
2023-02-14 20:07:57,173:INFO:Creating metrics dataframe
2023-02-14 20:07:57,178:INFO:Uploading results into container
2023-02-14 20:07:57,178:INFO:Uploading model into container now
2023-02-14 20:07:57,180:INFO:_master_model_container: 1
2023-02-14 20:07:57,181:INFO:_display_container: 2
2023-02-14 20:07:57,181:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4016, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-14 20:07:57,181:INFO:create_model() successfully completed......................................
2023-02-14 20:07:57,265:INFO:SubProcess create_model() end ==================================
2023-02-14 20:07:57,265:INFO:Creating metrics dataframe
2023-02-14 20:07:57,281:INFO:Initializing K Neighbors Classifier
2023-02-14 20:07:57,281:INFO:Total runtime is 0.3290165185928345 minutes
2023-02-14 20:07:57,286:INFO:SubProcess create_model() called ==================================
2023-02-14 20:07:57,287:INFO:Initializing create_model()
2023-02-14 20:07:57,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:07:57,287:INFO:Checking exceptions
2023-02-14 20:07:57,287:INFO:Importing libraries
2023-02-14 20:07:57,287:INFO:Copying training dataset
2023-02-14 20:07:57,325:INFO:Defining folds
2023-02-14 20:07:57,326:INFO:Declaring metric variables
2023-02-14 20:07:57,330:INFO:Importing untrained model
2023-02-14 20:07:57,335:INFO:K Neighbors Classifier Imported successfully
2023-02-14 20:07:57,344:INFO:Starting cross validation
2023-02-14 20:07:57,345:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:07:58,736:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 20:07:58,751:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 20:07:58,784:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 20:07:58,789:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 20:08:00,666:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 20:08:01,002:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 20:08:01,016:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 20:08:01,159:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 20:08:02,686:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 20:08:02,846:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 20:08:03,517:INFO:Calculating mean and std
2023-02-14 20:08:03,519:INFO:Creating metrics dataframe
2023-02-14 20:08:03,526:INFO:Uploading results into container
2023-02-14 20:08:03,527:INFO:Uploading model into container now
2023-02-14 20:08:03,527:INFO:_master_model_container: 2
2023-02-14 20:08:03,527:INFO:_display_container: 2
2023-02-14 20:08:03,528:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-14 20:08:03,528:INFO:create_model() successfully completed......................................
2023-02-14 20:08:03,611:INFO:SubProcess create_model() end ==================================
2023-02-14 20:08:03,611:INFO:Creating metrics dataframe
2023-02-14 20:08:03,620:INFO:Initializing Naive Bayes
2023-02-14 20:08:03,621:INFO:Total runtime is 0.4346866965293884 minutes
2023-02-14 20:08:03,626:INFO:SubProcess create_model() called ==================================
2023-02-14 20:08:03,627:INFO:Initializing create_model()
2023-02-14 20:08:03,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:08:03,627:INFO:Checking exceptions
2023-02-14 20:08:03,627:INFO:Importing libraries
2023-02-14 20:08:03,628:INFO:Copying training dataset
2023-02-14 20:08:03,664:INFO:Defining folds
2023-02-14 20:08:03,664:INFO:Declaring metric variables
2023-02-14 20:08:03,669:INFO:Importing untrained model
2023-02-14 20:08:03,676:INFO:Naive Bayes Imported successfully
2023-02-14 20:08:03,684:INFO:Starting cross validation
2023-02-14 20:08:03,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:08:04,448:INFO:Calculating mean and std
2023-02-14 20:08:04,450:INFO:Creating metrics dataframe
2023-02-14 20:08:04,457:INFO:Uploading results into container
2023-02-14 20:08:04,458:INFO:Uploading model into container now
2023-02-14 20:08:04,458:INFO:_master_model_container: 3
2023-02-14 20:08:04,458:INFO:_display_container: 2
2023-02-14 20:08:04,459:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-14 20:08:04,459:INFO:create_model() successfully completed......................................
2023-02-14 20:08:04,542:INFO:SubProcess create_model() end ==================================
2023-02-14 20:08:04,542:INFO:Creating metrics dataframe
2023-02-14 20:08:04,552:INFO:Initializing Decision Tree Classifier
2023-02-14 20:08:04,552:INFO:Total runtime is 0.4501960873603821 minutes
2023-02-14 20:08:04,558:INFO:SubProcess create_model() called ==================================
2023-02-14 20:08:04,559:INFO:Initializing create_model()
2023-02-14 20:08:04,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:08:04,559:INFO:Checking exceptions
2023-02-14 20:08:04,560:INFO:Importing libraries
2023-02-14 20:08:04,560:INFO:Copying training dataset
2023-02-14 20:08:04,594:INFO:Defining folds
2023-02-14 20:08:04,594:INFO:Declaring metric variables
2023-02-14 20:08:04,598:INFO:Importing untrained model
2023-02-14 20:08:04,604:INFO:Decision Tree Classifier Imported successfully
2023-02-14 20:08:04,615:INFO:Starting cross validation
2023-02-14 20:08:04,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:08:07,166:INFO:Calculating mean and std
2023-02-14 20:08:07,168:INFO:Creating metrics dataframe
2023-02-14 20:08:07,175:INFO:Uploading results into container
2023-02-14 20:08:07,176:INFO:Uploading model into container now
2023-02-14 20:08:07,176:INFO:_master_model_container: 4
2023-02-14 20:08:07,176:INFO:_display_container: 2
2023-02-14 20:08:07,177:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4016, splitter='best')
2023-02-14 20:08:07,177:INFO:create_model() successfully completed......................................
2023-02-14 20:08:07,263:INFO:SubProcess create_model() end ==================================
2023-02-14 20:08:07,264:INFO:Creating metrics dataframe
2023-02-14 20:08:07,276:INFO:Initializing SVM - Linear Kernel
2023-02-14 20:08:07,276:INFO:Total runtime is 0.4956052780151367 minutes
2023-02-14 20:08:07,281:INFO:SubProcess create_model() called ==================================
2023-02-14 20:08:07,282:INFO:Initializing create_model()
2023-02-14 20:08:07,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:08:07,282:INFO:Checking exceptions
2023-02-14 20:08:07,282:INFO:Importing libraries
2023-02-14 20:08:07,282:INFO:Copying training dataset
2023-02-14 20:08:07,317:INFO:Defining folds
2023-02-14 20:08:07,317:INFO:Declaring metric variables
2023-02-14 20:08:07,323:INFO:Importing untrained model
2023-02-14 20:08:07,328:INFO:SVM - Linear Kernel Imported successfully
2023-02-14 20:08:07,339:INFO:Starting cross validation
2023-02-14 20:08:07,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:08:09,680:INFO:Calculating mean and std
2023-02-14 20:08:09,681:INFO:Creating metrics dataframe
2023-02-14 20:08:09,685:INFO:Uploading results into container
2023-02-14 20:08:09,686:INFO:Uploading model into container now
2023-02-14 20:08:09,687:INFO:_master_model_container: 5
2023-02-14 20:08:09,689:INFO:_display_container: 2
2023-02-14 20:08:09,690:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4016, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-14 20:08:09,690:INFO:create_model() successfully completed......................................
2023-02-14 20:08:09,772:INFO:SubProcess create_model() end ==================================
2023-02-14 20:08:09,772:INFO:Creating metrics dataframe
2023-02-14 20:08:09,784:INFO:Initializing Ridge Classifier
2023-02-14 20:08:09,784:INFO:Total runtime is 0.5373933553695679 minutes
2023-02-14 20:08:09,789:INFO:SubProcess create_model() called ==================================
2023-02-14 20:08:09,789:INFO:Initializing create_model()
2023-02-14 20:08:09,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:08:09,790:INFO:Checking exceptions
2023-02-14 20:08:09,790:INFO:Importing libraries
2023-02-14 20:08:09,790:INFO:Copying training dataset
2023-02-14 20:08:09,826:INFO:Defining folds
2023-02-14 20:08:09,826:INFO:Declaring metric variables
2023-02-14 20:08:09,830:INFO:Importing untrained model
2023-02-14 20:08:09,835:INFO:Ridge Classifier Imported successfully
2023-02-14 20:08:09,845:INFO:Starting cross validation
2023-02-14 20:08:09,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:08:10,071:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.16763e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 20:08:10,072:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.18156e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 20:08:10,072:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.17604e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 20:08:10,202:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=4.30351e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 20:08:10,208:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.22774e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 20:08:10,225:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.17141e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 20:08:10,232:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.16868e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 20:08:10,316:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.21777e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 20:08:10,324:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.17831e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 20:08:10,464:INFO:Calculating mean and std
2023-02-14 20:08:10,466:INFO:Creating metrics dataframe
2023-02-14 20:08:10,470:INFO:Uploading results into container
2023-02-14 20:08:10,473:INFO:Uploading model into container now
2023-02-14 20:08:10,474:INFO:_master_model_container: 6
2023-02-14 20:08:10,474:INFO:_display_container: 2
2023-02-14 20:08:10,474:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=4016, solver='auto', tol=0.001)
2023-02-14 20:08:10,474:INFO:create_model() successfully completed......................................
2023-02-14 20:08:10,557:INFO:SubProcess create_model() end ==================================
2023-02-14 20:08:10,557:INFO:Creating metrics dataframe
2023-02-14 20:08:10,567:INFO:Initializing Random Forest Classifier
2023-02-14 20:08:10,567:INFO:Total runtime is 0.5504484216372172 minutes
2023-02-14 20:08:10,573:INFO:SubProcess create_model() called ==================================
2023-02-14 20:08:10,574:INFO:Initializing create_model()
2023-02-14 20:08:10,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:08:10,574:INFO:Checking exceptions
2023-02-14 20:08:10,574:INFO:Importing libraries
2023-02-14 20:08:10,574:INFO:Copying training dataset
2023-02-14 20:08:10,609:INFO:Defining folds
2023-02-14 20:08:10,610:INFO:Declaring metric variables
2023-02-14 20:08:10,615:INFO:Importing untrained model
2023-02-14 20:08:10,619:INFO:Random Forest Classifier Imported successfully
2023-02-14 20:08:10,630:INFO:Starting cross validation
2023-02-14 20:08:10,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:08:50,316:INFO:Calculating mean and std
2023-02-14 20:08:50,318:INFO:Creating metrics dataframe
2023-02-14 20:08:50,324:INFO:Uploading results into container
2023-02-14 20:08:50,326:INFO:Uploading model into container now
2023-02-14 20:08:50,326:INFO:_master_model_container: 7
2023-02-14 20:08:50,327:INFO:_display_container: 2
2023-02-14 20:08:50,328:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4016, verbose=0, warm_start=False)
2023-02-14 20:08:50,328:INFO:create_model() successfully completed......................................
2023-02-14 20:08:50,413:INFO:SubProcess create_model() end ==================================
2023-02-14 20:08:50,413:INFO:Creating metrics dataframe
2023-02-14 20:08:50,425:INFO:Initializing Quadratic Discriminant Analysis
2023-02-14 20:08:50,425:INFO:Total runtime is 1.2147571603457132 minutes
2023-02-14 20:08:50,430:INFO:SubProcess create_model() called ==================================
2023-02-14 20:08:50,431:INFO:Initializing create_model()
2023-02-14 20:08:50,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:08:50,431:INFO:Checking exceptions
2023-02-14 20:08:50,431:INFO:Importing libraries
2023-02-14 20:08:50,431:INFO:Copying training dataset
2023-02-14 20:08:50,467:INFO:Defining folds
2023-02-14 20:08:50,467:INFO:Declaring metric variables
2023-02-14 20:08:50,472:INFO:Importing untrained model
2023-02-14 20:08:50,478:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-14 20:08:50,487:INFO:Starting cross validation
2023-02-14 20:08:50,490:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:08:53,186:INFO:Calculating mean and std
2023-02-14 20:08:53,190:INFO:Creating metrics dataframe
2023-02-14 20:08:53,195:INFO:Uploading results into container
2023-02-14 20:08:53,196:INFO:Uploading model into container now
2023-02-14 20:08:53,196:INFO:_master_model_container: 8
2023-02-14 20:08:53,196:INFO:_display_container: 2
2023-02-14 20:08:53,197:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-14 20:08:53,197:INFO:create_model() successfully completed......................................
2023-02-14 20:08:53,306:INFO:SubProcess create_model() end ==================================
2023-02-14 20:08:53,307:INFO:Creating metrics dataframe
2023-02-14 20:08:53,317:INFO:Initializing Ada Boost Classifier
2023-02-14 20:08:53,318:INFO:Total runtime is 1.2629740436871846 minutes
2023-02-14 20:08:53,324:INFO:SubProcess create_model() called ==================================
2023-02-14 20:08:53,324:INFO:Initializing create_model()
2023-02-14 20:08:53,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:08:53,324:INFO:Checking exceptions
2023-02-14 20:08:53,324:INFO:Importing libraries
2023-02-14 20:08:53,325:INFO:Copying training dataset
2023-02-14 20:08:53,360:INFO:Defining folds
2023-02-14 20:08:53,361:INFO:Declaring metric variables
2023-02-14 20:08:53,365:INFO:Importing untrained model
2023-02-14 20:08:53,369:INFO:Ada Boost Classifier Imported successfully
2023-02-14 20:08:53,379:INFO:Starting cross validation
2023-02-14 20:08:53,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:09:06,239:INFO:Calculating mean and std
2023-02-14 20:09:06,240:INFO:Creating metrics dataframe
2023-02-14 20:09:06,246:INFO:Uploading results into container
2023-02-14 20:09:06,247:INFO:Uploading model into container now
2023-02-14 20:09:06,248:INFO:_master_model_container: 9
2023-02-14 20:09:06,248:INFO:_display_container: 2
2023-02-14 20:09:06,248:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4016)
2023-02-14 20:09:06,248:INFO:create_model() successfully completed......................................
2023-02-14 20:09:06,335:INFO:SubProcess create_model() end ==================================
2023-02-14 20:09:06,335:INFO:Creating metrics dataframe
2023-02-14 20:09:06,351:INFO:Initializing Gradient Boosting Classifier
2023-02-14 20:09:06,351:INFO:Total runtime is 1.480189534028371 minutes
2023-02-14 20:09:06,358:INFO:SubProcess create_model() called ==================================
2023-02-14 20:09:06,359:INFO:Initializing create_model()
2023-02-14 20:09:06,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:09:06,359:INFO:Checking exceptions
2023-02-14 20:09:06,359:INFO:Importing libraries
2023-02-14 20:09:06,359:INFO:Copying training dataset
2023-02-14 20:09:06,398:INFO:Defining folds
2023-02-14 20:09:06,399:INFO:Declaring metric variables
2023-02-14 20:09:06,403:INFO:Importing untrained model
2023-02-14 20:09:06,411:INFO:Gradient Boosting Classifier Imported successfully
2023-02-14 20:09:06,418:INFO:Starting cross validation
2023-02-14 20:09:06,419:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:10:14,580:INFO:Calculating mean and std
2023-02-14 20:10:14,584:INFO:Creating metrics dataframe
2023-02-14 20:10:14,592:INFO:Uploading results into container
2023-02-14 20:10:14,593:INFO:Uploading model into container now
2023-02-14 20:10:14,594:INFO:_master_model_container: 10
2023-02-14 20:10:14,594:INFO:_display_container: 2
2023-02-14 20:10:14,594:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-14 20:10:14,598:INFO:create_model() successfully completed......................................
2023-02-14 20:10:14,841:INFO:SubProcess create_model() end ==================================
2023-02-14 20:10:14,841:INFO:Creating metrics dataframe
2023-02-14 20:10:14,866:INFO:Initializing Linear Discriminant Analysis
2023-02-14 20:10:14,866:INFO:Total runtime is 2.6220922986666357 minutes
2023-02-14 20:10:14,871:INFO:SubProcess create_model() called ==================================
2023-02-14 20:10:14,872:INFO:Initializing create_model()
2023-02-14 20:10:14,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:10:14,872:INFO:Checking exceptions
2023-02-14 20:10:14,872:INFO:Importing libraries
2023-02-14 20:10:14,872:INFO:Copying training dataset
2023-02-14 20:10:14,943:INFO:Defining folds
2023-02-14 20:10:14,945:INFO:Declaring metric variables
2023-02-14 20:10:14,949:INFO:Importing untrained model
2023-02-14 20:10:15,016:INFO:Linear Discriminant Analysis Imported successfully
2023-02-14 20:10:15,026:INFO:Starting cross validation
2023-02-14 20:10:15,027:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:10:17,212:INFO:Calculating mean and std
2023-02-14 20:10:17,215:INFO:Creating metrics dataframe
2023-02-14 20:10:17,221:INFO:Uploading results into container
2023-02-14 20:10:17,222:INFO:Uploading model into container now
2023-02-14 20:10:17,222:INFO:_master_model_container: 11
2023-02-14 20:10:17,222:INFO:_display_container: 2
2023-02-14 20:10:17,223:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-14 20:10:17,223:INFO:create_model() successfully completed......................................
2023-02-14 20:10:17,390:INFO:SubProcess create_model() end ==================================
2023-02-14 20:10:17,390:INFO:Creating metrics dataframe
2023-02-14 20:10:17,424:INFO:Initializing Extra Trees Classifier
2023-02-14 20:10:17,424:INFO:Total runtime is 2.664727135499318 minutes
2023-02-14 20:10:17,429:INFO:SubProcess create_model() called ==================================
2023-02-14 20:10:17,429:INFO:Initializing create_model()
2023-02-14 20:10:17,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:10:17,429:INFO:Checking exceptions
2023-02-14 20:10:17,430:INFO:Importing libraries
2023-02-14 20:10:17,430:INFO:Copying training dataset
2023-02-14 20:10:17,548:INFO:Defining folds
2023-02-14 20:10:17,549:INFO:Declaring metric variables
2023-02-14 20:10:17,558:INFO:Importing untrained model
2023-02-14 20:10:17,564:INFO:Extra Trees Classifier Imported successfully
2023-02-14 20:10:17,577:INFO:Starting cross validation
2023-02-14 20:10:17,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:11:06,096:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:11:21,883:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 3.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:11:23,290:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 3.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:11:25,523:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:11:27,029:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:11:30,620:INFO:Calculating mean and std
2023-02-14 20:11:30,622:INFO:Creating metrics dataframe
2023-02-14 20:11:30,626:INFO:Uploading results into container
2023-02-14 20:11:30,627:INFO:Uploading model into container now
2023-02-14 20:11:30,627:INFO:_master_model_container: 12
2023-02-14 20:11:30,628:INFO:_display_container: 2
2023-02-14 20:11:30,628:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4016, verbose=0, warm_start=False)
2023-02-14 20:11:30,629:INFO:create_model() successfully completed......................................
2023-02-14 20:11:30,730:INFO:SubProcess create_model() end ==================================
2023-02-14 20:11:30,730:INFO:Creating metrics dataframe
2023-02-14 20:11:30,754:INFO:Initializing Extreme Gradient Boosting
2023-02-14 20:11:30,754:INFO:Total runtime is 3.886896129449208 minutes
2023-02-14 20:11:30,759:INFO:SubProcess create_model() called ==================================
2023-02-14 20:11:30,759:INFO:Initializing create_model()
2023-02-14 20:11:30,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:11:30,759:INFO:Checking exceptions
2023-02-14 20:11:30,759:INFO:Importing libraries
2023-02-14 20:11:30,760:INFO:Copying training dataset
2023-02-14 20:11:30,791:INFO:Defining folds
2023-02-14 20:11:30,791:INFO:Declaring metric variables
2023-02-14 20:11:30,795:INFO:Importing untrained model
2023-02-14 20:11:30,799:INFO:Extreme Gradient Boosting Imported successfully
2023-02-14 20:11:30,809:INFO:Starting cross validation
2023-02-14 20:11:30,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:12:08,727:INFO:Calculating mean and std
2023-02-14 20:12:08,740:INFO:Creating metrics dataframe
2023-02-14 20:12:08,745:INFO:Uploading results into container
2023-02-14 20:12:08,746:INFO:Uploading model into container now
2023-02-14 20:12:08,747:INFO:_master_model_container: 13
2023-02-14 20:12:08,747:INFO:_display_container: 2
2023-02-14 20:12:08,774:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-14 20:12:08,775:INFO:create_model() successfully completed......................................
2023-02-14 20:12:08,909:INFO:SubProcess create_model() end ==================================
2023-02-14 20:12:08,910:INFO:Creating metrics dataframe
2023-02-14 20:12:09,600:INFO:Initializing Light Gradient Boosting Machine
2023-02-14 20:12:09,600:INFO:Total runtime is 4.534339483578999 minutes
2023-02-14 20:12:09,606:INFO:SubProcess create_model() called ==================================
2023-02-14 20:12:09,606:INFO:Initializing create_model()
2023-02-14 20:12:09,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:12:09,606:INFO:Checking exceptions
2023-02-14 20:12:09,606:INFO:Importing libraries
2023-02-14 20:12:09,606:INFO:Copying training dataset
2023-02-14 20:12:09,638:INFO:Defining folds
2023-02-14 20:12:09,638:INFO:Declaring metric variables
2023-02-14 20:12:09,642:INFO:Importing untrained model
2023-02-14 20:12:09,646:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-14 20:12:09,654:INFO:Starting cross validation
2023-02-14 20:12:09,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:12:37,399:INFO:Calculating mean and std
2023-02-14 20:12:37,400:INFO:Creating metrics dataframe
2023-02-14 20:12:37,407:INFO:Uploading results into container
2023-02-14 20:12:37,408:INFO:Uploading model into container now
2023-02-14 20:12:37,408:INFO:_master_model_container: 14
2023-02-14 20:12:37,408:INFO:_display_container: 2
2023-02-14 20:12:37,462:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-14 20:12:37,462:INFO:create_model() successfully completed......................................
2023-02-14 20:12:37,545:INFO:SubProcess create_model() end ==================================
2023-02-14 20:12:37,545:INFO:Creating metrics dataframe
2023-02-14 20:12:37,724:INFO:Initializing Dummy Classifier
2023-02-14 20:12:37,724:INFO:Total runtime is 5.003073147932688 minutes
2023-02-14 20:12:37,728:INFO:SubProcess create_model() called ==================================
2023-02-14 20:12:37,729:INFO:Initializing create_model()
2023-02-14 20:12:37,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1155A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:12:37,729:INFO:Checking exceptions
2023-02-14 20:12:37,729:INFO:Importing libraries
2023-02-14 20:12:37,729:INFO:Copying training dataset
2023-02-14 20:12:37,761:INFO:Defining folds
2023-02-14 20:12:37,761:INFO:Declaring metric variables
2023-02-14 20:12:37,766:INFO:Importing untrained model
2023-02-14 20:12:37,772:INFO:Dummy Classifier Imported successfully
2023-02-14 20:12:37,782:INFO:Starting cross validation
2023-02-14 20:12:37,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:12:38,016:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 20:12:38,022:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 20:12:38,031:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 20:12:38,072:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 20:12:38,146:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 20:12:38,180:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 20:12:38,187:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 20:12:38,208:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 20:12:38,252:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 20:12:38,278:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 20:12:38,399:INFO:Calculating mean and std
2023-02-14 20:12:38,402:INFO:Creating metrics dataframe
2023-02-14 20:12:38,427:INFO:Uploading results into container
2023-02-14 20:12:38,428:INFO:Uploading model into container now
2023-02-14 20:12:38,428:INFO:_master_model_container: 15
2023-02-14 20:12:38,428:INFO:_display_container: 2
2023-02-14 20:12:38,428:INFO:DummyClassifier(constant=None, random_state=4016, strategy='prior')
2023-02-14 20:12:38,428:INFO:create_model() successfully completed......................................
2023-02-14 20:12:38,513:INFO:SubProcess create_model() end ==================================
2023-02-14 20:12:38,513:INFO:Creating metrics dataframe
2023-02-14 20:12:38,733:INFO:Initializing create_model()
2023-02-14 20:12:38,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:12:38,734:INFO:Checking exceptions
2023-02-14 20:12:39,021:INFO:Importing libraries
2023-02-14 20:12:39,021:INFO:Copying training dataset
2023-02-14 20:12:39,050:INFO:Defining folds
2023-02-14 20:12:39,050:INFO:Declaring metric variables
2023-02-14 20:12:39,050:INFO:Importing untrained model
2023-02-14 20:12:39,050:INFO:Declaring custom model
2023-02-14 20:12:39,053:INFO:Gradient Boosting Classifier Imported successfully
2023-02-14 20:12:39,054:INFO:Cross validation set to False
2023-02-14 20:12:39,054:INFO:Fitting Model
2023-02-14 20:12:54,845:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-14 20:12:54,845:INFO:create_model() successfully completed......................................
2023-02-14 20:12:54,993:INFO:Initializing create_model()
2023-02-14 20:12:54,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4016), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:12:54,993:INFO:Checking exceptions
2023-02-14 20:12:54,996:INFO:Importing libraries
2023-02-14 20:12:54,996:INFO:Copying training dataset
2023-02-14 20:12:55,038:INFO:Defining folds
2023-02-14 20:12:55,038:INFO:Declaring metric variables
2023-02-14 20:12:55,038:INFO:Importing untrained model
2023-02-14 20:12:55,038:INFO:Declaring custom model
2023-02-14 20:12:55,039:INFO:Ada Boost Classifier Imported successfully
2023-02-14 20:12:55,040:INFO:Cross validation set to False
2023-02-14 20:12:55,040:INFO:Fitting Model
2023-02-14 20:12:59,945:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4016)
2023-02-14 20:12:59,945:INFO:create_model() successfully completed......................................
2023-02-14 20:13:00,071:INFO:Initializing create_model()
2023-02-14 20:13:00,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:13:00,072:INFO:Checking exceptions
2023-02-14 20:13:00,075:INFO:Importing libraries
2023-02-14 20:13:00,075:INFO:Copying training dataset
2023-02-14 20:13:00,110:INFO:Defining folds
2023-02-14 20:13:00,110:INFO:Declaring metric variables
2023-02-14 20:13:00,111:INFO:Importing untrained model
2023-02-14 20:13:00,111:INFO:Declaring custom model
2023-02-14 20:13:00,111:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-14 20:13:00,112:INFO:Cross validation set to False
2023-02-14 20:13:00,112:INFO:Fitting Model
2023-02-14 20:13:01,969:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-14 20:13:01,969:INFO:create_model() successfully completed......................................
2023-02-14 20:13:02,178:INFO:_master_model_container: 15
2023-02-14 20:13:02,178:INFO:_display_container: 2
2023-02-14 20:13:02,183:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4016), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)]
2023-02-14 20:13:02,183:INFO:compare_models() successfully completed......................................
2023-02-14 20:13:02,294:INFO:Initializing save_model()
2023-02-14 20:13:02,294:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=saved_model_0, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                             'numero_de_dependentes'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-14 20:13:02,295:INFO:Adding model into prep_pipe
2023-02-14 20:13:02,423:INFO:saved_model_0.pkl saved in current working directory
2023-02-14 20:13:02,429:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=4016, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-02-14 20:13:02,429:INFO:save_model() successfully completed......................................
2023-02-14 20:13:02,514:INFO:Initializing save_model()
2023-02-14 20:13:02,515:INFO:save_model(model=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4016), model_name=saved_model_1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                             'numero_de_dependentes'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-14 20:13:02,515:INFO:Adding model into prep_pipe
2023-02-14 20:13:02,661:INFO:saved_model_1.pkl saved in current working directory
2023-02-14 20:13:02,667:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('trained_model',
                 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=4016))],
         verbose=False)
2023-02-14 20:13:02,667:INFO:save_model() successfully completed......................................
2023-02-14 20:13:02,758:INFO:Initializing save_model()
2023-02-14 20:13:02,758:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=saved_model_2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                             'numero_de_dependentes'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-14 20:13:02,758:INFO:Adding model into prep_pipe
2023-02-14 20:13:02,769:INFO:saved_model_2.pkl saved in current working directory
2023-02-14 20:13:02,775:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=4016, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-02-14 20:13:02,775:INFO:save_model() successfully completed......................................
2023-02-14 20:13:02,878:INFO:Initializing tune_model()
2023-02-14 20:13:02,878:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>)
2023-02-14 20:13:02,879:INFO:Checking exceptions
2023-02-14 20:13:03,123:INFO:Copying training dataset
2023-02-14 20:13:03,143:INFO:Checking base model
2023-02-14 20:13:03,143:INFO:Base model : Gradient Boosting Classifier
2023-02-14 20:13:03,147:INFO:Declaring metric variables
2023-02-14 20:13:03,150:INFO:Defining Hyperparameters
2023-02-14 20:13:03,262:INFO:Tuning with n_jobs=-1
2023-02-14 20:13:03,262:INFO:Initializing RandomizedSearchCV
2023-02-14 20:13:25,771:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 12.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:19:31,381:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.005}
2023-02-14 20:19:31,382:INFO:Hyperparameter search completed
2023-02-14 20:19:31,383:INFO:SubProcess create_model() called ==================================
2023-02-14 20:19:31,383:INFO:Initializing create_model()
2023-02-14 20:19:31,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBCB7C130>, model_only=True, return_train_score=False, kwargs={'subsample': 0.85, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.02, 'max_features': 'sqrt', 'max_depth': 8, 'learning_rate': 0.005})
2023-02-14 20:19:31,384:INFO:Checking exceptions
2023-02-14 20:19:31,384:INFO:Importing libraries
2023-02-14 20:19:31,384:INFO:Copying training dataset
2023-02-14 20:19:31,419:INFO:Defining folds
2023-02-14 20:19:31,419:INFO:Declaring metric variables
2023-02-14 20:19:31,426:INFO:Importing untrained model
2023-02-14 20:19:31,426:INFO:Declaring custom model
2023-02-14 20:19:31,484:INFO:Gradient Boosting Classifier Imported successfully
2023-02-14 20:19:31,494:INFO:Starting cross validation
2023-02-14 20:19:31,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:19:33,617:INFO:Calculating mean and std
2023-02-14 20:19:33,618:INFO:Creating metrics dataframe
2023-02-14 20:19:33,638:INFO:Finalizing model
2023-02-14 20:20:00,459:INFO:Uploading results into container
2023-02-14 20:20:00,460:INFO:Uploading model into container now
2023-02-14 20:20:00,461:INFO:_master_model_container: 16
2023-02-14 20:20:00,461:INFO:_display_container: 3
2023-02-14 20:20:00,461:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='deviance', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.02, min_samples_leaf=1,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=230, n_iter_no_change=None,
                           random_state=4016, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-14 20:20:00,461:INFO:create_model() successfully completed......................................
2023-02-14 20:20:00,554:INFO:SubProcess create_model() end ==================================
2023-02-14 20:20:00,554:INFO:choose_better activated
2023-02-14 20:20:00,557:INFO:SubProcess create_model() called ==================================
2023-02-14 20:20:00,557:INFO:Initializing create_model()
2023-02-14 20:20:00,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:20:00,558:INFO:Checking exceptions
2023-02-14 20:20:00,559:INFO:Importing libraries
2023-02-14 20:20:00,560:INFO:Copying training dataset
2023-02-14 20:20:00,593:INFO:Defining folds
2023-02-14 20:20:00,593:INFO:Declaring metric variables
2023-02-14 20:20:00,594:INFO:Importing untrained model
2023-02-14 20:20:00,594:INFO:Declaring custom model
2023-02-14 20:20:00,594:INFO:Gradient Boosting Classifier Imported successfully
2023-02-14 20:20:00,595:INFO:Starting cross validation
2023-02-14 20:20:00,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:20:01,543:INFO:Calculating mean and std
2023-02-14 20:20:01,544:INFO:Creating metrics dataframe
2023-02-14 20:20:01,546:INFO:Finalizing model
2023-02-14 20:20:01,592:INFO:Uploading results into container
2023-02-14 20:20:01,593:INFO:Uploading model into container now
2023-02-14 20:20:01,593:INFO:_master_model_container: 17
2023-02-14 20:20:01,594:INFO:_display_container: 4
2023-02-14 20:20:01,594:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-14 20:20:01,594:INFO:create_model() successfully completed......................................
2023-02-14 20:20:01,681:INFO:SubProcess create_model() end ==================================
2023-02-14 20:20:01,682:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.937
2023-02-14 20:20:01,684:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='deviance', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.02, min_samples_leaf=1,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=230, n_iter_no_change=None,
                           random_state=4016, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9348
2023-02-14 20:20:01,685:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-02-14 20:20:01,685:INFO:choose_better completed
2023-02-14 20:20:01,685:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-14 20:20:01,705:INFO:_master_model_container: 17
2023-02-14 20:20:01,706:INFO:_display_container: 3
2023-02-14 20:20:01,706:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-14 20:20:01,707:INFO:tune_model() successfully completed......................................
2023-02-14 20:20:01,806:INFO:Initializing tune_model()
2023-02-14 20:20:01,806:INFO:tune_model(estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4016), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>)
2023-02-14 20:20:01,806:INFO:Checking exceptions
2023-02-14 20:20:01,840:INFO:Copying training dataset
2023-02-14 20:20:01,870:INFO:Checking base model
2023-02-14 20:20:01,870:INFO:Base model : Ada Boost Classifier
2023-02-14 20:20:01,876:INFO:Declaring metric variables
2023-02-14 20:20:01,881:INFO:Defining Hyperparameters
2023-02-14 20:20:01,986:INFO:Tuning with n_jobs=-1
2023-02-14 20:20:01,986:INFO:Initializing RandomizedSearchCV
2023-02-14 20:24:15,159:INFO:best_params: {'actual_estimator__n_estimators': 170, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__algorithm': 'SAMME.R'}
2023-02-14 20:24:15,162:INFO:Hyperparameter search completed
2023-02-14 20:24:15,163:INFO:SubProcess create_model() called ==================================
2023-02-14 20:24:15,164:INFO:Initializing create_model()
2023-02-14 20:24:15,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4016), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DB1081D00>, model_only=True, return_train_score=False, kwargs={'n_estimators': 170, 'learning_rate': 0.4, 'algorithm': 'SAMME.R'})
2023-02-14 20:24:15,164:INFO:Checking exceptions
2023-02-14 20:24:15,164:INFO:Importing libraries
2023-02-14 20:24:15,164:INFO:Copying training dataset
2023-02-14 20:24:15,197:INFO:Defining folds
2023-02-14 20:24:15,197:INFO:Declaring metric variables
2023-02-14 20:24:15,201:INFO:Importing untrained model
2023-02-14 20:24:15,201:INFO:Declaring custom model
2023-02-14 20:24:15,228:INFO:Ada Boost Classifier Imported successfully
2023-02-14 20:24:15,236:INFO:Starting cross validation
2023-02-14 20:24:15,237:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:24:17,913:INFO:Calculating mean and std
2023-02-14 20:24:17,914:INFO:Creating metrics dataframe
2023-02-14 20:24:17,922:INFO:Finalizing model
2023-02-14 20:24:27,838:INFO:Uploading results into container
2023-02-14 20:24:27,839:INFO:Uploading model into container now
2023-02-14 20:24:27,840:INFO:_master_model_container: 18
2023-02-14 20:24:27,840:INFO:_display_container: 4
2023-02-14 20:24:27,840:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016)
2023-02-14 20:24:27,840:INFO:create_model() successfully completed......................................
2023-02-14 20:24:27,940:INFO:SubProcess create_model() end ==================================
2023-02-14 20:24:27,940:INFO:choose_better activated
2023-02-14 20:24:27,945:INFO:SubProcess create_model() called ==================================
2023-02-14 20:24:27,946:INFO:Initializing create_model()
2023-02-14 20:24:27,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4016), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:24:27,946:INFO:Checking exceptions
2023-02-14 20:24:27,948:INFO:Importing libraries
2023-02-14 20:24:27,948:INFO:Copying training dataset
2023-02-14 20:24:27,985:INFO:Defining folds
2023-02-14 20:24:27,985:INFO:Declaring metric variables
2023-02-14 20:24:27,985:INFO:Importing untrained model
2023-02-14 20:24:27,985:INFO:Declaring custom model
2023-02-14 20:24:27,985:INFO:Ada Boost Classifier Imported successfully
2023-02-14 20:24:27,986:INFO:Starting cross validation
2023-02-14 20:24:27,986:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:24:29,165:INFO:Calculating mean and std
2023-02-14 20:24:29,166:INFO:Creating metrics dataframe
2023-02-14 20:24:29,168:INFO:Finalizing model
2023-02-14 20:24:29,234:INFO:Uploading results into container
2023-02-14 20:24:29,234:INFO:Uploading model into container now
2023-02-14 20:24:29,235:INFO:_master_model_container: 19
2023-02-14 20:24:29,235:INFO:_display_container: 5
2023-02-14 20:24:29,235:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4016)
2023-02-14 20:24:29,235:INFO:create_model() successfully completed......................................
2023-02-14 20:24:29,318:INFO:SubProcess create_model() end ==================================
2023-02-14 20:24:29,319:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4016) result for Accuracy is 0.9365
2023-02-14 20:24:29,319:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016) result for Accuracy is 0.9367
2023-02-14 20:24:29,320:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016) is best model
2023-02-14 20:24:29,320:INFO:choose_better completed
2023-02-14 20:24:29,332:INFO:_master_model_container: 19
2023-02-14 20:24:29,333:INFO:_display_container: 4
2023-02-14 20:24:29,333:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016)
2023-02-14 20:24:29,333:INFO:tune_model() successfully completed......................................
2023-02-14 20:24:29,435:INFO:Initializing tune_model()
2023-02-14 20:24:29,435:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>)
2023-02-14 20:24:29,436:INFO:Checking exceptions
2023-02-14 20:24:29,469:INFO:Copying training dataset
2023-02-14 20:24:29,492:INFO:Checking base model
2023-02-14 20:24:29,492:INFO:Base model : Light Gradient Boosting Machine
2023-02-14 20:24:29,498:INFO:Declaring metric variables
2023-02-14 20:24:29,503:INFO:Defining Hyperparameters
2023-02-14 20:24:29,636:INFO:Tuning with n_jobs=-1
2023-02-14 20:24:29,636:INFO:Initializing RandomizedSearchCV
2023-02-14 20:25:45,721:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 50, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.6}
2023-02-14 20:25:45,722:INFO:Hyperparameter search completed
2023-02-14 20:25:45,722:INFO:SubProcess create_model() called ==================================
2023-02-14 20:25:45,723:INFO:Initializing create_model()
2023-02-14 20:25:45,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBC8384F0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.5, 'num_leaves': 50, 'n_estimators': 130, 'min_split_gain': 0.7, 'min_child_samples': 91, 'learning_rate': 0.05, 'feature_fraction': 0.6, 'bagging_freq': 1, 'bagging_fraction': 0.6})
2023-02-14 20:25:45,723:INFO:Checking exceptions
2023-02-14 20:25:45,723:INFO:Importing libraries
2023-02-14 20:25:45,723:INFO:Copying training dataset
2023-02-14 20:25:45,756:INFO:Defining folds
2023-02-14 20:25:45,757:INFO:Declaring metric variables
2023-02-14 20:25:45,763:INFO:Importing untrained model
2023-02-14 20:25:45,763:INFO:Declaring custom model
2023-02-14 20:25:45,832:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-14 20:25:45,848:INFO:Starting cross validation
2023-02-14 20:25:45,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:25:47,401:INFO:Calculating mean and std
2023-02-14 20:25:47,402:INFO:Creating metrics dataframe
2023-02-14 20:25:47,407:INFO:Finalizing model
2023-02-14 20:25:48,166:INFO:Uploading results into container
2023-02-14 20:25:48,167:INFO:Uploading model into container now
2023-02-14 20:25:48,167:INFO:_master_model_container: 20
2023-02-14 20:25:48,168:INFO:_display_container: 5
2023-02-14 20:25:48,169:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-14 20:25:48,169:INFO:create_model() successfully completed......................................
2023-02-14 20:25:48,255:INFO:SubProcess create_model() end ==================================
2023-02-14 20:25:48,256:INFO:choose_better activated
2023-02-14 20:25:48,260:INFO:SubProcess create_model() called ==================================
2023-02-14 20:25:48,261:INFO:Initializing create_model()
2023-02-14 20:25:48,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:25:48,261:INFO:Checking exceptions
2023-02-14 20:25:48,263:INFO:Importing libraries
2023-02-14 20:25:48,263:INFO:Copying training dataset
2023-02-14 20:25:48,299:INFO:Defining folds
2023-02-14 20:25:48,299:INFO:Declaring metric variables
2023-02-14 20:25:48,299:INFO:Importing untrained model
2023-02-14 20:25:48,299:INFO:Declaring custom model
2023-02-14 20:25:48,300:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-14 20:25:48,300:INFO:Starting cross validation
2023-02-14 20:25:48,301:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:25:49,392:INFO:Calculating mean and std
2023-02-14 20:25:49,394:INFO:Creating metrics dataframe
2023-02-14 20:25:49,396:INFO:Finalizing model
2023-02-14 20:25:49,443:INFO:Uploading results into container
2023-02-14 20:25:49,444:INFO:Uploading model into container now
2023-02-14 20:25:49,445:INFO:_master_model_container: 21
2023-02-14 20:25:49,445:INFO:_display_container: 6
2023-02-14 20:25:49,445:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-14 20:25:49,445:INFO:create_model() successfully completed......................................
2023-02-14 20:25:49,528:INFO:SubProcess create_model() end ==================================
2023-02-14 20:25:49,529:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9365
2023-02-14 20:25:49,530:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9374
2023-02-14 20:25:49,530:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-02-14 20:25:49,530:INFO:choose_better completed
2023-02-14 20:25:49,540:INFO:_master_model_container: 21
2023-02-14 20:25:49,540:INFO:_display_container: 5
2023-02-14 20:25:49,541:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-14 20:25:49,541:INFO:tune_model() successfully completed......................................
2023-02-14 20:25:49,661:INFO:Initializing blend_models()
2023-02-14 20:25:49,661:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016), LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-02-14 20:25:49,661:INFO:Checking exceptions
2023-02-14 20:25:49,691:INFO:Importing libraries
2023-02-14 20:25:49,691:INFO:Copying training dataset
2023-02-14 20:25:49,699:INFO:Getting model names
2023-02-14 20:25:49,704:INFO:SubProcess create_model() called ==================================
2023-02-14 20:25:49,712:INFO:Initializing create_model()
2023-02-14 20:25:49,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBD228E20>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:25:49,712:INFO:Checking exceptions
2023-02-14 20:25:49,712:INFO:Importing libraries
2023-02-14 20:25:49,712:INFO:Copying training dataset
2023-02-14 20:25:49,755:INFO:Defining folds
2023-02-14 20:25:49,755:INFO:Declaring metric variables
2023-02-14 20:25:49,760:INFO:Importing untrained model
2023-02-14 20:25:49,760:INFO:Declaring custom model
2023-02-14 20:25:49,766:INFO:Voting Classifier Imported successfully
2023-02-14 20:25:49,773:INFO:Starting cross validation
2023-02-14 20:25:49,774:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:26:58,810:INFO:Calculating mean and std
2023-02-14 20:26:58,812:INFO:Creating metrics dataframe
2023-02-14 20:26:58,820:INFO:Finalizing model
2023-02-14 20:27:12,071:INFO:Uploading results into container
2023-02-14 20:27:12,073:INFO:Uploading model into container now
2023-02-14 20:27:12,073:INFO:_master_model_container: 22
2023-02-14 20:27:12,073:INFO:_display_container: 6
2023-02-14 20:27:12,080:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-02-14 20:27:12,080:INFO:create_model() successfully completed......................................
2023-02-14 20:27:12,168:INFO:SubProcess create_model() end ==================================
2023-02-14 20:27:12,180:INFO:_master_model_container: 22
2023-02-14 20:27:12,180:INFO:_display_container: 6
2023-02-14 20:27:12,185:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-02-14 20:27:12,185:INFO:blend_models() successfully completed......................................
2023-02-14 20:27:12,289:INFO:Initializing stack_models()
2023-02-14 20:27:12,289:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016), LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-02-14 20:27:12,289:INFO:Checking exceptions
2023-02-14 20:27:12,301:INFO:Defining meta model
2023-02-14 20:27:12,329:INFO:Getting model names
2023-02-14 20:27:12,330:INFO:[('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Ada Boost Classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016)), ('Light Gradient Boosting Machine', LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0))]
2023-02-14 20:27:12,336:INFO:SubProcess create_model() called ==================================
2023-02-14 20:27:12,342:INFO:Initializing create_model()
2023-02-14 20:27:12,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.1,
                                                           loss='deviance',
                                                           max_depth=3,
                                                           max_features=None,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.0,
                                                           min_samples_leaf=1,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=100,
                                                           n_iter_no_cha...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=4016,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBCB7C460>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:27:12,343:INFO:Checking exceptions
2023-02-14 20:27:12,343:INFO:Importing libraries
2023-02-14 20:27:12,343:INFO:Copying training dataset
2023-02-14 20:27:12,381:INFO:Defining folds
2023-02-14 20:27:12,381:INFO:Declaring metric variables
2023-02-14 20:27:12,385:INFO:Importing untrained model
2023-02-14 20:27:12,385:INFO:Declaring custom model
2023-02-14 20:27:12,392:INFO:Stacking Classifier Imported successfully
2023-02-14 20:27:12,400:INFO:Starting cross validation
2023-02-14 20:27:12,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 20:29:29,078:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-02-14 20:29:29,275:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-02-14 20:29:29,292:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-02-14 20:29:29,402:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-02-14 20:31:48,030:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-02-14 20:31:48,261:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-02-14 20:31:48,399:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-02-14 20:31:48,860:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-02-14 20:33:05,438:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-02-14 20:33:06,276:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-02-14 20:33:07,750:INFO:Calculating mean and std
2023-02-14 20:33:07,752:INFO:Creating metrics dataframe
2023-02-14 20:33:07,760:INFO:Finalizing model
2023-02-14 20:34:01,244:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-02-14 20:34:01,592:INFO:Uploading results into container
2023-02-14 20:34:01,592:INFO:Uploading model into container now
2023-02-14 20:34:01,593:INFO:_master_model_container: 23
2023-02-14 20:34:01,593:INFO:_display_container: 7
2023-02-14 20:34:01,598:INFO:StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.1,
                                                           loss='deviance',
                                                           max_depth=3,
                                                           max_features=None,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.0,
                                                           min_samples_leaf=1,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=100,
                                                           n_iter_no_cha...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=4016,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2023-02-14 20:34:01,598:INFO:create_model() successfully completed......................................
2023-02-14 20:34:01,692:INFO:SubProcess create_model() end ==================================
2023-02-14 20:34:01,705:INFO:_master_model_container: 23
2023-02-14 20:34:01,705:INFO:_display_container: 7
2023-02-14 20:34:01,710:INFO:StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.1,
                                                           loss='deviance',
                                                           max_depth=3,
                                                           max_features=None,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.0,
                                                           min_samples_leaf=1,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=100,
                                                           n_iter_no_cha...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=4016,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2023-02-14 20:34:01,710:INFO:stack_models() successfully completed......................................
2023-02-14 20:34:01,830:INFO:Initializing automl()
2023-02-14 20:34:01,830:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, optimize=AUC, use_holdout=False, turbo=True, return_train_score=False)
2023-02-14 20:34:01,830:INFO:Model Selection Basis : CV Results on Training set
2023-02-14 20:34:01,830:INFO:Checking model 0
2023-02-14 20:34:01,831:INFO:Checking model 1
2023-02-14 20:34:01,831:INFO:Checking model 2
2023-02-14 20:34:01,831:INFO:Checking model 3
2023-02-14 20:34:01,831:INFO:Checking model 4
2023-02-14 20:34:01,831:INFO:Checking model 5
2023-02-14 20:34:01,832:INFO:Checking model 6
2023-02-14 20:34:01,832:INFO:Checking model 7
2023-02-14 20:34:01,832:INFO:Checking model 8
2023-02-14 20:34:01,832:INFO:Checking model 9
2023-02-14 20:34:01,832:INFO:Checking model 10
2023-02-14 20:34:01,832:INFO:Checking model 11
2023-02-14 20:34:01,833:INFO:Checking model 12
2023-02-14 20:34:01,833:INFO:Checking model 13
2023-02-14 20:34:01,833:INFO:Checking model 14
2023-02-14 20:34:01,833:INFO:Checking model 15
2023-02-14 20:34:01,833:INFO:Checking model 16
2023-02-14 20:34:01,833:INFO:Checking model 17
2023-02-14 20:34:01,834:INFO:Checking model 18
2023-02-14 20:34:01,834:INFO:Checking model 19
2023-02-14 20:34:01,834:INFO:Checking model 20
2023-02-14 20:34:01,834:INFO:Checking model 21
2023-02-14 20:34:01,834:INFO:Checking model 22
2023-02-14 20:34:01,841:INFO:Initializing create_model()
2023-02-14 20:34:01,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-14 20:34:01,841:INFO:Checking exceptions
2023-02-14 20:34:01,843:INFO:Importing libraries
2023-02-14 20:34:01,843:INFO:Copying training dataset
2023-02-14 20:34:01,875:INFO:Defining folds
2023-02-14 20:34:01,876:INFO:Declaring metric variables
2023-02-14 20:34:01,876:INFO:Importing untrained model
2023-02-14 20:34:01,876:INFO:Declaring custom model
2023-02-14 20:34:01,878:INFO:Voting Classifier Imported successfully
2023-02-14 20:34:01,878:INFO:Cross validation set to False
2023-02-14 20:34:01,878:INFO:Fitting Model
2023-02-14 20:34:02,043:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-02-14 20:34:02,043:INFO:create_model() successfully completed......................................
2023-02-14 20:34:02,228:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-02-14 20:34:02,228:INFO:automl() successfully completed......................................
2023-02-14 20:34:02,232:INFO:Initializing finalize_model()
2023-02-14 20:34:02,233:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-02-14 20:34:02,240:INFO:Finalizing VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-02-14 20:34:02,260:INFO:Initializing create_model()
2023-02-14 20:34:02,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-02-14 20:34:02,260:INFO:Checking exceptions
2023-02-14 20:34:02,262:INFO:Importing libraries
2023-02-14 20:34:02,262:INFO:Copying training dataset
2023-02-14 20:34:02,263:INFO:Defining folds
2023-02-14 20:34:02,263:INFO:Declaring metric variables
2023-02-14 20:34:02,263:INFO:Importing untrained model
2023-02-14 20:34:02,263:INFO:Declaring custom model
2023-02-14 20:34:02,265:INFO:Voting Classifier Imported successfully
2023-02-14 20:34:02,265:INFO:Cross validation set to False
2023-02-14 20:34:02,265:INFO:Fitting Model
2023-02-14 20:34:21,500:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-02-14 20:34:21,501:INFO:create_model() successfully completed......................................
2023-02-14 20:34:21,584:INFO:_master_model_container: 23
2023-02-14 20:34:21,584:INFO:_display_container: 7
2023-02-14 20:34:21,600:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-02-14 20:34:21,600:INFO:finalize_model() successfully completed......................................
2023-02-14 20:44:01,723:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-14 20:45:59,850:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:46:08,583:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:46:26,929:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:46:49,903:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-14 20:48:18,331:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:48:46,404:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:49:42,956:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:54:13,135:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-14 20:55:23,669:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:55:57,519:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:56:17,139:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:56:33,019:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:58:17,599:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-14 20:58:44,398:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 20:58:56,410:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-14 20:59:24,643:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 21:01:26,636:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 21:02:41,480:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 21:05:23,983:INFO:Initializing plot_model()
2023-02-14 21:05:23,983:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:05:23,983:INFO:Checking exceptions
2023-02-14 21:05:23,999:INFO:Preloading libraries
2023-02-14 21:05:24,046:INFO:Copying training dataset
2023-02-14 21:05:24,047:INFO:Plot type: pipeline
2023-02-14 21:05:24,688:INFO:Visual Rendered Successfully
2023-02-14 21:05:24,806:INFO:plot_model() successfully completed......................................
2023-02-14 21:05:33,223:INFO:Initializing evaluate_model()
2023-02-14 21:05:33,224:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-14 21:05:33,276:INFO:Initializing plot_model()
2023-02-14 21:05:33,277:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:05:33,277:INFO:Checking exceptions
2023-02-14 21:05:33,301:INFO:Preloading libraries
2023-02-14 21:05:33,365:INFO:Copying training dataset
2023-02-14 21:05:33,365:INFO:Plot type: pipeline
2023-02-14 21:05:33,477:INFO:Visual Rendered Successfully
2023-02-14 21:05:33,568:INFO:plot_model() successfully completed......................................
2023-02-14 21:05:38,701:INFO:Initializing plot_model()
2023-02-14 21:05:38,702:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:05:38,702:INFO:Checking exceptions
2023-02-14 21:05:38,715:INFO:Preloading libraries
2023-02-14 21:05:38,750:INFO:Copying training dataset
2023-02-14 21:05:38,750:INFO:Plot type: auc
2023-02-14 21:05:38,865:INFO:Fitting Model
2023-02-14 21:05:38,865:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-02-14 21:05:38,865:INFO:Scoring test/hold-out set
2023-02-14 21:05:40,738:INFO:Visual Rendered Successfully
2023-02-14 21:05:40,824:INFO:plot_model() successfully completed......................................
2023-02-14 21:05:49,817:INFO:Initializing plot_model()
2023-02-14 21:05:49,817:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:05:49,817:INFO:Checking exceptions
2023-02-14 21:05:49,828:INFO:Preloading libraries
2023-02-14 21:05:49,861:INFO:Copying training dataset
2023-02-14 21:05:49,861:INFO:Plot type: parameter
2023-02-14 21:05:49,866:INFO:Visual Rendered Successfully
2023-02-14 21:05:49,945:INFO:plot_model() successfully completed......................................
2023-02-14 21:05:54,961:INFO:Initializing plot_model()
2023-02-14 21:05:54,961:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:05:54,961:INFO:Checking exceptions
2023-02-14 21:05:54,973:INFO:Preloading libraries
2023-02-14 21:05:55,012:INFO:Copying training dataset
2023-02-14 21:05:55,012:INFO:Plot type: pipeline
2023-02-14 21:05:55,099:INFO:Visual Rendered Successfully
2023-02-14 21:05:55,190:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:31,298:INFO:Initializing plot_model()
2023-02-14 21:06:31,299:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:31,299:INFO:Checking exceptions
2023-02-14 21:06:31,322:INFO:Preloading libraries
2023-02-14 21:06:31,332:INFO:Copying training dataset
2023-02-14 21:06:31,332:INFO:Plot type: pipeline
2023-02-14 21:06:31,441:INFO:Visual Rendered Successfully
2023-02-14 21:06:31,539:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:31,539:INFO:Initializing plot_model()
2023-02-14 21:06:31,539:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:31,539:INFO:Checking exceptions
2023-02-14 21:06:31,549:INFO:Preloading libraries
2023-02-14 21:06:31,576:INFO:Copying training dataset
2023-02-14 21:06:31,576:INFO:Plot type: pipeline
2023-02-14 21:06:31,680:INFO:Visual Rendered Successfully
2023-02-14 21:06:31,768:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:31,768:INFO:Initializing plot_model()
2023-02-14 21:06:31,769:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:31,769:INFO:Checking exceptions
2023-02-14 21:06:31,783:INFO:Preloading libraries
2023-02-14 21:06:31,800:INFO:Copying training dataset
2023-02-14 21:06:31,800:INFO:Plot type: pipeline
2023-02-14 21:06:31,912:INFO:Visual Rendered Successfully
2023-02-14 21:06:32,001:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:46,613:INFO:Initializing plot_model()
2023-02-14 21:06:46,613:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:46,613:INFO:Checking exceptions
2023-02-14 21:06:46,629:INFO:Preloading libraries
2023-02-14 21:06:46,642:INFO:Copying training dataset
2023-02-14 21:06:46,642:INFO:Plot type: pipeline
2023-02-14 21:06:46,753:INFO:Visual Rendered Successfully
2023-02-14 21:06:46,841:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:46,841:INFO:Initializing plot_model()
2023-02-14 21:06:46,842:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:46,842:INFO:Checking exceptions
2023-02-14 21:06:46,859:INFO:Preloading libraries
2023-02-14 21:06:46,902:INFO:Copying training dataset
2023-02-14 21:06:46,902:INFO:Plot type: pipeline
2023-02-14 21:06:47,016:INFO:Visual Rendered Successfully
2023-02-14 21:06:47,104:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:47,105:INFO:Initializing plot_model()
2023-02-14 21:06:47,105:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:47,105:INFO:Checking exceptions
2023-02-14 21:06:47,119:INFO:Preloading libraries
2023-02-14 21:06:47,138:INFO:Copying training dataset
2023-02-14 21:06:47,138:INFO:Plot type: pipeline
2023-02-14 21:06:47,242:INFO:Visual Rendered Successfully
2023-02-14 21:06:47,335:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:48,123:INFO:Initializing plot_model()
2023-02-14 21:06:48,123:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:48,123:INFO:Checking exceptions
2023-02-14 21:06:48,142:INFO:Preloading libraries
2023-02-14 21:06:48,154:INFO:Copying training dataset
2023-02-14 21:06:48,154:INFO:Plot type: pipeline
2023-02-14 21:06:48,297:INFO:Visual Rendered Successfully
2023-02-14 21:06:48,389:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:48,389:INFO:Initializing plot_model()
2023-02-14 21:06:48,389:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:48,389:INFO:Checking exceptions
2023-02-14 21:06:48,406:INFO:Preloading libraries
2023-02-14 21:06:48,426:INFO:Copying training dataset
2023-02-14 21:06:48,426:INFO:Plot type: pipeline
2023-02-14 21:06:48,534:INFO:Visual Rendered Successfully
2023-02-14 21:06:48,632:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:48,633:INFO:Initializing plot_model()
2023-02-14 21:06:48,633:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:48,633:INFO:Checking exceptions
2023-02-14 21:06:48,646:INFO:Preloading libraries
2023-02-14 21:06:48,660:INFO:Copying training dataset
2023-02-14 21:06:48,660:INFO:Plot type: pipeline
2023-02-14 21:06:48,761:INFO:Visual Rendered Successfully
2023-02-14 21:06:48,848:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:49,672:INFO:Initializing plot_model()
2023-02-14 21:06:49,673:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:49,673:INFO:Checking exceptions
2023-02-14 21:06:49,691:INFO:Preloading libraries
2023-02-14 21:06:49,703:INFO:Copying training dataset
2023-02-14 21:06:49,703:INFO:Plot type: pipeline
2023-02-14 21:06:49,808:INFO:Visual Rendered Successfully
2023-02-14 21:06:49,894:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:49,895:INFO:Initializing plot_model()
2023-02-14 21:06:49,895:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:49,896:INFO:Checking exceptions
2023-02-14 21:06:49,914:INFO:Preloading libraries
2023-02-14 21:06:49,934:INFO:Copying training dataset
2023-02-14 21:06:49,934:INFO:Plot type: pipeline
2023-02-14 21:06:50,034:INFO:Visual Rendered Successfully
2023-02-14 21:06:50,132:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:50,133:INFO:Initializing plot_model()
2023-02-14 21:06:50,133:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:50,133:INFO:Checking exceptions
2023-02-14 21:06:50,145:INFO:Preloading libraries
2023-02-14 21:06:50,159:INFO:Copying training dataset
2023-02-14 21:06:50,160:INFO:Plot type: pipeline
2023-02-14 21:06:50,265:INFO:Visual Rendered Successfully
2023-02-14 21:06:50,352:INFO:plot_model() successfully completed......................................
2023-02-14 21:06:56,520:INFO:Initializing plot_model()
2023-02-14 21:06:56,520:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:56,521:INFO:Checking exceptions
2023-02-14 21:06:58,657:INFO:Initializing plot_model()
2023-02-14 21:06:58,657:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:06:58,657:INFO:Checking exceptions
2023-02-14 21:07:18,882:INFO:Initializing plot_model()
2023-02-14 21:07:18,882:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:07:18,883:INFO:Checking exceptions
2023-02-14 21:07:18,892:INFO:Preloading libraries
2023-02-14 21:07:18,924:INFO:Copying training dataset
2023-02-14 21:07:18,924:INFO:Plot type: class_report
2023-02-14 21:07:19,026:INFO:Fitting Model
2023-02-14 21:07:19,027:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-02-14 21:07:19,028:INFO:Scoring test/hold-out set
2023-02-14 21:07:20,743:INFO:Visual Rendered Successfully
2023-02-14 21:07:20,830:INFO:plot_model() successfully completed......................................
2023-02-14 21:07:54,440:INFO:Initializing plot_model()
2023-02-14 21:07:54,441:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:07:54,441:INFO:Checking exceptions
2023-02-14 21:07:54,453:INFO:Preloading libraries
2023-02-14 21:07:54,484:INFO:Copying training dataset
2023-02-14 21:07:54,484:INFO:Plot type: pipeline
2023-02-14 21:07:54,565:INFO:Visual Rendered Successfully
2023-02-14 21:07:54,648:INFO:plot_model() successfully completed......................................
2023-02-14 21:08:00,208:INFO:Initializing plot_model()
2023-02-14 21:08:00,208:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:08:00,209:INFO:Checking exceptions
2023-02-14 21:08:00,222:INFO:Preloading libraries
2023-02-14 21:08:00,258:INFO:Copying training dataset
2023-02-14 21:08:00,258:INFO:Plot type: confusion_matrix
2023-02-14 21:08:00,363:INFO:Fitting Model
2023-02-14 21:08:00,365:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-02-14 21:08:00,367:INFO:Scoring test/hold-out set
2023-02-14 21:08:02,010:INFO:Visual Rendered Successfully
2023-02-14 21:08:02,096:INFO:plot_model() successfully completed......................................
2023-02-14 21:08:07,570:INFO:Initializing plot_model()
2023-02-14 21:08:07,570:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:08:07,570:INFO:Checking exceptions
2023-02-14 21:08:07,581:INFO:Preloading libraries
2023-02-14 21:08:07,611:INFO:Copying training dataset
2023-02-14 21:08:07,611:INFO:Plot type: auc
2023-02-14 21:08:07,697:INFO:Fitting Model
2023-02-14 21:08:07,697:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-02-14 21:08:07,713:INFO:Scoring test/hold-out set
2023-02-14 21:08:09,365:INFO:Visual Rendered Successfully
2023-02-14 21:08:09,459:INFO:plot_model() successfully completed......................................
2023-02-14 21:08:15,054:INFO:Initializing plot_model()
2023-02-14 21:08:15,054:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:08:15,054:INFO:Checking exceptions
2023-02-14 21:08:15,071:INFO:Preloading libraries
2023-02-14 21:08:15,084:INFO:Copying training dataset
2023-02-14 21:08:15,085:INFO:Plot type: auc
2023-02-14 21:08:15,216:INFO:Fitting Model
2023-02-14 21:08:15,217:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-02-14 21:08:15,218:INFO:Scoring test/hold-out set
2023-02-14 21:08:15,570:INFO:Visual Rendered Successfully
2023-02-14 21:08:15,664:INFO:plot_model() successfully completed......................................
2023-02-14 21:08:15,665:INFO:Initializing plot_model()
2023-02-14 21:08:15,665:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:08:15,665:INFO:Checking exceptions
2023-02-14 21:08:15,680:INFO:Preloading libraries
2023-02-14 21:08:15,694:INFO:Copying training dataset
2023-02-14 21:08:15,694:INFO:Plot type: auc
2023-02-14 21:08:15,804:INFO:Fitting Model
2023-02-14 21:08:15,805:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2023-02-14 21:08:15,806:INFO:Scoring test/hold-out set
2023-02-14 21:08:17,185:INFO:Visual Rendered Successfully
2023-02-14 21:08:17,281:INFO:plot_model() successfully completed......................................
2023-02-14 21:08:17,283:INFO:Initializing plot_model()
2023-02-14 21:08:17,283:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:08:17,283:INFO:Checking exceptions
2023-02-14 21:08:17,300:INFO:Preloading libraries
2023-02-14 21:08:17,370:INFO:Copying training dataset
2023-02-14 21:08:17,370:INFO:Plot type: auc
2023-02-14 21:08:17,496:INFO:Fitting Model
2023-02-14 21:08:17,498:INFO:Scoring test/hold-out set
2023-02-14 21:08:18,010:INFO:Visual Rendered Successfully
2023-02-14 21:08:18,106:INFO:plot_model() successfully completed......................................
2023-02-14 21:09:03,359:INFO:Initializing plot_model()
2023-02-14 21:09:03,359:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.1,
                                                           loss='deviance',
                                                           max_depth=3,
                                                           max_features=None,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.0,
                                                           min_samples_leaf=1,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=100,
                                                           n_iter_no_cha...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=4016,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:09:03,360:INFO:Checking exceptions
2023-02-14 21:09:03,377:INFO:Preloading libraries
2023-02-14 21:09:03,419:INFO:Copying training dataset
2023-02-14 21:09:03,420:INFO:Plot type: auc
2023-02-14 21:09:03,638:INFO:Fitting Model
2023-02-14 21:09:03,639:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-02-14 21:09:03,640:INFO:Scoring test/hold-out set
2023-02-14 21:09:05,532:INFO:Visual Rendered Successfully
2023-02-14 21:09:05,652:INFO:plot_model() successfully completed......................................
2023-02-14 21:09:17,783:INFO:Initializing plot_model()
2023-02-14 21:09:17,783:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.1,
                                                           loss='deviance',
                                                           max_depth=3,
                                                           max_features=None,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.0,
                                                           min_samples_leaf=1,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=100,
                                                           n_iter_no_cha...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=4016,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:09:17,783:INFO:Checking exceptions
2023-02-14 21:09:17,802:INFO:Preloading libraries
2023-02-14 21:09:17,850:INFO:Copying training dataset
2023-02-14 21:09:17,850:INFO:Plot type: pipeline
2023-02-14 21:09:17,949:INFO:Visual Rendered Successfully
2023-02-14 21:09:18,046:INFO:plot_model() successfully completed......................................
2023-02-14 21:09:26,534:INFO:Initializing plot_model()
2023-02-14 21:09:26,535:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:09:26,535:INFO:Checking exceptions
2023-02-14 21:09:26,549:INFO:Preloading libraries
2023-02-14 21:09:26,597:INFO:Copying training dataset
2023-02-14 21:09:26,598:INFO:Plot type: pipeline
2023-02-14 21:09:26,695:INFO:Visual Rendered Successfully
2023-02-14 21:09:26,782:INFO:plot_model() successfully completed......................................
2023-02-14 21:09:38,111:INFO:Initializing plot_model()
2023-02-14 21:09:38,111:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:09:38,112:INFO:Checking exceptions
2023-02-14 21:09:38,128:INFO:Preloading libraries
2023-02-14 21:09:38,139:INFO:Copying training dataset
2023-02-14 21:09:38,139:INFO:Plot type: pipeline
2023-02-14 21:09:38,290:INFO:Visual Rendered Successfully
2023-02-14 21:09:38,405:INFO:plot_model() successfully completed......................................
2023-02-14 21:09:43,606:INFO:Initializing plot_model()
2023-02-14 21:09:43,606:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:09:43,606:INFO:Checking exceptions
2023-02-14 21:09:43,624:INFO:Preloading libraries
2023-02-14 21:09:43,642:INFO:Copying training dataset
2023-02-14 21:09:43,642:INFO:Plot type: pipeline
2023-02-14 21:09:43,742:INFO:Visual Rendered Successfully
2023-02-14 21:09:43,841:INFO:plot_model() successfully completed......................................
2023-02-14 21:12:25,763:INFO:Initializing plot_model()
2023-02-14 21:12:25,763:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                                              learning_rate=0.05,
                                                              max_depth=-1,
                                                              min_child_samples=91,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.7,
                                                              n_estimators=130,
                                                              n_jobs=-1,
                                                              num_leaves=50,
                                                              objective=None,
                                                              random_state=4016,
                                                              reg_alpha=0.5,
                                                              reg_lambda=0.1,
                                                              silent='warn',
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:12:25,763:INFO:Checking exceptions
2023-02-14 21:12:25,775:INFO:Preloading libraries
2023-02-14 21:12:25,818:INFO:Copying training dataset
2023-02-14 21:12:25,818:INFO:Plot type: pipeline
2023-02-14 21:12:25,910:INFO:Visual Rendered Successfully
2023-02-14 21:12:26,004:INFO:plot_model() successfully completed......................................
2023-02-14 21:12:26,803:INFO:Initializing evaluate_model()
2023-02-14 21:12:26,803:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-14 21:12:26,826:INFO:Initializing plot_model()
2023-02-14 21:12:26,826:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:12:26,826:INFO:Checking exceptions
2023-02-14 21:12:26,839:INFO:Preloading libraries
2023-02-14 21:12:26,858:INFO:Copying training dataset
2023-02-14 21:12:26,860:INFO:Plot type: pipeline
2023-02-14 21:12:26,979:INFO:Visual Rendered Successfully
2023-02-14 21:12:27,073:INFO:plot_model() successfully completed......................................
2023-02-14 21:12:34,163:INFO:Initializing plot_model()
2023-02-14 21:12:34,163:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:12:34,163:INFO:Checking exceptions
2023-02-14 21:12:34,176:INFO:Preloading libraries
2023-02-14 21:12:34,193:INFO:Copying training dataset
2023-02-14 21:12:34,194:INFO:Plot type: auc
2023-02-14 21:12:34,302:INFO:Fitting Model
2023-02-14 21:12:34,303:INFO:Scoring test/hold-out set
2023-02-14 21:12:34,804:INFO:Visual Rendered Successfully
2023-02-14 21:12:34,950:INFO:plot_model() successfully completed......................................
2023-02-14 21:12:42,945:INFO:Initializing evaluate_model()
2023-02-14 21:12:42,945:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.1,
                                                           loss='deviance',
                                                           max_depth=3,
                                                           max_features=None,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.0,
                                                           min_samples_leaf=1,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=100,
                                                           n_iter_no_cha...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=4016,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-14 21:12:42,978:INFO:Initializing plot_model()
2023-02-14 21:12:42,978:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.1,
                                                           loss='deviance',
                                                           max_depth=3,
                                                           max_features=None,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.0,
                                                           min_samples_leaf=1,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=100,
                                                           n_iter_no_cha...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=4016,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:12:42,979:INFO:Checking exceptions
2023-02-14 21:12:42,991:INFO:Preloading libraries
2023-02-14 21:12:43,060:INFO:Copying training dataset
2023-02-14 21:12:43,061:INFO:Plot type: pipeline
2023-02-14 21:12:43,239:INFO:Visual Rendered Successfully
2023-02-14 21:12:43,344:INFO:plot_model() successfully completed......................................
2023-02-14 21:12:45,922:INFO:Initializing plot_model()
2023-02-14 21:12:45,922:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=StackingClassifier(cv=5,
                   estimators=[('Gradient Boosting Classifier',
                                GradientBoostingClassifier(ccp_alpha=0.0,
                                                           criterion='friedman_mse',
                                                           init=None,
                                                           learning_rate=0.1,
                                                           loss='deviance',
                                                           max_depth=3,
                                                           max_features=None,
                                                           max_leaf_nodes=None,
                                                           min_impurity_decrease=0.0,
                                                           min_samples_leaf=1,
                                                           min_samples_split=2,
                                                           min_weight_fraction_leaf=0.0,
                                                           n_estimators=100,
                                                           n_iter_no_cha...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=4016,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:12:45,922:INFO:Checking exceptions
2023-02-14 21:12:45,933:INFO:Preloading libraries
2023-02-14 21:12:45,971:INFO:Copying training dataset
2023-02-14 21:12:45,971:INFO:Plot type: auc
2023-02-14 21:12:46,077:INFO:Fitting Model
2023-02-14 21:12:46,077:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-02-14 21:12:46,077:INFO:Scoring test/hold-out set
2023-02-14 21:12:47,769:INFO:Visual Rendered Successfully
2023-02-14 21:12:47,850:INFO:plot_model() successfully completed......................................
2023-02-14 21:13:06,579:INFO:Initializing evaluate_model()
2023-02-14 21:13:06,579:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-14 21:13:06,607:INFO:Initializing plot_model()
2023-02-14 21:13:06,607:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:13:06,607:INFO:Checking exceptions
2023-02-14 21:13:06,622:INFO:Preloading libraries
2023-02-14 21:13:06,697:INFO:Copying training dataset
2023-02-14 21:13:06,697:INFO:Plot type: pipeline
2023-02-14 21:13:06,819:INFO:Visual Rendered Successfully
2023-02-14 21:13:06,903:INFO:plot_model() successfully completed......................................
2023-02-14 21:13:08,613:INFO:Initializing plot_model()
2023-02-14 21:13:08,614:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='deviance',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.05, max_depth=-1,
                                             min_child_samples=91,
                                             min_child_weight=0.001,
                                             min_split_gain=0.7,
                                             n_estimators=130, n_jobs=-1,
                                             num_leaves=50, objective=None,
                                             random_state=4016, reg_alpha=0.5,
                                             reg_lambda=0.1, silent='warn',
                                             subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:13:08,614:INFO:Checking exceptions
2023-02-14 21:13:08,628:INFO:Preloading libraries
2023-02-14 21:13:08,663:INFO:Copying training dataset
2023-02-14 21:13:08,663:INFO:Plot type: auc
2023-02-14 21:13:08,773:INFO:Fitting Model
2023-02-14 21:13:08,774:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-02-14 21:13:08,776:INFO:Scoring test/hold-out set
2023-02-14 21:13:10,498:INFO:Visual Rendered Successfully
2023-02-14 21:13:10,595:INFO:plot_model() successfully completed......................................
2023-02-14 21:13:33,112:INFO:Initializing plot_model()
2023-02-14 21:13:33,113:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:13:33,113:INFO:Checking exceptions
2023-02-14 21:13:33,130:INFO:Preloading libraries
2023-02-14 21:13:33,142:INFO:Copying training dataset
2023-02-14 21:13:33,142:INFO:Plot type: pipeline
2023-02-14 21:13:33,264:INFO:Visual Rendered Successfully
2023-02-14 21:13:33,349:INFO:plot_model() successfully completed......................................
2023-02-14 21:13:41,056:INFO:Initializing plot_model()
2023-02-14 21:13:41,056:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=170, random_state=4016), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:13:41,057:INFO:Checking exceptions
2023-02-14 21:13:41,075:INFO:Preloading libraries
2023-02-14 21:13:41,092:INFO:Copying training dataset
2023-02-14 21:13:41,092:INFO:Plot type: pipeline
2023-02-14 21:13:41,203:INFO:Visual Rendered Successfully
2023-02-14 21:13:41,288:INFO:plot_model() successfully completed......................................
2023-02-14 21:13:47,532:INFO:Initializing plot_model()
2023-02-14 21:13:47,532:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:13:47,532:INFO:Checking exceptions
2023-02-14 21:13:47,547:INFO:Preloading libraries
2023-02-14 21:13:47,562:INFO:Copying training dataset
2023-02-14 21:13:47,562:INFO:Plot type: pipeline
2023-02-14 21:13:47,665:INFO:Visual Rendered Successfully
2023-02-14 21:13:47,766:INFO:plot_model() successfully completed......................................
2023-02-14 21:13:52,099:INFO:Initializing plot_model()
2023-02-14 21:13:52,099:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:13:52,099:INFO:Checking exceptions
2023-02-14 21:13:52,114:INFO:Preloading libraries
2023-02-14 21:13:52,132:INFO:Copying training dataset
2023-02-14 21:13:52,132:INFO:Plot type: auc
2023-02-14 21:13:52,262:INFO:Fitting Model
2023-02-14 21:13:52,264:INFO:Scoring test/hold-out set
2023-02-14 21:13:52,879:INFO:Visual Rendered Successfully
2023-02-14 21:13:52,990:INFO:plot_model() successfully completed......................................
2023-02-14 21:14:03,666:INFO:Initializing plot_model()
2023-02-14 21:14:03,666:INFO:plot_model(plot=pipeline, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:14:03,666:INFO:Checking exceptions
2023-02-14 21:14:03,683:INFO:Preloading libraries
2023-02-14 21:14:03,699:INFO:Copying training dataset
2023-02-14 21:14:03,699:INFO:Plot type: pipeline
2023-02-14 21:14:03,840:INFO:Visual Rendered Successfully
2023-02-14 21:14:03,933:INFO:plot_model() successfully completed......................................
2023-02-14 21:14:58,534:INFO:Initializing evaluate_model()
2023-02-14 21:14:58,535:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-14 21:14:58,560:INFO:Initializing plot_model()
2023-02-14 21:14:58,560:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:14:58,560:INFO:Checking exceptions
2023-02-14 21:14:58,572:INFO:Preloading libraries
2023-02-14 21:14:58,596:INFO:Copying training dataset
2023-02-14 21:14:58,596:INFO:Plot type: pipeline
2023-02-14 21:14:58,754:INFO:Visual Rendered Successfully
2023-02-14 21:14:58,871:INFO:plot_model() successfully completed......................................
2023-02-14 21:15:08,379:INFO:Initializing plot_model()
2023-02-14 21:15:08,379:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=130, n_jobs=-1, num_leaves=50, objective=None,
               random_state=4016, reg_alpha=0.5, reg_lambda=0.1, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DB1155460>, system=True)
2023-02-14 21:15:08,379:INFO:Checking exceptions
2023-02-14 21:15:08,392:INFO:Preloading libraries
2023-02-14 21:15:08,406:INFO:Copying training dataset
2023-02-14 21:15:08,406:INFO:Plot type: learning
2023-02-14 21:15:08,597:INFO:Fitting Model
2023-02-14 21:15:56,400:INFO:Visual Rendered Successfully
2023-02-14 21:15:56,487:INFO:plot_model() successfully completed......................................
2023-02-14 21:33:54,606:INFO:Soft dependency imported: explainerdashboard: 0.3.6.2
2023-02-14 21:34:29,775:INFO:Soft dependency imported: explainerdashboard: 0.3.6.2
2023-02-14 21:34:53,537:INFO:Soft dependency imported: explainerdashboard: 0.3.6.2
2023-02-14 21:39:02,439:INFO:Soft dependency imported: explainerdashboard: 0.3.6.2
2023-02-14 21:44:05,802:INFO:PyCaret ClassificationExperiment
2023-02-14 21:44:05,802:INFO:Logging name: clf-default-name
2023-02-14 21:44:05,802:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-14 21:44:05,802:INFO:version 3.0.0.rc9
2023-02-14 21:44:05,803:INFO:Initializing setup()
2023-02-14 21:44:05,803:INFO:self.USI: 0b50
2023-02-14 21:44:05,803:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'pipeline', 'seed', 'X', 'logging_param', 'X_train', 'data', 'fold_shuffle_param', 'log_plots_param', 'memory', '_available_plots', '_ml_usecase', 'html_param', 'fold_groups_param', 'USI', 'gpu_n_jobs_param', 'y_train', 'y', 'y_test', 'fix_imbalance', 'is_multiclass', 'fold_generator', 'target_param', 'exp_name_log', 'n_jobs_param', 'idx', 'X_test'}
2023-02-14 21:44:05,803:INFO:Checking environment
2023-02-14 21:44:05,803:INFO:python_version: 3.9.15
2023-02-14 21:44:05,803:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-14 21:44:05,803:INFO:machine: AMD64
2023-02-14 21:44:05,803:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-14 21:44:05,803:INFO:Memory: svmem(total=8469581824, available=1170608128, percent=86.2, used=7298973696, free=1170608128)
2023-02-14 21:44:05,803:INFO:Physical Core: 4
2023-02-14 21:44:05,804:INFO:Logical Core: 4
2023-02-14 21:44:05,804:INFO:Checking libraries
2023-02-14 21:44:05,804:INFO:System:
2023-02-14 21:44:05,804:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-14 21:44:05,804:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-14 21:44:05,804:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-14 21:44:05,804:INFO:PyCaret required dependencies:
2023-02-14 21:44:05,804:INFO:                 pip: 22.3.1
2023-02-14 21:44:05,804:INFO:          setuptools: 60.10.0
2023-02-14 21:44:05,804:INFO:             pycaret: 3.0.0rc9
2023-02-14 21:44:05,804:INFO:             IPython: 7.31.1
2023-02-14 21:44:05,805:INFO:          ipywidgets: 7.6.5
2023-02-14 21:44:05,805:INFO:                tqdm: 4.64.1
2023-02-14 21:44:05,805:INFO:               numpy: 1.21.5
2023-02-14 21:44:05,805:INFO:              pandas: 1.4.4
2023-02-14 21:44:05,805:INFO:              jinja2: 2.11.3
2023-02-14 21:44:05,805:INFO:               scipy: 1.9.3
2023-02-14 21:44:05,805:INFO:              joblib: 1.2.0
2023-02-14 21:44:05,805:INFO:             sklearn: 1.0.2
2023-02-14 21:44:05,805:INFO:                pyod: 1.0.7
2023-02-14 21:44:05,805:INFO:            imblearn: 0.10.1
2023-02-14 21:44:05,805:INFO:   category_encoders: 2.6.0
2023-02-14 21:44:05,805:INFO:            lightgbm: 3.3.5
2023-02-14 21:44:05,805:INFO:               numba: 0.56.4
2023-02-14 21:44:05,805:INFO:            requests: 2.28.1
2023-02-14 21:44:05,805:INFO:          matplotlib: 3.6.2
2023-02-14 21:44:05,805:INFO:          scikitplot: 0.3.7
2023-02-14 21:44:05,805:INFO:         yellowbrick: 1.5
2023-02-14 21:44:05,806:INFO:              plotly: 5.9.0
2023-02-14 21:44:05,806:INFO:             kaleido: 0.2.1
2023-02-14 21:44:05,806:INFO:         statsmodels: 0.13.2
2023-02-14 21:44:05,806:INFO:              sktime: 0.16.1
2023-02-14 21:44:05,806:INFO:               tbats: 1.1.2
2023-02-14 21:44:05,806:INFO:            pmdarima: 2.0.2
2023-02-14 21:44:05,806:INFO:              psutil: 5.9.0
2023-02-14 21:44:05,806:INFO:PyCaret optional dependencies:
2023-02-14 21:44:05,806:INFO:                shap: 0.41.0
2023-02-14 21:44:05,806:INFO:           interpret: Not installed
2023-02-14 21:44:05,806:INFO:                umap: Not installed
2023-02-14 21:44:05,806:INFO:    pandas_profiling: 4.0.0
2023-02-14 21:44:05,806:INFO:  explainerdashboard: 0.3.6.2
2023-02-14 21:44:05,806:INFO:             autoviz: 0.1.58
2023-02-14 21:44:05,806:INFO:           fairlearn: Not installed
2023-02-14 21:44:05,807:INFO:             xgboost: 1.7.3
2023-02-14 21:44:05,807:INFO:            catboost: Not installed
2023-02-14 21:44:05,807:INFO:              kmodes: Not installed
2023-02-14 21:44:05,807:INFO:             mlxtend: Not installed
2023-02-14 21:44:05,807:INFO:       statsforecast: Not installed
2023-02-14 21:44:05,807:INFO:        tune_sklearn: Not installed
2023-02-14 21:44:05,807:INFO:                 ray: Not installed
2023-02-14 21:44:05,807:INFO:            hyperopt: Not installed
2023-02-14 21:44:05,807:INFO:              optuna: 2.10.1
2023-02-14 21:44:05,807:INFO:               skopt: Not installed
2023-02-14 21:44:05,807:INFO:              mlflow: Not installed
2023-02-14 21:44:05,807:INFO:              gradio: Not installed
2023-02-14 21:44:05,807:INFO:             fastapi: Not installed
2023-02-14 21:44:05,807:INFO:             uvicorn: Not installed
2023-02-14 21:44:05,807:INFO:              m2cgen: Not installed
2023-02-14 21:44:05,807:INFO:           evidently: Not installed
2023-02-14 21:44:05,807:INFO:               fugue: Not installed
2023-02-14 21:44:05,807:INFO:           streamlit: Not installed
2023-02-14 21:44:05,807:INFO:             prophet: Not installed
2023-02-14 21:44:05,808:INFO:None
2023-02-14 21:44:05,808:INFO:Set up data.
2023-02-14 21:44:05,840:INFO:Set up train/test split.
2023-02-14 21:44:05,905:INFO:Set up index.
2023-02-14 21:44:05,909:INFO:Set up folding strategy.
2023-02-14 21:44:05,909:INFO:Assigning column types.
2023-02-14 21:44:05,935:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-14 21:44:05,996:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-14 21:44:06,007:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-14 21:44:06,046:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 21:44:06,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 21:44:06,100:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-14 21:44:06,101:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-14 21:44:06,135:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 21:44:06,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 21:44:06,139:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-14 21:44:06,191:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-14 21:44:06,224:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 21:44:06,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 21:44:06,276:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-14 21:44:06,307:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 21:44:06,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 21:44:06,310:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-14 21:44:06,401:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 21:44:06,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 21:44:06,490:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 21:44:06,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 21:44:06,494:INFO:Preparing preprocessing pipeline...
2023-02-14 21:44:06,508:INFO:Set up simple imputation.
2023-02-14 21:44:06,508:INFO:Set up imbalanced handling.
2023-02-14 21:44:06,579:INFO:Finished creating preprocessing pipeline.
2023-02-14 21:44:06,588:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2023-02-14 21:44:06,589:INFO:Creating final display dataframe.
2023-02-14 21:44:07,821:INFO:Setup _display_container:                     Description             Value
0                    Session id              6982
1                        Target      inadimplente
2                   Target type            Binary
3           Original data shape      (110000, 11)
4        Transformed data shape      (176736, 11)
5   Transformed train set shape      (143736, 11)
6    Transformed test set shape       (33000, 11)
7              Numeric features                10
8      Rows with missing values             19.8%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                Fix imbalance              True
14         Fix imbalance method             SMOTE
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              0b50
2023-02-14 21:44:07,930:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 21:44:07,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 21:44:08,016:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 21:44:08,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 21:44:08,021:INFO:setup() successfully completed in 2.22s...............
2023-02-14 21:44:25,285:INFO:Initializing compare_models()
2023-02-14 21:44:25,286:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DBDDC5370>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020DBDDC5370>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-14 21:44:25,286:INFO:Checking exceptions
2023-02-14 21:44:25,307:INFO:Preparing display monitor
2023-02-14 21:44:25,341:INFO:Initializing Logistic Regression
2023-02-14 21:44:25,342:INFO:Total runtime is 1.0704994201660156e-05 minutes
2023-02-14 21:44:25,346:INFO:SubProcess create_model() called ==================================
2023-02-14 21:44:25,347:INFO:Initializing create_model()
2023-02-14 21:44:25,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DBDDC5370>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBD2E9220>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 21:44:25,347:INFO:Checking exceptions
2023-02-14 21:44:25,348:INFO:Importing libraries
2023-02-14 21:44:25,348:INFO:Copying training dataset
2023-02-14 21:44:25,392:INFO:Defining folds
2023-02-14 21:44:25,392:INFO:Declaring metric variables
2023-02-14 21:44:25,398:INFO:Importing untrained model
2023-02-14 21:44:25,408:INFO:Logistic Regression Imported successfully
2023-02-14 21:44:25,418:INFO:Starting cross validation
2023-02-14 21:44:25,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 21:44:39,802:INFO:Calculating mean and std
2023-02-14 21:44:39,804:INFO:Creating metrics dataframe
2023-02-14 21:44:39,809:INFO:Uploading results into container
2023-02-14 21:44:39,809:INFO:Uploading model into container now
2023-02-14 21:44:39,810:INFO:_master_model_container: 1
2023-02-14 21:44:39,811:INFO:_display_container: 2
2023-02-14 21:44:39,811:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6982, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-14 21:44:39,811:INFO:create_model() successfully completed......................................
2023-02-14 21:44:40,187:INFO:SubProcess create_model() end ==================================
2023-02-14 21:44:40,188:INFO:Creating metrics dataframe
2023-02-14 21:44:40,197:INFO:Initializing K Neighbors Classifier
2023-02-14 21:44:40,197:INFO:Total runtime is 0.24759263594945272 minutes
2023-02-14 21:44:40,202:INFO:SubProcess create_model() called ==================================
2023-02-14 21:44:40,202:INFO:Initializing create_model()
2023-02-14 21:44:40,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DBDDC5370>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBD2E9220>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 21:44:40,203:INFO:Checking exceptions
2023-02-14 21:44:40,203:INFO:Importing libraries
2023-02-14 21:44:40,203:INFO:Copying training dataset
2023-02-14 21:44:40,235:INFO:Defining folds
2023-02-14 21:44:40,235:INFO:Declaring metric variables
2023-02-14 21:44:40,240:INFO:Importing untrained model
2023-02-14 21:44:40,245:INFO:K Neighbors Classifier Imported successfully
2023-02-14 21:44:40,254:INFO:Starting cross validation
2023-02-14 21:44:40,255:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 21:44:41,638:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 21:44:42,072:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 21:44:42,166:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 21:44:42,290:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 21:44:44,537:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 21:44:44,922:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 21:44:45,249:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 21:44:45,353:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 21:44:47,693:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 21:44:47,858:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 21:44:48,557:INFO:Calculating mean and std
2023-02-14 21:44:48,558:INFO:Creating metrics dataframe
2023-02-14 21:44:48,563:INFO:Uploading results into container
2023-02-14 21:44:48,564:INFO:Uploading model into container now
2023-02-14 21:44:48,565:INFO:_master_model_container: 2
2023-02-14 21:44:48,565:INFO:_display_container: 2
2023-02-14 21:44:48,565:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-14 21:44:48,565:INFO:create_model() successfully completed......................................
2023-02-14 21:44:48,707:INFO:SubProcess create_model() end ==================================
2023-02-14 21:44:48,707:INFO:Creating metrics dataframe
2023-02-14 21:44:48,724:INFO:Initializing Naive Bayes
2023-02-14 21:44:48,724:INFO:Total runtime is 0.38970654408137007 minutes
2023-02-14 21:44:48,729:INFO:SubProcess create_model() called ==================================
2023-02-14 21:44:48,730:INFO:Initializing create_model()
2023-02-14 21:44:48,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DBDDC5370>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBD2E9220>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 21:44:48,730:INFO:Checking exceptions
2023-02-14 21:44:48,731:INFO:Importing libraries
2023-02-14 21:44:48,731:INFO:Copying training dataset
2023-02-14 21:44:48,761:INFO:Defining folds
2023-02-14 21:44:48,761:INFO:Declaring metric variables
2023-02-14 21:44:48,770:INFO:Importing untrained model
2023-02-14 21:44:48,775:INFO:Naive Bayes Imported successfully
2023-02-14 21:44:48,784:INFO:Starting cross validation
2023-02-14 21:44:48,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 21:44:49,520:INFO:Calculating mean and std
2023-02-14 21:44:49,521:INFO:Creating metrics dataframe
2023-02-14 21:44:49,524:INFO:Uploading results into container
2023-02-14 21:44:49,524:INFO:Uploading model into container now
2023-02-14 21:44:49,524:INFO:_master_model_container: 3
2023-02-14 21:44:49,524:INFO:_display_container: 2
2023-02-14 21:44:49,524:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-14 21:44:49,528:INFO:create_model() successfully completed......................................
2023-02-14 21:44:49,640:INFO:SubProcess create_model() end ==================================
2023-02-14 21:44:49,640:INFO:Creating metrics dataframe
2023-02-14 21:44:49,656:INFO:Initializing Decision Tree Classifier
2023-02-14 21:44:49,656:INFO:Total runtime is 0.4052447676658631 minutes
2023-02-14 21:44:49,665:INFO:SubProcess create_model() called ==================================
2023-02-14 21:44:49,665:INFO:Initializing create_model()
2023-02-14 21:44:49,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DBDDC5370>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBD2E9220>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 21:44:49,665:INFO:Checking exceptions
2023-02-14 21:44:49,665:INFO:Importing libraries
2023-02-14 21:44:49,665:INFO:Copying training dataset
2023-02-14 21:44:49,692:INFO:Defining folds
2023-02-14 21:44:49,692:INFO:Declaring metric variables
2023-02-14 21:44:49,703:INFO:Importing untrained model
2023-02-14 21:44:49,704:INFO:Decision Tree Classifier Imported successfully
2023-02-14 21:44:49,708:INFO:Starting cross validation
2023-02-14 21:44:49,717:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 21:44:53,261:INFO:Calculating mean and std
2023-02-14 21:44:53,261:INFO:Creating metrics dataframe
2023-02-14 21:44:53,266:INFO:Uploading results into container
2023-02-14 21:44:53,266:INFO:Uploading model into container now
2023-02-14 21:44:53,269:INFO:_master_model_container: 4
2023-02-14 21:44:53,269:INFO:_display_container: 2
2023-02-14 21:44:53,270:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6982, splitter='best')
2023-02-14 21:44:53,270:INFO:create_model() successfully completed......................................
2023-02-14 21:44:53,383:INFO:SubProcess create_model() end ==================================
2023-02-14 21:44:53,383:INFO:Creating metrics dataframe
2023-02-14 21:44:53,398:INFO:Initializing SVM - Linear Kernel
2023-02-14 21:44:53,398:INFO:Total runtime is 0.46762090524037686 minutes
2023-02-14 21:44:53,406:INFO:SubProcess create_model() called ==================================
2023-02-14 21:44:53,406:INFO:Initializing create_model()
2023-02-14 21:44:53,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DBDDC5370>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBD2E9220>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 21:44:53,406:INFO:Checking exceptions
2023-02-14 21:44:53,406:INFO:Importing libraries
2023-02-14 21:44:53,406:INFO:Copying training dataset
2023-02-14 21:44:53,438:INFO:Defining folds
2023-02-14 21:44:53,438:INFO:Declaring metric variables
2023-02-14 21:44:53,446:INFO:Importing untrained model
2023-02-14 21:44:53,451:INFO:SVM - Linear Kernel Imported successfully
2023-02-14 21:44:53,460:INFO:Starting cross validation
2023-02-14 21:44:53,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 21:44:57,789:INFO:Calculating mean and std
2023-02-14 21:44:57,789:INFO:Creating metrics dataframe
2023-02-14 21:44:57,793:INFO:Uploading results into container
2023-02-14 21:44:57,793:INFO:Uploading model into container now
2023-02-14 21:44:57,793:INFO:_master_model_container: 5
2023-02-14 21:44:57,793:INFO:_display_container: 2
2023-02-14 21:44:57,793:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6982, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-14 21:44:57,793:INFO:create_model() successfully completed......................................
2023-02-14 21:44:57,936:INFO:SubProcess create_model() end ==================================
2023-02-14 21:44:57,936:INFO:Creating metrics dataframe
2023-02-14 21:44:57,956:INFO:Initializing Ridge Classifier
2023-02-14 21:44:57,956:INFO:Total runtime is 0.5435810128847759 minutes
2023-02-14 21:44:57,964:INFO:SubProcess create_model() called ==================================
2023-02-14 21:44:57,964:INFO:Initializing create_model()
2023-02-14 21:44:57,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DBDDC5370>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBD2E9220>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 21:44:57,965:INFO:Checking exceptions
2023-02-14 21:44:57,965:INFO:Importing libraries
2023-02-14 21:44:57,965:INFO:Copying training dataset
2023-02-14 21:44:58,003:INFO:Defining folds
2023-02-14 21:44:58,003:INFO:Declaring metric variables
2023-02-14 21:44:58,013:INFO:Importing untrained model
2023-02-14 21:44:58,018:INFO:Ridge Classifier Imported successfully
2023-02-14 21:44:58,020:INFO:Starting cross validation
2023-02-14 21:44:58,028:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 21:44:58,567:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.74599e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 21:44:58,567:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.45131e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 21:44:58,567:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.53217e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 21:44:58,567:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.80986e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 21:44:58,761:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.85098e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 21:44:58,761:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.44631e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 21:44:58,767:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.52195e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 21:44:58,789:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.7615e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 21:44:58,932:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.67004e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 21:44:58,938:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.40291e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 21:44:59,084:INFO:Calculating mean and std
2023-02-14 21:44:59,086:INFO:Creating metrics dataframe
2023-02-14 21:44:59,092:INFO:Uploading results into container
2023-02-14 21:44:59,094:INFO:Uploading model into container now
2023-02-14 21:44:59,094:INFO:_master_model_container: 6
2023-02-14 21:44:59,094:INFO:_display_container: 2
2023-02-14 21:44:59,094:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=6982, solver='auto', tol=0.001)
2023-02-14 21:44:59,094:INFO:create_model() successfully completed......................................
2023-02-14 21:44:59,387:INFO:SubProcess create_model() end ==================================
2023-02-14 21:44:59,387:INFO:Creating metrics dataframe
2023-02-14 21:44:59,406:INFO:Initializing Random Forest Classifier
2023-02-14 21:44:59,406:INFO:Total runtime is 0.5677422046661378 minutes
2023-02-14 21:44:59,411:INFO:SubProcess create_model() called ==================================
2023-02-14 21:44:59,412:INFO:Initializing create_model()
2023-02-14 21:44:59,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DBDDC5370>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBD2E9220>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 21:44:59,412:INFO:Checking exceptions
2023-02-14 21:44:59,412:INFO:Importing libraries
2023-02-14 21:44:59,412:INFO:Copying training dataset
2023-02-14 21:44:59,452:INFO:Defining folds
2023-02-14 21:44:59,452:INFO:Declaring metric variables
2023-02-14 21:44:59,460:INFO:Importing untrained model
2023-02-14 21:44:59,465:INFO:Random Forest Classifier Imported successfully
2023-02-14 21:44:59,475:INFO:Starting cross validation
2023-02-14 21:44:59,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 21:45:28,120:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 21:46:06,766:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 21:46:13,563:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 21:46:35,322:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 21:46:35,767:INFO:Calculating mean and std
2023-02-14 21:46:35,772:INFO:Creating metrics dataframe
2023-02-14 21:46:35,776:INFO:Uploading results into container
2023-02-14 21:46:35,777:INFO:Uploading model into container now
2023-02-14 21:46:35,778:INFO:_master_model_container: 7
2023-02-14 21:46:35,778:INFO:_display_container: 2
2023-02-14 21:46:35,778:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6982, verbose=0, warm_start=False)
2023-02-14 21:46:35,779:INFO:create_model() successfully completed......................................
2023-02-14 21:46:35,940:INFO:SubProcess create_model() end ==================================
2023-02-14 21:46:35,941:INFO:Creating metrics dataframe
2023-02-14 21:46:36,730:INFO:Initializing Quadratic Discriminant Analysis
2023-02-14 21:46:36,731:INFO:Total runtime is 2.189828761418661 minutes
2023-02-14 21:46:36,738:INFO:SubProcess create_model() called ==================================
2023-02-14 21:46:36,739:INFO:Initializing create_model()
2023-02-14 21:46:36,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DBDDC5370>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBD2E9220>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 21:46:36,739:INFO:Checking exceptions
2023-02-14 21:46:36,739:INFO:Importing libraries
2023-02-14 21:46:36,740:INFO:Copying training dataset
2023-02-14 21:46:36,776:INFO:Defining folds
2023-02-14 21:46:36,776:INFO:Declaring metric variables
2023-02-14 21:46:36,782:INFO:Importing untrained model
2023-02-14 21:46:36,787:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-14 21:46:36,798:INFO:Starting cross validation
2023-02-14 21:46:36,800:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 21:46:41,577:INFO:Calculating mean and std
2023-02-14 21:46:41,612:INFO:Creating metrics dataframe
2023-02-14 21:46:41,616:INFO:Uploading results into container
2023-02-14 21:46:41,617:INFO:Uploading model into container now
2023-02-14 21:46:41,618:INFO:_master_model_container: 8
2023-02-14 21:46:41,618:INFO:_display_container: 2
2023-02-14 21:46:41,618:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-14 21:46:41,618:INFO:create_model() successfully completed......................................
2023-02-14 21:46:41,839:INFO:SubProcess create_model() end ==================================
2023-02-14 21:46:41,839:INFO:Creating metrics dataframe
2023-02-14 21:46:41,860:INFO:Initializing Ada Boost Classifier
2023-02-14 21:46:41,861:INFO:Total runtime is 2.275328572591146 minutes
2023-02-14 21:46:41,865:INFO:SubProcess create_model() called ==================================
2023-02-14 21:46:41,865:INFO:Initializing create_model()
2023-02-14 21:46:41,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DBDDC5370>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBD2E9220>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 21:46:41,866:INFO:Checking exceptions
2023-02-14 21:46:41,866:INFO:Importing libraries
2023-02-14 21:46:41,866:INFO:Copying training dataset
2023-02-14 21:46:41,900:INFO:Defining folds
2023-02-14 21:46:41,900:INFO:Declaring metric variables
2023-02-14 21:46:41,906:INFO:Importing untrained model
2023-02-14 21:46:41,911:INFO:Ada Boost Classifier Imported successfully
2023-02-14 21:46:41,922:INFO:Starting cross validation
2023-02-14 21:46:41,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 21:47:10,523:INFO:Calculating mean and std
2023-02-14 21:47:10,524:INFO:Creating metrics dataframe
2023-02-14 21:47:10,529:INFO:Uploading results into container
2023-02-14 21:47:10,529:INFO:Uploading model into container now
2023-02-14 21:47:10,531:INFO:_master_model_container: 9
2023-02-14 21:47:10,531:INFO:_display_container: 2
2023-02-14 21:47:10,531:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6982)
2023-02-14 21:47:10,531:INFO:create_model() successfully completed......................................
2023-02-14 21:47:10,671:INFO:SubProcess create_model() end ==================================
2023-02-14 21:47:10,671:INFO:Creating metrics dataframe
2023-02-14 21:47:10,683:INFO:Initializing Gradient Boosting Classifier
2023-02-14 21:47:10,683:INFO:Total runtime is 2.755689803759257 minutes
2023-02-14 21:47:10,689:INFO:SubProcess create_model() called ==================================
2023-02-14 21:47:10,690:INFO:Initializing create_model()
2023-02-14 21:47:10,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DBDDC5370>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DBD2E9220>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 21:47:10,690:INFO:Checking exceptions
2023-02-14 21:47:10,690:INFO:Importing libraries
2023-02-14 21:47:10,690:INFO:Copying training dataset
2023-02-14 21:47:10,721:INFO:Defining folds
2023-02-14 21:47:10,721:INFO:Declaring metric variables
2023-02-14 21:47:10,727:INFO:Importing untrained model
2023-02-14 21:47:10,732:INFO:Gradient Boosting Classifier Imported successfully
2023-02-14 21:47:10,741:INFO:Starting cross validation
2023-02-14 21:47:10,743:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:19:27,104:INFO:Soft dependency imported: autoviz: 0.1.58
2023-02-14 22:36:43,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-14 22:36:43,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-14 22:36:43,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-14 22:36:43,615:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-14 22:36:45,500:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-14 22:47:35,686:INFO:PyCaret ClassificationExperiment
2023-02-14 22:47:35,686:INFO:Logging name: clf-default-name
2023-02-14 22:47:35,686:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-14 22:47:35,686:INFO:version 3.0.0.rc9
2023-02-14 22:47:35,686:INFO:Initializing setup()
2023-02-14 22:47:35,687:INFO:self.USI: 2254
2023-02-14 22:47:35,687:INFO:self._variable_keys: {'y', 'memory', 'gpu_param', 'exp_id', 'X_test', '_available_plots', 'fold_groups_param', 'y_train', 'gpu_n_jobs_param', '_ml_usecase', 'fold_shuffle_param', 'n_jobs_param', 'data', 'USI', 'X', 'fold_generator', 'pipeline', 'fix_imbalance', 'exp_name_log', 'is_multiclass', 'log_plots_param', 'idx', 'target_param', 'html_param', 'X_train', 'y_test', 'seed', 'logging_param'}
2023-02-14 22:47:35,687:INFO:Checking environment
2023-02-14 22:47:35,687:INFO:python_version: 3.9.15
2023-02-14 22:47:35,687:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-14 22:47:35,687:INFO:machine: AMD64
2023-02-14 22:47:35,687:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-14 22:47:35,687:INFO:Memory: svmem(total=8469581824, available=1256361984, percent=85.2, used=7213219840, free=1256361984)
2023-02-14 22:47:35,687:INFO:Physical Core: 4
2023-02-14 22:47:35,687:INFO:Logical Core: 4
2023-02-14 22:47:35,687:INFO:Checking libraries
2023-02-14 22:47:35,687:INFO:System:
2023-02-14 22:47:35,687:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-14 22:47:35,687:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-14 22:47:35,688:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-14 22:47:35,688:INFO:PyCaret required dependencies:
2023-02-14 22:47:35,688:INFO:                 pip: 22.3.1
2023-02-14 22:47:35,688:INFO:          setuptools: 60.10.0
2023-02-14 22:47:35,688:INFO:             pycaret: 3.0.0rc9
2023-02-14 22:47:35,688:INFO:             IPython: 7.31.1
2023-02-14 22:47:35,688:INFO:          ipywidgets: 7.6.5
2023-02-14 22:47:35,689:INFO:                tqdm: 4.64.1
2023-02-14 22:47:35,689:INFO:               numpy: 1.21.5
2023-02-14 22:47:35,689:INFO:              pandas: 1.4.4
2023-02-14 22:47:35,689:INFO:              jinja2: 2.11.3
2023-02-14 22:47:35,689:INFO:               scipy: 1.9.3
2023-02-14 22:47:35,689:INFO:              joblib: 1.2.0
2023-02-14 22:47:35,689:INFO:             sklearn: 1.0.2
2023-02-14 22:47:35,689:INFO:                pyod: 1.0.7
2023-02-14 22:47:35,689:INFO:            imblearn: 0.10.1
2023-02-14 22:47:35,689:INFO:   category_encoders: 2.6.0
2023-02-14 22:47:35,689:INFO:            lightgbm: 3.3.5
2023-02-14 22:47:35,689:INFO:               numba: 0.56.4
2023-02-14 22:47:35,689:INFO:            requests: 2.28.1
2023-02-14 22:47:35,689:INFO:          matplotlib: 3.6.2
2023-02-14 22:47:35,689:INFO:          scikitplot: 0.3.7
2023-02-14 22:47:35,689:INFO:         yellowbrick: 1.5
2023-02-14 22:47:35,689:INFO:              plotly: 5.9.0
2023-02-14 22:47:35,689:INFO:             kaleido: 0.2.1
2023-02-14 22:47:35,689:INFO:         statsmodels: 0.13.2
2023-02-14 22:47:35,689:INFO:              sktime: 0.16.1
2023-02-14 22:47:35,689:INFO:               tbats: 1.1.2
2023-02-14 22:47:35,689:INFO:            pmdarima: 2.0.2
2023-02-14 22:47:35,689:INFO:              psutil: 5.9.0
2023-02-14 22:47:35,689:INFO:PyCaret optional dependencies:
2023-02-14 22:47:35,709:INFO:                shap: 0.41.0
2023-02-14 22:47:35,709:INFO:           interpret: Not installed
2023-02-14 22:47:35,709:INFO:                umap: Not installed
2023-02-14 22:47:35,709:INFO:    pandas_profiling: 4.0.0
2023-02-14 22:47:35,709:INFO:  explainerdashboard: 0.3.6.2
2023-02-14 22:47:35,709:INFO:             autoviz: 0.1.58
2023-02-14 22:47:35,709:INFO:           fairlearn: Not installed
2023-02-14 22:47:35,709:INFO:             xgboost: 1.7.3
2023-02-14 22:47:35,709:INFO:            catboost: Not installed
2023-02-14 22:47:35,709:INFO:              kmodes: Not installed
2023-02-14 22:47:35,709:INFO:             mlxtend: Not installed
2023-02-14 22:47:35,710:INFO:       statsforecast: Not installed
2023-02-14 22:47:35,710:INFO:        tune_sklearn: Not installed
2023-02-14 22:47:35,710:INFO:                 ray: Not installed
2023-02-14 22:47:35,710:INFO:            hyperopt: Not installed
2023-02-14 22:47:35,710:INFO:              optuna: 2.10.1
2023-02-14 22:47:35,710:INFO:               skopt: Not installed
2023-02-14 22:47:35,710:INFO:              mlflow: Not installed
2023-02-14 22:47:35,710:INFO:              gradio: Not installed
2023-02-14 22:47:35,710:INFO:             fastapi: Not installed
2023-02-14 22:47:35,710:INFO:             uvicorn: Not installed
2023-02-14 22:47:35,710:INFO:              m2cgen: Not installed
2023-02-14 22:47:35,710:INFO:           evidently: Not installed
2023-02-14 22:47:35,710:INFO:               fugue: Not installed
2023-02-14 22:47:35,710:INFO:           streamlit: Not installed
2023-02-14 22:47:35,710:INFO:             prophet: Not installed
2023-02-14 22:47:35,710:INFO:None
2023-02-14 22:47:35,710:INFO:Set up data.
2023-02-14 22:47:35,738:INFO:Set up train/test split.
2023-02-14 22:47:35,801:INFO:Set up index.
2023-02-14 22:47:35,803:INFO:Set up folding strategy.
2023-02-14 22:47:35,803:INFO:Assigning column types.
2023-02-14 22:47:35,823:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-14 22:47:35,887:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-14 22:47:35,898:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-14 22:47:35,946:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 22:47:36,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 22:47:36,577:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-14 22:47:36,578:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-14 22:47:36,611:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 22:47:36,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 22:47:36,615:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-14 22:47:36,671:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-14 22:47:36,705:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 22:47:36,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 22:47:36,845:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-14 22:47:36,910:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 22:47:36,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 22:47:36,914:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-14 22:47:37,056:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 22:47:37,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 22:47:37,208:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 22:47:37,211:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 22:47:37,235:INFO:Preparing preprocessing pipeline...
2023-02-14 22:47:37,243:INFO:Set up simple imputation.
2023-02-14 22:47:37,243:INFO:Set up imbalanced handling.
2023-02-14 22:47:37,342:INFO:Finished creating preprocessing pipeline.
2023-02-14 22:47:37,352:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2023-02-14 22:47:37,353:INFO:Creating final display dataframe.
2023-02-14 22:47:38,778:INFO:Setup _display_container:                     Description             Value
0                    Session id              7455
1                        Target      inadimplente
2                   Target type            Binary
3           Original data shape      (110000, 11)
4        Transformed data shape      (176736, 11)
5   Transformed train set shape      (143736, 11)
6    Transformed test set shape       (33000, 11)
7              Numeric features                10
8      Rows with missing values             19.8%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                Fix imbalance              True
14         Fix imbalance method             SMOTE
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              2254
2023-02-14 22:47:38,906:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 22:47:38,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 22:47:39,005:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-14 22:47:39,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-14 22:47:39,008:INFO:setup() successfully completed in 3.33s...............
2023-02-14 22:47:44,514:INFO:Initializing compare_models()
2023-02-14 22:47:44,515:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-14 22:47:44,515:INFO:Checking exceptions
2023-02-14 22:47:44,535:INFO:Preparing display monitor
2023-02-14 22:47:44,572:INFO:Initializing Logistic Regression
2023-02-14 22:47:44,572:INFO:Total runtime is 0.0 minutes
2023-02-14 22:47:44,576:INFO:SubProcess create_model() called ==================================
2023-02-14 22:47:44,577:INFO:Initializing create_model()
2023-02-14 22:47:44,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:47:44,577:INFO:Checking exceptions
2023-02-14 22:47:44,577:INFO:Importing libraries
2023-02-14 22:47:44,577:INFO:Copying training dataset
2023-02-14 22:47:44,632:INFO:Defining folds
2023-02-14 22:47:44,632:INFO:Declaring metric variables
2023-02-14 22:47:44,640:INFO:Importing untrained model
2023-02-14 22:47:44,644:INFO:Logistic Regression Imported successfully
2023-02-14 22:47:44,653:INFO:Starting cross validation
2023-02-14 22:47:44,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:48:03,575:INFO:Calculating mean and std
2023-02-14 22:48:03,577:INFO:Creating metrics dataframe
2023-02-14 22:48:03,581:INFO:Uploading results into container
2023-02-14 22:48:03,582:INFO:Uploading model into container now
2023-02-14 22:48:03,582:INFO:_master_model_container: 1
2023-02-14 22:48:03,582:INFO:_display_container: 2
2023-02-14 22:48:03,582:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7455, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-14 22:48:03,583:INFO:create_model() successfully completed......................................
2023-02-14 22:48:03,759:INFO:SubProcess create_model() end ==================================
2023-02-14 22:48:03,759:INFO:Creating metrics dataframe
2023-02-14 22:48:03,772:INFO:Initializing K Neighbors Classifier
2023-02-14 22:48:03,773:INFO:Total runtime is 0.3200085838635763 minutes
2023-02-14 22:48:03,777:INFO:SubProcess create_model() called ==================================
2023-02-14 22:48:03,778:INFO:Initializing create_model()
2023-02-14 22:48:03,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:48:03,778:INFO:Checking exceptions
2023-02-14 22:48:03,779:INFO:Importing libraries
2023-02-14 22:48:03,779:INFO:Copying training dataset
2023-02-14 22:48:03,817:INFO:Defining folds
2023-02-14 22:48:03,817:INFO:Declaring metric variables
2023-02-14 22:48:03,821:INFO:Importing untrained model
2023-02-14 22:48:03,830:INFO:K Neighbors Classifier Imported successfully
2023-02-14 22:48:03,839:INFO:Starting cross validation
2023-02-14 22:48:03,841:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:48:05,829:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 22:48:06,128:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 22:48:06,174:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 22:48:06,745:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 22:48:10,093:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 22:48:10,206:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 22:48:10,567:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 22:48:10,813:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 22:48:12,902:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 22:48:13,038:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-14 22:48:13,789:INFO:Calculating mean and std
2023-02-14 22:48:13,790:INFO:Creating metrics dataframe
2023-02-14 22:48:13,794:INFO:Uploading results into container
2023-02-14 22:48:13,794:INFO:Uploading model into container now
2023-02-14 22:48:13,795:INFO:_master_model_container: 2
2023-02-14 22:48:13,795:INFO:_display_container: 2
2023-02-14 22:48:13,796:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-14 22:48:13,796:INFO:create_model() successfully completed......................................
2023-02-14 22:48:13,931:INFO:SubProcess create_model() end ==================================
2023-02-14 22:48:13,931:INFO:Creating metrics dataframe
2023-02-14 22:48:13,940:INFO:Initializing Naive Bayes
2023-02-14 22:48:13,941:INFO:Total runtime is 0.4894846717516581 minutes
2023-02-14 22:48:13,946:INFO:SubProcess create_model() called ==================================
2023-02-14 22:48:13,946:INFO:Initializing create_model()
2023-02-14 22:48:13,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:48:13,947:INFO:Checking exceptions
2023-02-14 22:48:13,947:INFO:Importing libraries
2023-02-14 22:48:13,947:INFO:Copying training dataset
2023-02-14 22:48:13,975:INFO:Defining folds
2023-02-14 22:48:13,976:INFO:Declaring metric variables
2023-02-14 22:48:13,982:INFO:Importing untrained model
2023-02-14 22:48:13,985:INFO:Naive Bayes Imported successfully
2023-02-14 22:48:13,992:INFO:Starting cross validation
2023-02-14 22:48:13,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:48:15,031:INFO:Calculating mean and std
2023-02-14 22:48:15,033:INFO:Creating metrics dataframe
2023-02-14 22:48:15,036:INFO:Uploading results into container
2023-02-14 22:48:15,036:INFO:Uploading model into container now
2023-02-14 22:48:15,037:INFO:_master_model_container: 3
2023-02-14 22:48:15,037:INFO:_display_container: 2
2023-02-14 22:48:15,037:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-14 22:48:15,037:INFO:create_model() successfully completed......................................
2023-02-14 22:48:15,169:INFO:SubProcess create_model() end ==================================
2023-02-14 22:48:15,169:INFO:Creating metrics dataframe
2023-02-14 22:48:15,183:INFO:Initializing Decision Tree Classifier
2023-02-14 22:48:15,184:INFO:Total runtime is 0.5101908365885417 minutes
2023-02-14 22:48:15,188:INFO:SubProcess create_model() called ==================================
2023-02-14 22:48:15,188:INFO:Initializing create_model()
2023-02-14 22:48:15,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:48:15,188:INFO:Checking exceptions
2023-02-14 22:48:15,188:INFO:Importing libraries
2023-02-14 22:48:15,188:INFO:Copying training dataset
2023-02-14 22:48:15,225:INFO:Defining folds
2023-02-14 22:48:15,225:INFO:Declaring metric variables
2023-02-14 22:48:15,229:INFO:Importing untrained model
2023-02-14 22:48:15,236:INFO:Decision Tree Classifier Imported successfully
2023-02-14 22:48:15,245:INFO:Starting cross validation
2023-02-14 22:48:15,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:48:19,537:INFO:Calculating mean and std
2023-02-14 22:48:19,538:INFO:Creating metrics dataframe
2023-02-14 22:48:19,543:INFO:Uploading results into container
2023-02-14 22:48:19,543:INFO:Uploading model into container now
2023-02-14 22:48:19,543:INFO:_master_model_container: 4
2023-02-14 22:48:19,543:INFO:_display_container: 2
2023-02-14 22:48:19,544:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7455, splitter='best')
2023-02-14 22:48:19,544:INFO:create_model() successfully completed......................................
2023-02-14 22:48:19,674:INFO:SubProcess create_model() end ==================================
2023-02-14 22:48:19,674:INFO:Creating metrics dataframe
2023-02-14 22:48:19,687:INFO:Initializing SVM - Linear Kernel
2023-02-14 22:48:19,687:INFO:Total runtime is 0.5852381507555644 minutes
2023-02-14 22:48:19,691:INFO:SubProcess create_model() called ==================================
2023-02-14 22:48:19,691:INFO:Initializing create_model()
2023-02-14 22:48:19,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:48:19,692:INFO:Checking exceptions
2023-02-14 22:48:19,692:INFO:Importing libraries
2023-02-14 22:48:19,692:INFO:Copying training dataset
2023-02-14 22:48:19,727:INFO:Defining folds
2023-02-14 22:48:19,727:INFO:Declaring metric variables
2023-02-14 22:48:19,732:INFO:Importing untrained model
2023-02-14 22:48:19,738:INFO:SVM - Linear Kernel Imported successfully
2023-02-14 22:48:19,747:INFO:Starting cross validation
2023-02-14 22:48:19,749:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:48:24,463:INFO:Calculating mean and std
2023-02-14 22:48:24,464:INFO:Creating metrics dataframe
2023-02-14 22:48:24,468:INFO:Uploading results into container
2023-02-14 22:48:24,469:INFO:Uploading model into container now
2023-02-14 22:48:24,470:INFO:_master_model_container: 5
2023-02-14 22:48:24,470:INFO:_display_container: 2
2023-02-14 22:48:24,471:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7455, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-14 22:48:24,471:INFO:create_model() successfully completed......................................
2023-02-14 22:48:24,605:INFO:SubProcess create_model() end ==================================
2023-02-14 22:48:24,605:INFO:Creating metrics dataframe
2023-02-14 22:48:24,617:INFO:Initializing Ridge Classifier
2023-02-14 22:48:24,617:INFO:Total runtime is 0.6674086809158326 minutes
2023-02-14 22:48:24,622:INFO:SubProcess create_model() called ==================================
2023-02-14 22:48:24,622:INFO:Initializing create_model()
2023-02-14 22:48:24,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:48:24,622:INFO:Checking exceptions
2023-02-14 22:48:24,622:INFO:Importing libraries
2023-02-14 22:48:24,622:INFO:Copying training dataset
2023-02-14 22:48:24,657:INFO:Defining folds
2023-02-14 22:48:24,657:INFO:Declaring metric variables
2023-02-14 22:48:24,664:INFO:Importing untrained model
2023-02-14 22:48:24,669:INFO:Ridge Classifier Imported successfully
2023-02-14 22:48:24,678:INFO:Starting cross validation
2023-02-14 22:48:24,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:48:24,918:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.6821e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T


2023-02-14 22:48:24,918:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.82393e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 22:48:24,918:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.67972e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 22:48:25,107:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.71335e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 22:48:25,107:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.66838e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 22:48:25,128:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.08437e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 22:48:25,128:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.64593e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 22:48:25,261:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.82275e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 22:48:25,274:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.65311e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-14 22:48:25,417:INFO:Calculating mean and std
2023-02-14 22:48:25,419:INFO:Creating metrics dataframe
2023-02-14 22:48:25,422:INFO:Uploading results into container
2023-02-14 22:48:25,424:INFO:Uploading model into container now
2023-02-14 22:48:25,426:INFO:_master_model_container: 6
2023-02-14 22:48:25,426:INFO:_display_container: 2
2023-02-14 22:48:25,426:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=7455, solver='auto', tol=0.001)
2023-02-14 22:48:25,426:INFO:create_model() successfully completed......................................
2023-02-14 22:48:25,554:INFO:SubProcess create_model() end ==================================
2023-02-14 22:48:25,555:INFO:Creating metrics dataframe
2023-02-14 22:48:25,567:INFO:Initializing Random Forest Classifier
2023-02-14 22:48:25,568:INFO:Total runtime is 0.6832687735557557 minutes
2023-02-14 22:48:25,573:INFO:SubProcess create_model() called ==================================
2023-02-14 22:48:25,573:INFO:Initializing create_model()
2023-02-14 22:48:25,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:48:25,573:INFO:Checking exceptions
2023-02-14 22:48:25,573:INFO:Importing libraries
2023-02-14 22:48:25,573:INFO:Copying training dataset
2023-02-14 22:48:25,609:INFO:Defining folds
2023-02-14 22:48:25,610:INFO:Declaring metric variables
2023-02-14 22:48:25,616:INFO:Importing untrained model
2023-02-14 22:48:25,621:INFO:Random Forest Classifier Imported successfully
2023-02-14 22:48:25,630:INFO:Starting cross validation
2023-02-14 22:48:25,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:48:53,299:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 22:48:58,553:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 22:49:00,737:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 22:49:54,189:INFO:Calculating mean and std
2023-02-14 22:49:54,190:INFO:Creating metrics dataframe
2023-02-14 22:49:54,196:INFO:Uploading results into container
2023-02-14 22:49:54,197:INFO:Uploading model into container now
2023-02-14 22:49:54,197:INFO:_master_model_container: 7
2023-02-14 22:49:54,198:INFO:_display_container: 2
2023-02-14 22:49:54,198:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7455, verbose=0, warm_start=False)
2023-02-14 22:49:54,199:INFO:create_model() successfully completed......................................
2023-02-14 22:49:54,335:INFO:SubProcess create_model() end ==================================
2023-02-14 22:49:54,336:INFO:Creating metrics dataframe
2023-02-14 22:49:54,348:INFO:Initializing Quadratic Discriminant Analysis
2023-02-14 22:49:54,349:INFO:Total runtime is 2.162951155503591 minutes
2023-02-14 22:49:54,351:INFO:SubProcess create_model() called ==================================
2023-02-14 22:49:54,351:INFO:Initializing create_model()
2023-02-14 22:49:54,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:49:54,351:INFO:Checking exceptions
2023-02-14 22:49:54,351:INFO:Importing libraries
2023-02-14 22:49:54,351:INFO:Copying training dataset
2023-02-14 22:49:54,391:INFO:Defining folds
2023-02-14 22:49:54,391:INFO:Declaring metric variables
2023-02-14 22:49:54,396:INFO:Importing untrained model
2023-02-14 22:49:54,402:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-14 22:49:54,410:INFO:Starting cross validation
2023-02-14 22:49:54,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:49:57,311:INFO:Calculating mean and std
2023-02-14 22:49:57,313:INFO:Creating metrics dataframe
2023-02-14 22:49:57,318:INFO:Uploading results into container
2023-02-14 22:49:57,319:INFO:Uploading model into container now
2023-02-14 22:49:57,320:INFO:_master_model_container: 8
2023-02-14 22:49:57,320:INFO:_display_container: 2
2023-02-14 22:49:57,320:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-14 22:49:57,321:INFO:create_model() successfully completed......................................
2023-02-14 22:49:57,457:INFO:SubProcess create_model() end ==================================
2023-02-14 22:49:57,457:INFO:Creating metrics dataframe
2023-02-14 22:49:57,470:INFO:Initializing Ada Boost Classifier
2023-02-14 22:49:57,470:INFO:Total runtime is 2.2149648825327555 minutes
2023-02-14 22:49:57,475:INFO:SubProcess create_model() called ==================================
2023-02-14 22:49:57,475:INFO:Initializing create_model()
2023-02-14 22:49:57,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:49:57,475:INFO:Checking exceptions
2023-02-14 22:49:57,475:INFO:Importing libraries
2023-02-14 22:49:57,476:INFO:Copying training dataset
2023-02-14 22:49:57,516:INFO:Defining folds
2023-02-14 22:49:57,516:INFO:Declaring metric variables
2023-02-14 22:49:57,520:INFO:Importing untrained model
2023-02-14 22:49:57,526:INFO:Ada Boost Classifier Imported successfully
2023-02-14 22:49:57,535:INFO:Starting cross validation
2023-02-14 22:49:57,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:50:23,279:INFO:Calculating mean and std
2023-02-14 22:50:23,280:INFO:Creating metrics dataframe
2023-02-14 22:50:23,285:INFO:Uploading results into container
2023-02-14 22:50:23,286:INFO:Uploading model into container now
2023-02-14 22:50:23,287:INFO:_master_model_container: 9
2023-02-14 22:50:23,287:INFO:_display_container: 2
2023-02-14 22:50:23,287:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7455)
2023-02-14 22:50:23,287:INFO:create_model() successfully completed......................................
2023-02-14 22:50:23,425:INFO:SubProcess create_model() end ==================================
2023-02-14 22:50:23,426:INFO:Creating metrics dataframe
2023-02-14 22:50:23,439:INFO:Initializing Gradient Boosting Classifier
2023-02-14 22:50:23,440:INFO:Total runtime is 2.6477981925010683 minutes
2023-02-14 22:50:23,445:INFO:SubProcess create_model() called ==================================
2023-02-14 22:50:23,445:INFO:Initializing create_model()
2023-02-14 22:50:23,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:50:23,446:INFO:Checking exceptions
2023-02-14 22:50:23,446:INFO:Importing libraries
2023-02-14 22:50:23,446:INFO:Copying training dataset
2023-02-14 22:50:23,489:INFO:Defining folds
2023-02-14 22:50:23,489:INFO:Declaring metric variables
2023-02-14 22:50:23,494:INFO:Importing untrained model
2023-02-14 22:50:23,501:INFO:Gradient Boosting Classifier Imported successfully
2023-02-14 22:50:23,508:INFO:Starting cross validation
2023-02-14 22:50:23,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:52:11,512:INFO:Calculating mean and std
2023-02-14 22:52:11,513:INFO:Creating metrics dataframe
2023-02-14 22:52:11,518:INFO:Uploading results into container
2023-02-14 22:52:11,519:INFO:Uploading model into container now
2023-02-14 22:52:11,519:INFO:_master_model_container: 10
2023-02-14 22:52:11,520:INFO:_display_container: 2
2023-02-14 22:52:11,521:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7455, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-14 22:52:11,521:INFO:create_model() successfully completed......................................
2023-02-14 22:52:11,655:INFO:SubProcess create_model() end ==================================
2023-02-14 22:52:11,655:INFO:Creating metrics dataframe
2023-02-14 22:52:11,669:INFO:Initializing Linear Discriminant Analysis
2023-02-14 22:52:11,669:INFO:Total runtime is 4.451617972056071 minutes
2023-02-14 22:52:11,674:INFO:SubProcess create_model() called ==================================
2023-02-14 22:52:11,675:INFO:Initializing create_model()
2023-02-14 22:52:11,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:52:11,675:INFO:Checking exceptions
2023-02-14 22:52:11,675:INFO:Importing libraries
2023-02-14 22:52:11,675:INFO:Copying training dataset
2023-02-14 22:52:11,713:INFO:Defining folds
2023-02-14 22:52:11,714:INFO:Declaring metric variables
2023-02-14 22:52:11,719:INFO:Importing untrained model
2023-02-14 22:52:11,723:INFO:Linear Discriminant Analysis Imported successfully
2023-02-14 22:52:11,733:INFO:Starting cross validation
2023-02-14 22:52:11,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:52:13,553:INFO:Calculating mean and std
2023-02-14 22:52:13,555:INFO:Creating metrics dataframe
2023-02-14 22:52:13,559:INFO:Uploading results into container
2023-02-14 22:52:13,560:INFO:Uploading model into container now
2023-02-14 22:52:13,560:INFO:_master_model_container: 11
2023-02-14 22:52:13,560:INFO:_display_container: 2
2023-02-14 22:52:13,561:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-14 22:52:13,561:INFO:create_model() successfully completed......................................
2023-02-14 22:52:13,856:INFO:SubProcess create_model() end ==================================
2023-02-14 22:52:13,856:INFO:Creating metrics dataframe
2023-02-14 22:52:13,877:INFO:Initializing Extra Trees Classifier
2023-02-14 22:52:13,878:INFO:Total runtime is 4.488429888089498 minutes
2023-02-14 22:52:13,882:INFO:SubProcess create_model() called ==================================
2023-02-14 22:52:13,883:INFO:Initializing create_model()
2023-02-14 22:52:13,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:52:13,883:INFO:Checking exceptions
2023-02-14 22:52:13,883:INFO:Importing libraries
2023-02-14 22:52:13,883:INFO:Copying training dataset
2023-02-14 22:52:13,918:INFO:Defining folds
2023-02-14 22:52:13,918:INFO:Declaring metric variables
2023-02-14 22:52:13,922:INFO:Importing untrained model
2023-02-14 22:52:13,927:INFO:Extra Trees Classifier Imported successfully
2023-02-14 22:52:13,935:INFO:Starting cross validation
2023-02-14 22:52:13,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:53:03,627:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 5.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 22:53:22,886:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 6.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 22:53:23,085:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 8.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 22:53:45,230:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 2.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 22:53:45,230:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 2.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 22:53:45,274:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 2.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 22:53:59,601:INFO:Calculating mean and std
2023-02-14 22:53:59,603:INFO:Creating metrics dataframe
2023-02-14 22:53:59,608:INFO:Uploading results into container
2023-02-14 22:53:59,610:INFO:Uploading model into container now
2023-02-14 22:53:59,610:INFO:_master_model_container: 12
2023-02-14 22:53:59,611:INFO:_display_container: 2
2023-02-14 22:53:59,611:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7455, verbose=0, warm_start=False)
2023-02-14 22:53:59,612:INFO:create_model() successfully completed......................................
2023-02-14 22:53:59,780:INFO:SubProcess create_model() end ==================================
2023-02-14 22:53:59,780:INFO:Creating metrics dataframe
2023-02-14 22:53:59,806:INFO:Initializing Extreme Gradient Boosting
2023-02-14 22:53:59,807:INFO:Total runtime is 6.253914916515351 minutes
2023-02-14 22:53:59,813:INFO:SubProcess create_model() called ==================================
2023-02-14 22:53:59,814:INFO:Initializing create_model()
2023-02-14 22:53:59,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:53:59,814:INFO:Checking exceptions
2023-02-14 22:53:59,814:INFO:Importing libraries
2023-02-14 22:53:59,814:INFO:Copying training dataset
2023-02-14 22:53:59,856:INFO:Defining folds
2023-02-14 22:53:59,856:INFO:Declaring metric variables
2023-02-14 22:53:59,863:INFO:Importing untrained model
2023-02-14 22:53:59,871:INFO:Extreme Gradient Boosting Imported successfully
2023-02-14 22:53:59,881:INFO:Starting cross validation
2023-02-14 22:53:59,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:55:12,845:INFO:Calculating mean and std
2023-02-14 22:55:12,847:INFO:Creating metrics dataframe
2023-02-14 22:55:12,851:INFO:Uploading results into container
2023-02-14 22:55:12,852:INFO:Uploading model into container now
2023-02-14 22:55:12,853:INFO:_master_model_container: 13
2023-02-14 22:55:12,853:INFO:_display_container: 2
2023-02-14 22:55:12,854:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-14 22:55:12,855:INFO:create_model() successfully completed......................................
2023-02-14 22:55:12,984:INFO:SubProcess create_model() end ==================================
2023-02-14 22:55:12,984:INFO:Creating metrics dataframe
2023-02-14 22:55:13,013:INFO:Initializing Light Gradient Boosting Machine
2023-02-14 22:55:13,013:INFO:Total runtime is 7.474011754989625 minutes
2023-02-14 22:55:13,017:INFO:SubProcess create_model() called ==================================
2023-02-14 22:55:13,018:INFO:Initializing create_model()
2023-02-14 22:55:13,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:55:13,018:INFO:Checking exceptions
2023-02-14 22:55:13,018:INFO:Importing libraries
2023-02-14 22:55:13,018:INFO:Copying training dataset
2023-02-14 22:55:13,054:INFO:Defining folds
2023-02-14 22:55:13,055:INFO:Declaring metric variables
2023-02-14 22:55:13,059:INFO:Importing untrained model
2023-02-14 22:55:13,067:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-14 22:55:13,078:INFO:Starting cross validation
2023-02-14 22:55:13,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:55:21,710:INFO:Calculating mean and std
2023-02-14 22:55:21,712:INFO:Creating metrics dataframe
2023-02-14 22:55:21,719:INFO:Uploading results into container
2023-02-14 22:55:21,720:INFO:Uploading model into container now
2023-02-14 22:55:21,720:INFO:_master_model_container: 14
2023-02-14 22:55:21,720:INFO:_display_container: 2
2023-02-14 22:55:21,720:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7455, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-14 22:55:21,721:INFO:create_model() successfully completed......................................
2023-02-14 22:55:21,850:INFO:SubProcess create_model() end ==================================
2023-02-14 22:55:21,851:INFO:Creating metrics dataframe
2023-02-14 22:55:21,877:INFO:Initializing Dummy Classifier
2023-02-14 22:55:21,890:INFO:Total runtime is 7.6219550490379335 minutes
2023-02-14 22:55:21,895:INFO:SubProcess create_model() called ==================================
2023-02-14 22:55:21,895:INFO:Initializing create_model()
2023-02-14 22:55:21,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025240B153A0>, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:55:21,896:INFO:Checking exceptions
2023-02-14 22:55:21,896:INFO:Importing libraries
2023-02-14 22:55:21,896:INFO:Copying training dataset
2023-02-14 22:55:21,939:INFO:Defining folds
2023-02-14 22:55:21,939:INFO:Declaring metric variables
2023-02-14 22:55:21,946:INFO:Importing untrained model
2023-02-14 22:55:21,949:INFO:Dummy Classifier Imported successfully
2023-02-14 22:55:21,958:INFO:Starting cross validation
2023-02-14 22:55:21,960:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:55:22,166:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 22:55:22,170:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 22:55:22,174:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 22:55:22,250:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 22:55:22,335:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 22:55:22,396:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 22:55:22,398:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 22:55:22,412:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 22:55:22,516:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 22:55:22,553:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-14 22:55:22,667:INFO:Calculating mean and std
2023-02-14 22:55:22,668:INFO:Creating metrics dataframe
2023-02-14 22:55:22,672:INFO:Uploading results into container
2023-02-14 22:55:22,672:INFO:Uploading model into container now
2023-02-14 22:55:22,672:INFO:_master_model_container: 15
2023-02-14 22:55:22,673:INFO:_display_container: 2
2023-02-14 22:55:22,673:INFO:DummyClassifier(constant=None, random_state=7455, strategy='prior')
2023-02-14 22:55:22,673:INFO:create_model() successfully completed......................................
2023-02-14 22:55:22,816:INFO:SubProcess create_model() end ==================================
2023-02-14 22:55:22,816:INFO:Creating metrics dataframe
2023-02-14 22:55:22,847:INFO:Initializing create_model()
2023-02-14 22:55:22,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7455, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:55:22,848:INFO:Checking exceptions
2023-02-14 22:55:22,851:INFO:Importing libraries
2023-02-14 22:55:22,851:INFO:Copying training dataset
2023-02-14 22:55:22,885:INFO:Defining folds
2023-02-14 22:55:22,885:INFO:Declaring metric variables
2023-02-14 22:55:22,885:INFO:Importing untrained model
2023-02-14 22:55:22,885:INFO:Declaring custom model
2023-02-14 22:55:22,886:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-14 22:55:22,893:INFO:Cross validation set to False
2023-02-14 22:55:22,893:INFO:Fitting Model
2023-02-14 22:55:24,182:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7455, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-14 22:55:24,182:INFO:create_model() successfully completed......................................
2023-02-14 22:55:24,404:INFO:Initializing create_model()
2023-02-14 22:55:24,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:55:24,404:INFO:Checking exceptions
2023-02-14 22:55:24,406:INFO:Importing libraries
2023-02-14 22:55:24,406:INFO:Copying training dataset
2023-02-14 22:55:24,448:INFO:Defining folds
2023-02-14 22:55:24,448:INFO:Declaring metric variables
2023-02-14 22:55:24,449:INFO:Importing untrained model
2023-02-14 22:55:24,449:INFO:Declaring custom model
2023-02-14 22:55:24,450:INFO:Extreme Gradient Boosting Imported successfully
2023-02-14 22:55:24,452:INFO:Cross validation set to False
2023-02-14 22:55:24,452:INFO:Fitting Model
2023-02-14 22:55:33,000:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-14 22:55:33,000:INFO:create_model() successfully completed......................................
2023-02-14 22:55:33,127:INFO:Initializing create_model()
2023-02-14 22:55:33,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=DummyClassifier(constant=None, random_state=7455, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:55:33,128:INFO:Checking exceptions
2023-02-14 22:55:33,131:INFO:Importing libraries
2023-02-14 22:55:33,131:INFO:Copying training dataset
2023-02-14 22:55:33,159:INFO:Defining folds
2023-02-14 22:55:33,159:INFO:Declaring metric variables
2023-02-14 22:55:33,159:INFO:Importing untrained model
2023-02-14 22:55:33,159:INFO:Declaring custom model
2023-02-14 22:55:33,160:INFO:Dummy Classifier Imported successfully
2023-02-14 22:55:33,161:INFO:Cross validation set to False
2023-02-14 22:55:33,161:INFO:Fitting Model
2023-02-14 22:55:33,250:INFO:DummyClassifier(constant=None, random_state=7455, strategy='prior')
2023-02-14 22:55:33,250:INFO:create_model() successfully completed......................................
2023-02-14 22:55:33,423:INFO:_master_model_container: 15
2023-02-14 22:55:33,423:INFO:_display_container: 2
2023-02-14 22:55:33,425:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7455, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), DummyClassifier(constant=None, random_state=7455, strategy='prior')]
2023-02-14 22:55:33,425:INFO:compare_models() successfully completed......................................
2023-02-14 22:55:33,445:INFO:Initializing tune_model()
2023-02-14 22:55:33,445:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7455, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>)
2023-02-14 22:55:33,445:INFO:Checking exceptions
2023-02-14 22:55:33,477:INFO:Copying training dataset
2023-02-14 22:55:33,501:INFO:Checking base model
2023-02-14 22:55:33,501:INFO:Base model : Light Gradient Boosting Machine
2023-02-14 22:55:33,506:INFO:Declaring metric variables
2023-02-14 22:55:33,510:INFO:Defining Hyperparameters
2023-02-14 22:55:33,656:INFO:Tuning with n_jobs=-1
2023-02-14 22:55:33,656:INFO:Initializing RandomizedSearchCV
2023-02-14 22:57:25,832:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 22:57:48,033:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 0.01, 'actual_estimator__num_leaves': 200, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 1e-06, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.8}
2023-02-14 22:57:48,033:INFO:Hyperparameter search completed
2023-02-14 22:57:48,034:INFO:SubProcess create_model() called ==================================
2023-02-14 22:57:48,035:INFO:Initializing create_model()
2023-02-14 22:57:48,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7455, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025242C939D0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.4, 'reg_alpha': 0.01, 'num_leaves': 200, 'n_estimators': 60, 'min_split_gain': 0.8, 'min_child_samples': 6, 'learning_rate': 1e-06, 'feature_fraction': 0.5, 'bagging_freq': 0, 'bagging_fraction': 0.8})
2023-02-14 22:57:48,035:INFO:Checking exceptions
2023-02-14 22:57:48,035:INFO:Importing libraries
2023-02-14 22:57:48,035:INFO:Copying training dataset
2023-02-14 22:57:48,068:INFO:Defining folds
2023-02-14 22:57:48,068:INFO:Declaring metric variables
2023-02-14 22:57:48,071:INFO:Importing untrained model
2023-02-14 22:57:48,073:INFO:Declaring custom model
2023-02-14 22:57:48,078:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-14 22:57:48,086:INFO:Starting cross validation
2023-02-14 22:57:48,088:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:57:51,690:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 22:57:51,699:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-14 22:57:56,647:INFO:Calculating mean and std
2023-02-14 22:57:56,649:INFO:Creating metrics dataframe
2023-02-14 22:57:56,656:INFO:Finalizing model
2023-02-14 22:57:58,874:INFO:Uploading results into container
2023-02-14 22:57:58,876:INFO:Uploading model into container now
2023-02-14 22:57:58,877:INFO:_master_model_container: 16
2023-02-14 22:57:58,877:INFO:_display_container: 3
2023-02-14 22:57:58,877:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=1e-06, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=60, n_jobs=-1, num_leaves=200, objective=None,
               random_state=7455, reg_alpha=0.01, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-14 22:57:58,877:INFO:create_model() successfully completed......................................
2023-02-14 22:57:59,011:INFO:SubProcess create_model() end ==================================
2023-02-14 22:57:59,012:INFO:choose_better activated
2023-02-14 22:57:59,015:INFO:SubProcess create_model() called ==================================
2023-02-14 22:57:59,016:INFO:Initializing create_model()
2023-02-14 22:57:59,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7455, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-14 22:57:59,016:INFO:Checking exceptions
2023-02-14 22:57:59,018:INFO:Importing libraries
2023-02-14 22:57:59,019:INFO:Copying training dataset
2023-02-14 22:57:59,058:INFO:Defining folds
2023-02-14 22:57:59,058:INFO:Declaring metric variables
2023-02-14 22:57:59,058:INFO:Importing untrained model
2023-02-14 22:57:59,058:INFO:Declaring custom model
2023-02-14 22:57:59,059:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-14 22:57:59,059:INFO:Starting cross validation
2023-02-14 22:57:59,061:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-14 22:58:00,787:INFO:Calculating mean and std
2023-02-14 22:58:00,788:INFO:Creating metrics dataframe
2023-02-14 22:58:00,794:INFO:Finalizing model
2023-02-14 22:58:00,963:INFO:Uploading results into container
2023-02-14 22:58:00,964:INFO:Uploading model into container now
2023-02-14 22:58:00,964:INFO:_master_model_container: 17
2023-02-14 22:58:00,964:INFO:_display_container: 4
2023-02-14 22:58:00,965:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7455, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-14 22:58:00,965:INFO:create_model() successfully completed......................................
2023-02-14 22:58:01,198:INFO:SubProcess create_model() end ==================================
2023-02-14 22:58:01,199:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7455, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9362
2023-02-14 22:58:01,216:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=1e-06, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=60, n_jobs=-1, num_leaves=200, objective=None,
               random_state=7455, reg_alpha=0.01, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9363
2023-02-14 22:58:01,216:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=1e-06, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=60, n_jobs=-1, num_leaves=200, objective=None,
               random_state=7455, reg_alpha=0.01, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-02-14 22:58:01,216:INFO:choose_better completed
2023-02-14 22:58:01,227:INFO:_master_model_container: 17
2023-02-14 22:58:01,227:INFO:_display_container: 3
2023-02-14 22:58:01,228:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=1e-06, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=60, n_jobs=-1, num_leaves=200, objective=None,
               random_state=7455, reg_alpha=0.01, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-14 22:58:01,228:INFO:tune_model() successfully completed......................................
2023-02-14 22:58:01,375:INFO:Initializing tune_model()
2023-02-14 22:58:01,375:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>)
2023-02-14 22:58:01,375:INFO:Checking exceptions
2023-02-14 22:58:01,417:INFO:Copying training dataset
2023-02-14 22:58:01,442:INFO:Checking base model
2023-02-14 22:58:01,442:INFO:Base model : Extreme Gradient Boosting
2023-02-14 22:58:01,447:INFO:Declaring metric variables
2023-02-14 22:58:01,452:INFO:Defining Hyperparameters
2023-02-14 22:58:01,621:INFO:Tuning with n_jobs=-1
2023-02-14 22:58:01,621:INFO:Initializing RandomizedSearchCV
2023-02-14 23:10:49,607:INFO:best_params: {'actual_estimator__subsample': 0.9, 'actual_estimator__scale_pos_weight': 0.0, 'actual_estimator__reg_lambda': 0.0001, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.005, 'actual_estimator__colsample_bytree': 0.5}
2023-02-14 23:10:49,609:INFO:Hyperparameter search completed
2023-02-14 23:10:49,609:INFO:SubProcess create_model() called ==================================
2023-02-14 23:10:49,609:INFO:Initializing create_model()
2023-02-14 23:10:49,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025240B15700>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025221DA0BB0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.9, 'scale_pos_weight': 0.0, 'reg_lambda': 0.0001, 'reg_alpha': 0.005, 'n_estimators': 130, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.005, 'colsample_bytree': 0.5})
2023-02-14 23:10:49,635:INFO:Checking exceptions
2023-02-14 23:10:49,636:INFO:Importing libraries
2023-02-14 23:10:49,636:INFO:Copying training dataset
2023-02-14 23:10:49,667:INFO:Defining folds
2023-02-14 23:10:49,667:INFO:Declaring metric variables
2023-02-14 23:10:49,670:INFO:Importing untrained model
2023-02-14 23:10:49,670:INFO:Declaring custom model
2023-02-14 23:10:49,676:INFO:Extreme Gradient Boosting Imported successfully
2023-02-14 23:10:49,686:INFO:Starting cross validation
2023-02-14 23:10:49,688:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 08:31:02,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 08:31:02,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 08:31:02,263:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 08:31:02,263:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 08:31:03,762:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 08:34:25,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 08:34:25,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 08:34:25,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 08:34:25,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 08:34:26,627:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 10:58:58,151:INFO:PyCaret ClassificationExperiment
2023-02-15 10:58:58,153:INFO:Logging name: clf-default-name
2023-02-15 10:58:58,154:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-15 10:58:58,154:INFO:version 3.0.0.rc9
2023-02-15 10:58:58,154:INFO:Initializing setup()
2023-02-15 10:58:58,154:INFO:self.USI: 1888
2023-02-15 10:58:58,154:INFO:self._variable_keys: {'is_multiclass', 'exp_id', 'y', 'gpu_param', 'X_train', 'target_param', 'gpu_n_jobs_param', 'y_test', 'USI', 'n_jobs_param', 'X_test', 'seed', 'fold_shuffle_param', '_available_plots', 'y_train', 'fold_groups_param', 'exp_name_log', 'logging_param', 'X', 'fold_generator', 'html_param', '_ml_usecase', 'idx', 'log_plots_param', 'memory', 'pipeline', 'fix_imbalance', 'data'}
2023-02-15 10:58:58,154:INFO:Checking environment
2023-02-15 10:58:58,154:INFO:python_version: 3.9.15
2023-02-15 10:58:58,154:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-15 10:58:58,154:INFO:machine: AMD64
2023-02-15 10:58:58,154:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-15 10:58:58,155:INFO:Memory: svmem(total=8469581824, available=767860736, percent=90.9, used=7701721088, free=767860736)
2023-02-15 10:58:58,156:INFO:Physical Core: 4
2023-02-15 10:58:58,156:INFO:Logical Core: 4
2023-02-15 10:58:58,156:INFO:Checking libraries
2023-02-15 10:58:58,156:INFO:System:
2023-02-15 10:58:58,156:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-15 10:58:58,156:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-15 10:58:58,156:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-15 10:58:58,156:INFO:PyCaret required dependencies:
2023-02-15 10:58:58,156:INFO:                 pip: 22.3.1
2023-02-15 10:58:58,156:INFO:          setuptools: 60.10.0
2023-02-15 10:58:58,156:INFO:             pycaret: 3.0.0rc9
2023-02-15 10:58:58,156:INFO:             IPython: 7.31.1
2023-02-15 10:58:58,156:INFO:          ipywidgets: 7.6.5
2023-02-15 10:58:58,157:INFO:                tqdm: 4.64.1
2023-02-15 10:58:58,157:INFO:               numpy: 1.21.5
2023-02-15 10:58:58,157:INFO:              pandas: 1.4.4
2023-02-15 10:58:58,157:INFO:              jinja2: 2.11.3
2023-02-15 10:58:58,157:INFO:               scipy: 1.9.3
2023-02-15 10:58:58,157:INFO:              joblib: 1.2.0
2023-02-15 10:58:58,157:INFO:             sklearn: 1.0.2
2023-02-15 10:58:58,157:INFO:                pyod: 1.0.7
2023-02-15 10:58:58,157:INFO:            imblearn: 0.10.1
2023-02-15 10:58:58,157:INFO:   category_encoders: 2.6.0
2023-02-15 10:58:58,157:INFO:            lightgbm: 3.3.5
2023-02-15 10:58:58,157:INFO:               numba: 0.56.4
2023-02-15 10:58:58,157:INFO:            requests: 2.28.1
2023-02-15 10:58:58,157:INFO:          matplotlib: 3.6.2
2023-02-15 10:58:58,157:INFO:          scikitplot: 0.3.7
2023-02-15 10:58:58,158:INFO:         yellowbrick: 1.5
2023-02-15 10:58:58,158:INFO:              plotly: 5.9.0
2023-02-15 10:58:58,158:INFO:             kaleido: 0.2.1
2023-02-15 10:58:58,158:INFO:         statsmodels: 0.13.2
2023-02-15 10:58:58,158:INFO:              sktime: 0.16.1
2023-02-15 10:58:58,158:INFO:               tbats: 1.1.2
2023-02-15 10:58:58,158:INFO:            pmdarima: 2.0.2
2023-02-15 10:58:58,158:INFO:              psutil: 5.9.0
2023-02-15 10:58:58,158:INFO:PyCaret optional dependencies:
2023-02-15 10:58:58,176:INFO:                shap: 0.41.0
2023-02-15 10:58:58,176:INFO:           interpret: Not installed
2023-02-15 10:58:58,176:INFO:                umap: Not installed
2023-02-15 10:58:58,176:INFO:    pandas_profiling: 4.0.0
2023-02-15 10:58:58,176:INFO:  explainerdashboard: 0.3.6.2
2023-02-15 10:58:58,176:INFO:             autoviz: 0.1.58
2023-02-15 10:58:58,176:INFO:           fairlearn: Not installed
2023-02-15 10:58:58,176:INFO:             xgboost: 1.7.3
2023-02-15 10:58:58,176:INFO:            catboost: Not installed
2023-02-15 10:58:58,176:INFO:              kmodes: Not installed
2023-02-15 10:58:58,176:INFO:             mlxtend: Not installed
2023-02-15 10:58:58,176:INFO:       statsforecast: Not installed
2023-02-15 10:58:58,176:INFO:        tune_sklearn: Not installed
2023-02-15 10:58:58,176:INFO:                 ray: Not installed
2023-02-15 10:58:58,176:INFO:            hyperopt: Not installed
2023-02-15 10:58:58,176:INFO:              optuna: 2.10.1
2023-02-15 10:58:58,176:INFO:               skopt: Not installed
2023-02-15 10:58:58,176:INFO:              mlflow: Not installed
2023-02-15 10:58:58,176:INFO:              gradio: Not installed
2023-02-15 10:58:58,176:INFO:             fastapi: Not installed
2023-02-15 10:58:58,176:INFO:             uvicorn: Not installed
2023-02-15 10:58:58,176:INFO:              m2cgen: Not installed
2023-02-15 10:58:58,176:INFO:           evidently: Not installed
2023-02-15 10:58:58,176:INFO:               fugue: Not installed
2023-02-15 10:58:58,176:INFO:           streamlit: Not installed
2023-02-15 10:58:58,176:INFO:             prophet: Not installed
2023-02-15 10:58:58,176:INFO:None
2023-02-15 10:58:58,177:INFO:Set up data.
2023-02-15 10:58:58,197:INFO:Set up train/test split.
2023-02-15 10:58:58,250:INFO:Set up index.
2023-02-15 10:58:58,253:INFO:Set up folding strategy.
2023-02-15 10:58:58,253:INFO:Assigning column types.
2023-02-15 10:58:58,269:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 10:58:58,328:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 10:58:58,332:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-15 10:58:58,385:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 10:58:58,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 10:58:58,987:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 10:58:58,990:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-15 10:58:59,031:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 10:58:59,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 10:58:59,034:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 10:58:59,090:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-15 10:58:59,120:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 10:58:59,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 10:58:59,179:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-15 10:58:59,212:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 10:58:59,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 10:58:59,215:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-15 10:58:59,304:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 10:58:59,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 10:58:59,393:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 10:58:59,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 10:58:59,399:INFO:Preparing preprocessing pipeline...
2023-02-15 10:58:59,407:INFO:Set up simple imputation.
2023-02-15 10:58:59,407:INFO:Set up imbalanced handling.
2023-02-15 10:58:59,527:INFO:Finished creating preprocessing pipeline.
2023-02-15 10:58:59,536:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2023-02-15 10:58:59,537:INFO:Creating final display dataframe.
2023-02-15 10:59:00,354:INFO:Setup _display_container:                     Description             Value
0                    Session id              1911
1                        Target      inadimplente
2                   Target type            Binary
3           Original data shape       (88000, 11)
4        Transformed data shape      (141361, 11)
5   Transformed train set shape      (114960, 11)
6    Transformed test set shape       (26401, 11)
7              Numeric features                10
8      Rows with missing values             19.8%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                Fix imbalance              True
14         Fix imbalance method             SMOTE
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              1888
2023-02-15 10:59:00,467:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 10:59:00,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 10:59:00,571:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 10:59:00,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 10:59:00,580:INFO:setup() successfully completed in 2.44s...............
2023-02-15 10:59:00,580:INFO:Initializing compare_models()
2023-02-15 10:59:00,580:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-15 10:59:00,580:INFO:Checking exceptions
2023-02-15 10:59:00,598:INFO:Preparing display monitor
2023-02-15 10:59:00,642:INFO:Initializing Logistic Regression
2023-02-15 10:59:00,642:INFO:Total runtime is 3.0159950256347657e-06 minutes
2023-02-15 10:59:00,646:INFO:SubProcess create_model() called ==================================
2023-02-15 10:59:00,647:INFO:Initializing create_model()
2023-02-15 10:59:00,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 10:59:00,647:INFO:Checking exceptions
2023-02-15 10:59:00,647:INFO:Importing libraries
2023-02-15 10:59:00,648:INFO:Copying training dataset
2023-02-15 10:59:00,715:INFO:Defining folds
2023-02-15 10:59:00,715:INFO:Declaring metric variables
2023-02-15 10:59:00,723:INFO:Importing untrained model
2023-02-15 10:59:00,728:INFO:Logistic Regression Imported successfully
2023-02-15 10:59:00,760:INFO:Starting cross validation
2023-02-15 10:59:00,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 10:59:18,739:INFO:Calculating mean and std
2023-02-15 10:59:18,751:INFO:Creating metrics dataframe
2023-02-15 10:59:18,760:INFO:Uploading results into container
2023-02-15 10:59:18,762:INFO:Uploading model into container now
2023-02-15 10:59:18,764:INFO:_master_model_container: 1
2023-02-15 10:59:18,764:INFO:_display_container: 2
2023-02-15 10:59:18,765:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1911, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-15 10:59:18,765:INFO:create_model() successfully completed......................................
2023-02-15 10:59:19,352:INFO:SubProcess create_model() end ==================================
2023-02-15 10:59:19,352:INFO:Creating metrics dataframe
2023-02-15 10:59:19,365:INFO:Initializing K Neighbors Classifier
2023-02-15 10:59:19,365:INFO:Total runtime is 0.31205477317174274 minutes
2023-02-15 10:59:19,371:INFO:SubProcess create_model() called ==================================
2023-02-15 10:59:19,372:INFO:Initializing create_model()
2023-02-15 10:59:19,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 10:59:19,372:INFO:Checking exceptions
2023-02-15 10:59:19,373:INFO:Importing libraries
2023-02-15 10:59:19,374:INFO:Copying training dataset
2023-02-15 10:59:19,412:INFO:Defining folds
2023-02-15 10:59:19,412:INFO:Declaring metric variables
2023-02-15 10:59:19,416:INFO:Importing untrained model
2023-02-15 10:59:19,421:INFO:K Neighbors Classifier Imported successfully
2023-02-15 10:59:19,431:INFO:Starting cross validation
2023-02-15 10:59:19,453:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 10:59:20,906:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 10:59:21,380:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 10:59:21,621:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 10:59:21,632:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 10:59:23,649:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 10:59:23,906:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 10:59:24,326:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 10:59:24,336:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 10:59:26,125:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 10:59:26,439:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 10:59:26,899:INFO:Calculating mean and std
2023-02-15 10:59:26,901:INFO:Creating metrics dataframe
2023-02-15 10:59:26,907:INFO:Uploading results into container
2023-02-15 10:59:26,908:INFO:Uploading model into container now
2023-02-15 10:59:26,908:INFO:_master_model_container: 2
2023-02-15 10:59:26,909:INFO:_display_container: 2
2023-02-15 10:59:26,909:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-15 10:59:26,909:INFO:create_model() successfully completed......................................
2023-02-15 10:59:27,052:INFO:SubProcess create_model() end ==================================
2023-02-15 10:59:27,052:INFO:Creating metrics dataframe
2023-02-15 10:59:27,065:INFO:Initializing Naive Bayes
2023-02-15 10:59:27,065:INFO:Total runtime is 0.4403851151466369 minutes
2023-02-15 10:59:27,069:INFO:SubProcess create_model() called ==================================
2023-02-15 10:59:27,070:INFO:Initializing create_model()
2023-02-15 10:59:27,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 10:59:27,070:INFO:Checking exceptions
2023-02-15 10:59:27,070:INFO:Importing libraries
2023-02-15 10:59:27,070:INFO:Copying training dataset
2023-02-15 10:59:27,101:INFO:Defining folds
2023-02-15 10:59:27,102:INFO:Declaring metric variables
2023-02-15 10:59:27,109:INFO:Importing untrained model
2023-02-15 10:59:27,114:INFO:Naive Bayes Imported successfully
2023-02-15 10:59:27,124:INFO:Starting cross validation
2023-02-15 10:59:27,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 10:59:27,731:INFO:Calculating mean and std
2023-02-15 10:59:27,732:INFO:Creating metrics dataframe
2023-02-15 10:59:27,736:INFO:Uploading results into container
2023-02-15 10:59:27,737:INFO:Uploading model into container now
2023-02-15 10:59:27,737:INFO:_master_model_container: 3
2023-02-15 10:59:27,737:INFO:_display_container: 2
2023-02-15 10:59:27,739:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-15 10:59:27,740:INFO:create_model() successfully completed......................................
2023-02-15 10:59:27,881:INFO:SubProcess create_model() end ==================================
2023-02-15 10:59:27,881:INFO:Creating metrics dataframe
2023-02-15 10:59:27,893:INFO:Initializing Decision Tree Classifier
2023-02-15 10:59:27,894:INFO:Total runtime is 0.4541960477828979 minutes
2023-02-15 10:59:27,898:INFO:SubProcess create_model() called ==================================
2023-02-15 10:59:27,898:INFO:Initializing create_model()
2023-02-15 10:59:27,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 10:59:27,898:INFO:Checking exceptions
2023-02-15 10:59:27,898:INFO:Importing libraries
2023-02-15 10:59:27,898:INFO:Copying training dataset
2023-02-15 10:59:27,931:INFO:Defining folds
2023-02-15 10:59:27,931:INFO:Declaring metric variables
2023-02-15 10:59:27,936:INFO:Importing untrained model
2023-02-15 10:59:27,944:INFO:Decision Tree Classifier Imported successfully
2023-02-15 10:59:27,952:INFO:Starting cross validation
2023-02-15 10:59:27,954:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 10:59:31,191:INFO:Calculating mean and std
2023-02-15 10:59:31,193:INFO:Creating metrics dataframe
2023-02-15 10:59:31,196:INFO:Uploading results into container
2023-02-15 10:59:31,197:INFO:Uploading model into container now
2023-02-15 10:59:31,197:INFO:_master_model_container: 4
2023-02-15 10:59:31,197:INFO:_display_container: 2
2023-02-15 10:59:31,197:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1911, splitter='best')
2023-02-15 10:59:31,198:INFO:create_model() successfully completed......................................
2023-02-15 10:59:31,352:INFO:SubProcess create_model() end ==================================
2023-02-15 10:59:31,352:INFO:Creating metrics dataframe
2023-02-15 10:59:31,367:INFO:Initializing SVM - Linear Kernel
2023-02-15 10:59:31,367:INFO:Total runtime is 0.5120883901913961 minutes
2023-02-15 10:59:31,374:INFO:SubProcess create_model() called ==================================
2023-02-15 10:59:31,374:INFO:Initializing create_model()
2023-02-15 10:59:31,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 10:59:31,375:INFO:Checking exceptions
2023-02-15 10:59:31,375:INFO:Importing libraries
2023-02-15 10:59:31,375:INFO:Copying training dataset
2023-02-15 10:59:31,409:INFO:Defining folds
2023-02-15 10:59:31,409:INFO:Declaring metric variables
2023-02-15 10:59:31,414:INFO:Importing untrained model
2023-02-15 10:59:31,419:INFO:SVM - Linear Kernel Imported successfully
2023-02-15 10:59:31,429:INFO:Starting cross validation
2023-02-15 10:59:31,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 10:59:34,883:INFO:Calculating mean and std
2023-02-15 10:59:34,884:INFO:Creating metrics dataframe
2023-02-15 10:59:34,887:INFO:Uploading results into container
2023-02-15 10:59:34,889:INFO:Uploading model into container now
2023-02-15 10:59:34,890:INFO:_master_model_container: 5
2023-02-15 10:59:34,891:INFO:_display_container: 2
2023-02-15 10:59:34,892:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1911, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-15 10:59:34,892:INFO:create_model() successfully completed......................................
2023-02-15 10:59:35,037:INFO:SubProcess create_model() end ==================================
2023-02-15 10:59:35,037:INFO:Creating metrics dataframe
2023-02-15 10:59:35,050:INFO:Initializing Ridge Classifier
2023-02-15 10:59:35,050:INFO:Total runtime is 0.5734655102094014 minutes
2023-02-15 10:59:35,053:INFO:SubProcess create_model() called ==================================
2023-02-15 10:59:35,054:INFO:Initializing create_model()
2023-02-15 10:59:35,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 10:59:35,056:INFO:Checking exceptions
2023-02-15 10:59:35,056:INFO:Importing libraries
2023-02-15 10:59:35,056:INFO:Copying training dataset
2023-02-15 10:59:35,085:INFO:Defining folds
2023-02-15 10:59:35,085:INFO:Declaring metric variables
2023-02-15 10:59:35,090:INFO:Importing untrained model
2023-02-15 10:59:35,096:INFO:Ridge Classifier Imported successfully
2023-02-15 10:59:35,104:INFO:Starting cross validation
2023-02-15 10:59:35,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 10:59:35,885:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.02321e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 10:59:36,104:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.61e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 10:59:36,112:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.71202e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 10:59:36,113:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.47386e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 10:59:36,134:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.50858e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 10:59:36,283:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=9.52878e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 10:59:36,284:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.32979e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 10:59:36,319:INFO:Calculating mean and std
2023-02-15 10:59:36,320:INFO:Creating metrics dataframe
2023-02-15 10:59:36,326:INFO:Uploading results into container
2023-02-15 10:59:36,327:INFO:Uploading model into container now
2023-02-15 10:59:36,327:INFO:_master_model_container: 6
2023-02-15 10:59:36,327:INFO:_display_container: 2
2023-02-15 10:59:36,327:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1911, solver='auto', tol=0.001)
2023-02-15 10:59:36,327:INFO:create_model() successfully completed......................................
2023-02-15 10:59:36,530:INFO:SubProcess create_model() end ==================================
2023-02-15 10:59:36,530:INFO:Creating metrics dataframe
2023-02-15 10:59:36,544:INFO:Initializing Random Forest Classifier
2023-02-15 10:59:36,544:INFO:Total runtime is 0.5983706752459208 minutes
2023-02-15 10:59:36,548:INFO:SubProcess create_model() called ==================================
2023-02-15 10:59:36,549:INFO:Initializing create_model()
2023-02-15 10:59:36,549:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 10:59:36,549:INFO:Checking exceptions
2023-02-15 10:59:36,549:INFO:Importing libraries
2023-02-15 10:59:36,549:INFO:Copying training dataset
2023-02-15 10:59:36,578:INFO:Defining folds
2023-02-15 10:59:36,579:INFO:Declaring metric variables
2023-02-15 10:59:36,584:INFO:Importing untrained model
2023-02-15 10:59:36,590:INFO:Random Forest Classifier Imported successfully
2023-02-15 10:59:36,600:INFO:Starting cross validation
2023-02-15 10:59:36,603:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:00:34,566:INFO:Calculating mean and std
2023-02-15 11:00:34,567:INFO:Creating metrics dataframe
2023-02-15 11:00:34,573:INFO:Uploading results into container
2023-02-15 11:00:34,574:INFO:Uploading model into container now
2023-02-15 11:00:34,574:INFO:_master_model_container: 7
2023-02-15 11:00:34,574:INFO:_display_container: 2
2023-02-15 11:00:34,575:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1911, verbose=0, warm_start=False)
2023-02-15 11:00:34,575:INFO:create_model() successfully completed......................................
2023-02-15 11:00:34,740:INFO:SubProcess create_model() end ==================================
2023-02-15 11:00:34,740:INFO:Creating metrics dataframe
2023-02-15 11:00:34,758:INFO:Initializing Quadratic Discriminant Analysis
2023-02-15 11:00:34,758:INFO:Total runtime is 1.568599279721578 minutes
2023-02-15 11:00:34,764:INFO:SubProcess create_model() called ==================================
2023-02-15 11:00:34,765:INFO:Initializing create_model()
2023-02-15 11:00:34,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:00:34,765:INFO:Checking exceptions
2023-02-15 11:00:34,765:INFO:Importing libraries
2023-02-15 11:00:34,766:INFO:Copying training dataset
2023-02-15 11:00:34,799:INFO:Defining folds
2023-02-15 11:00:34,799:INFO:Declaring metric variables
2023-02-15 11:00:34,805:INFO:Importing untrained model
2023-02-15 11:00:34,811:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-15 11:00:34,821:INFO:Starting cross validation
2023-02-15 11:00:34,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:00:36,810:INFO:Calculating mean and std
2023-02-15 11:00:36,811:INFO:Creating metrics dataframe
2023-02-15 11:00:36,816:INFO:Uploading results into container
2023-02-15 11:00:36,817:INFO:Uploading model into container now
2023-02-15 11:00:36,817:INFO:_master_model_container: 8
2023-02-15 11:00:36,818:INFO:_display_container: 2
2023-02-15 11:00:36,818:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-15 11:00:36,818:INFO:create_model() successfully completed......................................
2023-02-15 11:00:36,978:INFO:SubProcess create_model() end ==================================
2023-02-15 11:00:36,978:INFO:Creating metrics dataframe
2023-02-15 11:00:36,996:INFO:Initializing Ada Boost Classifier
2023-02-15 11:00:36,996:INFO:Total runtime is 1.6058995644251506 minutes
2023-02-15 11:00:37,001:INFO:SubProcess create_model() called ==================================
2023-02-15 11:00:37,001:INFO:Initializing create_model()
2023-02-15 11:00:37,002:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:00:37,002:INFO:Checking exceptions
2023-02-15 11:00:37,002:INFO:Importing libraries
2023-02-15 11:00:37,002:INFO:Copying training dataset
2023-02-15 11:00:37,034:INFO:Defining folds
2023-02-15 11:00:37,034:INFO:Declaring metric variables
2023-02-15 11:00:37,039:INFO:Importing untrained model
2023-02-15 11:00:37,044:INFO:Ada Boost Classifier Imported successfully
2023-02-15 11:00:37,053:INFO:Starting cross validation
2023-02-15 11:00:37,057:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:00:58,558:INFO:Calculating mean and std
2023-02-15 11:00:58,560:INFO:Creating metrics dataframe
2023-02-15 11:00:58,563:INFO:Uploading results into container
2023-02-15 11:00:58,564:INFO:Uploading model into container now
2023-02-15 11:00:58,565:INFO:_master_model_container: 9
2023-02-15 11:00:58,565:INFO:_display_container: 2
2023-02-15 11:00:58,565:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1911)
2023-02-15 11:00:58,566:INFO:create_model() successfully completed......................................
2023-02-15 11:00:58,733:INFO:SubProcess create_model() end ==================================
2023-02-15 11:00:58,735:INFO:Creating metrics dataframe
2023-02-15 11:00:58,750:INFO:Initializing Gradient Boosting Classifier
2023-02-15 11:00:58,750:INFO:Total runtime is 1.96846444606781 minutes
2023-02-15 11:00:58,755:INFO:SubProcess create_model() called ==================================
2023-02-15 11:00:58,756:INFO:Initializing create_model()
2023-02-15 11:00:58,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:00:58,757:INFO:Checking exceptions
2023-02-15 11:00:58,757:INFO:Importing libraries
2023-02-15 11:00:58,757:INFO:Copying training dataset
2023-02-15 11:00:58,790:INFO:Defining folds
2023-02-15 11:00:58,791:INFO:Declaring metric variables
2023-02-15 11:00:58,797:INFO:Importing untrained model
2023-02-15 11:00:58,802:INFO:Gradient Boosting Classifier Imported successfully
2023-02-15 11:00:58,812:INFO:Starting cross validation
2023-02-15 11:00:58,815:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:02:30,067:INFO:Calculating mean and std
2023-02-15 11:02:30,068:INFO:Creating metrics dataframe
2023-02-15 11:02:30,074:INFO:Uploading results into container
2023-02-15 11:02:30,074:INFO:Uploading model into container now
2023-02-15 11:02:30,075:INFO:_master_model_container: 10
2023-02-15 11:02:30,075:INFO:_display_container: 2
2023-02-15 11:02:30,075:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1911, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-15 11:02:30,075:INFO:create_model() successfully completed......................................
2023-02-15 11:02:30,227:INFO:SubProcess create_model() end ==================================
2023-02-15 11:02:30,228:INFO:Creating metrics dataframe
2023-02-15 11:02:30,245:INFO:Initializing Linear Discriminant Analysis
2023-02-15 11:02:30,245:INFO:Total runtime is 3.493381083011627 minutes
2023-02-15 11:02:30,250:INFO:SubProcess create_model() called ==================================
2023-02-15 11:02:30,251:INFO:Initializing create_model()
2023-02-15 11:02:30,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:02:30,251:INFO:Checking exceptions
2023-02-15 11:02:30,251:INFO:Importing libraries
2023-02-15 11:02:30,251:INFO:Copying training dataset
2023-02-15 11:02:30,285:INFO:Defining folds
2023-02-15 11:02:30,285:INFO:Declaring metric variables
2023-02-15 11:02:30,292:INFO:Importing untrained model
2023-02-15 11:02:30,297:INFO:Linear Discriminant Analysis Imported successfully
2023-02-15 11:02:30,307:INFO:Starting cross validation
2023-02-15 11:02:30,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:02:32,065:INFO:Calculating mean and std
2023-02-15 11:02:32,066:INFO:Creating metrics dataframe
2023-02-15 11:02:32,071:INFO:Uploading results into container
2023-02-15 11:02:32,073:INFO:Uploading model into container now
2023-02-15 11:02:32,074:INFO:_master_model_container: 11
2023-02-15 11:02:32,074:INFO:_display_container: 2
2023-02-15 11:02:32,074:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-15 11:02:32,074:INFO:create_model() successfully completed......................................
2023-02-15 11:02:32,239:INFO:SubProcess create_model() end ==================================
2023-02-15 11:02:32,239:INFO:Creating metrics dataframe
2023-02-15 11:02:32,255:INFO:Initializing Extra Trees Classifier
2023-02-15 11:02:32,255:INFO:Total runtime is 3.526889689763387 minutes
2023-02-15 11:02:32,263:INFO:SubProcess create_model() called ==================================
2023-02-15 11:02:32,264:INFO:Initializing create_model()
2023-02-15 11:02:32,264:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:02:32,264:INFO:Checking exceptions
2023-02-15 11:02:32,264:INFO:Importing libraries
2023-02-15 11:02:32,264:INFO:Copying training dataset
2023-02-15 11:02:32,292:INFO:Defining folds
2023-02-15 11:02:32,292:INFO:Declaring metric variables
2023-02-15 11:02:32,298:INFO:Importing untrained model
2023-02-15 11:02:32,302:INFO:Extra Trees Classifier Imported successfully
2023-02-15 11:02:32,313:INFO:Starting cross validation
2023-02-15 11:02:32,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:03:07,472:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 3.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:03:07,472:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 3.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:03:46,055:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:04:08,974:INFO:Calculating mean and std
2023-02-15 11:04:08,976:INFO:Creating metrics dataframe
2023-02-15 11:04:08,981:INFO:Uploading results into container
2023-02-15 11:04:08,981:INFO:Uploading model into container now
2023-02-15 11:04:08,982:INFO:_master_model_container: 12
2023-02-15 11:04:08,982:INFO:_display_container: 2
2023-02-15 11:04:08,983:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1911, verbose=0, warm_start=False)
2023-02-15 11:04:08,983:INFO:create_model() successfully completed......................................
2023-02-15 11:04:09,139:INFO:SubProcess create_model() end ==================================
2023-02-15 11:04:09,139:INFO:Creating metrics dataframe
2023-02-15 11:04:09,229:INFO:Initializing Extreme Gradient Boosting
2023-02-15 11:04:09,229:INFO:Total runtime is 5.143120217323303 minutes
2023-02-15 11:04:09,235:INFO:SubProcess create_model() called ==================================
2023-02-15 11:04:09,237:INFO:Initializing create_model()
2023-02-15 11:04:09,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:04:09,238:INFO:Checking exceptions
2023-02-15 11:04:09,238:INFO:Importing libraries
2023-02-15 11:04:09,238:INFO:Copying training dataset
2023-02-15 11:04:09,267:INFO:Defining folds
2023-02-15 11:04:09,267:INFO:Declaring metric variables
2023-02-15 11:04:09,274:INFO:Importing untrained model
2023-02-15 11:04:09,279:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 11:04:09,298:INFO:Starting cross validation
2023-02-15 11:04:09,300:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:05:19,610:INFO:Calculating mean and std
2023-02-15 11:05:19,611:INFO:Creating metrics dataframe
2023-02-15 11:05:19,615:INFO:Uploading results into container
2023-02-15 11:05:19,616:INFO:Uploading model into container now
2023-02-15 11:05:19,617:INFO:_master_model_container: 13
2023-02-15 11:05:19,617:INFO:_display_container: 2
2023-02-15 11:05:19,658:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-15 11:05:19,669:INFO:create_model() successfully completed......................................
2023-02-15 11:05:19,820:INFO:SubProcess create_model() end ==================================
2023-02-15 11:05:19,820:INFO:Creating metrics dataframe
2023-02-15 11:05:19,852:INFO:Initializing Light Gradient Boosting Machine
2023-02-15 11:05:19,853:INFO:Total runtime is 6.32017772992452 minutes
2023-02-15 11:05:19,858:INFO:SubProcess create_model() called ==================================
2023-02-15 11:05:19,858:INFO:Initializing create_model()
2023-02-15 11:05:19,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:05:19,859:INFO:Checking exceptions
2023-02-15 11:05:19,859:INFO:Importing libraries
2023-02-15 11:05:19,859:INFO:Copying training dataset
2023-02-15 11:05:19,890:INFO:Defining folds
2023-02-15 11:05:19,891:INFO:Declaring metric variables
2023-02-15 11:05:19,896:INFO:Importing untrained model
2023-02-15 11:05:19,900:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:05:19,911:INFO:Starting cross validation
2023-02-15 11:05:19,913:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:05:27,917:INFO:Calculating mean and std
2023-02-15 11:05:27,920:INFO:Creating metrics dataframe
2023-02-15 11:05:27,924:INFO:Uploading results into container
2023-02-15 11:05:27,925:INFO:Uploading model into container now
2023-02-15 11:05:27,925:INFO:_master_model_container: 14
2023-02-15 11:05:27,925:INFO:_display_container: 2
2023-02-15 11:05:27,926:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:05:27,926:INFO:create_model() successfully completed......................................
2023-02-15 11:05:28,076:INFO:SubProcess create_model() end ==================================
2023-02-15 11:05:28,076:INFO:Creating metrics dataframe
2023-02-15 11:05:28,139:INFO:Initializing Dummy Classifier
2023-02-15 11:05:28,139:INFO:Total runtime is 6.45828267733256 minutes
2023-02-15 11:05:28,143:INFO:SubProcess create_model() called ==================================
2023-02-15 11:05:28,144:INFO:Initializing create_model()
2023-02-15 11:05:28,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BD2EA910>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:05:28,144:INFO:Checking exceptions
2023-02-15 11:05:28,144:INFO:Importing libraries
2023-02-15 11:05:28,144:INFO:Copying training dataset
2023-02-15 11:05:28,177:INFO:Defining folds
2023-02-15 11:05:28,177:INFO:Declaring metric variables
2023-02-15 11:05:28,181:INFO:Importing untrained model
2023-02-15 11:05:28,188:INFO:Dummy Classifier Imported successfully
2023-02-15 11:05:28,195:INFO:Starting cross validation
2023-02-15 11:05:28,197:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:05:28,369:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:05:28,394:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:05:28,406:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:05:28,424:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:05:28,515:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:05:28,529:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:05:28,538:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:05:28,572:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:05:28,632:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:05:28,655:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:05:28,661:INFO:Calculating mean and std
2023-02-15 11:05:28,662:INFO:Creating metrics dataframe
2023-02-15 11:05:28,666:INFO:Uploading results into container
2023-02-15 11:05:28,666:INFO:Uploading model into container now
2023-02-15 11:05:28,667:INFO:_master_model_container: 15
2023-02-15 11:05:28,667:INFO:_display_container: 2
2023-02-15 11:05:28,668:INFO:DummyClassifier(constant=None, random_state=1911, strategy='prior')
2023-02-15 11:05:28,669:INFO:create_model() successfully completed......................................
2023-02-15 11:05:28,813:INFO:SubProcess create_model() end ==================================
2023-02-15 11:05:28,813:INFO:Creating metrics dataframe
2023-02-15 11:05:28,888:INFO:Initializing create_model()
2023-02-15 11:05:28,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:05:28,893:INFO:Checking exceptions
2023-02-15 11:05:28,970:INFO:Importing libraries
2023-02-15 11:05:28,970:INFO:Copying training dataset
2023-02-15 11:05:28,993:INFO:Defining folds
2023-02-15 11:05:28,994:INFO:Declaring metric variables
2023-02-15 11:05:28,994:INFO:Importing untrained model
2023-02-15 11:05:28,994:INFO:Declaring custom model
2023-02-15 11:05:28,995:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:05:28,996:INFO:Cross validation set to False
2023-02-15 11:05:28,996:INFO:Fitting Model
2023-02-15 11:05:29,980:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:05:29,980:INFO:create_model() successfully completed......................................
2023-02-15 11:05:30,174:INFO:Initializing create_model()
2023-02-15 11:05:30,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:05:30,175:INFO:Checking exceptions
2023-02-15 11:05:30,176:INFO:Importing libraries
2023-02-15 11:05:30,176:INFO:Copying training dataset
2023-02-15 11:05:30,208:INFO:Defining folds
2023-02-15 11:05:30,208:INFO:Declaring metric variables
2023-02-15 11:05:30,208:INFO:Importing untrained model
2023-02-15 11:05:30,208:INFO:Declaring custom model
2023-02-15 11:05:30,210:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 11:05:30,217:INFO:Cross validation set to False
2023-02-15 11:05:30,219:INFO:Fitting Model
2023-02-15 11:05:37,410:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-15 11:05:37,410:INFO:create_model() successfully completed......................................
2023-02-15 11:05:37,583:INFO:Initializing create_model()
2023-02-15 11:05:37,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:05:37,583:INFO:Checking exceptions
2023-02-15 11:05:37,587:INFO:Importing libraries
2023-02-15 11:05:37,587:INFO:Copying training dataset
2023-02-15 11:05:37,614:INFO:Defining folds
2023-02-15 11:05:37,614:INFO:Declaring metric variables
2023-02-15 11:05:37,615:INFO:Importing untrained model
2023-02-15 11:05:37,615:INFO:Declaring custom model
2023-02-15 11:05:37,616:INFO:Naive Bayes Imported successfully
2023-02-15 11:05:37,617:INFO:Cross validation set to False
2023-02-15 11:05:37,617:INFO:Fitting Model
2023-02-15 11:05:37,725:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-15 11:05:37,725:INFO:create_model() successfully completed......................................
2023-02-15 11:05:37,980:INFO:_master_model_container: 15
2023-02-15 11:05:37,980:INFO:_display_container: 2
2023-02-15 11:05:37,982:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), GaussianNB(priors=None, var_smoothing=1e-09)]
2023-02-15 11:05:37,982:INFO:compare_models() successfully completed......................................
2023-02-15 11:05:38,054:INFO:Initializing tune_model()
2023-02-15 11:05:38,054:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>)
2023-02-15 11:05:38,054:INFO:Checking exceptions
2023-02-15 11:05:38,097:INFO:Copying training dataset
2023-02-15 11:05:38,120:INFO:Checking base model
2023-02-15 11:05:38,120:INFO:Base model : Light Gradient Boosting Machine
2023-02-15 11:05:38,125:INFO:Declaring metric variables
2023-02-15 11:05:38,131:INFO:Defining Hyperparameters
2023-02-15 11:05:38,313:INFO:Tuning with n_jobs=-1
2023-02-15 11:05:38,313:INFO:Initializing RandomizedSearchCV
2023-02-15 11:06:54,621:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:06:55,957:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:06:55,958:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:07:40,780:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 3, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.7}
2023-02-15 11:07:40,781:INFO:Hyperparameter search completed
2023-02-15 11:07:40,781:INFO:SubProcess create_model() called ==================================
2023-02-15 11:07:40,782:INFO:Initializing create_model()
2023-02-15 11:07:40,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4CCAE5FD0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.4, 'reg_alpha': 3, 'num_leaves': 150, 'n_estimators': 260, 'min_split_gain': 0.2, 'min_child_samples': 91, 'learning_rate': 0.05, 'feature_fraction': 0.4, 'bagging_freq': 4, 'bagging_fraction': 0.7})
2023-02-15 11:07:40,783:INFO:Checking exceptions
2023-02-15 11:07:40,783:INFO:Importing libraries
2023-02-15 11:07:40,783:INFO:Copying training dataset
2023-02-15 11:07:40,811:INFO:Defining folds
2023-02-15 11:07:40,811:INFO:Declaring metric variables
2023-02-15 11:07:40,815:INFO:Importing untrained model
2023-02-15 11:07:40,815:INFO:Declaring custom model
2023-02-15 11:07:40,857:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:07:40,865:INFO:Starting cross validation
2023-02-15 11:07:40,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:07:45,131:INFO:Calculating mean and std
2023-02-15 11:07:45,132:INFO:Creating metrics dataframe
2023-02-15 11:07:45,140:INFO:Finalizing model
2023-02-15 11:07:49,094:INFO:Uploading results into container
2023-02-15 11:07:49,096:INFO:Uploading model into container now
2023-02-15 11:07:49,096:INFO:_master_model_container: 16
2023-02-15 11:07:49,096:INFO:_display_container: 3
2023-02-15 11:07:49,097:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=260, n_jobs=-1, num_leaves=150, objective=None,
               random_state=1911, reg_alpha=3, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:07:49,097:INFO:create_model() successfully completed......................................
2023-02-15 11:07:49,252:INFO:SubProcess create_model() end ==================================
2023-02-15 11:07:49,252:INFO:choose_better activated
2023-02-15 11:07:49,256:INFO:SubProcess create_model() called ==================================
2023-02-15 11:07:49,257:INFO:Initializing create_model()
2023-02-15 11:07:49,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:07:49,257:INFO:Checking exceptions
2023-02-15 11:07:49,258:INFO:Importing libraries
2023-02-15 11:07:49,259:INFO:Copying training dataset
2023-02-15 11:07:49,290:INFO:Defining folds
2023-02-15 11:07:49,290:INFO:Declaring metric variables
2023-02-15 11:07:49,290:INFO:Importing untrained model
2023-02-15 11:07:49,290:INFO:Declaring custom model
2023-02-15 11:07:49,292:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:07:49,292:INFO:Starting cross validation
2023-02-15 11:07:49,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:07:50,320:INFO:Calculating mean and std
2023-02-15 11:07:50,320:INFO:Creating metrics dataframe
2023-02-15 11:07:50,323:INFO:Finalizing model
2023-02-15 11:07:50,524:INFO:Uploading results into container
2023-02-15 11:07:50,525:INFO:Uploading model into container now
2023-02-15 11:07:50,526:INFO:_master_model_container: 17
2023-02-15 11:07:50,526:INFO:_display_container: 4
2023-02-15 11:07:50,527:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:07:50,527:INFO:create_model() successfully completed......................................
2023-02-15 11:07:50,851:INFO:SubProcess create_model() end ==================================
2023-02-15 11:07:50,852:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.936
2023-02-15 11:07:50,854:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=260, n_jobs=-1, num_leaves=150, objective=None,
               random_state=1911, reg_alpha=3, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9359
2023-02-15 11:07:50,854:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-02-15 11:07:50,854:INFO:choose_better completed
2023-02-15 11:07:50,854:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-15 11:07:50,882:INFO:_master_model_container: 17
2023-02-15 11:07:50,882:INFO:_display_container: 3
2023-02-15 11:07:50,885:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:07:50,885:INFO:tune_model() successfully completed......................................
2023-02-15 11:07:51,076:INFO:Initializing tune_model()
2023-02-15 11:07:51,076:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>)
2023-02-15 11:07:51,076:INFO:Checking exceptions
2023-02-15 11:07:51,112:INFO:Copying training dataset
2023-02-15 11:07:51,132:INFO:Checking base model
2023-02-15 11:07:51,132:INFO:Base model : Extreme Gradient Boosting
2023-02-15 11:07:51,143:INFO:Declaring metric variables
2023-02-15 11:07:51,149:INFO:Defining Hyperparameters
2023-02-15 11:07:51,347:INFO:Tuning with n_jobs=-1
2023-02-15 11:07:51,347:INFO:Initializing RandomizedSearchCV
2023-02-15 11:19:50,786:INFO:best_params: {'actual_estimator__subsample': 0.2, 'actual_estimator__scale_pos_weight': 0.1, 'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 2, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.005, 'actual_estimator__colsample_bytree': 1}
2023-02-15 11:19:50,787:INFO:Hyperparameter search completed
2023-02-15 11:19:50,788:INFO:SubProcess create_model() called ==================================
2023-02-15 11:19:50,790:INFO:Initializing create_model()
2023-02-15 11:19:50,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4CCB5C550>, model_only=True, return_train_score=False, kwargs={'subsample': 0.2, 'scale_pos_weight': 0.1, 'reg_lambda': 0.0005, 'reg_alpha': 2, 'n_estimators': 190, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.005, 'colsample_bytree': 1})
2023-02-15 11:19:50,790:INFO:Checking exceptions
2023-02-15 11:19:50,790:INFO:Importing libraries
2023-02-15 11:19:50,790:INFO:Copying training dataset
2023-02-15 11:19:50,821:INFO:Defining folds
2023-02-15 11:19:50,821:INFO:Declaring metric variables
2023-02-15 11:19:50,826:INFO:Importing untrained model
2023-02-15 11:19:50,826:INFO:Declaring custom model
2023-02-15 11:19:50,898:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 11:19:50,910:INFO:Starting cross validation
2023-02-15 11:19:50,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:19:53,116:INFO:Calculating mean and std
2023-02-15 11:19:53,117:INFO:Creating metrics dataframe
2023-02-15 11:19:53,123:INFO:Finalizing model
2023-02-15 11:19:59,029:INFO:Uploading results into container
2023-02-15 11:19:59,030:INFO:Uploading model into container now
2023-02-15 11:19:59,030:INFO:_master_model_container: 18
2023-02-15 11:19:59,030:INFO:_display_container: 4
2023-02-15 11:19:59,032:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, gamma=None, gpu_id=None,
              grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.005, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=3, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              n_estimators=190, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-15 11:19:59,032:INFO:create_model() successfully completed......................................
2023-02-15 11:19:59,196:INFO:SubProcess create_model() end ==================================
2023-02-15 11:19:59,196:INFO:choose_better activated
2023-02-15 11:19:59,200:INFO:SubProcess create_model() called ==================================
2023-02-15 11:19:59,202:INFO:Initializing create_model()
2023-02-15 11:19:59,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:19:59,202:INFO:Checking exceptions
2023-02-15 11:19:59,204:INFO:Importing libraries
2023-02-15 11:19:59,204:INFO:Copying training dataset
2023-02-15 11:19:59,232:INFO:Defining folds
2023-02-15 11:19:59,232:INFO:Declaring metric variables
2023-02-15 11:19:59,241:INFO:Importing untrained model
2023-02-15 11:19:59,241:INFO:Declaring custom model
2023-02-15 11:19:59,246:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 11:19:59,246:INFO:Starting cross validation
2023-02-15 11:19:59,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:20:00,091:INFO:Calculating mean and std
2023-02-15 11:20:00,093:INFO:Creating metrics dataframe
2023-02-15 11:20:00,096:INFO:Finalizing model
2023-02-15 11:20:00,177:INFO:Uploading results into container
2023-02-15 11:20:00,177:INFO:Uploading model into container now
2023-02-15 11:20:00,178:INFO:_master_model_container: 19
2023-02-15 11:20:00,178:INFO:_display_container: 5
2023-02-15 11:20:00,179:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-15 11:20:00,179:INFO:create_model() successfully completed......................................
2023-02-15 11:20:00,366:INFO:SubProcess create_model() end ==================================
2023-02-15 11:20:00,367:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for Accuracy is 0.9345
2023-02-15 11:20:00,368:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, gamma=None, gpu_id=None,
              grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.005, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=3, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              n_estimators=190, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for Accuracy is 0.9342
2023-02-15 11:20:00,369:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) is best model
2023-02-15 11:20:00,369:INFO:choose_better completed
2023-02-15 11:20:00,369:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-15 11:20:00,399:INFO:_master_model_container: 19
2023-02-15 11:20:00,400:INFO:_display_container: 4
2023-02-15 11:20:00,400:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-15 11:20:00,401:INFO:tune_model() successfully completed......................................
2023-02-15 11:20:00,693:INFO:Initializing tune_model()
2023-02-15 11:20:00,694:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>)
2023-02-15 11:20:00,694:INFO:Checking exceptions
2023-02-15 11:20:00,722:INFO:Copying training dataset
2023-02-15 11:20:00,741:INFO:Checking base model
2023-02-15 11:20:00,741:INFO:Base model : Naive Bayes
2023-02-15 11:20:00,749:INFO:Declaring metric variables
2023-02-15 11:20:00,753:INFO:Defining Hyperparameters
2023-02-15 11:20:00,900:INFO:Tuning with n_jobs=-1
2023-02-15 11:20:00,900:INFO:Initializing RandomizedSearchCV
2023-02-15 11:20:04,955:INFO:best_params: {'actual_estimator__var_smoothing': 1e-07}
2023-02-15 11:20:04,956:INFO:Hyperparameter search completed
2023-02-15 11:20:04,956:INFO:SubProcess create_model() called ==================================
2023-02-15 11:20:04,957:INFO:Initializing create_model()
2023-02-15 11:20:04,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C41E0610>, model_only=True, return_train_score=False, kwargs={'var_smoothing': 1e-07})
2023-02-15 11:20:04,957:INFO:Checking exceptions
2023-02-15 11:20:04,957:INFO:Importing libraries
2023-02-15 11:20:04,960:INFO:Copying training dataset
2023-02-15 11:20:04,988:INFO:Defining folds
2023-02-15 11:20:04,989:INFO:Declaring metric variables
2023-02-15 11:20:04,995:INFO:Importing untrained model
2023-02-15 11:20:04,995:INFO:Declaring custom model
2023-02-15 11:20:05,000:INFO:Naive Bayes Imported successfully
2023-02-15 11:20:05,010:INFO:Starting cross validation
2023-02-15 11:20:05,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:20:05,609:INFO:Calculating mean and std
2023-02-15 11:20:05,611:INFO:Creating metrics dataframe
2023-02-15 11:20:05,617:INFO:Finalizing model
2023-02-15 11:20:05,824:INFO:Uploading results into container
2023-02-15 11:20:05,826:INFO:Uploading model into container now
2023-02-15 11:20:05,827:INFO:_master_model_container: 20
2023-02-15 11:20:05,827:INFO:_display_container: 5
2023-02-15 11:20:05,827:INFO:GaussianNB(priors=None, var_smoothing=1e-07)
2023-02-15 11:20:05,828:INFO:create_model() successfully completed......................................
2023-02-15 11:20:05,986:INFO:SubProcess create_model() end ==================================
2023-02-15 11:20:05,986:INFO:choose_better activated
2023-02-15 11:20:05,990:INFO:SubProcess create_model() called ==================================
2023-02-15 11:20:05,991:INFO:Initializing create_model()
2023-02-15 11:20:05,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:20:05,991:INFO:Checking exceptions
2023-02-15 11:20:05,994:INFO:Importing libraries
2023-02-15 11:20:05,994:INFO:Copying training dataset
2023-02-15 11:20:06,021:INFO:Defining folds
2023-02-15 11:20:06,021:INFO:Declaring metric variables
2023-02-15 11:20:06,021:INFO:Importing untrained model
2023-02-15 11:20:06,021:INFO:Declaring custom model
2023-02-15 11:20:06,022:INFO:Naive Bayes Imported successfully
2023-02-15 11:20:06,022:INFO:Starting cross validation
2023-02-15 11:20:06,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:20:06,604:INFO:Calculating mean and std
2023-02-15 11:20:06,605:INFO:Creating metrics dataframe
2023-02-15 11:20:06,607:INFO:Finalizing model
2023-02-15 11:20:06,690:INFO:Uploading results into container
2023-02-15 11:20:06,691:INFO:Uploading model into container now
2023-02-15 11:20:06,691:INFO:_master_model_container: 21
2023-02-15 11:20:06,691:INFO:_display_container: 6
2023-02-15 11:20:06,691:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-15 11:20:06,691:INFO:create_model() successfully completed......................................
2023-02-15 11:20:06,836:INFO:SubProcess create_model() end ==================================
2023-02-15 11:20:06,837:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Accuracy is 0.9335
2023-02-15 11:20:06,837:INFO:GaussianNB(priors=None, var_smoothing=1e-07) result for Accuracy is 0.9337
2023-02-15 11:20:06,837:INFO:GaussianNB(priors=None, var_smoothing=1e-07) is best model
2023-02-15 11:20:06,837:INFO:choose_better completed
2023-02-15 11:20:06,850:INFO:_master_model_container: 21
2023-02-15 11:20:06,850:INFO:_display_container: 5
2023-02-15 11:20:06,850:INFO:GaussianNB(priors=None, var_smoothing=1e-07)
2023-02-15 11:20:06,850:INFO:tune_model() successfully completed......................................
2023-02-15 11:20:07,001:INFO:Initializing automl()
2023-02-15 11:20:07,001:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, optimize=AUC, use_holdout=False, turbo=True, return_train_score=False)
2023-02-15 11:20:07,001:INFO:Model Selection Basis : CV Results on Training set
2023-02-15 11:20:07,001:INFO:Checking model 0
2023-02-15 11:20:07,001:INFO:Checking model 1
2023-02-15 11:20:07,001:INFO:Checking model 2
2023-02-15 11:20:07,001:INFO:Checking model 3
2023-02-15 11:20:07,002:INFO:Checking model 4
2023-02-15 11:20:07,002:INFO:Checking model 5
2023-02-15 11:20:07,002:INFO:Checking model 6
2023-02-15 11:20:07,002:INFO:Checking model 7
2023-02-15 11:20:07,002:INFO:Checking model 8
2023-02-15 11:20:07,002:INFO:Checking model 9
2023-02-15 11:20:07,003:INFO:Checking model 10
2023-02-15 11:20:07,003:INFO:Checking model 11
2023-02-15 11:20:07,003:INFO:Checking model 12
2023-02-15 11:20:07,003:INFO:Checking model 13
2023-02-15 11:20:07,003:INFO:Checking model 14
2023-02-15 11:20:07,003:INFO:Checking model 15
2023-02-15 11:20:07,004:INFO:Checking model 16
2023-02-15 11:20:07,004:INFO:Checking model 17
2023-02-15 11:20:07,004:INFO:Checking model 18
2023-02-15 11:20:07,004:INFO:Checking model 19
2023-02-15 11:20:07,004:INFO:Checking model 20
2023-02-15 11:20:07,005:INFO:Initializing create_model()
2023-02-15 11:20:07,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:20:07,005:INFO:Checking exceptions
2023-02-15 11:20:07,006:INFO:Importing libraries
2023-02-15 11:20:07,006:INFO:Copying training dataset
2023-02-15 11:20:07,034:INFO:Defining folds
2023-02-15 11:20:07,034:INFO:Declaring metric variables
2023-02-15 11:20:07,034:INFO:Importing untrained model
2023-02-15 11:20:07,035:INFO:Declaring custom model
2023-02-15 11:20:07,035:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:20:07,036:INFO:Cross validation set to False
2023-02-15 11:20:07,036:INFO:Fitting Model
2023-02-15 11:20:07,106:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:20:07,106:INFO:create_model() successfully completed......................................
2023-02-15 11:20:07,400:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1911, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:20:07,400:INFO:automl() successfully completed......................................
2023-02-15 11:20:07,400:INFO:Initializing automl()
2023-02-15 11:20:07,400:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, optimize=Recall, use_holdout=False, turbo=True, return_train_score=False)
2023-02-15 11:20:07,401:INFO:Model Selection Basis : CV Results on Training set
2023-02-15 11:20:07,401:INFO:Checking model 0
2023-02-15 11:20:07,401:INFO:Checking model 1
2023-02-15 11:20:07,401:INFO:Checking model 2
2023-02-15 11:20:07,401:INFO:Checking model 3
2023-02-15 11:20:07,401:INFO:Checking model 4
2023-02-15 11:20:07,401:INFO:Checking model 5
2023-02-15 11:20:07,402:INFO:Checking model 6
2023-02-15 11:20:07,402:INFO:Checking model 7
2023-02-15 11:20:07,402:INFO:Checking model 8
2023-02-15 11:20:07,402:INFO:Checking model 9
2023-02-15 11:20:07,402:INFO:Checking model 10
2023-02-15 11:20:07,402:INFO:Checking model 11
2023-02-15 11:20:07,403:INFO:Checking model 12
2023-02-15 11:20:07,403:INFO:Checking model 13
2023-02-15 11:20:07,403:INFO:Checking model 14
2023-02-15 11:20:07,403:INFO:Checking model 15
2023-02-15 11:20:07,403:INFO:Checking model 16
2023-02-15 11:20:07,403:INFO:Checking model 17
2023-02-15 11:20:07,404:INFO:Checking model 18
2023-02-15 11:20:07,404:INFO:Checking model 19
2023-02-15 11:20:07,404:INFO:Checking model 20
2023-02-15 11:20:07,404:INFO:Initializing create_model()
2023-02-15 11:20:07,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1911, solver='auto', tol=0.001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:20:07,404:INFO:Checking exceptions
2023-02-15 11:20:07,406:INFO:Importing libraries
2023-02-15 11:20:07,406:INFO:Copying training dataset
2023-02-15 11:20:07,432:INFO:Defining folds
2023-02-15 11:20:07,432:INFO:Declaring metric variables
2023-02-15 11:20:07,433:INFO:Importing untrained model
2023-02-15 11:20:07,433:INFO:Declaring custom model
2023-02-15 11:20:07,433:INFO:Ridge Classifier Imported successfully
2023-02-15 11:20:07,434:INFO:Cross validation set to False
2023-02-15 11:20:07,434:INFO:Fitting Model
2023-02-15 11:20:07,710:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=9.04764e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:20:07,728:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1911, solver='auto', tol=0.001)
2023-02-15 11:20:07,728:INFO:create_model() successfully completed......................................
2023-02-15 11:20:08,038:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1911, solver='auto', tol=0.001)
2023-02-15 11:20:08,038:INFO:automl() successfully completed......................................
2023-02-15 11:20:08,039:INFO:Initializing finalize_model()
2023-02-15 11:20:08,039:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1911, solver='auto', tol=0.001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-02-15 11:20:08,039:INFO:Finalizing RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1911, solver='auto', tol=0.001)
2023-02-15 11:20:08,061:INFO:Initializing create_model()
2023-02-15 11:20:08,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4C41E0D30>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1911, solver='auto', tol=0.001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-02-15 11:20:08,061:INFO:Checking exceptions
2023-02-15 11:20:08,063:INFO:Importing libraries
2023-02-15 11:20:08,063:INFO:Copying training dataset
2023-02-15 11:20:08,063:INFO:Defining folds
2023-02-15 11:20:08,064:INFO:Declaring metric variables
2023-02-15 11:20:08,064:INFO:Importing untrained model
2023-02-15 11:20:08,064:INFO:Declaring custom model
2023-02-15 11:20:08,065:INFO:Ridge Classifier Imported successfully
2023-02-15 11:20:08,066:INFO:Cross validation set to False
2023-02-15 11:20:08,066:INFO:Fitting Model
2023-02-15 11:20:08,629:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=7.98811e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:20:08,641:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 normalize='deprecated', positive=False,
                                 random_state=1911, solver='auto',
                                 tol=0.001))],
         verbose=False)
2023-02-15 11:20:08,641:INFO:create_model() successfully completed......................................
2023-02-15 11:20:08,796:INFO:_master_model_container: 21
2023-02-15 11:20:08,796:INFO:_display_container: 5
2023-02-15 11:20:08,804:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 normalize='deprecated', positive=False,
                                 random_state=1911, solver='auto',
                                 tol=0.001))],
         verbose=False)
2023-02-15 11:20:08,804:INFO:finalize_model() successfully completed......................................
2023-02-15 11:21:36,219:INFO:Soft dependency imported: autoviz: 0.1.58
2023-02-15 11:28:35,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 11:28:35,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 11:28:35,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 11:28:35,458:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 11:28:37,524:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 11:29:15,643:INFO:PyCaret ClassificationExperiment
2023-02-15 11:29:15,643:INFO:Logging name: clf-default-name
2023-02-15 11:29:15,643:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-15 11:29:15,643:INFO:version 3.0.0.rc9
2023-02-15 11:29:15,643:INFO:Initializing setup()
2023-02-15 11:29:15,643:INFO:self.USI: 62d9
2023-02-15 11:29:15,643:INFO:self._variable_keys: {'is_multiclass', 'pipeline', 'n_jobs_param', 'X_train', 'fold_generator', '_available_plots', 'X_test', 'idx', 'seed', 'log_plots_param', 'y_test', 'fix_imbalance', 'logging_param', 'fold_groups_param', 'exp_id', 'X', 'exp_name_log', '_ml_usecase', 'data', 'memory', 'USI', 'html_param', 'target_param', 'y_train', 'gpu_n_jobs_param', 'y', 'fold_shuffle_param', 'gpu_param'}
2023-02-15 11:29:15,643:INFO:Checking environment
2023-02-15 11:29:15,643:INFO:python_version: 3.9.15
2023-02-15 11:29:15,643:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-15 11:29:15,643:INFO:machine: AMD64
2023-02-15 11:29:15,643:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-15 11:29:15,644:INFO:Memory: svmem(total=8469581824, available=1162440704, percent=86.3, used=7307141120, free=1162440704)
2023-02-15 11:29:15,644:INFO:Physical Core: 4
2023-02-15 11:29:15,644:INFO:Logical Core: 4
2023-02-15 11:29:15,644:INFO:Checking libraries
2023-02-15 11:29:15,644:INFO:System:
2023-02-15 11:29:15,644:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-15 11:29:15,644:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-15 11:29:15,644:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-15 11:29:15,644:INFO:PyCaret required dependencies:
2023-02-15 11:29:15,644:INFO:                 pip: 22.3.1
2023-02-15 11:29:15,644:INFO:          setuptools: 60.10.0
2023-02-15 11:29:15,644:INFO:             pycaret: 3.0.0rc9
2023-02-15 11:29:15,644:INFO:             IPython: 7.31.1
2023-02-15 11:29:15,644:INFO:          ipywidgets: 7.6.5
2023-02-15 11:29:15,644:INFO:                tqdm: 4.64.1
2023-02-15 11:29:15,644:INFO:               numpy: 1.21.5
2023-02-15 11:29:15,644:INFO:              pandas: 1.4.4
2023-02-15 11:29:15,645:INFO:              jinja2: 2.11.3
2023-02-15 11:29:15,645:INFO:               scipy: 1.9.3
2023-02-15 11:29:15,645:INFO:              joblib: 1.2.0
2023-02-15 11:29:15,645:INFO:             sklearn: 1.0.2
2023-02-15 11:29:15,645:INFO:                pyod: 1.0.7
2023-02-15 11:29:15,645:INFO:            imblearn: 0.10.1
2023-02-15 11:29:15,645:INFO:   category_encoders: 2.6.0
2023-02-15 11:29:15,645:INFO:            lightgbm: 3.3.5
2023-02-15 11:29:15,645:INFO:               numba: 0.56.4
2023-02-15 11:29:15,645:INFO:            requests: 2.28.1
2023-02-15 11:29:15,645:INFO:          matplotlib: 3.6.2
2023-02-15 11:29:15,645:INFO:          scikitplot: 0.3.7
2023-02-15 11:29:15,645:INFO:         yellowbrick: 1.5
2023-02-15 11:29:15,645:INFO:              plotly: 5.9.0
2023-02-15 11:29:15,645:INFO:             kaleido: 0.2.1
2023-02-15 11:29:15,645:INFO:         statsmodels: 0.13.2
2023-02-15 11:29:15,645:INFO:              sktime: 0.16.1
2023-02-15 11:29:15,645:INFO:               tbats: 1.1.2
2023-02-15 11:29:15,645:INFO:            pmdarima: 2.0.2
2023-02-15 11:29:15,646:INFO:              psutil: 5.9.0
2023-02-15 11:29:15,646:INFO:PyCaret optional dependencies:
2023-02-15 11:29:15,663:INFO:                shap: 0.41.0
2023-02-15 11:29:15,663:INFO:           interpret: Not installed
2023-02-15 11:29:15,663:INFO:                umap: Not installed
2023-02-15 11:29:15,663:INFO:    pandas_profiling: 4.0.0
2023-02-15 11:29:15,663:INFO:  explainerdashboard: 0.3.6.2
2023-02-15 11:29:15,663:INFO:             autoviz: 0.1.58
2023-02-15 11:29:15,663:INFO:           fairlearn: Not installed
2023-02-15 11:29:15,663:INFO:             xgboost: 1.7.3
2023-02-15 11:29:15,663:INFO:            catboost: Not installed
2023-02-15 11:29:15,663:INFO:              kmodes: Not installed
2023-02-15 11:29:15,663:INFO:             mlxtend: Not installed
2023-02-15 11:29:15,664:INFO:       statsforecast: Not installed
2023-02-15 11:29:15,664:INFO:        tune_sklearn: Not installed
2023-02-15 11:29:15,664:INFO:                 ray: Not installed
2023-02-15 11:29:15,664:INFO:            hyperopt: Not installed
2023-02-15 11:29:15,664:INFO:              optuna: 2.10.1
2023-02-15 11:29:15,664:INFO:               skopt: Not installed
2023-02-15 11:29:15,664:INFO:              mlflow: Not installed
2023-02-15 11:29:15,664:INFO:              gradio: Not installed
2023-02-15 11:29:15,664:INFO:             fastapi: Not installed
2023-02-15 11:29:15,664:INFO:             uvicorn: Not installed
2023-02-15 11:29:15,664:INFO:              m2cgen: Not installed
2023-02-15 11:29:15,664:INFO:           evidently: Not installed
2023-02-15 11:29:15,664:INFO:               fugue: Not installed
2023-02-15 11:29:15,664:INFO:           streamlit: Not installed
2023-02-15 11:29:15,664:INFO:             prophet: Not installed
2023-02-15 11:29:15,664:INFO:None
2023-02-15 11:29:15,664:INFO:Set up data.
2023-02-15 11:29:15,691:INFO:Set up train/test split.
2023-02-15 11:29:15,733:INFO:Set up index.
2023-02-15 11:29:15,737:INFO:Set up folding strategy.
2023-02-15 11:29:15,738:INFO:Assigning column types.
2023-02-15 11:29:15,752:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 11:29:15,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 11:29:15,823:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-15 11:29:15,871:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:29:16,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:29:16,369:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 11:29:16,370:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-15 11:29:16,408:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:29:16,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:29:16,411:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 11:29:16,471:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-15 11:29:16,507:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:29:16,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:29:16,610:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-15 11:29:16,646:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:29:16,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:29:16,650:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-15 11:29:16,738:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:29:16,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:29:16,829:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:29:16,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:29:16,834:INFO:Preparing preprocessing pipeline...
2023-02-15 11:29:16,842:INFO:Set up simple imputation.
2023-02-15 11:29:16,842:INFO:Set up imbalanced handling.
2023-02-15 11:29:16,912:INFO:Finished creating preprocessing pipeline.
2023-02-15 11:29:16,921:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2023-02-15 11:29:16,922:INFO:Creating final display dataframe.
2023-02-15 11:29:17,715:INFO:Setup _display_container:                     Description             Value
0                    Session id              7749
1                        Target      inadimplente
2                   Target type            Binary
3           Original data shape       (88000, 11)
4        Transformed data shape      (141361, 11)
5   Transformed train set shape      (114960, 11)
6    Transformed test set shape       (26401, 11)
7              Numeric features                10
8      Rows with missing values             19.8%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                Fix imbalance              True
14         Fix imbalance method             SMOTE
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              62d9
2023-02-15 11:29:17,828:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:29:17,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:29:17,923:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:29:17,925:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:29:17,926:INFO:setup() successfully completed in 2.28s...............
2023-02-15 11:29:17,926:INFO:Initializing compare_models()
2023-02-15 11:29:17,926:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-15 11:29:17,926:INFO:Checking exceptions
2023-02-15 11:29:17,942:INFO:Preparing display monitor
2023-02-15 11:29:17,979:INFO:Initializing Logistic Regression
2023-02-15 11:29:17,980:INFO:Total runtime is 1.531044642130534e-05 minutes
2023-02-15 11:29:17,985:INFO:SubProcess create_model() called ==================================
2023-02-15 11:29:17,985:INFO:Initializing create_model()
2023-02-15 11:29:17,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:29:17,986:INFO:Checking exceptions
2023-02-15 11:29:17,986:INFO:Importing libraries
2023-02-15 11:29:17,986:INFO:Copying training dataset
2023-02-15 11:29:18,023:INFO:Defining folds
2023-02-15 11:29:18,024:INFO:Declaring metric variables
2023-02-15 11:29:18,028:INFO:Importing untrained model
2023-02-15 11:29:18,034:INFO:Logistic Regression Imported successfully
2023-02-15 11:29:18,047:INFO:Starting cross validation
2023-02-15 11:29:18,058:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:29:33,677:INFO:Calculating mean and std
2023-02-15 11:29:33,678:INFO:Creating metrics dataframe
2023-02-15 11:29:33,682:INFO:Uploading results into container
2023-02-15 11:29:33,682:INFO:Uploading model into container now
2023-02-15 11:29:33,683:INFO:_master_model_container: 1
2023-02-15 11:29:33,683:INFO:_display_container: 2
2023-02-15 11:29:33,684:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7749, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-15 11:29:33,685:INFO:create_model() successfully completed......................................
2023-02-15 11:29:34,058:INFO:SubProcess create_model() end ==================================
2023-02-15 11:29:34,058:INFO:Creating metrics dataframe
2023-02-15 11:29:34,075:INFO:Initializing K Neighbors Classifier
2023-02-15 11:29:34,076:INFO:Total runtime is 0.2682840545972188 minutes
2023-02-15 11:29:34,081:INFO:SubProcess create_model() called ==================================
2023-02-15 11:29:34,081:INFO:Initializing create_model()
2023-02-15 11:29:34,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:29:34,081:INFO:Checking exceptions
2023-02-15 11:29:34,081:INFO:Importing libraries
2023-02-15 11:29:34,081:INFO:Copying training dataset
2023-02-15 11:29:34,112:INFO:Defining folds
2023-02-15 11:29:34,112:INFO:Declaring metric variables
2023-02-15 11:29:34,116:INFO:Importing untrained model
2023-02-15 11:29:34,123:INFO:K Neighbors Classifier Imported successfully
2023-02-15 11:29:34,132:INFO:Starting cross validation
2023-02-15 11:29:34,135:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:29:35,332:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:29:35,684:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:29:35,860:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:29:35,884:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:29:37,945:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:29:38,261:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:29:38,267:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:29:38,326:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:29:40,284:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:29:40,883:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:29:41,276:INFO:Calculating mean and std
2023-02-15 11:29:41,278:INFO:Creating metrics dataframe
2023-02-15 11:29:41,281:INFO:Uploading results into container
2023-02-15 11:29:41,282:INFO:Uploading model into container now
2023-02-15 11:29:41,283:INFO:_master_model_container: 2
2023-02-15 11:29:41,283:INFO:_display_container: 2
2023-02-15 11:29:41,284:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-15 11:29:41,284:INFO:create_model() successfully completed......................................
2023-02-15 11:29:41,417:INFO:SubProcess create_model() end ==================================
2023-02-15 11:29:41,417:INFO:Creating metrics dataframe
2023-02-15 11:29:41,429:INFO:Initializing Naive Bayes
2023-02-15 11:29:41,429:INFO:Total runtime is 0.3908251086870829 minutes
2023-02-15 11:29:41,433:INFO:SubProcess create_model() called ==================================
2023-02-15 11:29:41,433:INFO:Initializing create_model()
2023-02-15 11:29:41,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:29:41,434:INFO:Checking exceptions
2023-02-15 11:29:41,434:INFO:Importing libraries
2023-02-15 11:29:41,434:INFO:Copying training dataset
2023-02-15 11:29:41,463:INFO:Defining folds
2023-02-15 11:29:41,464:INFO:Declaring metric variables
2023-02-15 11:29:41,471:INFO:Importing untrained model
2023-02-15 11:29:41,476:INFO:Naive Bayes Imported successfully
2023-02-15 11:29:41,485:INFO:Starting cross validation
2023-02-15 11:29:41,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:29:42,855:INFO:Calculating mean and std
2023-02-15 11:29:42,857:INFO:Creating metrics dataframe
2023-02-15 11:29:42,861:INFO:Uploading results into container
2023-02-15 11:29:42,861:INFO:Uploading model into container now
2023-02-15 11:29:42,862:INFO:_master_model_container: 3
2023-02-15 11:29:42,862:INFO:_display_container: 2
2023-02-15 11:29:42,862:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-15 11:29:42,863:INFO:create_model() successfully completed......................................
2023-02-15 11:29:43,024:INFO:SubProcess create_model() end ==================================
2023-02-15 11:29:43,025:INFO:Creating metrics dataframe
2023-02-15 11:29:43,035:INFO:Initializing Decision Tree Classifier
2023-02-15 11:29:43,035:INFO:Total runtime is 0.4175942937533061 minutes
2023-02-15 11:29:43,042:INFO:SubProcess create_model() called ==================================
2023-02-15 11:29:43,042:INFO:Initializing create_model()
2023-02-15 11:29:43,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:29:43,042:INFO:Checking exceptions
2023-02-15 11:29:43,042:INFO:Importing libraries
2023-02-15 11:29:43,043:INFO:Copying training dataset
2023-02-15 11:29:43,073:INFO:Defining folds
2023-02-15 11:29:43,074:INFO:Declaring metric variables
2023-02-15 11:29:43,078:INFO:Importing untrained model
2023-02-15 11:29:43,088:INFO:Decision Tree Classifier Imported successfully
2023-02-15 11:29:43,097:INFO:Starting cross validation
2023-02-15 11:29:43,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:29:46,374:INFO:Calculating mean and std
2023-02-15 11:29:46,375:INFO:Creating metrics dataframe
2023-02-15 11:29:46,379:INFO:Uploading results into container
2023-02-15 11:29:46,380:INFO:Uploading model into container now
2023-02-15 11:29:46,380:INFO:_master_model_container: 4
2023-02-15 11:29:46,380:INFO:_display_container: 2
2023-02-15 11:29:46,381:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7749, splitter='best')
2023-02-15 11:29:46,381:INFO:create_model() successfully completed......................................
2023-02-15 11:29:46,526:INFO:SubProcess create_model() end ==================================
2023-02-15 11:29:46,526:INFO:Creating metrics dataframe
2023-02-15 11:29:46,540:INFO:Initializing SVM - Linear Kernel
2023-02-15 11:29:46,540:INFO:Total runtime is 0.47601126829783125 minutes
2023-02-15 11:29:46,544:INFO:SubProcess create_model() called ==================================
2023-02-15 11:29:46,545:INFO:Initializing create_model()
2023-02-15 11:29:46,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:29:46,545:INFO:Checking exceptions
2023-02-15 11:29:46,545:INFO:Importing libraries
2023-02-15 11:29:46,546:INFO:Copying training dataset
2023-02-15 11:29:46,574:INFO:Defining folds
2023-02-15 11:29:46,574:INFO:Declaring metric variables
2023-02-15 11:29:46,578:INFO:Importing untrained model
2023-02-15 11:29:46,584:INFO:SVM - Linear Kernel Imported successfully
2023-02-15 11:29:46,593:INFO:Starting cross validation
2023-02-15 11:29:46,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:29:51,220:INFO:Calculating mean and std
2023-02-15 11:29:51,222:INFO:Creating metrics dataframe
2023-02-15 11:29:51,227:INFO:Uploading results into container
2023-02-15 11:29:51,228:INFO:Uploading model into container now
2023-02-15 11:29:51,229:INFO:_master_model_container: 5
2023-02-15 11:29:51,229:INFO:_display_container: 2
2023-02-15 11:29:51,229:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7749, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-15 11:29:51,229:INFO:create_model() successfully completed......................................
2023-02-15 11:29:51,382:INFO:SubProcess create_model() end ==================================
2023-02-15 11:29:51,382:INFO:Creating metrics dataframe
2023-02-15 11:29:51,397:INFO:Initializing Ridge Classifier
2023-02-15 11:29:51,397:INFO:Total runtime is 0.5569599787394206 minutes
2023-02-15 11:29:51,401:INFO:SubProcess create_model() called ==================================
2023-02-15 11:29:51,402:INFO:Initializing create_model()
2023-02-15 11:29:51,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:29:51,402:INFO:Checking exceptions
2023-02-15 11:29:51,402:INFO:Importing libraries
2023-02-15 11:29:51,403:INFO:Copying training dataset
2023-02-15 11:29:51,439:INFO:Defining folds
2023-02-15 11:29:51,440:INFO:Declaring metric variables
2023-02-15 11:29:51,443:INFO:Importing untrained model
2023-02-15 11:29:51,450:INFO:Ridge Classifier Imported successfully
2023-02-15 11:29:51,459:INFO:Starting cross validation
2023-02-15 11:29:51,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:29:51,679:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.96729e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:29:51,682:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=9.282e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:29:51,695:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=9.08522e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:29:51,873:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.09436e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:29:51,874:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.19242e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:29:51,878:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=9.05139e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:29:51,918:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=9.37867e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:29:52,026:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.91384e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:29:52,034:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=9.46821e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:29:52,064:INFO:Calculating mean and std
2023-02-15 11:29:52,065:INFO:Creating metrics dataframe
2023-02-15 11:29:52,071:INFO:Uploading results into container
2023-02-15 11:29:52,072:INFO:Uploading model into container now
2023-02-15 11:29:52,072:INFO:_master_model_container: 6
2023-02-15 11:29:52,072:INFO:_display_container: 2
2023-02-15 11:29:52,073:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=7749, solver='auto', tol=0.001)
2023-02-15 11:29:52,073:INFO:create_model() successfully completed......................................
2023-02-15 11:29:52,216:INFO:SubProcess create_model() end ==================================
2023-02-15 11:29:52,216:INFO:Creating metrics dataframe
2023-02-15 11:29:52,229:INFO:Initializing Random Forest Classifier
2023-02-15 11:29:52,230:INFO:Total runtime is 0.5708335677782694 minutes
2023-02-15 11:29:52,234:INFO:SubProcess create_model() called ==================================
2023-02-15 11:29:52,236:INFO:Initializing create_model()
2023-02-15 11:29:52,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:29:52,237:INFO:Checking exceptions
2023-02-15 11:29:52,237:INFO:Importing libraries
2023-02-15 11:29:52,237:INFO:Copying training dataset
2023-02-15 11:29:52,265:INFO:Defining folds
2023-02-15 11:29:52,265:INFO:Declaring metric variables
2023-02-15 11:29:52,273:INFO:Importing untrained model
2023-02-15 11:29:52,278:INFO:Random Forest Classifier Imported successfully
2023-02-15 11:29:52,290:INFO:Starting cross validation
2023-02-15 11:29:52,293:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:30:57,252:INFO:Calculating mean and std
2023-02-15 11:30:57,254:INFO:Creating metrics dataframe
2023-02-15 11:30:57,258:INFO:Uploading results into container
2023-02-15 11:30:57,259:INFO:Uploading model into container now
2023-02-15 11:30:57,259:INFO:_master_model_container: 7
2023-02-15 11:30:57,259:INFO:_display_container: 2
2023-02-15 11:30:57,260:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7749, verbose=0, warm_start=False)
2023-02-15 11:30:57,260:INFO:create_model() successfully completed......................................
2023-02-15 11:30:57,411:INFO:SubProcess create_model() end ==================================
2023-02-15 11:30:57,411:INFO:Creating metrics dataframe
2023-02-15 11:30:57,426:INFO:Initializing Quadratic Discriminant Analysis
2023-02-15 11:30:57,426:INFO:Total runtime is 1.657440475622813 minutes
2023-02-15 11:30:57,430:INFO:SubProcess create_model() called ==================================
2023-02-15 11:30:57,431:INFO:Initializing create_model()
2023-02-15 11:30:57,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:30:57,431:INFO:Checking exceptions
2023-02-15 11:30:57,431:INFO:Importing libraries
2023-02-15 11:30:57,431:INFO:Copying training dataset
2023-02-15 11:30:57,462:INFO:Defining folds
2023-02-15 11:30:57,462:INFO:Declaring metric variables
2023-02-15 11:30:57,467:INFO:Importing untrained model
2023-02-15 11:30:57,474:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-15 11:30:57,483:INFO:Starting cross validation
2023-02-15 11:30:57,487:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:31:02,013:INFO:Calculating mean and std
2023-02-15 11:31:02,014:INFO:Creating metrics dataframe
2023-02-15 11:31:02,020:INFO:Uploading results into container
2023-02-15 11:31:02,021:INFO:Uploading model into container now
2023-02-15 11:31:02,021:INFO:_master_model_container: 8
2023-02-15 11:31:02,021:INFO:_display_container: 2
2023-02-15 11:31:02,022:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-15 11:31:02,022:INFO:create_model() successfully completed......................................
2023-02-15 11:31:02,159:INFO:SubProcess create_model() end ==================================
2023-02-15 11:31:02,159:INFO:Creating metrics dataframe
2023-02-15 11:31:02,174:INFO:Initializing Ada Boost Classifier
2023-02-15 11:31:02,174:INFO:Total runtime is 1.7365803718566895 minutes
2023-02-15 11:31:02,177:INFO:SubProcess create_model() called ==================================
2023-02-15 11:31:02,178:INFO:Initializing create_model()
2023-02-15 11:31:02,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:31:02,178:INFO:Checking exceptions
2023-02-15 11:31:02,179:INFO:Importing libraries
2023-02-15 11:31:02,179:INFO:Copying training dataset
2023-02-15 11:31:02,209:INFO:Defining folds
2023-02-15 11:31:02,209:INFO:Declaring metric variables
2023-02-15 11:31:02,215:INFO:Importing untrained model
2023-02-15 11:31:02,221:INFO:Ada Boost Classifier Imported successfully
2023-02-15 11:31:02,230:INFO:Starting cross validation
2023-02-15 11:31:02,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:31:18,709:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:31:25,578:INFO:Calculating mean and std
2023-02-15 11:31:25,580:INFO:Creating metrics dataframe
2023-02-15 11:31:25,583:INFO:Uploading results into container
2023-02-15 11:31:25,583:INFO:Uploading model into container now
2023-02-15 11:31:25,585:INFO:_master_model_container: 9
2023-02-15 11:31:25,586:INFO:_display_container: 2
2023-02-15 11:31:25,587:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7749)
2023-02-15 11:31:25,587:INFO:create_model() successfully completed......................................
2023-02-15 11:31:25,727:INFO:SubProcess create_model() end ==================================
2023-02-15 11:31:25,727:INFO:Creating metrics dataframe
2023-02-15 11:31:25,741:INFO:Initializing Gradient Boosting Classifier
2023-02-15 11:31:25,741:INFO:Total runtime is 2.1293639103571573 minutes
2023-02-15 11:31:25,745:INFO:SubProcess create_model() called ==================================
2023-02-15 11:31:25,745:INFO:Initializing create_model()
2023-02-15 11:31:25,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:31:25,746:INFO:Checking exceptions
2023-02-15 11:31:25,746:INFO:Importing libraries
2023-02-15 11:31:25,746:INFO:Copying training dataset
2023-02-15 11:31:25,775:INFO:Defining folds
2023-02-15 11:31:25,775:INFO:Declaring metric variables
2023-02-15 11:31:25,780:INFO:Importing untrained model
2023-02-15 11:31:25,785:INFO:Gradient Boosting Classifier Imported successfully
2023-02-15 11:31:25,795:INFO:Starting cross validation
2023-02-15 11:31:25,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:33:01,630:INFO:Calculating mean and std
2023-02-15 11:33:01,631:INFO:Creating metrics dataframe
2023-02-15 11:33:01,637:INFO:Uploading results into container
2023-02-15 11:33:01,638:INFO:Uploading model into container now
2023-02-15 11:33:01,638:INFO:_master_model_container: 10
2023-02-15 11:33:01,638:INFO:_display_container: 2
2023-02-15 11:33:01,639:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7749, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-15 11:33:01,639:INFO:create_model() successfully completed......................................
2023-02-15 11:33:01,781:INFO:SubProcess create_model() end ==================================
2023-02-15 11:33:01,781:INFO:Creating metrics dataframe
2023-02-15 11:33:01,796:INFO:Initializing Linear Discriminant Analysis
2023-02-15 11:33:01,797:INFO:Total runtime is 3.7303005139033 minutes
2023-02-15 11:33:01,804:INFO:SubProcess create_model() called ==================================
2023-02-15 11:33:01,804:INFO:Initializing create_model()
2023-02-15 11:33:01,804:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:33:01,805:INFO:Checking exceptions
2023-02-15 11:33:01,805:INFO:Importing libraries
2023-02-15 11:33:01,805:INFO:Copying training dataset
2023-02-15 11:33:01,835:INFO:Defining folds
2023-02-15 11:33:01,835:INFO:Declaring metric variables
2023-02-15 11:33:01,840:INFO:Importing untrained model
2023-02-15 11:33:01,844:INFO:Linear Discriminant Analysis Imported successfully
2023-02-15 11:33:01,855:INFO:Starting cross validation
2023-02-15 11:33:01,858:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:33:03,264:INFO:Calculating mean and std
2023-02-15 11:33:03,266:INFO:Creating metrics dataframe
2023-02-15 11:33:03,272:INFO:Uploading results into container
2023-02-15 11:33:03,273:INFO:Uploading model into container now
2023-02-15 11:33:03,274:INFO:_master_model_container: 11
2023-02-15 11:33:03,274:INFO:_display_container: 2
2023-02-15 11:33:03,275:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-15 11:33:03,275:INFO:create_model() successfully completed......................................
2023-02-15 11:33:03,422:INFO:SubProcess create_model() end ==================================
2023-02-15 11:33:03,422:INFO:Creating metrics dataframe
2023-02-15 11:33:03,437:INFO:Initializing Extra Trees Classifier
2023-02-15 11:33:03,437:INFO:Total runtime is 3.75762886206309 minutes
2023-02-15 11:33:03,444:INFO:SubProcess create_model() called ==================================
2023-02-15 11:33:03,444:INFO:Initializing create_model()
2023-02-15 11:33:03,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:33:03,445:INFO:Checking exceptions
2023-02-15 11:33:03,445:INFO:Importing libraries
2023-02-15 11:33:03,445:INFO:Copying training dataset
2023-02-15 11:33:03,481:INFO:Defining folds
2023-02-15 11:33:03,481:INFO:Declaring metric variables
2023-02-15 11:33:03,488:INFO:Importing untrained model
2023-02-15 11:33:03,495:INFO:Extra Trees Classifier Imported successfully
2023-02-15 11:33:03,507:INFO:Starting cross validation
2023-02-15 11:33:03,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:33:54,319:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:34:18,602:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:34:18,950:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:34:30,570:INFO:Calculating mean and std
2023-02-15 11:34:30,570:INFO:Creating metrics dataframe
2023-02-15 11:34:30,576:INFO:Uploading results into container
2023-02-15 11:34:30,577:INFO:Uploading model into container now
2023-02-15 11:34:30,578:INFO:_master_model_container: 12
2023-02-15 11:34:30,578:INFO:_display_container: 2
2023-02-15 11:34:30,579:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7749, verbose=0, warm_start=False)
2023-02-15 11:34:30,579:INFO:create_model() successfully completed......................................
2023-02-15 11:34:30,792:INFO:SubProcess create_model() end ==================================
2023-02-15 11:34:30,792:INFO:Creating metrics dataframe
2023-02-15 11:34:30,899:INFO:Initializing Extreme Gradient Boosting
2023-02-15 11:34:30,900:INFO:Total runtime is 5.215347846349081 minutes
2023-02-15 11:34:30,904:INFO:SubProcess create_model() called ==================================
2023-02-15 11:34:30,904:INFO:Initializing create_model()
2023-02-15 11:34:30,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:34:30,983:INFO:Checking exceptions
2023-02-15 11:34:30,983:INFO:Importing libraries
2023-02-15 11:34:30,983:INFO:Copying training dataset
2023-02-15 11:34:31,010:INFO:Defining folds
2023-02-15 11:34:31,010:INFO:Declaring metric variables
2023-02-15 11:34:31,017:INFO:Importing untrained model
2023-02-15 11:34:31,041:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 11:34:31,051:INFO:Starting cross validation
2023-02-15 11:34:31,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:35:37,703:INFO:Calculating mean and std
2023-02-15 11:35:37,705:INFO:Creating metrics dataframe
2023-02-15 11:35:37,709:INFO:Uploading results into container
2023-02-15 11:35:37,710:INFO:Uploading model into container now
2023-02-15 11:35:37,711:INFO:_master_model_container: 13
2023-02-15 11:35:37,711:INFO:_display_container: 2
2023-02-15 11:35:37,712:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-15 11:35:37,722:INFO:create_model() successfully completed......................................
2023-02-15 11:35:37,851:INFO:SubProcess create_model() end ==================================
2023-02-15 11:35:37,851:INFO:Creating metrics dataframe
2023-02-15 11:35:37,897:INFO:Initializing Light Gradient Boosting Machine
2023-02-15 11:35:37,897:INFO:Total runtime is 6.331972169876099 minutes
2023-02-15 11:35:37,904:INFO:SubProcess create_model() called ==================================
2023-02-15 11:35:37,904:INFO:Initializing create_model()
2023-02-15 11:35:37,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:35:37,904:INFO:Checking exceptions
2023-02-15 11:35:37,904:INFO:Importing libraries
2023-02-15 11:35:37,904:INFO:Copying training dataset
2023-02-15 11:35:37,942:INFO:Defining folds
2023-02-15 11:35:37,942:INFO:Declaring metric variables
2023-02-15 11:35:37,946:INFO:Importing untrained model
2023-02-15 11:35:37,952:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:35:37,959:INFO:Starting cross validation
2023-02-15 11:35:37,962:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:35:45,191:INFO:Calculating mean and std
2023-02-15 11:35:45,192:INFO:Creating metrics dataframe
2023-02-15 11:35:45,196:INFO:Uploading results into container
2023-02-15 11:35:45,197:INFO:Uploading model into container now
2023-02-15 11:35:45,198:INFO:_master_model_container: 14
2023-02-15 11:35:45,198:INFO:_display_container: 2
2023-02-15 11:35:45,199:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7749, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:35:45,200:INFO:create_model() successfully completed......................................
2023-02-15 11:35:45,334:INFO:SubProcess create_model() end ==================================
2023-02-15 11:35:45,334:INFO:Creating metrics dataframe
2023-02-15 11:35:45,368:INFO:Initializing Dummy Classifier
2023-02-15 11:35:45,368:INFO:Total runtime is 6.456479537487031 minutes
2023-02-15 11:35:45,373:INFO:SubProcess create_model() called ==================================
2023-02-15 11:35:45,374:INFO:Initializing create_model()
2023-02-15 11:35:45,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201235F1D00>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:35:45,374:INFO:Checking exceptions
2023-02-15 11:35:45,374:INFO:Importing libraries
2023-02-15 11:35:45,374:INFO:Copying training dataset
2023-02-15 11:35:45,407:INFO:Defining folds
2023-02-15 11:35:45,408:INFO:Declaring metric variables
2023-02-15 11:35:45,413:INFO:Importing untrained model
2023-02-15 11:35:45,419:INFO:Dummy Classifier Imported successfully
2023-02-15 11:35:45,427:INFO:Starting cross validation
2023-02-15 11:35:45,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:35:45,602:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:35:45,613:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:35:45,654:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:35:45,694:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:35:45,752:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:35:45,795:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:35:45,839:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:35:45,841:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:35:45,888:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:35:45,923:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:35:45,928:INFO:Calculating mean and std
2023-02-15 11:35:45,929:INFO:Creating metrics dataframe
2023-02-15 11:35:45,934:INFO:Uploading results into container
2023-02-15 11:35:45,935:INFO:Uploading model into container now
2023-02-15 11:35:45,935:INFO:_master_model_container: 15
2023-02-15 11:35:45,935:INFO:_display_container: 2
2023-02-15 11:35:45,936:INFO:DummyClassifier(constant=None, random_state=7749, strategy='prior')
2023-02-15 11:35:45,936:INFO:create_model() successfully completed......................................
2023-02-15 11:35:46,064:INFO:SubProcess create_model() end ==================================
2023-02-15 11:35:46,064:INFO:Creating metrics dataframe
2023-02-15 11:35:46,121:INFO:Initializing create_model()
2023-02-15 11:35:46,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7749, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:35:46,121:INFO:Checking exceptions
2023-02-15 11:35:46,139:INFO:Importing libraries
2023-02-15 11:35:46,139:INFO:Copying training dataset
2023-02-15 11:35:46,169:INFO:Defining folds
2023-02-15 11:35:46,169:INFO:Declaring metric variables
2023-02-15 11:35:46,169:INFO:Importing untrained model
2023-02-15 11:35:46,169:INFO:Declaring custom model
2023-02-15 11:35:46,170:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:35:46,171:INFO:Cross validation set to False
2023-02-15 11:35:46,171:INFO:Fitting Model
2023-02-15 11:35:47,271:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7749, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:35:47,271:INFO:create_model() successfully completed......................................
2023-02-15 11:35:47,416:INFO:Initializing create_model()
2023-02-15 11:35:47,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:35:47,417:INFO:Checking exceptions
2023-02-15 11:35:47,420:INFO:Importing libraries
2023-02-15 11:35:47,420:INFO:Copying training dataset
2023-02-15 11:35:47,445:INFO:Defining folds
2023-02-15 11:35:47,445:INFO:Declaring metric variables
2023-02-15 11:35:47,445:INFO:Importing untrained model
2023-02-15 11:35:47,445:INFO:Declaring custom model
2023-02-15 11:35:47,447:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 11:35:47,448:INFO:Cross validation set to False
2023-02-15 11:35:47,448:INFO:Fitting Model
2023-02-15 11:35:53,806:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-15 11:35:53,806:INFO:create_model() successfully completed......................................
2023-02-15 11:35:53,941:INFO:Initializing create_model()
2023-02-15 11:35:53,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:35:53,941:INFO:Checking exceptions
2023-02-15 11:35:53,944:INFO:Importing libraries
2023-02-15 11:35:53,944:INFO:Copying training dataset
2023-02-15 11:35:53,970:INFO:Defining folds
2023-02-15 11:35:53,970:INFO:Declaring metric variables
2023-02-15 11:35:53,971:INFO:Importing untrained model
2023-02-15 11:35:53,971:INFO:Declaring custom model
2023-02-15 11:35:53,971:INFO:Naive Bayes Imported successfully
2023-02-15 11:35:53,972:INFO:Cross validation set to False
2023-02-15 11:35:53,972:INFO:Fitting Model
2023-02-15 11:35:54,054:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-15 11:35:54,054:INFO:create_model() successfully completed......................................
2023-02-15 11:35:54,211:INFO:_master_model_container: 15
2023-02-15 11:35:54,211:INFO:_display_container: 2
2023-02-15 11:35:54,213:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7749, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), GaussianNB(priors=None, var_smoothing=1e-09)]
2023-02-15 11:35:54,213:INFO:compare_models() successfully completed......................................
2023-02-15 11:35:54,218:INFO:Initializing tune_model()
2023-02-15 11:35:54,218:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7749, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>)
2023-02-15 11:35:54,218:INFO:Checking exceptions
2023-02-15 11:35:54,252:INFO:Copying training dataset
2023-02-15 11:35:54,271:INFO:Checking base model
2023-02-15 11:35:54,271:INFO:Base model : Light Gradient Boosting Machine
2023-02-15 11:35:54,276:INFO:Declaring metric variables
2023-02-15 11:35:54,280:INFO:Defining Hyperparameters
2023-02-15 11:35:54,410:INFO:Tuning with n_jobs=-1
2023-02-15 11:35:54,410:INFO:Initializing RandomizedSearchCV
2023-02-15 11:36:48,782:INFO:best_params: {'actual_estimator__reg_lambda': 4, 'actual_estimator__reg_alpha': 1e-07, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 56, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.7}
2023-02-15 11:36:48,785:INFO:Hyperparameter search completed
2023-02-15 11:36:48,785:INFO:SubProcess create_model() called ==================================
2023-02-15 11:36:48,786:INFO:Initializing create_model()
2023-02-15 11:36:48,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7749, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201228F4E20>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 4, 'reg_alpha': 1e-07, 'num_leaves': 40, 'n_estimators': 130, 'min_split_gain': 0.9, 'min_child_samples': 56, 'learning_rate': 0.1, 'feature_fraction': 0.7, 'bagging_freq': 0, 'bagging_fraction': 0.7})
2023-02-15 11:36:48,787:INFO:Checking exceptions
2023-02-15 11:36:48,787:INFO:Importing libraries
2023-02-15 11:36:48,787:INFO:Copying training dataset
2023-02-15 11:36:48,820:INFO:Defining folds
2023-02-15 11:36:48,820:INFO:Declaring metric variables
2023-02-15 11:36:48,824:INFO:Importing untrained model
2023-02-15 11:36:48,824:INFO:Declaring custom model
2023-02-15 11:36:48,862:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:36:48,874:INFO:Starting cross validation
2023-02-15 11:36:48,877:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:36:50,777:INFO:Calculating mean and std
2023-02-15 11:36:50,779:INFO:Creating metrics dataframe
2023-02-15 11:36:50,789:INFO:Finalizing model
2023-02-15 11:36:52,406:INFO:Uploading results into container
2023-02-15 11:36:52,407:INFO:Uploading model into container now
2023-02-15 11:36:52,407:INFO:_master_model_container: 16
2023-02-15 11:36:52,407:INFO:_display_container: 3
2023-02-15 11:36:52,408:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=56, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=7749, reg_alpha=1e-07, reg_lambda=4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:36:52,408:INFO:create_model() successfully completed......................................
2023-02-15 11:36:52,562:INFO:SubProcess create_model() end ==================================
2023-02-15 11:36:52,563:INFO:choose_better activated
2023-02-15 11:36:52,571:INFO:SubProcess create_model() called ==================================
2023-02-15 11:36:52,572:INFO:Initializing create_model()
2023-02-15 11:36:52,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7749, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:36:52,573:INFO:Checking exceptions
2023-02-15 11:36:52,575:INFO:Importing libraries
2023-02-15 11:36:52,575:INFO:Copying training dataset
2023-02-15 11:36:52,612:INFO:Defining folds
2023-02-15 11:36:52,612:INFO:Declaring metric variables
2023-02-15 11:36:52,613:INFO:Importing untrained model
2023-02-15 11:36:52,613:INFO:Declaring custom model
2023-02-15 11:36:52,619:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:36:52,620:INFO:Starting cross validation
2023-02-15 11:36:52,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:36:53,651:INFO:Calculating mean and std
2023-02-15 11:36:53,652:INFO:Creating metrics dataframe
2023-02-15 11:36:53,654:INFO:Finalizing model
2023-02-15 11:36:53,756:INFO:Uploading results into container
2023-02-15 11:36:53,757:INFO:Uploading model into container now
2023-02-15 11:36:53,757:INFO:_master_model_container: 17
2023-02-15 11:36:53,757:INFO:_display_container: 4
2023-02-15 11:36:53,758:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7749, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:36:53,758:INFO:create_model() successfully completed......................................
2023-02-15 11:36:53,980:INFO:SubProcess create_model() end ==================================
2023-02-15 11:36:53,982:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7749, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9354
2023-02-15 11:36:53,984:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=56, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=7749, reg_alpha=1e-07, reg_lambda=4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9359
2023-02-15 11:36:53,984:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=56, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=7749, reg_alpha=1e-07, reg_lambda=4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-02-15 11:36:53,985:INFO:choose_better completed
2023-02-15 11:36:53,997:INFO:_master_model_container: 17
2023-02-15 11:36:53,999:INFO:_display_container: 3
2023-02-15 11:36:54,000:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=56, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=7749, reg_alpha=1e-07, reg_lambda=4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:36:54,000:INFO:tune_model() successfully completed......................................
2023-02-15 11:36:54,179:INFO:Initializing tune_model()
2023-02-15 11:36:54,179:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020122710250>)
2023-02-15 11:36:54,179:INFO:Checking exceptions
2023-02-15 11:36:54,216:INFO:Copying training dataset
2023-02-15 11:36:54,244:INFO:Checking base model
2023-02-15 11:36:54,244:INFO:Base model : Extreme Gradient Boosting
2023-02-15 11:36:54,255:INFO:Declaring metric variables
2023-02-15 11:36:54,259:INFO:Defining Hyperparameters
2023-02-15 11:36:54,420:INFO:Tuning with n_jobs=-1
2023-02-15 11:36:54,420:INFO:Initializing RandomizedSearchCV
2023-02-15 11:45:08,122:INFO:PyCaret ClassificationExperiment
2023-02-15 11:45:08,122:INFO:Logging name: clf-default-name
2023-02-15 11:45:08,122:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-15 11:45:08,122:INFO:version 3.0.0.rc9
2023-02-15 11:45:08,122:INFO:Initializing setup()
2023-02-15 11:45:08,122:INFO:self.USI: 6ecb
2023-02-15 11:45:08,123:INFO:self._variable_keys: {'is_multiclass', 'pipeline', 'n_jobs_param', 'X_train', 'fold_generator', '_available_plots', 'X_test', 'idx', 'seed', 'log_plots_param', 'y_test', 'fix_imbalance', 'logging_param', 'fold_groups_param', 'exp_id', 'X', 'exp_name_log', '_ml_usecase', 'data', 'memory', 'USI', 'html_param', 'target_param', 'y_train', 'gpu_n_jobs_param', 'y', 'fold_shuffle_param', 'gpu_param'}
2023-02-15 11:45:08,123:INFO:Checking environment
2023-02-15 11:45:08,123:INFO:python_version: 3.9.15
2023-02-15 11:45:08,123:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-15 11:45:08,123:INFO:machine: AMD64
2023-02-15 11:45:08,123:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-15 11:45:08,123:INFO:Memory: svmem(total=8469581824, available=2096599040, percent=75.2, used=6372982784, free=2096599040)
2023-02-15 11:45:08,123:INFO:Physical Core: 4
2023-02-15 11:45:08,123:INFO:Logical Core: 4
2023-02-15 11:45:08,123:INFO:Checking libraries
2023-02-15 11:45:08,123:INFO:System:
2023-02-15 11:45:08,123:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-15 11:45:08,123:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-15 11:45:08,124:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-15 11:45:08,124:INFO:PyCaret required dependencies:
2023-02-15 11:45:08,124:INFO:                 pip: 22.3.1
2023-02-15 11:45:08,124:INFO:          setuptools: 60.10.0
2023-02-15 11:45:08,124:INFO:             pycaret: 3.0.0rc9
2023-02-15 11:45:08,124:INFO:             IPython: 7.31.1
2023-02-15 11:45:08,124:INFO:          ipywidgets: 7.6.5
2023-02-15 11:45:08,124:INFO:                tqdm: 4.64.1
2023-02-15 11:45:08,124:INFO:               numpy: 1.21.5
2023-02-15 11:45:08,124:INFO:              pandas: 1.4.4
2023-02-15 11:45:08,124:INFO:              jinja2: 2.11.3
2023-02-15 11:45:08,124:INFO:               scipy: 1.9.3
2023-02-15 11:45:08,124:INFO:              joblib: 1.2.0
2023-02-15 11:45:08,124:INFO:             sklearn: 1.0.2
2023-02-15 11:45:08,124:INFO:                pyod: 1.0.7
2023-02-15 11:45:08,124:INFO:            imblearn: 0.10.1
2023-02-15 11:45:08,124:INFO:   category_encoders: 2.6.0
2023-02-15 11:45:08,125:INFO:            lightgbm: 3.3.5
2023-02-15 11:45:08,125:INFO:               numba: 0.56.4
2023-02-15 11:45:08,125:INFO:            requests: 2.28.1
2023-02-15 11:45:08,125:INFO:          matplotlib: 3.6.2
2023-02-15 11:45:08,125:INFO:          scikitplot: 0.3.7
2023-02-15 11:45:08,125:INFO:         yellowbrick: 1.5
2023-02-15 11:45:08,125:INFO:              plotly: 5.9.0
2023-02-15 11:45:08,125:INFO:             kaleido: 0.2.1
2023-02-15 11:45:08,125:INFO:         statsmodels: 0.13.2
2023-02-15 11:45:08,125:INFO:              sktime: 0.16.1
2023-02-15 11:45:08,125:INFO:               tbats: 1.1.2
2023-02-15 11:45:08,125:INFO:            pmdarima: 2.0.2
2023-02-15 11:45:08,125:INFO:              psutil: 5.9.0
2023-02-15 11:45:08,126:INFO:PyCaret optional dependencies:
2023-02-15 11:45:08,126:INFO:                shap: 0.41.0
2023-02-15 11:45:08,126:INFO:           interpret: Not installed
2023-02-15 11:45:08,126:INFO:                umap: Not installed
2023-02-15 11:45:08,126:INFO:    pandas_profiling: 4.0.0
2023-02-15 11:45:08,126:INFO:  explainerdashboard: 0.3.6.2
2023-02-15 11:45:08,126:INFO:             autoviz: 0.1.58
2023-02-15 11:45:08,126:INFO:           fairlearn: Not installed
2023-02-15 11:45:08,126:INFO:             xgboost: 1.7.3
2023-02-15 11:45:08,126:INFO:            catboost: Not installed
2023-02-15 11:45:08,126:INFO:              kmodes: Not installed
2023-02-15 11:45:08,126:INFO:             mlxtend: Not installed
2023-02-15 11:45:08,126:INFO:       statsforecast: Not installed
2023-02-15 11:45:08,126:INFO:        tune_sklearn: Not installed
2023-02-15 11:45:08,127:INFO:                 ray: Not installed
2023-02-15 11:45:08,127:INFO:            hyperopt: Not installed
2023-02-15 11:45:08,127:INFO:              optuna: 2.10.1
2023-02-15 11:45:08,127:INFO:               skopt: Not installed
2023-02-15 11:45:08,127:INFO:              mlflow: Not installed
2023-02-15 11:45:08,127:INFO:              gradio: Not installed
2023-02-15 11:45:08,127:INFO:             fastapi: Not installed
2023-02-15 11:45:08,127:INFO:             uvicorn: Not installed
2023-02-15 11:45:08,127:INFO:              m2cgen: Not installed
2023-02-15 11:45:08,127:INFO:           evidently: Not installed
2023-02-15 11:45:08,127:INFO:               fugue: Not installed
2023-02-15 11:45:08,127:INFO:           streamlit: Not installed
2023-02-15 11:45:08,127:INFO:             prophet: Not installed
2023-02-15 11:45:08,127:INFO:None
2023-02-15 11:45:08,127:INFO:Set up data.
2023-02-15 11:45:08,233:INFO:Set up train/test split.
2023-02-15 11:45:08,290:INFO:Set up index.
2023-02-15 11:45:08,294:INFO:Set up folding strategy.
2023-02-15 11:45:08,294:INFO:Assigning column types.
2023-02-15 11:45:08,311:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-15 11:45:08,367:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 11:45:08,368:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-15 11:45:08,406:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:45:08,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:45:08,473:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-15 11:45:08,477:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-15 11:45:08,529:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:45:08,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:45:08,533:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-15 11:45:08,590:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-15 11:45:08,624:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:45:08,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:45:08,694:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-15 11:45:08,730:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:45:08,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:45:08,733:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-15 11:45:08,829:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:45:08,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:45:08,935:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:45:08,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:45:08,939:INFO:Preparing preprocessing pipeline...
2023-02-15 11:45:08,948:INFO:Set up simple imputation.
2023-02-15 11:45:08,948:INFO:Set up imbalanced handling.
2023-02-15 11:45:09,124:INFO:Finished creating preprocessing pipeline.
2023-02-15 11:45:09,141:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2023-02-15 11:45:09,141:INFO:Creating final display dataframe.
2023-02-15 11:45:10,204:INFO:Setup _display_container:                     Description             Value
0                    Session id              2421
1                        Target      inadimplente
2                   Target type            Binary
3           Original data shape       (88000, 11)
4        Transformed data shape      (141361, 11)
5   Transformed train set shape      (114960, 11)
6    Transformed test set shape       (26401, 11)
7              Numeric features                10
8      Rows with missing values             19.8%
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                Fix imbalance              True
14         Fix imbalance method             SMOTE
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              6ecb
2023-02-15 11:45:10,316:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:45:10,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:45:10,410:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-15 11:45:10,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-15 11:45:10,414:INFO:setup() successfully completed in 2.29s...............
2023-02-15 11:45:10,414:INFO:Initializing compare_models()
2023-02-15 11:45:10,414:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-15 11:45:10,414:INFO:Checking exceptions
2023-02-15 11:45:10,429:INFO:Preparing display monitor
2023-02-15 11:45:10,471:INFO:Initializing Logistic Regression
2023-02-15 11:45:10,471:INFO:Total runtime is 0.0 minutes
2023-02-15 11:45:10,481:INFO:SubProcess create_model() called ==================================
2023-02-15 11:45:10,482:INFO:Initializing create_model()
2023-02-15 11:45:10,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:45:10,482:INFO:Checking exceptions
2023-02-15 11:45:10,482:INFO:Importing libraries
2023-02-15 11:45:10,482:INFO:Copying training dataset
2023-02-15 11:45:10,517:INFO:Defining folds
2023-02-15 11:45:10,517:INFO:Declaring metric variables
2023-02-15 11:45:10,523:INFO:Importing untrained model
2023-02-15 11:45:10,529:INFO:Logistic Regression Imported successfully
2023-02-15 11:45:10,537:INFO:Starting cross validation
2023-02-15 11:45:10,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:45:22,782:INFO:Calculating mean and std
2023-02-15 11:45:22,783:INFO:Creating metrics dataframe
2023-02-15 11:45:22,788:INFO:Uploading results into container
2023-02-15 11:45:22,789:INFO:Uploading model into container now
2023-02-15 11:45:22,789:INFO:_master_model_container: 1
2023-02-15 11:45:22,790:INFO:_display_container: 2
2023-02-15 11:45:22,790:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2421, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-15 11:45:22,791:INFO:create_model() successfully completed......................................
2023-02-15 11:45:22,948:INFO:SubProcess create_model() end ==================================
2023-02-15 11:45:22,949:INFO:Creating metrics dataframe
2023-02-15 11:45:22,959:INFO:Initializing K Neighbors Classifier
2023-02-15 11:45:22,959:INFO:Total runtime is 0.2081484874089559 minutes
2023-02-15 11:45:22,965:INFO:SubProcess create_model() called ==================================
2023-02-15 11:45:22,965:INFO:Initializing create_model()
2023-02-15 11:45:22,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:45:22,965:INFO:Checking exceptions
2023-02-15 11:45:22,966:INFO:Importing libraries
2023-02-15 11:45:22,966:INFO:Copying training dataset
2023-02-15 11:45:23,001:INFO:Defining folds
2023-02-15 11:45:23,001:INFO:Declaring metric variables
2023-02-15 11:45:23,006:INFO:Importing untrained model
2023-02-15 11:45:23,011:INFO:K Neighbors Classifier Imported successfully
2023-02-15 11:45:23,019:INFO:Starting cross validation
2023-02-15 11:45:23,021:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:45:25,069:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:45:25,069:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:45:25,072:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:45:25,123:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:45:27,195:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:45:27,424:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:45:27,802:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:45:28,106:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:45:29,582:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:45:29,840:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-15 11:45:30,479:INFO:Calculating mean and std
2023-02-15 11:45:30,481:INFO:Creating metrics dataframe
2023-02-15 11:45:30,487:INFO:Uploading results into container
2023-02-15 11:45:30,488:INFO:Uploading model into container now
2023-02-15 11:45:30,488:INFO:_master_model_container: 2
2023-02-15 11:45:30,488:INFO:_display_container: 2
2023-02-15 11:45:30,489:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-15 11:45:30,489:INFO:create_model() successfully completed......................................
2023-02-15 11:45:30,662:INFO:SubProcess create_model() end ==================================
2023-02-15 11:45:30,662:INFO:Creating metrics dataframe
2023-02-15 11:45:30,681:INFO:Initializing Naive Bayes
2023-02-15 11:45:30,682:INFO:Total runtime is 0.33686269124348955 minutes
2023-02-15 11:45:30,687:INFO:SubProcess create_model() called ==================================
2023-02-15 11:45:30,687:INFO:Initializing create_model()
2023-02-15 11:45:30,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:45:30,688:INFO:Checking exceptions
2023-02-15 11:45:30,688:INFO:Importing libraries
2023-02-15 11:45:30,688:INFO:Copying training dataset
2023-02-15 11:45:30,722:INFO:Defining folds
2023-02-15 11:45:30,722:INFO:Declaring metric variables
2023-02-15 11:45:30,728:INFO:Importing untrained model
2023-02-15 11:45:30,735:INFO:Naive Bayes Imported successfully
2023-02-15 11:45:30,747:INFO:Starting cross validation
2023-02-15 11:45:30,749:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:45:31,454:INFO:Calculating mean and std
2023-02-15 11:45:31,455:INFO:Creating metrics dataframe
2023-02-15 11:45:31,462:INFO:Uploading results into container
2023-02-15 11:45:31,463:INFO:Uploading model into container now
2023-02-15 11:45:31,463:INFO:_master_model_container: 3
2023-02-15 11:45:31,464:INFO:_display_container: 2
2023-02-15 11:45:31,464:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-15 11:45:31,464:INFO:create_model() successfully completed......................................
2023-02-15 11:45:31,608:INFO:SubProcess create_model() end ==================================
2023-02-15 11:45:31,610:INFO:Creating metrics dataframe
2023-02-15 11:45:31,633:INFO:Initializing Decision Tree Classifier
2023-02-15 11:45:31,634:INFO:Total runtime is 0.35271601279576614 minutes
2023-02-15 11:45:31,639:INFO:SubProcess create_model() called ==================================
2023-02-15 11:45:31,639:INFO:Initializing create_model()
2023-02-15 11:45:31,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:45:31,640:INFO:Checking exceptions
2023-02-15 11:45:31,640:INFO:Importing libraries
2023-02-15 11:45:31,640:INFO:Copying training dataset
2023-02-15 11:45:31,696:INFO:Defining folds
2023-02-15 11:45:31,696:INFO:Declaring metric variables
2023-02-15 11:45:31,701:INFO:Importing untrained model
2023-02-15 11:45:31,706:INFO:Decision Tree Classifier Imported successfully
2023-02-15 11:45:31,717:INFO:Starting cross validation
2023-02-15 11:45:31,719:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:45:34,816:INFO:Calculating mean and std
2023-02-15 11:45:34,817:INFO:Creating metrics dataframe
2023-02-15 11:45:34,821:INFO:Uploading results into container
2023-02-15 11:45:34,822:INFO:Uploading model into container now
2023-02-15 11:45:34,823:INFO:_master_model_container: 4
2023-02-15 11:45:34,823:INFO:_display_container: 2
2023-02-15 11:45:34,823:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2421, splitter='best')
2023-02-15 11:45:34,823:INFO:create_model() successfully completed......................................
2023-02-15 11:45:34,999:INFO:SubProcess create_model() end ==================================
2023-02-15 11:45:34,999:INFO:Creating metrics dataframe
2023-02-15 11:45:35,016:INFO:Initializing SVM - Linear Kernel
2023-02-15 11:45:35,016:INFO:Total runtime is 0.409091571966807 minutes
2023-02-15 11:45:35,021:INFO:SubProcess create_model() called ==================================
2023-02-15 11:45:35,022:INFO:Initializing create_model()
2023-02-15 11:45:35,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:45:35,022:INFO:Checking exceptions
2023-02-15 11:45:35,022:INFO:Importing libraries
2023-02-15 11:45:35,022:INFO:Copying training dataset
2023-02-15 11:45:35,051:INFO:Defining folds
2023-02-15 11:45:35,051:INFO:Declaring metric variables
2023-02-15 11:45:35,057:INFO:Importing untrained model
2023-02-15 11:45:35,064:INFO:SVM - Linear Kernel Imported successfully
2023-02-15 11:45:35,072:INFO:Starting cross validation
2023-02-15 11:45:35,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:45:37,667:INFO:Calculating mean and std
2023-02-15 11:45:37,668:INFO:Creating metrics dataframe
2023-02-15 11:45:37,673:INFO:Uploading results into container
2023-02-15 11:45:37,673:INFO:Uploading model into container now
2023-02-15 11:45:37,674:INFO:_master_model_container: 5
2023-02-15 11:45:37,674:INFO:_display_container: 2
2023-02-15 11:45:37,675:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2421, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-15 11:45:37,676:INFO:create_model() successfully completed......................................
2023-02-15 11:45:37,831:INFO:SubProcess create_model() end ==================================
2023-02-15 11:45:37,831:INFO:Creating metrics dataframe
2023-02-15 11:45:37,847:INFO:Initializing Ridge Classifier
2023-02-15 11:45:37,847:INFO:Total runtime is 0.45626725753148395 minutes
2023-02-15 11:45:37,851:INFO:SubProcess create_model() called ==================================
2023-02-15 11:45:37,851:INFO:Initializing create_model()
2023-02-15 11:45:37,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:45:37,852:INFO:Checking exceptions
2023-02-15 11:45:37,852:INFO:Importing libraries
2023-02-15 11:45:37,852:INFO:Copying training dataset
2023-02-15 11:45:37,884:INFO:Defining folds
2023-02-15 11:45:37,885:INFO:Declaring metric variables
2023-02-15 11:45:37,889:INFO:Importing untrained model
2023-02-15 11:45:37,894:INFO:Ridge Classifier Imported successfully
2023-02-15 11:45:37,905:INFO:Starting cross validation
2023-02-15 11:45:37,906:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:45:38,148:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=6.58598e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:45:38,157:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=7.34692e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:45:38,163:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=7.2917e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:45:38,197:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=6.82058e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:45:38,334:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=6.70096e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:45:38,368:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=6.54732e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:45:38,395:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=7.31751e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:45:38,402:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=6.74642e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:45:38,503:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=7.1823e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:45:38,530:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=6.27679e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 11:45:38,566:INFO:Calculating mean and std
2023-02-15 11:45:38,567:INFO:Creating metrics dataframe
2023-02-15 11:45:38,571:INFO:Uploading results into container
2023-02-15 11:45:38,571:INFO:Uploading model into container now
2023-02-15 11:45:38,572:INFO:_master_model_container: 6
2023-02-15 11:45:38,572:INFO:_display_container: 2
2023-02-15 11:45:38,573:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2421, solver='auto', tol=0.001)
2023-02-15 11:45:38,573:INFO:create_model() successfully completed......................................
2023-02-15 11:45:38,719:INFO:SubProcess create_model() end ==================================
2023-02-15 11:45:38,719:INFO:Creating metrics dataframe
2023-02-15 11:45:38,734:INFO:Initializing Random Forest Classifier
2023-02-15 11:45:38,734:INFO:Total runtime is 0.47105963627497355 minutes
2023-02-15 11:45:38,739:INFO:SubProcess create_model() called ==================================
2023-02-15 11:45:38,739:INFO:Initializing create_model()
2023-02-15 11:45:38,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:45:38,739:INFO:Checking exceptions
2023-02-15 11:45:38,740:INFO:Importing libraries
2023-02-15 11:45:38,740:INFO:Copying training dataset
2023-02-15 11:45:38,770:INFO:Defining folds
2023-02-15 11:45:38,770:INFO:Declaring metric variables
2023-02-15 11:45:38,776:INFO:Importing untrained model
2023-02-15 11:45:38,781:INFO:Random Forest Classifier Imported successfully
2023-02-15 11:45:38,789:INFO:Starting cross validation
2023-02-15 11:45:38,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:46:33,038:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:46:35,701:INFO:Calculating mean and std
2023-02-15 11:46:35,703:INFO:Creating metrics dataframe
2023-02-15 11:46:35,707:INFO:Uploading results into container
2023-02-15 11:46:35,709:INFO:Uploading model into container now
2023-02-15 11:46:35,709:INFO:_master_model_container: 7
2023-02-15 11:46:35,709:INFO:_display_container: 2
2023-02-15 11:46:35,710:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2421, verbose=0, warm_start=False)
2023-02-15 11:46:35,710:INFO:create_model() successfully completed......................................
2023-02-15 11:46:35,879:INFO:SubProcess create_model() end ==================================
2023-02-15 11:46:35,879:INFO:Creating metrics dataframe
2023-02-15 11:46:35,893:INFO:Initializing Quadratic Discriminant Analysis
2023-02-15 11:46:35,893:INFO:Total runtime is 1.423701238632202 minutes
2023-02-15 11:46:35,898:INFO:SubProcess create_model() called ==================================
2023-02-15 11:46:35,898:INFO:Initializing create_model()
2023-02-15 11:46:35,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:46:35,899:INFO:Checking exceptions
2023-02-15 11:46:35,899:INFO:Importing libraries
2023-02-15 11:46:35,899:INFO:Copying training dataset
2023-02-15 11:46:35,938:INFO:Defining folds
2023-02-15 11:46:35,939:INFO:Declaring metric variables
2023-02-15 11:46:35,945:INFO:Importing untrained model
2023-02-15 11:46:35,950:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-15 11:46:35,959:INFO:Starting cross validation
2023-02-15 11:46:35,961:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:46:41,459:INFO:Calculating mean and std
2023-02-15 11:46:41,460:INFO:Creating metrics dataframe
2023-02-15 11:46:41,466:INFO:Uploading results into container
2023-02-15 11:46:41,467:INFO:Uploading model into container now
2023-02-15 11:46:41,468:INFO:_master_model_container: 8
2023-02-15 11:46:41,468:INFO:_display_container: 2
2023-02-15 11:46:41,468:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-15 11:46:41,468:INFO:create_model() successfully completed......................................
2023-02-15 11:46:41,639:INFO:SubProcess create_model() end ==================================
2023-02-15 11:46:41,640:INFO:Creating metrics dataframe
2023-02-15 11:46:41,654:INFO:Initializing Ada Boost Classifier
2023-02-15 11:46:41,654:INFO:Total runtime is 1.5197265187899271 minutes
2023-02-15 11:46:41,659:INFO:SubProcess create_model() called ==================================
2023-02-15 11:46:41,660:INFO:Initializing create_model()
2023-02-15 11:46:41,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:46:41,662:INFO:Checking exceptions
2023-02-15 11:46:41,662:INFO:Importing libraries
2023-02-15 11:46:41,662:INFO:Copying training dataset
2023-02-15 11:46:41,699:INFO:Defining folds
2023-02-15 11:46:41,699:INFO:Declaring metric variables
2023-02-15 11:46:41,712:INFO:Importing untrained model
2023-02-15 11:46:41,718:INFO:Ada Boost Classifier Imported successfully
2023-02-15 11:46:41,730:INFO:Starting cross validation
2023-02-15 11:46:41,732:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:47:05,089:INFO:Calculating mean and std
2023-02-15 11:47:05,090:INFO:Creating metrics dataframe
2023-02-15 11:47:05,095:INFO:Uploading results into container
2023-02-15 11:47:05,096:INFO:Uploading model into container now
2023-02-15 11:47:05,097:INFO:_master_model_container: 9
2023-02-15 11:47:05,097:INFO:_display_container: 2
2023-02-15 11:47:05,098:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2421)
2023-02-15 11:47:05,098:INFO:create_model() successfully completed......................................
2023-02-15 11:47:05,237:INFO:SubProcess create_model() end ==================================
2023-02-15 11:47:05,238:INFO:Creating metrics dataframe
2023-02-15 11:47:05,252:INFO:Initializing Gradient Boosting Classifier
2023-02-15 11:47:05,252:INFO:Total runtime is 1.9130252679189046 minutes
2023-02-15 11:47:05,256:INFO:SubProcess create_model() called ==================================
2023-02-15 11:47:05,257:INFO:Initializing create_model()
2023-02-15 11:47:05,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:47:05,258:INFO:Checking exceptions
2023-02-15 11:47:05,258:INFO:Importing libraries
2023-02-15 11:47:05,258:INFO:Copying training dataset
2023-02-15 11:47:05,296:INFO:Defining folds
2023-02-15 11:47:05,296:INFO:Declaring metric variables
2023-02-15 11:47:05,300:INFO:Importing untrained model
2023-02-15 11:47:05,304:INFO:Gradient Boosting Classifier Imported successfully
2023-02-15 11:47:05,314:INFO:Starting cross validation
2023-02-15 11:47:05,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:48:44,422:INFO:Calculating mean and std
2023-02-15 11:48:44,426:INFO:Creating metrics dataframe
2023-02-15 11:48:44,432:INFO:Uploading results into container
2023-02-15 11:48:44,433:INFO:Uploading model into container now
2023-02-15 11:48:44,434:INFO:_master_model_container: 10
2023-02-15 11:48:44,434:INFO:_display_container: 2
2023-02-15 11:48:44,435:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2421, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-15 11:48:44,435:INFO:create_model() successfully completed......................................
2023-02-15 11:48:44,601:INFO:SubProcess create_model() end ==================================
2023-02-15 11:48:44,601:INFO:Creating metrics dataframe
2023-02-15 11:48:44,655:INFO:Initializing Linear Discriminant Analysis
2023-02-15 11:48:44,655:INFO:Total runtime is 3.5697415550549825 minutes
2023-02-15 11:48:44,663:INFO:SubProcess create_model() called ==================================
2023-02-15 11:48:44,664:INFO:Initializing create_model()
2023-02-15 11:48:44,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:48:44,665:INFO:Checking exceptions
2023-02-15 11:48:44,665:INFO:Importing libraries
2023-02-15 11:48:44,665:INFO:Copying training dataset
2023-02-15 11:48:44,699:INFO:Defining folds
2023-02-15 11:48:44,699:INFO:Declaring metric variables
2023-02-15 11:48:44,704:INFO:Importing untrained model
2023-02-15 11:48:44,711:INFO:Linear Discriminant Analysis Imported successfully
2023-02-15 11:48:44,721:INFO:Starting cross validation
2023-02-15 11:48:44,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:48:46,610:INFO:Calculating mean and std
2023-02-15 11:48:46,611:INFO:Creating metrics dataframe
2023-02-15 11:48:46,621:INFO:Uploading results into container
2023-02-15 11:48:46,622:INFO:Uploading model into container now
2023-02-15 11:48:46,622:INFO:_master_model_container: 11
2023-02-15 11:48:46,622:INFO:_display_container: 2
2023-02-15 11:48:46,623:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-15 11:48:46,623:INFO:create_model() successfully completed......................................
2023-02-15 11:48:46,810:INFO:SubProcess create_model() end ==================================
2023-02-15 11:48:46,810:INFO:Creating metrics dataframe
2023-02-15 11:48:46,828:INFO:Initializing Extra Trees Classifier
2023-02-15 11:48:46,828:INFO:Total runtime is 3.605961445967356 minutes
2023-02-15 11:48:46,833:INFO:SubProcess create_model() called ==================================
2023-02-15 11:48:46,833:INFO:Initializing create_model()
2023-02-15 11:48:46,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:48:46,833:INFO:Checking exceptions
2023-02-15 11:48:46,834:INFO:Importing libraries
2023-02-15 11:48:46,834:INFO:Copying training dataset
2023-02-15 11:48:46,878:INFO:Defining folds
2023-02-15 11:48:46,878:INFO:Declaring metric variables
2023-02-15 11:48:46,883:INFO:Importing untrained model
2023-02-15 11:48:46,887:INFO:Extra Trees Classifier Imported successfully
2023-02-15 11:48:46,899:INFO:Starting cross validation
2023-02-15 11:48:46,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:49:17,613:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:49:21,437:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 2.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:49:22,104:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:49:47,746:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 4.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:49:59,630:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 4.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:49:59,813:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 5.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:50:00,670:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 5.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:50:00,671:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-15 11:50:01,380:INFO:Calculating mean and std
2023-02-15 11:50:01,382:INFO:Creating metrics dataframe
2023-02-15 11:50:01,391:INFO:Uploading results into container
2023-02-15 11:50:01,392:INFO:Uploading model into container now
2023-02-15 11:50:01,393:INFO:_master_model_container: 12
2023-02-15 11:50:01,393:INFO:_display_container: 2
2023-02-15 11:50:01,394:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2421, verbose=0, warm_start=False)
2023-02-15 11:50:01,394:INFO:create_model() successfully completed......................................
2023-02-15 11:50:01,563:INFO:SubProcess create_model() end ==================================
2023-02-15 11:50:01,563:INFO:Creating metrics dataframe
2023-02-15 11:50:01,604:INFO:Initializing Extreme Gradient Boosting
2023-02-15 11:50:01,604:INFO:Total runtime is 4.852226920922597 minutes
2023-02-15 11:50:01,610:INFO:SubProcess create_model() called ==================================
2023-02-15 11:50:01,611:INFO:Initializing create_model()
2023-02-15 11:50:01,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:50:01,612:INFO:Checking exceptions
2023-02-15 11:50:01,612:INFO:Importing libraries
2023-02-15 11:50:01,612:INFO:Copying training dataset
2023-02-15 11:50:01,645:INFO:Defining folds
2023-02-15 11:50:01,646:INFO:Declaring metric variables
2023-02-15 11:50:01,654:INFO:Importing untrained model
2023-02-15 11:50:01,662:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 11:50:01,671:INFO:Starting cross validation
2023-02-15 11:50:01,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:51:11,940:INFO:Calculating mean and std
2023-02-15 11:51:11,942:INFO:Creating metrics dataframe
2023-02-15 11:51:11,947:INFO:Uploading results into container
2023-02-15 11:51:11,948:INFO:Uploading model into container now
2023-02-15 11:51:11,948:INFO:_master_model_container: 13
2023-02-15 11:51:11,949:INFO:_display_container: 2
2023-02-15 11:51:11,950:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-15 11:51:11,951:INFO:create_model() successfully completed......................................
2023-02-15 11:51:12,094:INFO:SubProcess create_model() end ==================================
2023-02-15 11:51:12,094:INFO:Creating metrics dataframe
2023-02-15 11:51:12,160:INFO:Initializing Light Gradient Boosting Machine
2023-02-15 11:51:12,160:INFO:Total runtime is 6.028159459431966 minutes
2023-02-15 11:51:12,165:INFO:SubProcess create_model() called ==================================
2023-02-15 11:51:12,166:INFO:Initializing create_model()
2023-02-15 11:51:12,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:51:12,166:INFO:Checking exceptions
2023-02-15 11:51:12,166:INFO:Importing libraries
2023-02-15 11:51:12,166:INFO:Copying training dataset
2023-02-15 11:51:12,195:INFO:Defining folds
2023-02-15 11:51:12,196:INFO:Declaring metric variables
2023-02-15 11:51:12,202:INFO:Importing untrained model
2023-02-15 11:51:12,209:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:51:12,230:INFO:Starting cross validation
2023-02-15 11:51:12,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:51:20,982:INFO:Calculating mean and std
2023-02-15 11:51:20,983:INFO:Creating metrics dataframe
2023-02-15 11:51:20,988:INFO:Uploading results into container
2023-02-15 11:51:20,990:INFO:Uploading model into container now
2023-02-15 11:51:20,991:INFO:_master_model_container: 14
2023-02-15 11:51:20,991:INFO:_display_container: 2
2023-02-15 11:51:20,992:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:51:20,992:INFO:create_model() successfully completed......................................
2023-02-15 11:51:21,136:INFO:SubProcess create_model() end ==================================
2023-02-15 11:51:21,136:INFO:Creating metrics dataframe
2023-02-15 11:51:21,192:INFO:Initializing Dummy Classifier
2023-02-15 11:51:21,192:INFO:Total runtime is 6.178693687915802 minutes
2023-02-15 11:51:21,196:INFO:SubProcess create_model() called ==================================
2023-02-15 11:51:21,197:INFO:Initializing create_model()
2023-02-15 11:51:21,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020121440640>, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:51:21,197:INFO:Checking exceptions
2023-02-15 11:51:21,197:INFO:Importing libraries
2023-02-15 11:51:21,197:INFO:Copying training dataset
2023-02-15 11:51:21,229:INFO:Defining folds
2023-02-15 11:51:21,229:INFO:Declaring metric variables
2023-02-15 11:51:21,234:INFO:Importing untrained model
2023-02-15 11:51:21,243:INFO:Dummy Classifier Imported successfully
2023-02-15 11:51:21,252:INFO:Starting cross validation
2023-02-15 11:51:21,255:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:51:21,459:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:51:21,474:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:51:21,492:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:51:21,600:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:51:21,634:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:51:21,646:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:51:21,667:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:51:21,733:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:51:21,793:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 11:51:21,799:INFO:Calculating mean and std
2023-02-15 11:51:21,800:INFO:Creating metrics dataframe
2023-02-15 11:51:21,815:INFO:Uploading results into container
2023-02-15 11:51:21,816:INFO:Uploading model into container now
2023-02-15 11:51:21,816:INFO:_master_model_container: 15
2023-02-15 11:51:21,816:INFO:_display_container: 2
2023-02-15 11:51:21,817:INFO:DummyClassifier(constant=None, random_state=2421, strategy='prior')
2023-02-15 11:51:21,817:INFO:create_model() successfully completed......................................
2023-02-15 11:51:21,960:INFO:SubProcess create_model() end ==================================
2023-02-15 11:51:21,960:INFO:Creating metrics dataframe
2023-02-15 11:51:22,077:INFO:Initializing create_model()
2023-02-15 11:51:22,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:51:22,112:INFO:Checking exceptions
2023-02-15 11:51:22,115:INFO:Importing libraries
2023-02-15 11:51:22,115:INFO:Copying training dataset
2023-02-15 11:51:22,147:INFO:Defining folds
2023-02-15 11:51:22,147:INFO:Declaring metric variables
2023-02-15 11:51:22,147:INFO:Importing untrained model
2023-02-15 11:51:22,147:INFO:Declaring custom model
2023-02-15 11:51:22,148:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:51:22,149:INFO:Cross validation set to False
2023-02-15 11:51:22,149:INFO:Fitting Model
2023-02-15 11:51:24,081:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:51:24,081:INFO:create_model() successfully completed......................................
2023-02-15 11:51:24,236:INFO:Initializing create_model()
2023-02-15 11:51:24,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:51:24,237:INFO:Checking exceptions
2023-02-15 11:51:24,243:INFO:Importing libraries
2023-02-15 11:51:24,243:INFO:Copying training dataset
2023-02-15 11:51:24,273:INFO:Defining folds
2023-02-15 11:51:24,273:INFO:Declaring metric variables
2023-02-15 11:51:24,274:INFO:Importing untrained model
2023-02-15 11:51:24,274:INFO:Declaring custom model
2023-02-15 11:51:24,276:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 11:51:24,277:INFO:Cross validation set to False
2023-02-15 11:51:24,278:INFO:Fitting Model
2023-02-15 11:51:31,164:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-15 11:51:31,164:INFO:create_model() successfully completed......................................
2023-02-15 11:51:31,337:INFO:Initializing create_model()
2023-02-15 11:51:31,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=DummyClassifier(constant=None, random_state=2421, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:51:31,337:INFO:Checking exceptions
2023-02-15 11:51:31,343:INFO:Importing libraries
2023-02-15 11:51:31,343:INFO:Copying training dataset
2023-02-15 11:51:31,368:INFO:Defining folds
2023-02-15 11:51:31,368:INFO:Declaring metric variables
2023-02-15 11:51:31,369:INFO:Importing untrained model
2023-02-15 11:51:31,369:INFO:Declaring custom model
2023-02-15 11:51:31,369:INFO:Dummy Classifier Imported successfully
2023-02-15 11:51:31,372:INFO:Cross validation set to False
2023-02-15 11:51:31,372:INFO:Fitting Model
2023-02-15 11:51:31,446:INFO:DummyClassifier(constant=None, random_state=2421, strategy='prior')
2023-02-15 11:51:31,446:INFO:create_model() successfully completed......................................
2023-02-15 11:51:31,636:INFO:_master_model_container: 15
2023-02-15 11:51:31,636:INFO:_display_container: 2
2023-02-15 11:51:31,639:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), DummyClassifier(constant=None, random_state=2421, strategy='prior')]
2023-02-15 11:51:31,639:INFO:compare_models() successfully completed......................................
2023-02-15 11:51:31,646:INFO:Initializing tune_model()
2023-02-15 11:51:31,646:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>)
2023-02-15 11:51:31,646:INFO:Checking exceptions
2023-02-15 11:51:31,683:INFO:Copying training dataset
2023-02-15 11:51:31,701:INFO:Checking base model
2023-02-15 11:51:31,701:INFO:Base model : Light Gradient Boosting Machine
2023-02-15 11:51:31,708:INFO:Declaring metric variables
2023-02-15 11:51:31,713:INFO:Defining Hyperparameters
2023-02-15 11:51:31,884:INFO:Tuning with n_jobs=-1
2023-02-15 11:51:31,885:INFO:Initializing RandomizedSearchCV
2023-02-15 11:53:09,951:INFO:best_params: {'actual_estimator__reg_lambda': 0.3, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 280, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 81, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.8}
2023-02-15 11:53:09,952:INFO:Hyperparameter search completed
2023-02-15 11:53:09,953:INFO:SubProcess create_model() called ==================================
2023-02-15 11:53:09,955:INFO:Initializing create_model()
2023-02-15 11:53:10,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020122964370>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.3, 'reg_alpha': 0.005, 'num_leaves': 30, 'n_estimators': 280, 'min_split_gain': 0.9, 'min_child_samples': 81, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 5, 'bagging_fraction': 0.8})
2023-02-15 11:53:10,014:INFO:Checking exceptions
2023-02-15 11:53:10,015:INFO:Importing libraries
2023-02-15 11:53:10,017:INFO:Copying training dataset
2023-02-15 11:53:10,059:INFO:Defining folds
2023-02-15 11:53:10,062:INFO:Declaring metric variables
2023-02-15 11:53:10,068:INFO:Importing untrained model
2023-02-15 11:53:10,071:INFO:Declaring custom model
2023-02-15 11:53:10,079:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:53:10,092:INFO:Starting cross validation
2023-02-15 11:53:10,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:53:27,335:INFO:Calculating mean and std
2023-02-15 11:53:27,338:INFO:Creating metrics dataframe
2023-02-15 11:53:27,346:INFO:Finalizing model
2023-02-15 11:53:30,368:INFO:Uploading results into container
2023-02-15 11:53:30,370:INFO:Uploading model into container now
2023-02-15 11:53:30,371:INFO:_master_model_container: 16
2023-02-15 11:53:30,371:INFO:_display_container: 3
2023-02-15 11:53:30,372:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=280, n_jobs=-1, num_leaves=30, objective=None,
               random_state=2421, reg_alpha=0.005, reg_lambda=0.3,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-02-15 11:53:30,372:INFO:create_model() successfully completed......................................
2023-02-15 11:53:30,531:INFO:SubProcess create_model() end ==================================
2023-02-15 11:53:30,531:INFO:choose_better activated
2023-02-15 11:53:30,534:INFO:SubProcess create_model() called ==================================
2023-02-15 11:53:30,535:INFO:Initializing create_model()
2023-02-15 11:53:30,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 11:53:30,535:INFO:Checking exceptions
2023-02-15 11:53:30,540:INFO:Importing libraries
2023-02-15 11:53:30,540:INFO:Copying training dataset
2023-02-15 11:53:30,568:INFO:Defining folds
2023-02-15 11:53:30,568:INFO:Declaring metric variables
2023-02-15 11:53:30,568:INFO:Importing untrained model
2023-02-15 11:53:30,568:INFO:Declaring custom model
2023-02-15 11:53:30,569:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 11:53:30,569:INFO:Starting cross validation
2023-02-15 11:53:30,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 11:53:36,469:INFO:Calculating mean and std
2023-02-15 11:53:36,472:INFO:Creating metrics dataframe
2023-02-15 11:53:36,474:INFO:Finalizing model
2023-02-15 11:53:38,368:INFO:Uploading results into container
2023-02-15 11:53:38,368:INFO:Uploading model into container now
2023-02-15 11:53:38,369:INFO:_master_model_container: 17
2023-02-15 11:53:38,369:INFO:_display_container: 4
2023-02-15 11:53:38,369:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:53:38,369:INFO:create_model() successfully completed......................................
2023-02-15 11:53:38,558:INFO:SubProcess create_model() end ==================================
2023-02-15 11:53:38,560:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9354
2023-02-15 11:53:38,561:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=280, n_jobs=-1, num_leaves=30, objective=None,
               random_state=2421, reg_alpha=0.005, reg_lambda=0.3,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for Accuracy is 0.9354
2023-02-15 11:53:38,561:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-02-15 11:53:38,561:INFO:choose_better completed
2023-02-15 11:53:38,561:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-15 11:53:38,574:INFO:_master_model_container: 17
2023-02-15 11:53:38,574:INFO:_display_container: 3
2023-02-15 11:53:38,574:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 11:53:38,575:INFO:tune_model() successfully completed......................................
2023-02-15 11:53:38,725:INFO:Initializing tune_model()
2023-02-15 11:53:38,725:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>)
2023-02-15 11:53:38,725:INFO:Checking exceptions
2023-02-15 11:53:38,759:INFO:Copying training dataset
2023-02-15 11:53:38,780:INFO:Checking base model
2023-02-15 11:53:38,781:INFO:Base model : Extreme Gradient Boosting
2023-02-15 11:53:38,785:INFO:Declaring metric variables
2023-02-15 11:53:38,792:INFO:Defining Hyperparameters
2023-02-15 11:53:38,977:INFO:Tuning with n_jobs=-1
2023-02-15 11:53:38,977:INFO:Initializing RandomizedSearchCV
2023-02-15 12:04:30,324:INFO:best_params: {'actual_estimator__subsample': 0.9, 'actual_estimator__scale_pos_weight': 35.7, 'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__colsample_bytree': 0.7}
2023-02-15 12:04:30,324:INFO:Hyperparameter search completed
2023-02-15 12:04:30,325:INFO:SubProcess create_model() called ==================================
2023-02-15 12:04:30,326:INFO:Initializing create_model()
2023-02-15 12:04:30,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020122964370>, model_only=True, return_train_score=False, kwargs={'subsample': 0.9, 'scale_pos_weight': 35.7, 'reg_lambda': 0.1, 'reg_alpha': 0.7, 'n_estimators': 190, 'min_child_weight': 3, 'max_depth': 9, 'learning_rate': 0.3, 'colsample_bytree': 0.7})
2023-02-15 12:04:30,327:INFO:Checking exceptions
2023-02-15 12:04:30,327:INFO:Importing libraries
2023-02-15 12:04:30,327:INFO:Copying training dataset
2023-02-15 12:04:30,358:INFO:Defining folds
2023-02-15 12:04:30,358:INFO:Declaring metric variables
2023-02-15 12:04:30,361:INFO:Importing untrained model
2023-02-15 12:04:30,362:INFO:Declaring custom model
2023-02-15 12:04:30,448:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 12:04:30,459:INFO:Starting cross validation
2023-02-15 12:04:30,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 12:04:33,543:INFO:Calculating mean and std
2023-02-15 12:04:33,543:INFO:Creating metrics dataframe
2023-02-15 12:04:33,550:INFO:Finalizing model
2023-02-15 12:04:51,054:INFO:Uploading results into container
2023-02-15 12:04:51,055:INFO:Uploading model into container now
2023-02-15 12:04:51,056:INFO:_master_model_container: 18
2023-02-15 12:04:51,056:INFO:_display_container: 4
2023-02-15 12:04:51,057:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.3, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=9, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              n_estimators=190, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-15 12:04:51,057:INFO:create_model() successfully completed......................................
2023-02-15 12:04:51,214:INFO:SubProcess create_model() end ==================================
2023-02-15 12:04:51,214:INFO:choose_better activated
2023-02-15 12:04:51,219:INFO:SubProcess create_model() called ==================================
2023-02-15 12:04:51,220:INFO:Initializing create_model()
2023-02-15 12:04:51,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:04:51,220:INFO:Checking exceptions
2023-02-15 12:04:51,222:INFO:Importing libraries
2023-02-15 12:04:51,222:INFO:Copying training dataset
2023-02-15 12:04:51,256:INFO:Defining folds
2023-02-15 12:04:51,256:INFO:Declaring metric variables
2023-02-15 12:04:51,256:INFO:Importing untrained model
2023-02-15 12:04:51,256:INFO:Declaring custom model
2023-02-15 12:04:51,258:INFO:Extreme Gradient Boosting Imported successfully
2023-02-15 12:04:51,258:INFO:Starting cross validation
2023-02-15 12:04:51,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 12:04:52,156:INFO:Calculating mean and std
2023-02-15 12:04:52,156:INFO:Creating metrics dataframe
2023-02-15 12:04:52,158:INFO:Finalizing model
2023-02-15 12:04:59,426:INFO:Uploading results into container
2023-02-15 12:04:59,427:INFO:Uploading model into container now
2023-02-15 12:04:59,427:INFO:_master_model_container: 19
2023-02-15 12:04:59,427:INFO:_display_container: 5
2023-02-15 12:04:59,428:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-15 12:04:59,429:INFO:create_model() successfully completed......................................
2023-02-15 12:04:59,576:INFO:SubProcess create_model() end ==================================
2023-02-15 12:04:59,577:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for Accuracy is 0.9347
2023-02-15 12:04:59,579:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.3, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=9, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              n_estimators=190, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for Accuracy is 0.8813
2023-02-15 12:04:59,581:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) is best model
2023-02-15 12:04:59,581:INFO:choose_better completed
2023-02-15 12:04:59,581:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-15 12:04:59,592:INFO:_master_model_container: 19
2023-02-15 12:04:59,593:INFO:_display_container: 4
2023-02-15 12:04:59,594:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-15 12:04:59,594:INFO:tune_model() successfully completed......................................
2023-02-15 12:04:59,750:INFO:Initializing tune_model()
2023-02-15 12:04:59,750:INFO:tune_model(estimator=DummyClassifier(constant=None, random_state=2421, strategy='prior'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>)
2023-02-15 12:04:59,750:INFO:Checking exceptions
2023-02-15 12:04:59,792:INFO:Copying training dataset
2023-02-15 12:04:59,843:INFO:Checking base model
2023-02-15 12:04:59,843:INFO:Base model : Dummy Classifier
2023-02-15 12:04:59,850:INFO:Declaring metric variables
2023-02-15 12:04:59,855:INFO:Defining Hyperparameters
2023-02-15 12:04:59,856:INFO:10 is bigger than total combinations 4, setting search algorithm to grid
2023-02-15 12:05:00,053:INFO:Tuning with n_jobs=-1
2023-02-15 12:05:00,053:INFO:Initializing GridSearchCV
2023-02-15 12:05:01,994:INFO:best_params: {'actual_estimator__strategy': 'most_frequent'}
2023-02-15 12:05:01,998:INFO:Hyperparameter search completed
2023-02-15 12:05:01,998:INFO:SubProcess create_model() called ==================================
2023-02-15 12:05:01,999:INFO:Initializing create_model()
2023-02-15 12:05:01,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=DummyClassifier(constant=None, random_state=2421, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020122964370>, model_only=True, return_train_score=False, kwargs={'strategy': 'most_frequent'})
2023-02-15 12:05:01,999:INFO:Checking exceptions
2023-02-15 12:05:01,999:INFO:Importing libraries
2023-02-15 12:05:01,999:INFO:Copying training dataset
2023-02-15 12:05:02,036:INFO:Defining folds
2023-02-15 12:05:02,036:INFO:Declaring metric variables
2023-02-15 12:05:02,042:INFO:Importing untrained model
2023-02-15 12:05:02,042:INFO:Declaring custom model
2023-02-15 12:05:02,093:INFO:Dummy Classifier Imported successfully
2023-02-15 12:05:02,105:INFO:Starting cross validation
2023-02-15 12:05:02,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 12:05:02,319:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:02,339:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:02,339:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:02,385:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:02,507:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:02,532:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:02,540:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:02,557:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:02,634:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:02,653:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:02,660:INFO:Calculating mean and std
2023-02-15 12:05:02,665:INFO:Creating metrics dataframe
2023-02-15 12:05:02,674:INFO:Finalizing model
2023-02-15 12:05:02,757:INFO:Uploading results into container
2023-02-15 12:05:02,758:INFO:Uploading model into container now
2023-02-15 12:05:02,759:INFO:_master_model_container: 20
2023-02-15 12:05:02,759:INFO:_display_container: 5
2023-02-15 12:05:02,759:INFO:DummyClassifier(constant=None, random_state=2421, strategy='most_frequent')
2023-02-15 12:05:02,759:INFO:create_model() successfully completed......................................
2023-02-15 12:05:02,916:INFO:SubProcess create_model() end ==================================
2023-02-15 12:05:02,917:INFO:choose_better activated
2023-02-15 12:05:02,920:INFO:SubProcess create_model() called ==================================
2023-02-15 12:05:02,921:INFO:Initializing create_model()
2023-02-15 12:05:02,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=DummyClassifier(constant=None, random_state=2421, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:05:02,921:INFO:Checking exceptions
2023-02-15 12:05:02,924:INFO:Importing libraries
2023-02-15 12:05:02,924:INFO:Copying training dataset
2023-02-15 12:05:02,960:INFO:Defining folds
2023-02-15 12:05:02,960:INFO:Declaring metric variables
2023-02-15 12:05:02,960:INFO:Importing untrained model
2023-02-15 12:05:02,960:INFO:Declaring custom model
2023-02-15 12:05:02,961:INFO:Dummy Classifier Imported successfully
2023-02-15 12:05:02,961:INFO:Starting cross validation
2023-02-15 12:05:02,966:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-15 12:05:03,156:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:03,177:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:03,187:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:03,211:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:03,340:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:03,343:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:03,344:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:03,359:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:03,476:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:03,486:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:05:03,493:INFO:Calculating mean and std
2023-02-15 12:05:03,494:INFO:Creating metrics dataframe
2023-02-15 12:05:03,498:INFO:Finalizing model
2023-02-15 12:05:03,576:INFO:Uploading results into container
2023-02-15 12:05:03,577:INFO:Uploading model into container now
2023-02-15 12:05:03,577:INFO:_master_model_container: 21
2023-02-15 12:05:03,577:INFO:_display_container: 6
2023-02-15 12:05:03,577:INFO:DummyClassifier(constant=None, random_state=2421, strategy='prior')
2023-02-15 12:05:03,577:INFO:create_model() successfully completed......................................
2023-02-15 12:05:03,723:INFO:SubProcess create_model() end ==================================
2023-02-15 12:05:03,724:INFO:DummyClassifier(constant=None, random_state=2421, strategy='prior') result for Accuracy is 0.9331
2023-02-15 12:05:03,724:INFO:DummyClassifier(constant=None, random_state=2421, strategy='most_frequent') result for Accuracy is 0.9331
2023-02-15 12:05:03,724:INFO:DummyClassifier(constant=None, random_state=2421, strategy='prior') is best model
2023-02-15 12:05:03,724:INFO:choose_better completed
2023-02-15 12:05:03,725:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-15 12:05:03,741:INFO:_master_model_container: 21
2023-02-15 12:05:03,741:INFO:_display_container: 5
2023-02-15 12:05:03,741:INFO:DummyClassifier(constant=None, random_state=2421, strategy='prior')
2023-02-15 12:05:03,742:INFO:tune_model() successfully completed......................................
2023-02-15 12:05:03,905:INFO:Initializing automl()
2023-02-15 12:05:03,905:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, optimize=AUC, use_holdout=False, turbo=True, return_train_score=False)
2023-02-15 12:05:03,905:INFO:Model Selection Basis : CV Results on Training set
2023-02-15 12:05:03,905:INFO:Checking model 0
2023-02-15 12:05:03,905:INFO:Checking model 1
2023-02-15 12:05:03,905:INFO:Checking model 2
2023-02-15 12:05:03,906:INFO:Checking model 3
2023-02-15 12:05:03,906:INFO:Checking model 4
2023-02-15 12:05:03,906:INFO:Checking model 5
2023-02-15 12:05:03,906:INFO:Checking model 6
2023-02-15 12:05:03,906:INFO:Checking model 7
2023-02-15 12:05:03,906:INFO:Checking model 8
2023-02-15 12:05:03,907:INFO:Checking model 9
2023-02-15 12:05:03,907:INFO:Checking model 10
2023-02-15 12:05:03,907:INFO:Checking model 11
2023-02-15 12:05:03,907:INFO:Checking model 12
2023-02-15 12:05:03,907:INFO:Checking model 13
2023-02-15 12:05:03,907:INFO:Checking model 14
2023-02-15 12:05:03,907:INFO:Checking model 15
2023-02-15 12:05:03,908:INFO:Checking model 16
2023-02-15 12:05:03,908:INFO:Checking model 17
2023-02-15 12:05:03,908:INFO:Checking model 18
2023-02-15 12:05:03,908:INFO:Checking model 19
2023-02-15 12:05:03,908:INFO:Checking model 20
2023-02-15 12:05:03,909:INFO:Initializing create_model()
2023-02-15 12:05:03,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:05:03,909:INFO:Checking exceptions
2023-02-15 12:05:03,911:INFO:Importing libraries
2023-02-15 12:05:03,911:INFO:Copying training dataset
2023-02-15 12:05:03,972:INFO:Defining folds
2023-02-15 12:05:03,972:INFO:Declaring metric variables
2023-02-15 12:05:03,972:INFO:Importing untrained model
2023-02-15 12:05:03,972:INFO:Declaring custom model
2023-02-15 12:05:03,973:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 12:05:03,974:INFO:Cross validation set to False
2023-02-15 12:05:03,975:INFO:Fitting Model
2023-02-15 12:05:06,502:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 12:05:06,503:INFO:create_model() successfully completed......................................
2023-02-15 12:05:06,918:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 12:05:06,918:INFO:automl() successfully completed......................................
2023-02-15 12:05:06,918:INFO:Initializing automl()
2023-02-15 12:05:06,918:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, optimize=Recall, use_holdout=False, turbo=True, return_train_score=False)
2023-02-15 12:05:06,918:INFO:Model Selection Basis : CV Results on Training set
2023-02-15 12:05:06,918:INFO:Checking model 0
2023-02-15 12:05:06,919:INFO:Checking model 1
2023-02-15 12:05:06,919:INFO:Checking model 2
2023-02-15 12:05:06,919:INFO:Checking model 3
2023-02-15 12:05:06,919:INFO:Checking model 4
2023-02-15 12:05:06,919:INFO:Checking model 5
2023-02-15 12:05:06,919:INFO:Checking model 6
2023-02-15 12:05:06,920:INFO:Checking model 7
2023-02-15 12:05:06,920:INFO:Checking model 8
2023-02-15 12:05:06,920:INFO:Checking model 9
2023-02-15 12:05:06,920:INFO:Checking model 10
2023-02-15 12:05:06,920:INFO:Checking model 11
2023-02-15 12:05:06,920:INFO:Checking model 12
2023-02-15 12:05:06,921:INFO:Checking model 13
2023-02-15 12:05:06,921:INFO:Checking model 14
2023-02-15 12:05:06,921:INFO:Checking model 15
2023-02-15 12:05:06,921:INFO:Checking model 16
2023-02-15 12:05:06,921:INFO:Checking model 17
2023-02-15 12:05:06,921:INFO:Checking model 18
2023-02-15 12:05:06,921:INFO:Checking model 19
2023-02-15 12:05:06,922:INFO:Checking model 20
2023-02-15 12:05:06,922:INFO:Initializing create_model()
2023-02-15 12:05:06,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2421, solver='auto', tol=0.001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:05:06,922:INFO:Checking exceptions
2023-02-15 12:05:06,924:INFO:Importing libraries
2023-02-15 12:05:06,924:INFO:Copying training dataset
2023-02-15 12:05:06,954:INFO:Defining folds
2023-02-15 12:05:06,954:INFO:Declaring metric variables
2023-02-15 12:05:06,954:INFO:Importing untrained model
2023-02-15 12:05:06,954:INFO:Declaring custom model
2023-02-15 12:05:06,955:INFO:Ridge Classifier Imported successfully
2023-02-15 12:05:06,956:INFO:Cross validation set to False
2023-02-15 12:05:06,956:INFO:Fitting Model
2023-02-15 12:05:07,244:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=6.71784e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 12:05:07,267:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2421, solver='auto', tol=0.001)
2023-02-15 12:05:07,268:INFO:create_model() successfully completed......................................
2023-02-15 12:05:07,673:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2421, solver='auto', tol=0.001)
2023-02-15 12:05:07,673:INFO:automl() successfully completed......................................
2023-02-15 12:05:07,676:INFO:Initializing finalize_model()
2023-02-15 12:05:07,676:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2421, solver='auto', tol=0.001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-02-15 12:05:07,676:INFO:Finalizing RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2421, solver='auto', tol=0.001)
2023-02-15 12:05:07,692:INFO:Initializing create_model()
2023-02-15 12:05:07,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2421, solver='auto', tol=0.001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-02-15 12:05:07,692:INFO:Checking exceptions
2023-02-15 12:05:07,693:INFO:Importing libraries
2023-02-15 12:05:07,693:INFO:Copying training dataset
2023-02-15 12:05:07,693:INFO:Defining folds
2023-02-15 12:05:07,694:INFO:Declaring metric variables
2023-02-15 12:05:07,694:INFO:Importing untrained model
2023-02-15 12:05:07,694:INFO:Declaring custom model
2023-02-15 12:05:07,697:INFO:Ridge Classifier Imported successfully
2023-02-15 12:05:07,699:INFO:Cross validation set to False
2023-02-15 12:05:07,699:INFO:Fitting Model
2023-02-15 12:05:08,255:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=7.7579e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-15 12:05:08,285:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 normalize='deprecated', positive=False,
                                 random_state=2421, solver='auto',
                                 tol=0.001))],
         verbose=False)
2023-02-15 12:05:08,285:INFO:create_model() successfully completed......................................
2023-02-15 12:05:08,427:INFO:_master_model_container: 21
2023-02-15 12:05:08,427:INFO:_display_container: 5
2023-02-15 12:05:08,438:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 normalize='deprecated', positive=False,
                                 random_state=2421, solver='auto',
                                 tol=0.001))],
         verbose=False)
2023-02-15 12:05:08,438:INFO:finalize_model() successfully completed......................................
2023-02-15 12:05:08,737:INFO:Initializing save_model()
2023-02-15 12:05:08,737:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 normalize='deprecated', positive=False,
                                 random_state=2421, solver='auto',
                                 tol=0.001))],
         verbose=False), model_name=best_auc_model.pkl, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-15 12:05:08,742:INFO:Adding model into prep_pipe
2023-02-15 12:05:08,744:WARNING:Only Model saved as it was a pipeline.
2023-02-15 12:05:08,752:INFO:best_auc_model.pkl.pkl saved in current working directory
2023-02-15 12:05:08,760:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 normalize='deprecated', positive=False,
                                 random_state=2421, solver='auto',
                                 tol=0.001))],
         verbose=False)
2023-02-15 12:05:08,760:INFO:save_model() successfully completed......................................
2023-02-15 12:12:22,663:INFO:Initializing evaluate_model()
2023-02-15 12:12:22,663:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 normalize='deprecated', positive=False,
                                 random_state=2421, solver='auto',
                                 tol=0.001))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-15 12:12:22,709:INFO:Initializing plot_model()
2023-02-15 12:12:22,709:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 normalize='deprecated', positive=False,
                                 random_state=2421, solver='auto',
                                 tol=0.001))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, system=True)
2023-02-15 12:12:22,709:INFO:Checking exceptions
2023-02-15 12:12:22,719:INFO:Preloading libraries
2023-02-15 12:12:22,720:INFO:Copying training dataset
2023-02-15 12:12:22,720:INFO:Plot type: pipeline
2023-02-15 12:12:23,510:INFO:Visual Rendered Successfully
2023-02-15 12:12:23,787:INFO:plot_model() successfully completed......................................
2023-02-15 12:12:59,121:INFO:Initializing automl()
2023-02-15 12:12:59,122:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, optimize=AUC, use_holdout=False, turbo=True, return_train_score=False)
2023-02-15 12:12:59,122:INFO:Model Selection Basis : CV Results on Training set
2023-02-15 12:12:59,122:INFO:Checking model 0
2023-02-15 12:12:59,122:INFO:Checking model 1
2023-02-15 12:12:59,123:INFO:Checking model 2
2023-02-15 12:12:59,123:INFO:Checking model 3
2023-02-15 12:12:59,124:INFO:Checking model 4
2023-02-15 12:12:59,125:INFO:Checking model 5
2023-02-15 12:12:59,125:INFO:Checking model 6
2023-02-15 12:12:59,125:INFO:Checking model 7
2023-02-15 12:12:59,126:INFO:Checking model 8
2023-02-15 12:12:59,126:INFO:Checking model 9
2023-02-15 12:12:59,126:INFO:Checking model 10
2023-02-15 12:12:59,126:INFO:Checking model 11
2023-02-15 12:12:59,127:INFO:Checking model 12
2023-02-15 12:12:59,127:INFO:Checking model 13
2023-02-15 12:12:59,127:INFO:Checking model 14
2023-02-15 12:12:59,127:INFO:Checking model 15
2023-02-15 12:12:59,128:INFO:Checking model 16
2023-02-15 12:12:59,128:INFO:Checking model 17
2023-02-15 12:12:59,128:INFO:Checking model 18
2023-02-15 12:12:59,129:INFO:Checking model 19
2023-02-15 12:12:59,129:INFO:Checking model 20
2023-02-15 12:12:59,129:INFO:Initializing create_model()
2023-02-15 12:12:59,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:12:59,130:INFO:Checking exceptions
2023-02-15 12:12:59,132:INFO:Importing libraries
2023-02-15 12:12:59,132:INFO:Copying training dataset
2023-02-15 12:12:59,177:INFO:Defining folds
2023-02-15 12:12:59,177:INFO:Declaring metric variables
2023-02-15 12:12:59,178:INFO:Importing untrained model
2023-02-15 12:12:59,178:INFO:Declaring custom model
2023-02-15 12:12:59,180:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-15 12:12:59,182:INFO:Cross validation set to False
2023-02-15 12:12:59,182:INFO:Fitting Model
2023-02-15 12:12:59,502:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 12:12:59,503:INFO:create_model() successfully completed......................................
2023-02-15 12:12:59,850:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-15 12:12:59,850:INFO:automl() successfully completed......................................
2023-02-15 12:12:59,850:INFO:Initializing automl()
2023-02-15 12:12:59,850:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, optimize=Recall, use_holdout=False, turbo=True, return_train_score=False)
2023-02-15 12:12:59,850:INFO:Model Selection Basis : CV Results on Training set
2023-02-15 12:12:59,850:INFO:Checking model 0
2023-02-15 12:12:59,851:INFO:Checking model 1
2023-02-15 12:12:59,851:INFO:Checking model 2
2023-02-15 12:12:59,851:INFO:Checking model 3
2023-02-15 12:12:59,851:INFO:Checking model 4
2023-02-15 12:12:59,851:INFO:Checking model 5
2023-02-15 12:12:59,851:INFO:Checking model 6
2023-02-15 12:12:59,852:INFO:Checking model 7
2023-02-15 12:12:59,852:INFO:Checking model 8
2023-02-15 12:12:59,852:INFO:Checking model 9
2023-02-15 12:12:59,852:INFO:Checking model 10
2023-02-15 12:12:59,852:INFO:Checking model 11
2023-02-15 12:12:59,852:INFO:Checking model 12
2023-02-15 12:12:59,852:INFO:Checking model 13
2023-02-15 12:12:59,852:INFO:Checking model 14
2023-02-15 12:12:59,853:INFO:Checking model 15
2023-02-15 12:12:59,853:INFO:Checking model 16
2023-02-15 12:12:59,853:INFO:Checking model 17
2023-02-15 12:12:59,853:INFO:Checking model 18
2023-02-15 12:12:59,853:INFO:Checking model 19
2023-02-15 12:12:59,853:INFO:Checking model 20
2023-02-15 12:12:59,854:INFO:Initializing create_model()
2023-02-15 12:12:59,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2421, solver='auto', tol=0.001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-15 12:12:59,854:INFO:Checking exceptions
2023-02-15 12:12:59,855:INFO:Importing libraries
2023-02-15 12:12:59,855:INFO:Copying training dataset
2023-02-15 12:12:59,886:INFO:Defining folds
2023-02-15 12:12:59,886:INFO:Declaring metric variables
2023-02-15 12:12:59,886:INFO:Importing untrained model
2023-02-15 12:12:59,886:INFO:Declaring custom model
2023-02-15 12:12:59,887:INFO:Ridge Classifier Imported successfully
2023-02-15 12:12:59,888:INFO:Cross validation set to False
2023-02-15 12:12:59,888:INFO:Fitting Model
2023-02-15 12:13:00,064:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2421, solver='auto', tol=0.001)
2023-02-15 12:13:00,064:INFO:create_model() successfully completed......................................
2023-02-15 12:13:00,603:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2421, solver='auto', tol=0.001)
2023-02-15 12:13:00,603:INFO:automl() successfully completed......................................
2023-02-15 12:13:00,604:INFO:Initializing evaluate_model()
2023-02-15 12:13:00,604:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-15 12:13:00,633:INFO:Initializing plot_model()
2023-02-15 12:13:00,633:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, system=True)
2023-02-15 12:13:00,634:INFO:Checking exceptions
2023-02-15 12:13:00,647:INFO:Preloading libraries
2023-02-15 12:13:00,666:INFO:Copying training dataset
2023-02-15 12:13:00,667:INFO:Plot type: pipeline
2023-02-15 12:13:00,839:INFO:Visual Rendered Successfully
2023-02-15 12:13:00,998:INFO:plot_model() successfully completed......................................
2023-02-15 12:13:04,831:INFO:Initializing plot_model()
2023-02-15 12:13:04,831:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, system=True)
2023-02-15 12:13:04,831:INFO:Checking exceptions
2023-02-15 12:13:04,843:INFO:Preloading libraries
2023-02-15 12:13:04,856:INFO:Copying training dataset
2023-02-15 12:13:04,856:INFO:Plot type: auc
2023-02-15 12:13:04,989:INFO:Fitting Model
2023-02-15 12:13:04,993:INFO:Scoring test/hold-out set
2023-02-15 12:13:05,528:INFO:Visual Rendered Successfully
2023-02-15 12:13:05,698:INFO:plot_model() successfully completed......................................
2023-02-15 12:13:07,835:INFO:Initializing plot_model()
2023-02-15 12:13:07,835:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, system=True)
2023-02-15 12:13:07,835:INFO:Checking exceptions
2023-02-15 12:13:07,849:INFO:Preloading libraries
2023-02-15 12:13:07,856:INFO:Copying training dataset
2023-02-15 12:13:07,857:INFO:Plot type: confusion_matrix
2023-02-15 12:13:07,959:INFO:Fitting Model
2023-02-15 12:13:07,961:INFO:Scoring test/hold-out set
2023-02-15 12:13:08,248:INFO:Visual Rendered Successfully
2023-02-15 12:13:08,410:INFO:plot_model() successfully completed......................................
2023-02-15 12:13:15,372:INFO:Initializing plot_model()
2023-02-15 12:13:15,372:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, system=True)
2023-02-15 12:13:15,372:INFO:Checking exceptions
2023-02-15 12:13:18,899:INFO:Initializing plot_model()
2023-02-15 12:13:18,900:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, system=True)
2023-02-15 12:13:18,900:INFO:Checking exceptions
2023-02-15 12:13:18,915:INFO:Preloading libraries
2023-02-15 12:13:18,922:INFO:Copying training dataset
2023-02-15 12:13:18,922:INFO:Plot type: feature_all
2023-02-15 12:13:18,954:WARNING:No coef_ found. Trying feature_importances_
2023-02-15 12:13:19,263:INFO:Visual Rendered Successfully
2023-02-15 12:13:19,429:INFO:plot_model() successfully completed......................................
2023-02-15 12:13:21,171:INFO:Initializing plot_model()
2023-02-15 12:13:21,171:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, system=True)
2023-02-15 12:13:21,171:INFO:Checking exceptions
2023-02-15 12:13:21,186:INFO:Preloading libraries
2023-02-15 12:13:21,230:INFO:Copying training dataset
2023-02-15 12:13:21,230:INFO:Plot type: feature
2023-02-15 12:13:21,231:WARNING:No coef_ found. Trying feature_importances_
2023-02-15 12:13:21,470:INFO:Visual Rendered Successfully
2023-02-15 12:13:21,638:INFO:plot_model() successfully completed......................................
2023-02-15 12:14:00,252:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\ensemble\_iforest.py", line 258, in fit
    X = self._validate_data(X, accept_sparse=["csc"])
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 12:14:00,546:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\ensemble\_iforest.py", line 258, in fit
    X = self._validate_data(X, accept_sparse=["csc"])
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 12:14:01,029:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\ensemble\_iforest.py", line 258, in fit
    X = self._validate_data(X, accept_sparse=["csc"])
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 12:14:01,297:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\ensemble\_iforest.py", line 258, in fit
    X = self._validate_data(X, accept_sparse=["csc"])
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 12:14:01,591:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\ensemble\_iforest.py", line 258, in fit
    X = self._validate_data(X, accept_sparse=["csc"])
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 12:14:01,876:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\ensemble\_iforest.py", line 258, in fit
    X = self._validate_data(X, accept_sparse=["csc"])
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 12:14:02,284:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\ensemble\_iforest.py", line 258, in fit
    X = self._validate_data(X, accept_sparse=["csc"])
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 12:14:02,580:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\ensemble\_iforest.py", line 258, in fit
    X = self._validate_data(X, accept_sparse=["csc"])
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 12:14:02,861:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\ensemble\_iforest.py", line 258, in fit
    X = self._validate_data(X, accept_sparse=["csc"])
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 12:14:03,143:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\ensemble\_iforest.py", line 258, in fit
    X = self._validate_data(X, accept_sparse=["csc"])
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py", line 566, in _validate_data
    X = check_array(X, **check_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 12:17:46,918:INFO:Initializing plot_model()
2023-02-15 12:17:46,918:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, system=True)
2023-02-15 12:17:46,919:INFO:Checking exceptions
2023-02-15 12:17:46,931:INFO:Preloading libraries
2023-02-15 12:17:46,939:INFO:Copying training dataset
2023-02-15 12:17:46,939:INFO:Plot type: class_report
2023-02-15 12:17:47,125:INFO:Fitting Model
2023-02-15 12:17:47,127:INFO:Scoring test/hold-out set
2023-02-15 12:17:47,577:INFO:Visual Rendered Successfully
2023-02-15 12:17:47,743:INFO:plot_model() successfully completed......................................
2023-02-15 12:21:36,028:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-02-15 12:21:50,195:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-02-15 12:22:33,399:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-02-15 12:23:25,465:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-02-15 12:23:28,425:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:23:28,426:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:23:28,439:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:23:28,439:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:23:28,444:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:23:28,444:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-15 12:34:39,304:INFO:Initializing evaluate_model()
2023-02-15 12:34:39,304:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-15 12:34:39,328:INFO:Initializing plot_model()
2023-02-15 12:34:39,328:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, system=True)
2023-02-15 12:34:39,328:INFO:Checking exceptions
2023-02-15 12:34:39,338:INFO:Preloading libraries
2023-02-15 12:34:39,930:INFO:Copying training dataset
2023-02-15 12:34:39,930:INFO:Plot type: pipeline
2023-02-15 12:34:40,102:INFO:Visual Rendered Successfully
2023-02-15 12:34:40,268:INFO:plot_model() successfully completed......................................
2023-02-15 12:34:45,644:INFO:Initializing plot_model()
2023-02-15 12:34:45,645:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, system=True)
2023-02-15 12:34:45,645:INFO:Checking exceptions
2023-02-15 12:34:45,659:INFO:Preloading libraries
2023-02-15 12:34:45,666:INFO:Copying training dataset
2023-02-15 12:34:45,666:INFO:Plot type: auc
2023-02-15 12:34:46,107:INFO:Fitting Model
2023-02-15 12:34:46,111:INFO:Scoring test/hold-out set
2023-02-15 12:34:46,422:INFO:Visual Rendered Successfully
2023-02-15 12:34:46,571:INFO:plot_model() successfully completed......................................
2023-02-15 12:34:51,340:INFO:Initializing plot_model()
2023-02-15 12:34:51,340:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000201226D5A30>, system=True)
2023-02-15 12:34:51,341:INFO:Checking exceptions
2023-02-15 12:34:51,354:INFO:Preloading libraries
2023-02-15 12:34:51,359:INFO:Copying training dataset
2023-02-15 12:34:51,359:INFO:Plot type: class_report
2023-02-15 12:34:51,540:INFO:Fitting Model
2023-02-15 12:34:51,543:INFO:Scoring test/hold-out set
2023-02-15 12:34:51,836:INFO:Visual Rendered Successfully
2023-02-15 12:34:51,981:INFO:plot_model() successfully completed......................................
2023-02-15 13:04:53,048:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:53,192:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:53,316:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:53,444:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:53,558:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:54,589:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:54,729:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:54,847:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:55,023:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:55,154:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:56,968:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:57,140:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:57,257:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:57,377:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:04:57,513:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:10,333:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:10,482:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:10,597:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:10,717:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:10,824:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:12,454:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:12,585:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:12,703:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:12,827:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:12,941:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:13,091:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:13,207:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:13,323:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:13,447:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:13,730:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:13,869:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:13,987:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:14,107:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:14,270:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:14,380:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:14,528:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:14,647:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:14,833:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:15,011:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:15,123:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:15,265:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:15,380:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:15,498:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:15,628:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:15,735:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:21,635:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:21,753:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:21,873:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:21,986:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:22,099:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:22,239:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:22,358:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:22,479:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:22,604:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:22,716:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:23,483:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:23,604:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:23,723:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:23,837:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:23,944:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:25,263:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:25,378:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:25,491:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:25,617:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:25,728:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:25,871:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:25,984:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:26,105:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:26,214:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:26,320:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:26,463:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:26,578:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:26,698:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:26,808:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:26,914:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:27,052:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:27,178:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:27,291:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:27,403:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:27,516:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:27,666:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:27,784:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:27,895:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:28,004:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:28,119:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:28,257:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:28,370:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:28,484:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:28,601:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:28,714:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:28,860:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:28,970:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:29,079:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:29,191:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:29,295:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:29,440:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:29,552:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:29,694:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:29,815:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:29,951:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:30,115:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:30,238:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:30,434:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:30,623:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:30,820:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:31,023:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:31,200:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:31,333:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:31,465:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:31,598:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:40,631:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:40,771:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:40,907:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:41,036:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:41,162:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:41,323:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:41,458:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:41,591:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:41,726:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:41,865:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:42,007:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:42,248:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:42,373:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:42,503:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:42,635:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:42,790:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:42,908:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:43,023:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:43,138:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:43,250:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:43,394:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:43,505:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:43,625:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:43,752:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:43,859:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:44,004:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:44,139:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:44,263:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:44,407:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:44,527:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:44,737:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:44,867:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:44,989:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:45,120:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:45,239:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:45,396:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:45,516:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:45,646:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:45,782:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:45,898:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:46,043:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:46,167:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:46,291:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:46,410:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:46,524:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:46,677:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:46,799:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:46,916:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:47,030:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:47,138:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:47,295:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:47,412:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:47,528:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:47,650:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:47,773:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:47,920:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:48,032:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:48,150:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:48,271:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:05:48,381:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\impute\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode = stats.mode(array)

2023-02-15 13:26:48,277:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\lightgbm\sklearn.py", line 967, in fit
    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,
  File "c:\Users\pedro\anaconda3\lib\site-packages\lightgbm\sklearn.py", line 667, in fit
    class_sample_weight = _LGBMComputeSampleWeight(self._class_weight, y)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\class_weight.py", line 167, in compute_sample_weight
    weight_k = compute_class_weight(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\class_weight.py", line 42, in compute_class_weight
    if class_weight is None or len(class_weight) == 0:
TypeError: object of type 'numpy.float64' has no len()

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 13:26:48,619:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\lightgbm\sklearn.py", line 967, in fit
    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,
  File "c:\Users\pedro\anaconda3\lib\site-packages\lightgbm\sklearn.py", line 667, in fit
    class_sample_weight = _LGBMComputeSampleWeight(self._class_weight, y)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\class_weight.py", line 167, in compute_sample_weight
    weight_k = compute_class_weight(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\class_weight.py", line 42, in compute_class_weight
    if class_weight is None or len(class_weight) == 0:
TypeError: object of type 'numpy.float64' has no len()

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 13:26:53,544:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\lightgbm\sklearn.py", line 967, in fit
    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,
  File "c:\Users\pedro\anaconda3\lib\site-packages\lightgbm\sklearn.py", line 667, in fit
    class_sample_weight = _LGBMComputeSampleWeight(self._class_weight, y)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\class_weight.py", line 167, in compute_sample_weight
    weight_k = compute_class_weight(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\class_weight.py", line 42, in compute_class_weight
    if class_weight is None or len(class_weight) == 0:
TypeError: object of type 'numpy.float64' has no len()

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 13:38:33,870:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\lightgbm\sklearn.py", line 967, in fit
    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,
  File "c:\Users\pedro\anaconda3\lib\site-packages\lightgbm\sklearn.py", line 667, in fit
    class_sample_weight = _LGBMComputeSampleWeight(self._class_weight, y)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\class_weight.py", line 167, in compute_sample_weight
    weight_k = compute_class_weight(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\class_weight.py", line 42, in compute_class_weight
    if class_weight is None or len(class_weight) == 0:
TypeError: object of type 'numpy.float64' has no len()

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 13:38:34,378:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\pipeline.py", line 394, in fit
    self._final_estimator.fit(Xt, y, **fit_params_last_step)
  File "c:\Users\pedro\anaconda3\lib\site-packages\lightgbm\sklearn.py", line 967, in fit
    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,
  File "c:\Users\pedro\anaconda3\lib\site-packages\lightgbm\sklearn.py", line 667, in fit
    class_sample_weight = _LGBMComputeSampleWeight(self._class_weight, y)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\class_weight.py", line 167, in compute_sample_weight
    weight_k = compute_class_weight(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\class_weight.py", line 42, in compute_class_weight
    if class_weight is None or len(class_weight) == 0:
TypeError: object of type 'numpy.float64' has no len()

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-15 16:11:56,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:11:56,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:11:56,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:11:56,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 16:11:57,915:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 16:43:06,295:WARNING:C:\Users\pedro\AppData\Local\Temp\ipykernel_7992\1138696499.py:1: UserWarning: Dataset has 0 variance; skipping density estimate. Pass `warn_singular=False` to disable this warning.
  sns.kdeplot(df_train.query('salario_mensal < 0.2')['salario_mensal'])

2023-02-15 16:43:09,411:WARNING:C:\Users\pedro\AppData\Local\Temp\ipykernel_7992\1138696499.py:1: UserWarning: Dataset has 0 variance; skipping density estimate. Pass `warn_singular=False` to disable this warning.
  sns.kdeplot(df_train.query('salario_mensal < 0.2')['salario_mensal'])

2023-02-15 16:44:42,513:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\arraylike.py:397: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)

2023-02-15 16:44:53,828:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\arraylike.py:397: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)

2023-02-15 17:18:06,599:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\internals\blocks.py:402: RuntimeWarning: divide by zero encountered in log
  result = func(self.values, **kwargs)

2023-02-15 17:18:33,918:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\internals\blocks.py:402: RuntimeWarning: divide by zero encountered in log
  result = func(self.values, **kwargs)

2023-02-15 17:20:40,575:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\internals\blocks.py:402: RuntimeWarning: divide by zero encountered in log
  result = func(self.values, **kwargs)

2023-02-15 17:20:46,486:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\internals\blocks.py:402: RuntimeWarning: divide by zero encountered in log
  result = func(self.values, **kwargs)

2023-02-15 17:20:57,901:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\internals\blocks.py:402: RuntimeWarning: divide by zero encountered in log
  result = func(self.values, **kwargs)

2023-02-15 17:21:44,613:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\arraylike.py:397: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)

2023-02-15 17:22:22,463:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\arraylike.py:397: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)

2023-02-15 17:23:50,238:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\arraylike.py:397: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)

2023-02-15 17:24:28,418:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\arraylike.py:397: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)

2023-02-15 17:24:56,494:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\arraylike.py:397: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)

2023-02-15 17:32:06,146:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\arraylike.py:397: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)

2023-02-15 17:34:11,819:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\internals\blocks.py:402: RuntimeWarning: divide by zero encountered in log
  result = func(self.values, **kwargs)

2023-02-15 17:34:42,598:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\internals\blocks.py:402: RuntimeWarning: divide by zero encountered in log
  result = func(self.values, **kwargs)

2023-02-15 17:34:55,883:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\internals\blocks.py:402: RuntimeWarning: divide by zero encountered in log
  result = func(self.values, **kwargs)

2023-02-15 17:35:06,817:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\internals\blocks.py:402: RuntimeWarning: divide by zero encountered in log
  result = func(self.values, **kwargs)

2023-02-15 17:37:38,109:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\internals\blocks.py:402: RuntimeWarning: divide by zero encountered in log
  result = func(self.values, **kwargs)

2023-02-15 17:37:38,191:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\preprocessing\_function_transformer.py:137: UserWarning: The provided functions are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'.
  warnings.warn(

2023-02-15 17:37:52,170:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\preprocessing\_function_transformer.py:137: UserWarning: The provided functions are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'.
  warnings.warn(

2023-02-15 22:29:03,803:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-15 22:38:25,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 22:38:25,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 22:38:25,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 22:38:25,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-15 22:38:27,344:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-15 22:49:46,506:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-16 08:56:07,556:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-16 08:56:07,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-16 08:56:07,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-16 08:56:07,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-16 08:56:09,316:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-16 08:58:19,492:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 08:58:52,515:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 09:01:07,042:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 09:04:09,085:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 09:04:33,097:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 09:04:34,622:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 09:16:25,254:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 09:16:29,954:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:23:17,490:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:24:09,269:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:24:11,527:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:24:12,101:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:25:01,227:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:25:05,572:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:25:20,146:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:25:40,603:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:25:53,367:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:28:24,346:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:47:22,117:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:48:07,295:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:49:11,880:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:58:05,439:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 10:58:07,699:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 11:00:45,197:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 11:00:50,648:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 11:00:52,348:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 11:00:54,064:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 11:01:05,907:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 11:01:07,894:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 11:02:41,915:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 11:32:28,805:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\preprocessing\_function_transformer.py:137: UserWarning: The provided functions are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'.
  warnings.warn(

2023-02-16 11:36:31,655:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\preprocessing\_function_transformer.py:137: UserWarning: The provided functions are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'.
  warnings.warn(

2023-02-16 11:36:40,197:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\preprocessing\_function_transformer.py:137: UserWarning: The provided functions are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'.
  warnings.warn(

2023-02-16 11:37:36,812:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\preprocessing\_function_transformer.py:137: UserWarning: The provided functions are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'.
  warnings.warn(

2023-02-16 11:40:00,633:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\preprocessing\_function_transformer.py:137: UserWarning: The provided functions are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'.
  warnings.warn(

2023-02-16 11:58:09,003:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:01:26,319:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:02:37,437:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:03:37,498:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:06:12,167:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:12:52,254:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:16:12,462:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:19:14,402:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:20:15,680:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:22:00,326:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:23:02,735:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:24:51,668:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-16 12:27:31,275:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:28:27,295:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:36:57,220:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:37:57,302:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:40:04,805:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:40:05,930:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:41:16,732:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:41:18,146:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:45:08,707:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:46:07,853:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:47:07,664:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:48:06,277:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:51:36,967:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:51:37,274:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:52:36,924:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:52:37,243:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:56:22,977:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:57:23,488:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:58:21,366:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 12:59:19,358:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 13:04:55,837:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 13:06:03,890:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 13:07:10,211:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 13:08:09,773:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:443: UserWarning: X has feature names, but RobustScaler was fitted without feature names
  warnings.warn(

2023-02-16 13:35:03,214:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\preprocessing\_function_transformer.py:137: UserWarning: The provided functions are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'.
  warnings.warn(

2023-02-16 13:35:10,787:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\preprocessing\_function_transformer.py:137: UserWarning: The provided functions are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'.
  warnings.warn(

2023-02-16 13:36:35,227:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\preprocessing\_function_transformer.py:137: UserWarning: The provided functions are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'.
  warnings.warn(

2023-02-16 13:42:00,536:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\preprocessing\_function_transformer.py:137: UserWarning: The provided functions are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'.
  warnings.warn(

2023-02-16 13:45:20,642:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names seen at fit time, yet now missing:
- idade
- numero_de_dependentes
- numero_de_vezes_que_passou_60_89_dias
- numero_emprestimos_imobiliarios
- numero_linhas_crdto_aberto
- ...

  warnings.warn(message, FutureWarning)

2023-02-16 13:46:32,974:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\preprocessing\_function_transformer.py:137: UserWarning: The provided functions are not strictly inverse of each other. If you are sure you want to proceed regardless, set 'check_inverse=False'.
  warnings.warn(

2023-02-16 14:02:28,483:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.
  warnings.warn(

2023-02-16 14:02:28,542:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.
  warnings.warn(

2023-02-16 14:02:29,199:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.
  warnings.warn(

2023-02-16 14:02:29,208:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.
  warnings.warn(

2023-02-16 14:02:29,940:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.
  warnings.warn(

2023-02-16 14:02:29,954:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.
  warnings.warn(

2023-02-16 15:22:21,749:INFO:PyCaret ClassificationExperiment
2023-02-16 15:22:21,779:INFO:Logging name: clf-default-name
2023-02-16 15:22:21,779:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-16 15:22:21,779:INFO:version 3.0.0.rc9
2023-02-16 15:22:21,779:INFO:Initializing setup()
2023-02-16 15:22:21,779:INFO:self.USI: 570a
2023-02-16 15:22:21,796:INFO:self._variable_keys: {'n_jobs_param', 'data', 'exp_id', 'pipeline', 'memory', 'fold_generator', 'idx', 'html_param', 'y', '_ml_usecase', 'target_param', 'X_test', 'is_multiclass', 'USI', 'y_train', '_available_plots', 'log_plots_param', 'logging_param', 'fix_imbalance', 'exp_name_log', 'gpu_param', 'seed', 'fold_shuffle_param', 'X', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'X_train'}
2023-02-16 15:22:21,796:INFO:Checking environment
2023-02-16 15:22:21,796:INFO:python_version: 3.9.15
2023-02-16 15:22:21,796:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-16 15:22:21,796:INFO:machine: AMD64
2023-02-16 15:22:21,796:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-16 15:22:21,797:INFO:Memory: svmem(total=8469581824, available=2430341120, percent=71.3, used=6039240704, free=2430341120)
2023-02-16 15:22:21,797:INFO:Physical Core: 4
2023-02-16 15:22:21,797:INFO:Logical Core: 4
2023-02-16 15:22:21,797:INFO:Checking libraries
2023-02-16 15:22:21,797:INFO:System:
2023-02-16 15:22:21,797:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-16 15:22:21,797:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-16 15:22:21,797:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-16 15:22:21,797:INFO:PyCaret required dependencies:
2023-02-16 15:22:21,797:INFO:                 pip: 22.3.1
2023-02-16 15:22:21,797:INFO:          setuptools: 60.10.0
2023-02-16 15:22:21,797:INFO:             pycaret: 3.0.0rc9
2023-02-16 15:22:21,797:INFO:             IPython: 7.31.1
2023-02-16 15:22:21,797:INFO:          ipywidgets: 7.6.5
2023-02-16 15:22:21,797:INFO:                tqdm: 4.64.1
2023-02-16 15:22:21,798:INFO:               numpy: 1.21.5
2023-02-16 15:22:21,798:INFO:              pandas: 1.4.4
2023-02-16 15:22:21,798:INFO:              jinja2: 2.11.3
2023-02-16 15:22:21,798:INFO:               scipy: 1.9.3
2023-02-16 15:22:21,798:INFO:              joblib: 1.2.0
2023-02-16 15:22:21,798:INFO:             sklearn: 1.0.2
2023-02-16 15:22:21,798:INFO:                pyod: 1.0.7
2023-02-16 15:22:21,798:INFO:            imblearn: 0.10.1
2023-02-16 15:22:21,798:INFO:   category_encoders: 2.6.0
2023-02-16 15:22:21,798:INFO:            lightgbm: 3.3.5
2023-02-16 15:22:21,798:INFO:               numba: 0.56.4
2023-02-16 15:22:21,798:INFO:            requests: 2.28.1
2023-02-16 15:22:21,798:INFO:          matplotlib: 3.6.2
2023-02-16 15:22:21,798:INFO:          scikitplot: 0.3.7
2023-02-16 15:22:21,798:INFO:         yellowbrick: 1.5
2023-02-16 15:22:21,798:INFO:              plotly: 5.9.0
2023-02-16 15:22:21,798:INFO:             kaleido: 0.2.1
2023-02-16 15:22:21,798:INFO:         statsmodels: 0.13.2
2023-02-16 15:22:21,798:INFO:              sktime: 0.16.1
2023-02-16 15:22:21,798:INFO:               tbats: 1.1.2
2023-02-16 15:22:21,799:INFO:            pmdarima: 2.0.2
2023-02-16 15:22:21,799:INFO:              psutil: 5.9.0
2023-02-16 15:22:21,799:INFO:PyCaret optional dependencies:
2023-02-16 15:22:21,828:INFO:                shap: 0.41.0
2023-02-16 15:22:21,828:INFO:           interpret: Not installed
2023-02-16 15:22:21,828:INFO:                umap: Not installed
2023-02-16 15:22:21,828:INFO:    pandas_profiling: 4.0.0
2023-02-16 15:22:21,828:INFO:  explainerdashboard: 0.3.6.2
2023-02-16 15:22:21,828:INFO:             autoviz: 0.1.58
2023-02-16 15:22:21,828:INFO:           fairlearn: Not installed
2023-02-16 15:22:21,828:INFO:             xgboost: 1.7.3
2023-02-16 15:22:21,828:INFO:            catboost: Not installed
2023-02-16 15:22:21,828:INFO:              kmodes: Not installed
2023-02-16 15:22:21,828:INFO:             mlxtend: Not installed
2023-02-16 15:22:21,828:INFO:       statsforecast: Not installed
2023-02-16 15:22:21,828:INFO:        tune_sklearn: Not installed
2023-02-16 15:22:21,828:INFO:                 ray: Not installed
2023-02-16 15:22:21,828:INFO:            hyperopt: Not installed
2023-02-16 15:22:21,828:INFO:              optuna: 2.10.1
2023-02-16 15:22:21,828:INFO:               skopt: Not installed
2023-02-16 15:22:21,828:INFO:              mlflow: Not installed
2023-02-16 15:22:21,829:INFO:              gradio: Not installed
2023-02-16 15:22:21,829:INFO:             fastapi: Not installed
2023-02-16 15:22:21,829:INFO:             uvicorn: Not installed
2023-02-16 15:22:21,829:INFO:              m2cgen: Not installed
2023-02-16 15:22:21,829:INFO:           evidently: Not installed
2023-02-16 15:22:21,829:INFO:               fugue: Not installed
2023-02-16 15:22:21,829:INFO:           streamlit: Not installed
2023-02-16 15:22:21,829:INFO:             prophet: Not installed
2023-02-16 15:22:21,829:INFO:None
2023-02-16 15:22:21,829:INFO:Set up data.
2023-02-16 15:22:27,238:INFO:PyCaret ClassificationExperiment
2023-02-16 15:22:27,238:INFO:Logging name: clf-default-name
2023-02-16 15:22:27,238:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-16 15:22:27,238:INFO:version 3.0.0.rc9
2023-02-16 15:22:27,238:INFO:Initializing setup()
2023-02-16 15:22:27,238:INFO:self.USI: 918d
2023-02-16 15:22:27,238:INFO:self._variable_keys: {'n_jobs_param', 'data', 'exp_id', 'pipeline', 'memory', 'fold_generator', 'idx', 'html_param', 'y', '_ml_usecase', 'target_param', 'X_test', 'is_multiclass', 'USI', 'y_train', '_available_plots', 'log_plots_param', 'logging_param', 'fix_imbalance', 'exp_name_log', 'gpu_param', 'seed', 'fold_shuffle_param', 'X', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'X_train'}
2023-02-16 15:22:27,238:INFO:Checking environment
2023-02-16 15:22:27,238:INFO:python_version: 3.9.15
2023-02-16 15:22:27,238:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-16 15:22:27,238:INFO:machine: AMD64
2023-02-16 15:22:27,238:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-16 15:22:27,238:INFO:Memory: svmem(total=8469581824, available=2376454144, percent=71.9, used=6093127680, free=2376454144)
2023-02-16 15:22:27,238:INFO:Physical Core: 4
2023-02-16 15:22:27,240:INFO:Logical Core: 4
2023-02-16 15:22:27,240:INFO:Checking libraries
2023-02-16 15:22:27,240:INFO:System:
2023-02-16 15:22:27,240:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-16 15:22:27,240:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-16 15:22:27,240:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-16 15:22:27,240:INFO:PyCaret required dependencies:
2023-02-16 15:22:27,240:INFO:                 pip: 22.3.1
2023-02-16 15:22:27,240:INFO:          setuptools: 60.10.0
2023-02-16 15:22:27,240:INFO:             pycaret: 3.0.0rc9
2023-02-16 15:22:27,240:INFO:             IPython: 7.31.1
2023-02-16 15:22:27,240:INFO:          ipywidgets: 7.6.5
2023-02-16 15:22:27,240:INFO:                tqdm: 4.64.1
2023-02-16 15:22:27,240:INFO:               numpy: 1.21.5
2023-02-16 15:22:27,240:INFO:              pandas: 1.4.4
2023-02-16 15:22:27,240:INFO:              jinja2: 2.11.3
2023-02-16 15:22:27,240:INFO:               scipy: 1.9.3
2023-02-16 15:22:27,240:INFO:              joblib: 1.2.0
2023-02-16 15:22:27,240:INFO:             sklearn: 1.0.2
2023-02-16 15:22:27,240:INFO:                pyod: 1.0.7
2023-02-16 15:22:27,240:INFO:            imblearn: 0.10.1
2023-02-16 15:22:27,241:INFO:   category_encoders: 2.6.0
2023-02-16 15:22:27,241:INFO:            lightgbm: 3.3.5
2023-02-16 15:22:27,241:INFO:               numba: 0.56.4
2023-02-16 15:22:27,241:INFO:            requests: 2.28.1
2023-02-16 15:22:27,241:INFO:          matplotlib: 3.6.2
2023-02-16 15:22:27,241:INFO:          scikitplot: 0.3.7
2023-02-16 15:22:27,241:INFO:         yellowbrick: 1.5
2023-02-16 15:22:27,241:INFO:              plotly: 5.9.0
2023-02-16 15:22:27,241:INFO:             kaleido: 0.2.1
2023-02-16 15:22:27,241:INFO:         statsmodels: 0.13.2
2023-02-16 15:22:27,241:INFO:              sktime: 0.16.1
2023-02-16 15:22:27,241:INFO:               tbats: 1.1.2
2023-02-16 15:22:27,241:INFO:            pmdarima: 2.0.2
2023-02-16 15:22:27,241:INFO:              psutil: 5.9.0
2023-02-16 15:22:27,241:INFO:PyCaret optional dependencies:
2023-02-16 15:22:27,241:INFO:                shap: 0.41.0
2023-02-16 15:22:27,241:INFO:           interpret: Not installed
2023-02-16 15:22:27,241:INFO:                umap: Not installed
2023-02-16 15:22:27,241:INFO:    pandas_profiling: 4.0.0
2023-02-16 15:22:27,242:INFO:  explainerdashboard: 0.3.6.2
2023-02-16 15:22:27,242:INFO:             autoviz: 0.1.58
2023-02-16 15:22:27,242:INFO:           fairlearn: Not installed
2023-02-16 15:22:27,242:INFO:             xgboost: 1.7.3
2023-02-16 15:22:27,242:INFO:            catboost: Not installed
2023-02-16 15:22:27,242:INFO:              kmodes: Not installed
2023-02-16 15:22:27,242:INFO:             mlxtend: Not installed
2023-02-16 15:22:27,242:INFO:       statsforecast: Not installed
2023-02-16 15:22:27,242:INFO:        tune_sklearn: Not installed
2023-02-16 15:22:27,242:INFO:                 ray: Not installed
2023-02-16 15:22:27,242:INFO:            hyperopt: Not installed
2023-02-16 15:22:27,242:INFO:              optuna: 2.10.1
2023-02-16 15:22:27,242:INFO:               skopt: Not installed
2023-02-16 15:22:27,242:INFO:              mlflow: Not installed
2023-02-16 15:22:27,242:INFO:              gradio: Not installed
2023-02-16 15:22:27,242:INFO:             fastapi: Not installed
2023-02-16 15:22:27,242:INFO:             uvicorn: Not installed
2023-02-16 15:22:27,242:INFO:              m2cgen: Not installed
2023-02-16 15:22:27,242:INFO:           evidently: Not installed
2023-02-16 15:22:27,242:INFO:               fugue: Not installed
2023-02-16 15:22:27,242:INFO:           streamlit: Not installed
2023-02-16 15:22:27,242:INFO:             prophet: Not installed
2023-02-16 15:22:27,242:INFO:None
2023-02-16 15:22:27,242:INFO:Set up data.
2023-02-16 15:22:27,343:INFO:Set up train/test split.
2023-02-16 15:22:27,420:INFO:Set up index.
2023-02-16 15:22:27,487:INFO:Set up folding strategy.
2023-02-16 15:22:27,487:INFO:Assigning column types.
2023-02-16 15:22:27,518:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-16 15:22:27,571:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 15:22:27,623:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:22:27,670:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:22:27,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:22:27,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 15:22:27,737:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:22:27,770:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:22:27,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:22:27,770:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-16 15:22:27,831:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:22:27,864:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:22:27,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:22:27,922:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:22:27,955:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:22:27,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:22:27,959:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-16 15:22:28,055:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:22:28,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:22:28,153:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:22:28,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:22:28,153:INFO:Preparing preprocessing pipeline...
2023-02-16 15:22:28,176:INFO:Set up simple imputation.
2023-02-16 15:22:28,443:INFO:Finished creating preprocessing pipeline.
2023-02-16 15:22:28,445:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                             'numero_de_dependentes'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-02-16 15:22:28,456:INFO:Creating final display dataframe.
2023-02-16 15:22:28,953:INFO:Setup _display_container:                     Description             Value
0                    Session id              7430
1                        Target            target
2                   Target type            Binary
3           Original data shape      (123202, 11)
4        Transformed data shape      (123202, 11)
5   Transformed train set shape       (86241, 11)
6    Transformed test set shape       (36961, 11)
7              Numeric features                10
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              918d
2023-02-16 15:22:29,087:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:22:29,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:22:29,196:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:22:29,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:22:29,217:INFO:setup() successfully completed in 1.98s...............
2023-02-16 15:22:41,807:INFO:Initializing compare_models()
2023-02-16 15:22:41,807:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFE6D252B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002BFE6D252B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-16 15:22:41,807:INFO:Checking exceptions
2023-02-16 15:22:41,841:INFO:Preparing display monitor
2023-02-16 15:22:41,953:INFO:Initializing Logistic Regression
2023-02-16 15:22:41,953:INFO:Total runtime is 0.0 minutes
2023-02-16 15:22:41,953:INFO:SubProcess create_model() called ==================================
2023-02-16 15:22:41,953:INFO:Initializing create_model()
2023-02-16 15:22:41,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFE6D252B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFE6ED8FA0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:22:41,953:INFO:Checking exceptions
2023-02-16 15:22:41,953:INFO:Importing libraries
2023-02-16 15:22:41,953:INFO:Copying training dataset
2023-02-16 15:22:42,017:INFO:Defining folds
2023-02-16 15:22:42,017:INFO:Declaring metric variables
2023-02-16 15:22:42,023:INFO:Importing untrained model
2023-02-16 15:22:42,028:INFO:Logistic Regression Imported successfully
2023-02-16 15:22:42,039:INFO:Starting cross validation
2023-02-16 15:22:42,040:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:23:00,180:INFO:Calculating mean and std
2023-02-16 15:23:00,183:INFO:Creating metrics dataframe
2023-02-16 15:23:00,188:INFO:Uploading results into container
2023-02-16 15:23:00,189:INFO:Uploading model into container now
2023-02-16 15:23:00,190:INFO:_master_model_container: 1
2023-02-16 15:23:00,190:INFO:_display_container: 2
2023-02-16 15:23:00,190:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7430, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-16 15:23:00,190:INFO:create_model() successfully completed......................................
2023-02-16 15:23:00,540:INFO:SubProcess create_model() end ==================================
2023-02-16 15:23:00,540:INFO:Creating metrics dataframe
2023-02-16 15:23:00,565:INFO:Initializing K Neighbors Classifier
2023-02-16 15:23:00,565:INFO:Total runtime is 0.31019701560338336 minutes
2023-02-16 15:23:00,571:INFO:SubProcess create_model() called ==================================
2023-02-16 15:23:00,572:INFO:Initializing create_model()
2023-02-16 15:23:00,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFE6D252B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFE6ED8FA0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:23:00,572:INFO:Checking exceptions
2023-02-16 15:23:00,572:INFO:Importing libraries
2023-02-16 15:23:00,572:INFO:Copying training dataset
2023-02-16 15:23:00,608:INFO:Defining folds
2023-02-16 15:23:00,608:INFO:Declaring metric variables
2023-02-16 15:23:00,611:INFO:Importing untrained model
2023-02-16 15:23:00,611:INFO:K Neighbors Classifier Imported successfully
2023-02-16 15:23:00,628:INFO:Starting cross validation
2023-02-16 15:23:00,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:23:01,397:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:23:01,415:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:23:01,487:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:23:01,530:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:23:02,986:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:23:03,191:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:23:03,235:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:23:03,236:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:23:04,222:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:23:04,410:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:23:04,920:INFO:Calculating mean and std
2023-02-16 15:23:04,922:INFO:Creating metrics dataframe
2023-02-16 15:23:04,922:INFO:Uploading results into container
2023-02-16 15:23:04,922:INFO:Uploading model into container now
2023-02-16 15:23:04,922:INFO:_master_model_container: 2
2023-02-16 15:23:04,929:INFO:_display_container: 2
2023-02-16 15:23:04,929:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-16 15:23:04,929:INFO:create_model() successfully completed......................................
2023-02-16 15:23:05,152:INFO:SubProcess create_model() end ==================================
2023-02-16 15:23:05,152:INFO:Creating metrics dataframe
2023-02-16 15:23:05,162:INFO:Initializing Naive Bayes
2023-02-16 15:23:05,163:INFO:Total runtime is 0.3868271787961324 minutes
2023-02-16 15:23:05,163:INFO:SubProcess create_model() called ==================================
2023-02-16 15:23:05,163:INFO:Initializing create_model()
2023-02-16 15:23:05,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFE6D252B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFE6ED8FA0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:23:05,163:INFO:Checking exceptions
2023-02-16 15:23:05,163:INFO:Importing libraries
2023-02-16 15:23:05,163:INFO:Copying training dataset
2023-02-16 15:23:05,195:INFO:Defining folds
2023-02-16 15:23:05,195:INFO:Declaring metric variables
2023-02-16 15:23:05,212:INFO:Importing untrained model
2023-02-16 15:23:05,217:INFO:Naive Bayes Imported successfully
2023-02-16 15:23:05,227:INFO:Starting cross validation
2023-02-16 15:23:05,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:23:05,870:INFO:Calculating mean and std
2023-02-16 15:23:05,872:INFO:Creating metrics dataframe
2023-02-16 15:23:05,877:INFO:Uploading results into container
2023-02-16 15:23:05,878:INFO:Uploading model into container now
2023-02-16 15:23:05,879:INFO:_master_model_container: 3
2023-02-16 15:23:05,879:INFO:_display_container: 2
2023-02-16 15:23:05,879:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-16 15:23:05,880:INFO:create_model() successfully completed......................................
2023-02-16 15:23:06,114:INFO:SubProcess create_model() end ==================================
2023-02-16 15:23:06,114:INFO:Creating metrics dataframe
2023-02-16 15:23:06,114:INFO:Initializing Decision Tree Classifier
2023-02-16 15:23:06,130:INFO:Total runtime is 0.40295116901397704 minutes
2023-02-16 15:23:06,135:INFO:SubProcess create_model() called ==================================
2023-02-16 15:23:06,135:INFO:Initializing create_model()
2023-02-16 15:23:06,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFE6D252B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFE6ED8FA0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:23:06,136:INFO:Checking exceptions
2023-02-16 15:23:06,136:INFO:Importing libraries
2023-02-16 15:23:06,136:INFO:Copying training dataset
2023-02-16 15:23:06,171:INFO:Defining folds
2023-02-16 15:23:06,172:INFO:Declaring metric variables
2023-02-16 15:23:06,177:INFO:Importing untrained model
2023-02-16 15:23:06,181:INFO:Decision Tree Classifier Imported successfully
2023-02-16 15:23:06,193:INFO:Starting cross validation
2023-02-16 15:23:06,194:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:23:09,092:INFO:Calculating mean and std
2023-02-16 15:23:09,093:INFO:Creating metrics dataframe
2023-02-16 15:23:09,099:INFO:Uploading results into container
2023-02-16 15:23:09,100:INFO:Uploading model into container now
2023-02-16 15:23:09,101:INFO:_master_model_container: 4
2023-02-16 15:23:09,101:INFO:_display_container: 2
2023-02-16 15:23:09,101:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7430, splitter='best')
2023-02-16 15:23:09,101:INFO:create_model() successfully completed......................................
2023-02-16 15:23:09,327:INFO:SubProcess create_model() end ==================================
2023-02-16 15:23:09,327:INFO:Creating metrics dataframe
2023-02-16 15:23:09,327:INFO:Initializing SVM - Linear Kernel
2023-02-16 15:23:09,327:INFO:Total runtime is 0.45622992515563965 minutes
2023-02-16 15:23:09,345:INFO:SubProcess create_model() called ==================================
2023-02-16 15:23:09,346:INFO:Initializing create_model()
2023-02-16 15:23:09,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFE6D252B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFE6ED8FA0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:23:09,346:INFO:Checking exceptions
2023-02-16 15:23:09,346:INFO:Importing libraries
2023-02-16 15:23:09,347:INFO:Copying training dataset
2023-02-16 15:23:09,388:INFO:Defining folds
2023-02-16 15:23:09,389:INFO:Declaring metric variables
2023-02-16 15:23:09,393:INFO:Importing untrained model
2023-02-16 15:23:09,393:INFO:SVM - Linear Kernel Imported successfully
2023-02-16 15:23:09,393:INFO:Starting cross validation
2023-02-16 15:23:09,393:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:24:08,609:INFO:PyCaret ClassificationExperiment
2023-02-16 15:24:08,609:INFO:Logging name: clf-default-name
2023-02-16 15:24:08,610:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-16 15:24:08,610:INFO:version 3.0.0.rc9
2023-02-16 15:24:08,610:INFO:Initializing setup()
2023-02-16 15:24:08,610:INFO:self.USI: 55a6
2023-02-16 15:24:08,610:INFO:self._variable_keys: {'n_jobs_param', 'data', 'exp_id', 'pipeline', 'memory', 'fold_generator', 'idx', 'html_param', 'y', '_ml_usecase', 'target_param', 'X_test', 'is_multiclass', 'USI', 'y_train', '_available_plots', 'log_plots_param', 'logging_param', 'fix_imbalance', 'exp_name_log', 'gpu_param', 'seed', 'fold_shuffle_param', 'X', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'X_train'}
2023-02-16 15:24:08,610:INFO:Checking environment
2023-02-16 15:24:08,610:INFO:python_version: 3.9.15
2023-02-16 15:24:08,611:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-16 15:24:08,611:INFO:machine: AMD64
2023-02-16 15:24:08,611:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-16 15:24:08,611:INFO:Memory: svmem(total=8469581824, available=2379399168, percent=71.9, used=6090182656, free=2379399168)
2023-02-16 15:24:08,611:INFO:Physical Core: 4
2023-02-16 15:24:08,611:INFO:Logical Core: 4
2023-02-16 15:24:08,611:INFO:Checking libraries
2023-02-16 15:24:08,611:INFO:System:
2023-02-16 15:24:08,611:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-16 15:24:08,611:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-16 15:24:08,611:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-16 15:24:08,611:INFO:PyCaret required dependencies:
2023-02-16 15:24:08,611:INFO:                 pip: 22.3.1
2023-02-16 15:24:08,611:INFO:          setuptools: 60.10.0
2023-02-16 15:24:08,611:INFO:             pycaret: 3.0.0rc9
2023-02-16 15:24:08,611:INFO:             IPython: 7.31.1
2023-02-16 15:24:08,611:INFO:          ipywidgets: 7.6.5
2023-02-16 15:24:08,611:INFO:                tqdm: 4.64.1
2023-02-16 15:24:08,611:INFO:               numpy: 1.21.5
2023-02-16 15:24:08,611:INFO:              pandas: 1.4.4
2023-02-16 15:24:08,611:INFO:              jinja2: 2.11.3
2023-02-16 15:24:08,611:INFO:               scipy: 1.9.3
2023-02-16 15:24:08,612:INFO:              joblib: 1.2.0
2023-02-16 15:24:08,612:INFO:             sklearn: 1.0.2
2023-02-16 15:24:08,612:INFO:                pyod: 1.0.7
2023-02-16 15:24:08,612:INFO:            imblearn: 0.10.1
2023-02-16 15:24:08,612:INFO:   category_encoders: 2.6.0
2023-02-16 15:24:08,612:INFO:            lightgbm: 3.3.5
2023-02-16 15:24:08,612:INFO:               numba: 0.56.4
2023-02-16 15:24:08,612:INFO:            requests: 2.28.1
2023-02-16 15:24:08,612:INFO:          matplotlib: 3.6.2
2023-02-16 15:24:08,612:INFO:          scikitplot: 0.3.7
2023-02-16 15:24:08,612:INFO:         yellowbrick: 1.5
2023-02-16 15:24:08,612:INFO:              plotly: 5.9.0
2023-02-16 15:24:08,612:INFO:             kaleido: 0.2.1
2023-02-16 15:24:08,612:INFO:         statsmodels: 0.13.2
2023-02-16 15:24:08,612:INFO:              sktime: 0.16.1
2023-02-16 15:24:08,612:INFO:               tbats: 1.1.2
2023-02-16 15:24:08,612:INFO:            pmdarima: 2.0.2
2023-02-16 15:24:08,612:INFO:              psutil: 5.9.0
2023-02-16 15:24:08,612:INFO:PyCaret optional dependencies:
2023-02-16 15:24:08,613:INFO:                shap: 0.41.0
2023-02-16 15:24:08,613:INFO:           interpret: Not installed
2023-02-16 15:24:08,613:INFO:                umap: Not installed
2023-02-16 15:24:08,613:INFO:    pandas_profiling: 4.0.0
2023-02-16 15:24:08,613:INFO:  explainerdashboard: 0.3.6.2
2023-02-16 15:24:08,613:INFO:             autoviz: 0.1.58
2023-02-16 15:24:08,613:INFO:           fairlearn: Not installed
2023-02-16 15:24:08,613:INFO:             xgboost: 1.7.3
2023-02-16 15:24:08,613:INFO:            catboost: Not installed
2023-02-16 15:24:08,613:INFO:              kmodes: Not installed
2023-02-16 15:24:08,613:INFO:             mlxtend: Not installed
2023-02-16 15:24:08,613:INFO:       statsforecast: Not installed
2023-02-16 15:24:08,613:INFO:        tune_sklearn: Not installed
2023-02-16 15:24:08,613:INFO:                 ray: Not installed
2023-02-16 15:24:08,613:INFO:            hyperopt: Not installed
2023-02-16 15:24:08,613:INFO:              optuna: 2.10.1
2023-02-16 15:24:08,613:INFO:               skopt: Not installed
2023-02-16 15:24:08,614:INFO:              mlflow: Not installed
2023-02-16 15:24:08,614:INFO:              gradio: Not installed
2023-02-16 15:24:08,614:INFO:             fastapi: Not installed
2023-02-16 15:24:08,614:INFO:             uvicorn: Not installed
2023-02-16 15:24:08,614:INFO:              m2cgen: Not installed
2023-02-16 15:24:08,614:INFO:           evidently: Not installed
2023-02-16 15:24:08,614:INFO:               fugue: Not installed
2023-02-16 15:24:08,614:INFO:           streamlit: Not installed
2023-02-16 15:24:08,614:INFO:             prophet: Not installed
2023-02-16 15:24:08,614:INFO:None
2023-02-16 15:24:08,614:INFO:Set up data.
2023-02-16 15:24:08,644:INFO:Set up train/test split.
2023-02-16 15:24:08,721:INFO:Set up index.
2023-02-16 15:24:08,726:INFO:Set up folding strategy.
2023-02-16 15:24:08,726:INFO:Assigning column types.
2023-02-16 15:24:08,745:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-16 15:24:08,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 15:24:08,798:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:24:08,814:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:08,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:08,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 15:24:08,882:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:24:08,915:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:08,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:08,915:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-16 15:24:08,974:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:24:09,005:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:09,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:09,048:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:24:09,081:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:09,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:09,081:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-16 15:24:09,163:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:09,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:09,261:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:09,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:09,265:INFO:Preparing preprocessing pipeline...
2023-02-16 15:24:09,265:INFO:Set up simple imputation.
2023-02-16 15:24:09,352:INFO:Finished creating preprocessing pipeline.
2023-02-16 15:24:09,356:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['util_linhas_inseguras', 'idade',
                                             'vezes_passou_de_30_59_dias',
                                             'razao_debito', 'salario_mensal',
                                             'numero_linhas_crdto_aberto',
                                             'numero_vezes_passou_90_dias',
                                             'numero_emprestimos_imobiliarios',
                                             'numero_de_vezes_...
                                             'numero_de_dependentes'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-02-16 15:24:09,356:INFO:Creating final display dataframe.
2023-02-16 15:24:09,751:INFO:Setup _display_container:                     Description             Value
0                    Session id              6451
1                        Target            target
2                   Target type            Binary
3           Original data shape      (123202, 11)
4        Transformed data shape      (123202, 11)
5   Transformed train set shape       (86241, 11)
6    Transformed test set shape       (36961, 11)
7              Numeric features                10
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              55a6
2023-02-16 15:24:09,935:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:09,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:10,133:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:10,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:10,137:INFO:setup() successfully completed in 1.53s...............
2023-02-16 15:24:27,331:INFO:PyCaret ClassificationExperiment
2023-02-16 15:24:27,331:INFO:Logging name: clf-default-name
2023-02-16 15:24:27,331:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-16 15:24:27,331:INFO:version 3.0.0.rc9
2023-02-16 15:24:27,331:INFO:Initializing setup()
2023-02-16 15:24:27,331:INFO:self.USI: 52c1
2023-02-16 15:24:27,331:INFO:self._variable_keys: {'n_jobs_param', 'data', 'exp_id', 'pipeline', 'memory', 'fold_generator', 'idx', 'html_param', 'y', '_ml_usecase', 'target_param', 'X_test', 'is_multiclass', 'USI', 'y_train', '_available_plots', 'log_plots_param', 'logging_param', 'fix_imbalance', 'exp_name_log', 'gpu_param', 'seed', 'fold_shuffle_param', 'X', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'X_train'}
2023-02-16 15:24:27,331:INFO:Checking environment
2023-02-16 15:24:27,331:INFO:python_version: 3.9.15
2023-02-16 15:24:27,331:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-16 15:24:27,331:INFO:machine: AMD64
2023-02-16 15:24:27,331:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-16 15:24:27,331:INFO:Memory: svmem(total=8469581824, available=2257072128, percent=73.4, used=6212509696, free=2257072128)
2023-02-16 15:24:27,331:INFO:Physical Core: 4
2023-02-16 15:24:27,331:INFO:Logical Core: 4
2023-02-16 15:24:27,331:INFO:Checking libraries
2023-02-16 15:24:27,331:INFO:System:
2023-02-16 15:24:27,331:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-16 15:24:27,331:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-16 15:24:27,331:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-16 15:24:27,331:INFO:PyCaret required dependencies:
2023-02-16 15:24:27,331:INFO:                 pip: 22.3.1
2023-02-16 15:24:27,331:INFO:          setuptools: 60.10.0
2023-02-16 15:24:27,331:INFO:             pycaret: 3.0.0rc9
2023-02-16 15:24:27,331:INFO:             IPython: 7.31.1
2023-02-16 15:24:27,331:INFO:          ipywidgets: 7.6.5
2023-02-16 15:24:27,331:INFO:                tqdm: 4.64.1
2023-02-16 15:24:27,331:INFO:               numpy: 1.21.5
2023-02-16 15:24:27,331:INFO:              pandas: 1.4.4
2023-02-16 15:24:27,331:INFO:              jinja2: 2.11.3
2023-02-16 15:24:27,331:INFO:               scipy: 1.9.3
2023-02-16 15:24:27,331:INFO:              joblib: 1.2.0
2023-02-16 15:24:27,331:INFO:             sklearn: 1.0.2
2023-02-16 15:24:27,331:INFO:                pyod: 1.0.7
2023-02-16 15:24:27,331:INFO:            imblearn: 0.10.1
2023-02-16 15:24:27,331:INFO:   category_encoders: 2.6.0
2023-02-16 15:24:27,331:INFO:            lightgbm: 3.3.5
2023-02-16 15:24:27,331:INFO:               numba: 0.56.4
2023-02-16 15:24:27,331:INFO:            requests: 2.28.1
2023-02-16 15:24:27,331:INFO:          matplotlib: 3.6.2
2023-02-16 15:24:27,331:INFO:          scikitplot: 0.3.7
2023-02-16 15:24:27,331:INFO:         yellowbrick: 1.5
2023-02-16 15:24:27,331:INFO:              plotly: 5.9.0
2023-02-16 15:24:27,331:INFO:             kaleido: 0.2.1
2023-02-16 15:24:27,331:INFO:         statsmodels: 0.13.2
2023-02-16 15:24:27,331:INFO:              sktime: 0.16.1
2023-02-16 15:24:27,331:INFO:               tbats: 1.1.2
2023-02-16 15:24:27,331:INFO:            pmdarima: 2.0.2
2023-02-16 15:24:27,331:INFO:              psutil: 5.9.0
2023-02-16 15:24:27,331:INFO:PyCaret optional dependencies:
2023-02-16 15:24:27,331:INFO:                shap: 0.41.0
2023-02-16 15:24:27,331:INFO:           interpret: Not installed
2023-02-16 15:24:27,331:INFO:                umap: Not installed
2023-02-16 15:24:27,331:INFO:    pandas_profiling: 4.0.0
2023-02-16 15:24:27,331:INFO:  explainerdashboard: 0.3.6.2
2023-02-16 15:24:27,331:INFO:             autoviz: 0.1.58
2023-02-16 15:24:27,331:INFO:           fairlearn: Not installed
2023-02-16 15:24:27,331:INFO:             xgboost: 1.7.3
2023-02-16 15:24:27,331:INFO:            catboost: Not installed
2023-02-16 15:24:27,331:INFO:              kmodes: Not installed
2023-02-16 15:24:27,331:INFO:             mlxtend: Not installed
2023-02-16 15:24:27,331:INFO:       statsforecast: Not installed
2023-02-16 15:24:27,331:INFO:        tune_sklearn: Not installed
2023-02-16 15:24:27,331:INFO:                 ray: Not installed
2023-02-16 15:24:27,331:INFO:            hyperopt: Not installed
2023-02-16 15:24:27,331:INFO:              optuna: 2.10.1
2023-02-16 15:24:27,331:INFO:               skopt: Not installed
2023-02-16 15:24:27,331:INFO:              mlflow: Not installed
2023-02-16 15:24:27,331:INFO:              gradio: Not installed
2023-02-16 15:24:27,331:INFO:             fastapi: Not installed
2023-02-16 15:24:27,331:INFO:             uvicorn: Not installed
2023-02-16 15:24:27,331:INFO:              m2cgen: Not installed
2023-02-16 15:24:27,331:INFO:           evidently: Not installed
2023-02-16 15:24:27,331:INFO:               fugue: Not installed
2023-02-16 15:24:27,331:INFO:           streamlit: Not installed
2023-02-16 15:24:27,331:INFO:             prophet: Not installed
2023-02-16 15:24:27,331:INFO:None
2023-02-16 15:24:27,331:INFO:Set up data.
2023-02-16 15:24:27,389:INFO:Set up train/test split.
2023-02-16 15:24:27,536:INFO:Set up index.
2023-02-16 15:24:27,568:INFO:Set up folding strategy.
2023-02-16 15:24:27,568:INFO:Assigning column types.
2023-02-16 15:24:27,590:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-16 15:24:27,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 15:24:27,644:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:24:27,677:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:27,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:27,725:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 15:24:27,725:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:24:27,758:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:27,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:27,777:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-16 15:24:27,834:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:24:27,865:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:27,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:27,909:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:24:27,943:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:27,943:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:27,943:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-16 15:24:28,049:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:28,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:28,149:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:28,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:28,179:INFO:Finished creating preprocessing pipeline.
2023-02-16 15:24:28,179:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2023-02-16 15:24:28,179:INFO:Creating final display dataframe.
2023-02-16 15:24:28,405:INFO:Setup _display_container:                    Description         Value
0                   Session id          1758
1                       Target        target
2                  Target type        Binary
3          Original data shape  (123202, 11)
4       Transformed data shape  (123202, 11)
5  Transformed train set shape   (86241, 11)
6   Transformed test set shape   (36961, 11)
7             Numeric features            10
2023-02-16 15:24:28,572:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:28,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:28,755:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:24:28,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:24:28,772:INFO:setup() successfully completed in 1.44s...............
2023-02-16 15:25:55,315:INFO:PyCaret ClassificationExperiment
2023-02-16 15:25:55,315:INFO:Logging name: clf-default-name
2023-02-16 15:25:55,315:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-16 15:25:55,315:INFO:version 3.0.0.rc9
2023-02-16 15:25:55,315:INFO:Initializing setup()
2023-02-16 15:25:55,315:INFO:self.USI: 37fe
2023-02-16 15:25:55,315:INFO:self._variable_keys: {'n_jobs_param', 'data', 'exp_id', 'pipeline', 'memory', 'fold_generator', 'idx', 'html_param', 'y', '_ml_usecase', 'target_param', 'X_test', 'is_multiclass', 'USI', 'y_train', '_available_plots', 'log_plots_param', 'logging_param', 'fix_imbalance', 'exp_name_log', 'gpu_param', 'seed', 'fold_shuffle_param', 'X', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'X_train'}
2023-02-16 15:25:55,315:INFO:Checking environment
2023-02-16 15:25:55,315:INFO:python_version: 3.9.15
2023-02-16 15:25:55,316:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-16 15:25:55,316:INFO:machine: AMD64
2023-02-16 15:25:55,316:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-16 15:25:55,316:INFO:Memory: svmem(total=8469581824, available=2449489920, percent=71.1, used=6020091904, free=2449489920)
2023-02-16 15:25:55,316:INFO:Physical Core: 4
2023-02-16 15:25:55,316:INFO:Logical Core: 4
2023-02-16 15:25:55,316:INFO:Checking libraries
2023-02-16 15:25:55,316:INFO:System:
2023-02-16 15:25:55,316:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-16 15:25:55,316:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-16 15:25:55,316:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-16 15:25:55,316:INFO:PyCaret required dependencies:
2023-02-16 15:25:55,316:INFO:                 pip: 22.3.1
2023-02-16 15:25:55,316:INFO:          setuptools: 60.10.0
2023-02-16 15:25:55,316:INFO:             pycaret: 3.0.0rc9
2023-02-16 15:25:55,316:INFO:             IPython: 7.31.1
2023-02-16 15:25:55,316:INFO:          ipywidgets: 7.6.5
2023-02-16 15:25:55,316:INFO:                tqdm: 4.64.1
2023-02-16 15:25:55,316:INFO:               numpy: 1.21.5
2023-02-16 15:25:55,316:INFO:              pandas: 1.4.4
2023-02-16 15:25:55,316:INFO:              jinja2: 2.11.3
2023-02-16 15:25:55,316:INFO:               scipy: 1.9.3
2023-02-16 15:25:55,316:INFO:              joblib: 1.2.0
2023-02-16 15:25:55,316:INFO:             sklearn: 1.0.2
2023-02-16 15:25:55,316:INFO:                pyod: 1.0.7
2023-02-16 15:25:55,316:INFO:            imblearn: 0.10.1
2023-02-16 15:25:55,316:INFO:   category_encoders: 2.6.0
2023-02-16 15:25:55,316:INFO:            lightgbm: 3.3.5
2023-02-16 15:25:55,316:INFO:               numba: 0.56.4
2023-02-16 15:25:55,316:INFO:            requests: 2.28.1
2023-02-16 15:25:55,316:INFO:          matplotlib: 3.6.2
2023-02-16 15:25:55,316:INFO:          scikitplot: 0.3.7
2023-02-16 15:25:55,316:INFO:         yellowbrick: 1.5
2023-02-16 15:25:55,316:INFO:              plotly: 5.9.0
2023-02-16 15:25:55,316:INFO:             kaleido: 0.2.1
2023-02-16 15:25:55,316:INFO:         statsmodels: 0.13.2
2023-02-16 15:25:55,316:INFO:              sktime: 0.16.1
2023-02-16 15:25:55,316:INFO:               tbats: 1.1.2
2023-02-16 15:25:55,316:INFO:            pmdarima: 2.0.2
2023-02-16 15:25:55,316:INFO:              psutil: 5.9.0
2023-02-16 15:25:55,316:INFO:PyCaret optional dependencies:
2023-02-16 15:25:55,316:INFO:                shap: 0.41.0
2023-02-16 15:25:55,316:INFO:           interpret: Not installed
2023-02-16 15:25:55,316:INFO:                umap: Not installed
2023-02-16 15:25:55,316:INFO:    pandas_profiling: 4.0.0
2023-02-16 15:25:55,316:INFO:  explainerdashboard: 0.3.6.2
2023-02-16 15:25:55,316:INFO:             autoviz: 0.1.58
2023-02-16 15:25:55,316:INFO:           fairlearn: Not installed
2023-02-16 15:25:55,316:INFO:             xgboost: 1.7.3
2023-02-16 15:25:55,316:INFO:            catboost: Not installed
2023-02-16 15:25:55,316:INFO:              kmodes: Not installed
2023-02-16 15:25:55,316:INFO:             mlxtend: Not installed
2023-02-16 15:25:55,316:INFO:       statsforecast: Not installed
2023-02-16 15:25:55,316:INFO:        tune_sklearn: Not installed
2023-02-16 15:25:55,316:INFO:                 ray: Not installed
2023-02-16 15:25:55,316:INFO:            hyperopt: Not installed
2023-02-16 15:25:55,316:INFO:              optuna: 2.10.1
2023-02-16 15:25:55,320:INFO:               skopt: Not installed
2023-02-16 15:25:55,320:INFO:              mlflow: Not installed
2023-02-16 15:25:55,320:INFO:              gradio: Not installed
2023-02-16 15:25:55,320:INFO:             fastapi: Not installed
2023-02-16 15:25:55,320:INFO:             uvicorn: Not installed
2023-02-16 15:25:55,320:INFO:              m2cgen: Not installed
2023-02-16 15:25:55,320:INFO:           evidently: Not installed
2023-02-16 15:25:55,320:INFO:               fugue: Not installed
2023-02-16 15:25:55,320:INFO:           streamlit: Not installed
2023-02-16 15:25:55,320:INFO:             prophet: Not installed
2023-02-16 15:25:55,320:INFO:None
2023-02-16 15:25:55,320:INFO:Set up data.
2023-02-16 15:25:55,398:INFO:Set up train/test split.
2023-02-16 15:25:55,461:INFO:Set up index.
2023-02-16 15:25:55,467:INFO:Set up folding strategy.
2023-02-16 15:25:55,467:INFO:Assigning column types.
2023-02-16 15:25:55,492:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-16 15:25:55,540:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 15:25:55,542:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:25:55,626:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:25:55,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:25:55,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 15:25:55,701:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:25:55,734:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:25:55,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:25:55,737:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-16 15:25:55,782:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:25:55,822:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:25:55,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:25:55,879:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 15:25:55,902:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:25:55,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:25:55,902:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-16 15:25:55,993:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:25:55,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:25:56,072:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:25:56,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:25:56,104:INFO:Finished creating preprocessing pipeline.
2023-02-16 15:25:56,105:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2023-02-16 15:25:56,105:INFO:Creating final display dataframe.
2023-02-16 15:25:56,270:INFO:Setup _display_container:                    Description         Value
0                   Session id          5924
1                       Target        target
2                  Target type        Binary
3          Original data shape  (123202, 11)
4       Transformed data shape  (123202, 11)
5  Transformed train set shape   (86241, 11)
6   Transformed test set shape   (36961, 11)
7             Numeric features            10
2023-02-16 15:25:56,440:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:25:56,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:25:56,535:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 15:25:56,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 15:25:56,539:INFO:setup() successfully completed in 1.23s...............
2023-02-16 15:26:04,596:INFO:Initializing compare_models()
2023-02-16 15:26:04,597:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-16 15:26:04,597:INFO:Checking exceptions
2023-02-16 15:26:04,621:INFO:Preparing display monitor
2023-02-16 15:26:04,658:INFO:Initializing Logistic Regression
2023-02-16 15:26:04,658:INFO:Total runtime is 4.36703364054362e-06 minutes
2023-02-16 15:26:04,659:INFO:SubProcess create_model() called ==================================
2023-02-16 15:26:04,659:INFO:Initializing create_model()
2023-02-16 15:26:04,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:26:04,659:INFO:Checking exceptions
2023-02-16 15:26:04,659:INFO:Importing libraries
2023-02-16 15:26:04,659:INFO:Copying training dataset
2023-02-16 15:26:04,716:INFO:Defining folds
2023-02-16 15:26:04,716:INFO:Declaring metric variables
2023-02-16 15:26:04,720:INFO:Importing untrained model
2023-02-16 15:26:04,724:INFO:Logistic Regression Imported successfully
2023-02-16 15:26:04,737:INFO:Starting cross validation
2023-02-16 15:26:04,738:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:26:19,395:INFO:Calculating mean and std
2023-02-16 15:26:19,397:INFO:Creating metrics dataframe
2023-02-16 15:26:19,402:INFO:Uploading results into container
2023-02-16 15:26:19,403:INFO:Uploading model into container now
2023-02-16 15:26:19,403:INFO:_master_model_container: 1
2023-02-16 15:26:19,404:INFO:_display_container: 2
2023-02-16 15:26:19,405:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5924, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-16 15:26:19,405:INFO:create_model() successfully completed......................................
2023-02-16 15:26:19,705:INFO:SubProcess create_model() end ==================================
2023-02-16 15:26:19,705:INFO:Creating metrics dataframe
2023-02-16 15:26:19,729:INFO:Initializing K Neighbors Classifier
2023-02-16 15:26:19,729:INFO:Total runtime is 0.2511918346087138 minutes
2023-02-16 15:26:19,732:INFO:SubProcess create_model() called ==================================
2023-02-16 15:26:19,733:INFO:Initializing create_model()
2023-02-16 15:26:19,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:26:19,734:INFO:Checking exceptions
2023-02-16 15:26:19,734:INFO:Importing libraries
2023-02-16 15:26:19,734:INFO:Copying training dataset
2023-02-16 15:26:19,772:INFO:Defining folds
2023-02-16 15:26:19,772:INFO:Declaring metric variables
2023-02-16 15:26:19,772:INFO:Importing untrained model
2023-02-16 15:26:19,772:INFO:K Neighbors Classifier Imported successfully
2023-02-16 15:26:19,793:INFO:Starting cross validation
2023-02-16 15:26:19,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:26:20,484:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:26:20,545:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:26:20,601:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:26:20,659:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:26:22,024:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:26:22,145:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:26:22,257:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:26:22,487:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:26:23,312:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:26:23,419:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 15:26:23,943:INFO:Calculating mean and std
2023-02-16 15:26:23,944:INFO:Creating metrics dataframe
2023-02-16 15:26:23,944:INFO:Uploading results into container
2023-02-16 15:26:23,944:INFO:Uploading model into container now
2023-02-16 15:26:23,944:INFO:_master_model_container: 2
2023-02-16 15:26:23,944:INFO:_display_container: 2
2023-02-16 15:26:23,944:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-16 15:26:23,952:INFO:create_model() successfully completed......................................
2023-02-16 15:26:24,174:INFO:SubProcess create_model() end ==================================
2023-02-16 15:26:24,174:INFO:Creating metrics dataframe
2023-02-16 15:26:24,196:INFO:Initializing Naive Bayes
2023-02-16 15:26:24,196:INFO:Total runtime is 0.32562798659006753 minutes
2023-02-16 15:26:24,201:INFO:SubProcess create_model() called ==================================
2023-02-16 15:26:24,202:INFO:Initializing create_model()
2023-02-16 15:26:24,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:26:24,202:INFO:Checking exceptions
2023-02-16 15:26:24,203:INFO:Importing libraries
2023-02-16 15:26:24,203:INFO:Copying training dataset
2023-02-16 15:26:24,242:INFO:Defining folds
2023-02-16 15:26:24,242:INFO:Declaring metric variables
2023-02-16 15:26:24,242:INFO:Importing untrained model
2023-02-16 15:26:24,242:INFO:Naive Bayes Imported successfully
2023-02-16 15:26:24,262:INFO:Starting cross validation
2023-02-16 15:26:24,263:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:26:24,669:INFO:Calculating mean and std
2023-02-16 15:26:24,671:INFO:Creating metrics dataframe
2023-02-16 15:26:24,675:INFO:Uploading results into container
2023-02-16 15:26:24,675:INFO:Uploading model into container now
2023-02-16 15:26:24,676:INFO:_master_model_container: 3
2023-02-16 15:26:24,677:INFO:_display_container: 2
2023-02-16 15:26:24,677:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-16 15:26:24,677:INFO:create_model() successfully completed......................................
2023-02-16 15:26:24,893:INFO:SubProcess create_model() end ==================================
2023-02-16 15:26:24,893:INFO:Creating metrics dataframe
2023-02-16 15:26:24,911:INFO:Initializing Decision Tree Classifier
2023-02-16 15:26:24,911:INFO:Total runtime is 0.3375454028447469 minutes
2023-02-16 15:26:24,916:INFO:SubProcess create_model() called ==================================
2023-02-16 15:26:24,917:INFO:Initializing create_model()
2023-02-16 15:26:24,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:26:24,918:INFO:Checking exceptions
2023-02-16 15:26:24,918:INFO:Importing libraries
2023-02-16 15:26:24,918:INFO:Copying training dataset
2023-02-16 15:26:24,957:INFO:Defining folds
2023-02-16 15:26:24,957:INFO:Declaring metric variables
2023-02-16 15:26:24,957:INFO:Importing untrained model
2023-02-16 15:26:24,957:INFO:Decision Tree Classifier Imported successfully
2023-02-16 15:26:24,978:INFO:Starting cross validation
2023-02-16 15:26:24,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:26:27,460:INFO:Calculating mean and std
2023-02-16 15:26:27,460:INFO:Creating metrics dataframe
2023-02-16 15:26:27,467:INFO:Uploading results into container
2023-02-16 15:26:27,467:INFO:Uploading model into container now
2023-02-16 15:26:27,467:INFO:_master_model_container: 4
2023-02-16 15:26:27,467:INFO:_display_container: 2
2023-02-16 15:26:27,467:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best')
2023-02-16 15:26:27,467:INFO:create_model() successfully completed......................................
2023-02-16 15:26:27,697:INFO:SubProcess create_model() end ==================================
2023-02-16 15:26:27,697:INFO:Creating metrics dataframe
2023-02-16 15:26:27,710:INFO:Initializing SVM - Linear Kernel
2023-02-16 15:26:27,710:INFO:Total runtime is 0.38419394493103026 minutes
2023-02-16 15:26:27,711:INFO:SubProcess create_model() called ==================================
2023-02-16 15:26:27,711:INFO:Initializing create_model()
2023-02-16 15:26:27,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:26:27,711:INFO:Checking exceptions
2023-02-16 15:26:27,711:INFO:Importing libraries
2023-02-16 15:26:27,711:INFO:Copying training dataset
2023-02-16 15:26:27,744:INFO:Defining folds
2023-02-16 15:26:27,744:INFO:Declaring metric variables
2023-02-16 15:26:27,763:INFO:Importing untrained model
2023-02-16 15:26:27,769:INFO:SVM - Linear Kernel Imported successfully
2023-02-16 15:26:27,778:INFO:Starting cross validation
2023-02-16 15:26:27,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:26:39,845:INFO:Calculating mean and std
2023-02-16 15:26:39,847:INFO:Creating metrics dataframe
2023-02-16 15:26:39,851:INFO:Uploading results into container
2023-02-16 15:26:39,852:INFO:Uploading model into container now
2023-02-16 15:26:39,852:INFO:_master_model_container: 5
2023-02-16 15:26:39,853:INFO:_display_container: 2
2023-02-16 15:26:39,854:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5924, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-16 15:26:39,854:INFO:create_model() successfully completed......................................
2023-02-16 15:26:40,072:INFO:SubProcess create_model() end ==================================
2023-02-16 15:26:40,072:INFO:Creating metrics dataframe
2023-02-16 15:26:40,082:INFO:Initializing Ridge Classifier
2023-02-16 15:26:40,082:INFO:Total runtime is 0.5903935233751932 minutes
2023-02-16 15:26:40,084:INFO:SubProcess create_model() called ==================================
2023-02-16 15:26:40,084:INFO:Initializing create_model()
2023-02-16 15:26:40,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:26:40,084:INFO:Checking exceptions
2023-02-16 15:26:40,084:INFO:Importing libraries
2023-02-16 15:26:40,084:INFO:Copying training dataset
2023-02-16 15:26:40,117:INFO:Defining folds
2023-02-16 15:26:40,117:INFO:Declaring metric variables
2023-02-16 15:26:40,117:INFO:Importing untrained model
2023-02-16 15:26:40,138:INFO:Ridge Classifier Imported successfully
2023-02-16 15:26:40,149:INFO:Starting cross validation
2023-02-16 15:26:40,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:26:40,616:INFO:Calculating mean and std
2023-02-16 15:26:40,616:INFO:Creating metrics dataframe
2023-02-16 15:26:40,621:INFO:Uploading results into container
2023-02-16 15:26:40,621:INFO:Uploading model into container now
2023-02-16 15:26:40,621:INFO:_master_model_container: 6
2023-02-16 15:26:40,621:INFO:_display_container: 2
2023-02-16 15:26:40,621:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=5924, solver='auto', tol=0.001)
2023-02-16 15:26:40,621:INFO:create_model() successfully completed......................................
2023-02-16 15:26:40,843:INFO:SubProcess create_model() end ==================================
2023-02-16 15:26:40,843:INFO:Creating metrics dataframe
2023-02-16 15:26:40,843:INFO:Initializing Random Forest Classifier
2023-02-16 15:26:40,843:INFO:Total runtime is 0.603080940246582 minutes
2023-02-16 15:26:40,858:INFO:SubProcess create_model() called ==================================
2023-02-16 15:26:40,858:INFO:Initializing create_model()
2023-02-16 15:26:40,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:26:40,858:INFO:Checking exceptions
2023-02-16 15:26:40,858:INFO:Importing libraries
2023-02-16 15:26:40,858:INFO:Copying training dataset
2023-02-16 15:26:40,892:INFO:Defining folds
2023-02-16 15:26:40,892:INFO:Declaring metric variables
2023-02-16 15:26:40,892:INFO:Importing untrained model
2023-02-16 15:26:40,910:INFO:Random Forest Classifier Imported successfully
2023-02-16 15:26:40,919:INFO:Starting cross validation
2023-02-16 15:26:40,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:27:16,198:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 15:27:17,712:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 15:27:23,840:INFO:Calculating mean and std
2023-02-16 15:27:23,840:INFO:Creating metrics dataframe
2023-02-16 15:27:23,845:INFO:Uploading results into container
2023-02-16 15:27:23,845:INFO:Uploading model into container now
2023-02-16 15:27:23,845:INFO:_master_model_container: 7
2023-02-16 15:27:23,845:INFO:_display_container: 2
2023-02-16 15:27:23,845:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False)
2023-02-16 15:27:23,845:INFO:create_model() successfully completed......................................
2023-02-16 15:27:24,098:INFO:SubProcess create_model() end ==================================
2023-02-16 15:27:24,098:INFO:Creating metrics dataframe
2023-02-16 15:27:24,109:INFO:Initializing Quadratic Discriminant Analysis
2023-02-16 15:27:24,109:INFO:Total runtime is 1.324179478486379 minutes
2023-02-16 15:27:24,114:INFO:SubProcess create_model() called ==================================
2023-02-16 15:27:24,114:INFO:Initializing create_model()
2023-02-16 15:27:24,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:27:24,118:INFO:Checking exceptions
2023-02-16 15:27:24,118:INFO:Importing libraries
2023-02-16 15:27:24,118:INFO:Copying training dataset
2023-02-16 15:27:24,163:INFO:Defining folds
2023-02-16 15:27:24,163:INFO:Declaring metric variables
2023-02-16 15:27:24,168:INFO:Importing untrained model
2023-02-16 15:27:24,171:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-16 15:27:24,179:INFO:Starting cross validation
2023-02-16 15:27:24,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:27:31,781:INFO:Calculating mean and std
2023-02-16 15:27:31,783:INFO:Creating metrics dataframe
2023-02-16 15:27:31,789:INFO:Uploading results into container
2023-02-16 15:27:31,790:INFO:Uploading model into container now
2023-02-16 15:27:31,791:INFO:_master_model_container: 8
2023-02-16 15:27:31,791:INFO:_display_container: 2
2023-02-16 15:27:31,791:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-16 15:27:31,791:INFO:create_model() successfully completed......................................
2023-02-16 15:27:32,033:INFO:SubProcess create_model() end ==================================
2023-02-16 15:27:32,033:INFO:Creating metrics dataframe
2023-02-16 15:27:32,046:INFO:Initializing Ada Boost Classifier
2023-02-16 15:27:32,046:INFO:Total runtime is 1.456468399365743 minutes
2023-02-16 15:27:32,046:INFO:SubProcess create_model() called ==================================
2023-02-16 15:27:32,046:INFO:Initializing create_model()
2023-02-16 15:27:32,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:27:32,046:INFO:Checking exceptions
2023-02-16 15:27:32,046:INFO:Importing libraries
2023-02-16 15:27:32,046:INFO:Copying training dataset
2023-02-16 15:27:32,104:INFO:Defining folds
2023-02-16 15:27:32,104:INFO:Declaring metric variables
2023-02-16 15:27:32,109:INFO:Importing untrained model
2023-02-16 15:27:32,115:INFO:Ada Boost Classifier Imported successfully
2023-02-16 15:27:32,125:INFO:Starting cross validation
2023-02-16 15:27:32,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:27:44,254:INFO:Calculating mean and std
2023-02-16 15:27:44,257:INFO:Creating metrics dataframe
2023-02-16 15:27:44,260:INFO:Uploading results into container
2023-02-16 15:27:44,261:INFO:Uploading model into container now
2023-02-16 15:27:44,262:INFO:_master_model_container: 9
2023-02-16 15:27:44,263:INFO:_display_container: 2
2023-02-16 15:27:44,263:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5924)
2023-02-16 15:27:44,263:INFO:create_model() successfully completed......................................
2023-02-16 15:27:44,488:INFO:SubProcess create_model() end ==================================
2023-02-16 15:27:44,488:INFO:Creating metrics dataframe
2023-02-16 15:27:44,494:INFO:Initializing Gradient Boosting Classifier
2023-02-16 15:27:44,494:INFO:Total runtime is 1.6639300306638083 minutes
2023-02-16 15:27:44,513:INFO:SubProcess create_model() called ==================================
2023-02-16 15:27:44,513:INFO:Initializing create_model()
2023-02-16 15:27:44,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:27:44,514:INFO:Checking exceptions
2023-02-16 15:27:44,514:INFO:Importing libraries
2023-02-16 15:27:44,514:INFO:Copying training dataset
2023-02-16 15:27:44,556:INFO:Defining folds
2023-02-16 15:27:44,556:INFO:Declaring metric variables
2023-02-16 15:27:44,559:INFO:Importing untrained model
2023-02-16 15:27:44,559:INFO:Gradient Boosting Classifier Imported successfully
2023-02-16 15:27:44,576:INFO:Starting cross validation
2023-02-16 15:27:44,577:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:28:40,313:INFO:Calculating mean and std
2023-02-16 15:28:40,313:INFO:Creating metrics dataframe
2023-02-16 15:28:40,313:INFO:Uploading results into container
2023-02-16 15:28:40,313:INFO:Uploading model into container now
2023-02-16 15:28:40,324:INFO:_master_model_container: 10
2023-02-16 15:28:40,324:INFO:_display_container: 2
2023-02-16 15:28:40,324:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5924, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-16 15:28:40,325:INFO:create_model() successfully completed......................................
2023-02-16 15:28:40,551:INFO:SubProcess create_model() end ==================================
2023-02-16 15:28:40,551:INFO:Creating metrics dataframe
2023-02-16 15:28:40,575:INFO:Initializing Linear Discriminant Analysis
2023-02-16 15:28:40,575:INFO:Total runtime is 2.5986160079638165 minutes
2023-02-16 15:28:40,580:INFO:SubProcess create_model() called ==================================
2023-02-16 15:28:40,581:INFO:Initializing create_model()
2023-02-16 15:28:40,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:28:40,582:INFO:Checking exceptions
2023-02-16 15:28:40,582:INFO:Importing libraries
2023-02-16 15:28:40,582:INFO:Copying training dataset
2023-02-16 15:28:40,619:INFO:Defining folds
2023-02-16 15:28:40,619:INFO:Declaring metric variables
2023-02-16 15:28:40,619:INFO:Importing untrained model
2023-02-16 15:28:40,619:INFO:Linear Discriminant Analysis Imported successfully
2023-02-16 15:28:40,642:INFO:Starting cross validation
2023-02-16 15:28:40,643:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:28:41,582:INFO:Calculating mean and std
2023-02-16 15:28:41,583:INFO:Creating metrics dataframe
2023-02-16 15:28:41,588:INFO:Uploading results into container
2023-02-16 15:28:41,589:INFO:Uploading model into container now
2023-02-16 15:28:41,589:INFO:_master_model_container: 11
2023-02-16 15:28:41,590:INFO:_display_container: 2
2023-02-16 15:28:41,590:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-16 15:28:41,591:INFO:create_model() successfully completed......................................
2023-02-16 15:28:41,975:INFO:SubProcess create_model() end ==================================
2023-02-16 15:28:41,975:INFO:Creating metrics dataframe
2023-02-16 15:28:42,054:INFO:Initializing Extra Trees Classifier
2023-02-16 15:28:42,054:INFO:Total runtime is 2.623262321949005 minutes
2023-02-16 15:28:42,054:INFO:SubProcess create_model() called ==================================
2023-02-16 15:28:42,054:INFO:Initializing create_model()
2023-02-16 15:28:42,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:28:42,065:INFO:Checking exceptions
2023-02-16 15:28:42,065:INFO:Importing libraries
2023-02-16 15:28:42,065:INFO:Copying training dataset
2023-02-16 15:28:42,116:INFO:Defining folds
2023-02-16 15:28:42,116:INFO:Declaring metric variables
2023-02-16 15:28:42,121:INFO:Importing untrained model
2023-02-16 15:28:42,139:INFO:Extra Trees Classifier Imported successfully
2023-02-16 15:28:42,169:INFO:Starting cross validation
2023-02-16 15:28:42,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:29:51,022:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 2.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 15:29:51,030:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 2.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 15:29:51,467:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 2.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 15:29:52,599:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 8.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 15:30:08,645:INFO:Calculating mean and std
2023-02-16 15:30:08,647:INFO:Creating metrics dataframe
2023-02-16 15:30:08,653:INFO:Uploading results into container
2023-02-16 15:30:08,655:INFO:Uploading model into container now
2023-02-16 15:30:08,655:INFO:_master_model_container: 12
2023-02-16 15:30:08,656:INFO:_display_container: 2
2023-02-16 15:30:08,656:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False)
2023-02-16 15:30:08,656:INFO:create_model() successfully completed......................................
2023-02-16 15:30:08,960:INFO:SubProcess create_model() end ==================================
2023-02-16 15:30:08,960:INFO:Creating metrics dataframe
2023-02-16 15:30:09,077:INFO:Initializing Extreme Gradient Boosting
2023-02-16 15:30:09,089:INFO:Total runtime is 4.073847273985545 minutes
2023-02-16 15:30:09,102:INFO:SubProcess create_model() called ==================================
2023-02-16 15:30:09,103:INFO:Initializing create_model()
2023-02-16 15:30:09,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:30:09,103:INFO:Checking exceptions
2023-02-16 15:30:09,103:INFO:Importing libraries
2023-02-16 15:30:09,104:INFO:Copying training dataset
2023-02-16 15:30:09,147:INFO:Defining folds
2023-02-16 15:30:09,147:INFO:Declaring metric variables
2023-02-16 15:30:09,152:INFO:Importing untrained model
2023-02-16 15:30:09,158:INFO:Extreme Gradient Boosting Imported successfully
2023-02-16 15:30:09,169:INFO:Starting cross validation
2023-02-16 15:30:09,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:30:09,646:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-16 15:30:09,718:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\queues.py", line 125, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 211, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 204, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py", line 446, in __call__
    for dumped_filename in dump(a, filename):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 553, in dump
    NumpyPickler(f, protocol=protocol).dump(value)
  File "c:\Users\pedro\anaconda3\lib\pickle.py", line 487, in dump
    self.save(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 352, in save
    wrapper.write_array(obj, self)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 134, in write_array
    pickler.file_handle.write(chunk.tobytes('C'))
OSError: [Errno 28] No space left on device
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 446, in result
    return self.__get_result()
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2023-02-16 15:30:09,718:INFO:Initializing create_model()
2023-02-16 15:30:09,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:30:09,718:INFO:Checking exceptions
2023-02-16 15:30:09,719:INFO:Importing libraries
2023-02-16 15:30:09,719:INFO:Copying training dataset
2023-02-16 15:30:09,801:INFO:Defining folds
2023-02-16 15:30:09,801:INFO:Declaring metric variables
2023-02-16 15:30:09,805:INFO:Importing untrained model
2023-02-16 15:30:09,811:INFO:Extreme Gradient Boosting Imported successfully
2023-02-16 15:30:09,822:INFO:Starting cross validation
2023-02-16 15:30:09,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:30:10,362:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2023-02-16 15:30:10,363:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\queues.py", line 125, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 211, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 204, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py", line 446, in __call__
    for dumped_filename in dump(a, filename):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 553, in dump
    NumpyPickler(f, protocol=protocol).dump(value)
  File "c:\Users\pedro\anaconda3\lib\pickle.py", line 487, in dump
    self.save(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 352, in save
    wrapper.write_array(obj, self)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 134, in write_array
    pickler.file_handle.write(chunk.tobytes('C'))
OSError: [Errno 28] No space left on device
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 439, in result
    return self.__get_result()
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2023-02-16 15:30:10,363:INFO:Initializing Light Gradient Boosting Machine
2023-02-16 15:30:10,363:INFO:Total runtime is 4.095083904266358 minutes
2023-02-16 15:30:10,387:INFO:SubProcess create_model() called ==================================
2023-02-16 15:30:10,387:INFO:Initializing create_model()
2023-02-16 15:30:10,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:30:10,387:INFO:Checking exceptions
2023-02-16 15:30:10,388:INFO:Importing libraries
2023-02-16 15:30:10,388:INFO:Copying training dataset
2023-02-16 15:30:10,438:INFO:Defining folds
2023-02-16 15:30:10,439:INFO:Declaring metric variables
2023-02-16 15:30:10,445:INFO:Importing untrained model
2023-02-16 15:30:10,452:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-16 15:30:10,466:INFO:Starting cross validation
2023-02-16 15:30:10,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:30:10,780:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-16 15:30:10,780:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\queues.py", line 125, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 211, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 204, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py", line 446, in __call__
    for dumped_filename in dump(a, filename):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 553, in dump
    NumpyPickler(f, protocol=protocol).dump(value)
  File "c:\Users\pedro\anaconda3\lib\pickle.py", line 487, in dump
    self.save(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 352, in save
    wrapper.write_array(obj, self)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 134, in write_array
    pickler.file_handle.write(chunk.tobytes('C'))
OSError: [Errno 28] No space left on device
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 439, in result
    return self.__get_result()
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2023-02-16 15:30:10,780:INFO:Initializing create_model()
2023-02-16 15:30:10,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:30:10,781:INFO:Checking exceptions
2023-02-16 15:30:10,781:INFO:Importing libraries
2023-02-16 15:30:10,781:INFO:Copying training dataset
2023-02-16 15:30:10,825:INFO:Defining folds
2023-02-16 15:30:10,825:INFO:Declaring metric variables
2023-02-16 15:30:10,830:INFO:Importing untrained model
2023-02-16 15:30:10,835:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-16 15:30:10,846:INFO:Starting cross validation
2023-02-16 15:30:10,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:30:11,225:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-02-16 15:30:11,230:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\queues.py", line 125, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 211, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 204, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py", line 446, in __call__
    for dumped_filename in dump(a, filename):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 553, in dump
    NumpyPickler(f, protocol=protocol).dump(value)
  File "c:\Users\pedro\anaconda3\lib\pickle.py", line 487, in dump
    self.save(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 352, in save
    wrapper.write_array(obj, self)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 134, in write_array
    pickler.file_handle.write(chunk.tobytes('C'))
OSError: [Errno 28] No space left on device
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 439, in result
    return self.__get_result()
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2023-02-16 15:30:11,230:INFO:Initializing Dummy Classifier
2023-02-16 15:30:11,230:INFO:Total runtime is 4.109529785315196 minutes
2023-02-16 15:30:11,236:INFO:SubProcess create_model() called ==================================
2023-02-16 15:30:11,237:INFO:Initializing create_model()
2023-02-16 15:30:11,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:30:11,237:INFO:Checking exceptions
2023-02-16 15:30:11,237:INFO:Importing libraries
2023-02-16 15:30:11,237:INFO:Copying training dataset
2023-02-16 15:30:11,279:INFO:Defining folds
2023-02-16 15:30:11,280:INFO:Declaring metric variables
2023-02-16 15:30:11,286:INFO:Importing untrained model
2023-02-16 15:30:11,288:INFO:Dummy Classifier Imported successfully
2023-02-16 15:30:11,296:INFO:Starting cross validation
2023-02-16 15:30:11,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:30:11,617:WARNING:create_model() for dummy raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-16 15:30:11,618:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\queues.py", line 125, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 211, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 204, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py", line 446, in __call__
    for dumped_filename in dump(a, filename):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 553, in dump
    NumpyPickler(f, protocol=protocol).dump(value)
  File "c:\Users\pedro\anaconda3\lib\pickle.py", line 487, in dump
    self.save(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 352, in save
    wrapper.write_array(obj, self)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 134, in write_array
    pickler.file_handle.write(chunk.tobytes('C'))
OSError: [Errno 28] No space left on device
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 446, in result
    return self.__get_result()
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2023-02-16 15:30:11,618:INFO:Initializing create_model()
2023-02-16 15:30:11,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFEA0426D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:30:11,619:INFO:Checking exceptions
2023-02-16 15:30:11,619:INFO:Importing libraries
2023-02-16 15:30:11,620:INFO:Copying training dataset
2023-02-16 15:30:11,663:INFO:Defining folds
2023-02-16 15:30:11,664:INFO:Declaring metric variables
2023-02-16 15:30:11,669:INFO:Importing untrained model
2023-02-16 15:30:11,673:INFO:Dummy Classifier Imported successfully
2023-02-16 15:30:11,683:INFO:Starting cross validation
2023-02-16 15:30:11,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 15:30:12,001:ERROR:create_model() for dummy raised an exception or returned all 0.0:
2023-02-16 15:30:12,002:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\queues.py", line 125, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 211, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 204, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py", line 446, in __call__
    for dumped_filename in dump(a, filename):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 553, in dump
    NumpyPickler(f, protocol=protocol).dump(value)
  File "c:\Users\pedro\anaconda3\lib\pickle.py", line 487, in dump
    self.save(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 352, in save
    wrapper.write_array(obj, self)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 134, in write_array
    pickler.file_handle.write(chunk.tobytes('C'))
OSError: [Errno 28] No space left on device
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 446, in result
    return self.__get_result()
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2023-02-16 15:30:12,030:INFO:Initializing create_model()
2023-02-16 15:30:12,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:30:12,030:INFO:Checking exceptions
2023-02-16 15:30:12,034:INFO:Importing libraries
2023-02-16 15:30:12,034:INFO:Copying training dataset
2023-02-16 15:30:12,078:INFO:Defining folds
2023-02-16 15:30:12,078:INFO:Declaring metric variables
2023-02-16 15:30:12,078:INFO:Importing untrained model
2023-02-16 15:30:12,078:INFO:Declaring custom model
2023-02-16 15:30:12,079:INFO:Random Forest Classifier Imported successfully
2023-02-16 15:30:12,079:INFO:Cross validation set to False
2023-02-16 15:30:12,080:INFO:Fitting Model
2023-02-16 15:30:18,218:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False)
2023-02-16 15:30:18,218:INFO:create_model() successfully completed......................................
2023-02-16 15:30:18,476:INFO:Initializing create_model()
2023-02-16 15:30:18,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:30:18,482:INFO:Checking exceptions
2023-02-16 15:30:18,484:INFO:Importing libraries
2023-02-16 15:30:18,484:INFO:Copying training dataset
2023-02-16 15:30:18,509:INFO:Defining folds
2023-02-16 15:30:18,509:INFO:Declaring metric variables
2023-02-16 15:30:18,509:INFO:Importing untrained model
2023-02-16 15:30:18,509:INFO:Declaring custom model
2023-02-16 15:30:18,509:INFO:Extra Trees Classifier Imported successfully
2023-02-16 15:30:18,509:INFO:Cross validation set to False
2023-02-16 15:30:18,509:INFO:Fitting Model
2023-02-16 15:30:21,395:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False)
2023-02-16 15:30:21,395:INFO:create_model() successfully completed......................................
2023-02-16 15:30:21,651:INFO:Initializing create_model()
2023-02-16 15:30:21,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 15:30:21,652:INFO:Checking exceptions
2023-02-16 15:30:21,654:INFO:Importing libraries
2023-02-16 15:30:21,655:INFO:Copying training dataset
2023-02-16 15:30:21,697:INFO:Defining folds
2023-02-16 15:30:21,698:INFO:Declaring metric variables
2023-02-16 15:30:21,698:INFO:Importing untrained model
2023-02-16 15:30:21,698:INFO:Declaring custom model
2023-02-16 15:30:21,698:INFO:Decision Tree Classifier Imported successfully
2023-02-16 15:30:21,698:INFO:Cross validation set to False
2023-02-16 15:30:21,700:INFO:Fitting Model
2023-02-16 15:30:22,371:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best')
2023-02-16 15:30:22,371:INFO:create_model() successfully completed......................................
2023-02-16 15:30:22,661:INFO:_master_model_container: 12
2023-02-16 15:30:22,662:INFO:_display_container: 2
2023-02-16 15:30:22,663:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best')]
2023-02-16 15:30:22,663:INFO:compare_models() successfully completed......................................
2023-02-16 15:32:10,116:INFO:Initializing tune_model()
2023-02-16 15:32:10,116:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>)
2023-02-16 15:32:10,116:INFO:Checking exceptions
2023-02-16 15:32:10,270:INFO:Copying training dataset
2023-02-16 15:32:10,308:INFO:Checking base model
2023-02-16 15:32:10,308:INFO:Base model : Random Forest Classifier
2023-02-16 15:32:10,312:INFO:Declaring metric variables
2023-02-16 15:32:10,318:INFO:Defining Hyperparameters
2023-02-16 15:32:10,589:INFO:Tuning with n_jobs=-1
2023-02-16 15:32:10,589:INFO:Initializing RandomizedSearchCV
2023-02-16 15:58:34,822:INFO:Initializing tune_model()
2023-02-16 15:58:34,927:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>)
2023-02-16 15:58:34,961:INFO:Checking exceptions
2023-02-16 15:58:41,995:INFO:Copying training dataset
2023-02-16 15:58:42,112:INFO:Checking base model
2023-02-16 15:58:42,192:INFO:Base model : Random Forest Classifier
2023-02-16 15:58:42,269:INFO:Declaring metric variables
2023-02-16 15:58:42,287:INFO:Defining Hyperparameters
2023-02-16 15:58:56,950:INFO:Tuning with n_jobs=-1
2023-02-16 15:58:56,950:INFO:Initializing RandomizedSearchCV
2023-02-16 15:59:17,086:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:00:04,506:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:01:12,344:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:01:22,436:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:01:32,492:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:01:41,436:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:02:53,453:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:03:13,851:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:03:35,638:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:03:37,601:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:04:03,031:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:04:05,869:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:04:07,050:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:04:28,702:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:04:33,135:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:04:51,462:INFO:best_params: {'actual_estimator__n_estimators': 170, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': True}
2023-02-16 16:04:51,559:INFO:Hyperparameter search completed
2023-02-16 16:04:51,559:INFO:SubProcess create_model() called ==================================
2023-02-16 16:04:51,628:INFO:Initializing create_model()
2023-02-16 16:04:51,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFE6591B20>, model_only=True, return_train_score=False, kwargs={'n_estimators': 170, 'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0, 'max_features': 'log2', 'max_depth': 11, 'criterion': 'gini', 'class_weight': 'balanced', 'bootstrap': True})
2023-02-16 16:04:51,628:INFO:Checking exceptions
2023-02-16 16:04:51,629:INFO:Importing libraries
2023-02-16 16:04:51,630:INFO:Copying training dataset
2023-02-16 16:04:52,015:INFO:Defining folds
2023-02-16 16:04:52,016:INFO:Declaring metric variables
2023-02-16 16:04:52,190:INFO:Importing untrained model
2023-02-16 16:04:52,191:INFO:Declaring custom model
2023-02-16 16:04:52,433:INFO:Random Forest Classifier Imported successfully
2023-02-16 16:04:52,541:INFO:Starting cross validation
2023-02-16 16:04:52,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:04:56,660:INFO:Calculating mean and std
2023-02-16 16:04:56,703:INFO:Creating metrics dataframe
2023-02-16 16:04:56,841:INFO:Finalizing model
2023-02-16 16:05:07,024:INFO:Uploading results into container
2023-02-16 16:05:07,040:INFO:Uploading model into container now
2023-02-16 16:05:07,050:INFO:_master_model_container: 13
2023-02-16 16:05:07,050:INFO:_display_container: 3
2023-02-16 16:05:07,050:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=170, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False)
2023-02-16 16:05:07,051:INFO:create_model() successfully completed......................................
2023-02-16 16:05:07,881:INFO:SubProcess create_model() end ==================================
2023-02-16 16:05:07,881:INFO:choose_better activated
2023-02-16 16:05:07,914:INFO:SubProcess create_model() called ==================================
2023-02-16 16:05:07,915:INFO:Initializing create_model()
2023-02-16 16:05:07,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 16:05:07,916:INFO:Checking exceptions
2023-02-16 16:05:07,920:INFO:Importing libraries
2023-02-16 16:05:07,920:INFO:Copying training dataset
2023-02-16 16:05:07,973:INFO:Defining folds
2023-02-16 16:05:07,973:INFO:Declaring metric variables
2023-02-16 16:05:07,977:INFO:Importing untrained model
2023-02-16 16:05:07,978:INFO:Declaring custom model
2023-02-16 16:05:07,978:INFO:Random Forest Classifier Imported successfully
2023-02-16 16:05:07,979:INFO:Starting cross validation
2023-02-16 16:05:07,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:05:15,028:INFO:Calculating mean and std
2023-02-16 16:05:15,086:INFO:Creating metrics dataframe
2023-02-16 16:05:15,086:INFO:Finalizing model
2023-02-16 16:05:25,808:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:05:25,810:INFO:Uploading results into container
2023-02-16 16:05:25,811:INFO:Uploading model into container now
2023-02-16 16:05:25,811:INFO:_master_model_container: 14
2023-02-16 16:05:25,811:INFO:_display_container: 4
2023-02-16 16:05:25,816:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False)
2023-02-16 16:05:25,816:INFO:create_model() successfully completed......................................
2023-02-16 16:05:26,552:INFO:SubProcess create_model() end ==================================
2023-02-16 16:05:26,553:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False) result for Accuracy is 0.9233
2023-02-16 16:05:26,554:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=170, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False) result for Accuracy is 0.8442
2023-02-16 16:05:26,555:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False) is best model
2023-02-16 16:05:26,556:INFO:choose_better completed
2023-02-16 16:05:26,556:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-16 16:05:27,011:INFO:_master_model_container: 14
2023-02-16 16:05:27,011:INFO:_display_container: 3
2023-02-16 16:05:27,011:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False)
2023-02-16 16:05:27,011:INFO:tune_model() successfully completed......................................
2023-02-16 16:05:27,293:INFO:Initializing tune_model()
2023-02-16 16:05:27,293:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>)
2023-02-16 16:05:27,368:INFO:Checking exceptions
2023-02-16 16:05:27,417:INFO:Copying training dataset
2023-02-16 16:05:27,450:INFO:Checking base model
2023-02-16 16:05:27,450:INFO:Base model : Extra Trees Classifier
2023-02-16 16:05:27,466:INFO:Declaring metric variables
2023-02-16 16:05:27,472:INFO:Defining Hyperparameters
2023-02-16 16:05:27,787:INFO:Tuning with n_jobs=-1
2023-02-16 16:05:27,787:INFO:Initializing RandomizedSearchCV
2023-02-16 16:05:39,458:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:05:41,515:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:05:47,939:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:05:50,402:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:05:53,002:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:05:53,195:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:05:57,730:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:02,191:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:06,212:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:07,214:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:08,411:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:09,691:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:10,658:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:11,591:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:22,298:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:22,859:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:22,868:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:26,590:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:27,637:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:29,080:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:30,679:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:37,451:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:47,444:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:06:58,120:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:07,070:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:08,734:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:10,290:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:11,124:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:16,321:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:17,647:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:18,948:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:20,961:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:25,195:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:26,310:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:28,614:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:30,429:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:32,518:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:07:38,030:INFO:Initializing tune_model()
2023-02-16 16:07:38,053:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False)}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>)
2023-02-16 16:07:38,053:INFO:Checking exceptions
2023-02-16 16:07:38,100:INFO:Copying training dataset
2023-02-16 16:07:38,132:INFO:Checking base model
2023-02-16 16:07:38,132:INFO:Base model : Random Forest Classifier
2023-02-16 16:07:38,196:INFO:Declaring metric variables
2023-02-16 16:07:38,202:INFO:Defining Hyperparameters
2023-02-16 16:07:38,573:INFO:Tuning with n_jobs=-1
2023-02-16 16:07:38,573:INFO:Initializing RandomizedSearchCV
2023-02-16 16:07:42,648:INFO:Initializing tune_model()
2023-02-16 16:07:42,648:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False)}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>)
2023-02-16 16:07:42,648:INFO:Checking exceptions
2023-02-16 16:07:42,747:INFO:Copying training dataset
2023-02-16 16:07:42,772:INFO:Checking base model
2023-02-16 16:07:42,772:INFO:Base model : Random Forest Classifier
2023-02-16 16:07:42,783:INFO:Declaring metric variables
2023-02-16 16:07:42,783:INFO:Defining Hyperparameters
2023-02-16 16:07:43,171:INFO:Tuning with n_jobs=-1
2023-02-16 16:07:43,172:INFO:Initializing RandomizedSearchCV
2023-02-16 16:09:02,967:INFO:Initializing tune_model()
2023-02-16 16:09:02,968:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False)}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>)
2023-02-16 16:09:02,968:INFO:Checking exceptions
2023-02-16 16:09:03,013:INFO:Copying training dataset
2023-02-16 16:09:03,054:INFO:Checking base model
2023-02-16 16:09:03,054:INFO:Base model : Random Forest Classifier
2023-02-16 16:09:03,059:INFO:Declaring metric variables
2023-02-16 16:09:03,064:INFO:Defining Hyperparameters
2023-02-16 16:09:03,511:INFO:Tuning with n_jobs=-1
2023-02-16 16:09:03,512:INFO:Initializing RandomizedSearchCV
2023-02-16 16:10:39,250:INFO:Initializing tune_model()
2023-02-16 16:10:39,250:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>)
2023-02-16 16:10:39,250:INFO:Checking exceptions
2023-02-16 16:10:39,330:INFO:Copying training dataset
2023-02-16 16:10:39,374:INFO:Checking base model
2023-02-16 16:10:39,375:INFO:Base model : Random Forest Classifier
2023-02-16 16:10:39,382:INFO:Declaring metric variables
2023-02-16 16:10:39,387:INFO:Defining Hyperparameters
2023-02-16 16:10:39,909:INFO:Tuning with n_jobs=-1
2023-02-16 16:10:39,910:INFO:Initializing RandomizedSearchCV
2023-02-16 16:11:04,417:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-02-16 16:11:04,419:INFO:Hyperparameter search completed
2023-02-16 16:11:04,419:INFO:SubProcess create_model() called ==================================
2023-02-16 16:11:04,419:INFO:Initializing create_model()
2023-02-16 16:11:04,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFB9A0F640>, model_only=True, return_train_score=False, kwargs={'n_estimators': 160, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.4, 'max_features': 'log2', 'max_depth': 7, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-02-16 16:11:04,429:INFO:Checking exceptions
2023-02-16 16:11:04,430:INFO:Importing libraries
2023-02-16 16:11:04,430:INFO:Copying training dataset
2023-02-16 16:11:04,471:INFO:Defining folds
2023-02-16 16:11:04,471:INFO:Declaring metric variables
2023-02-16 16:11:04,475:INFO:Importing untrained model
2023-02-16 16:11:04,475:INFO:Declaring custom model
2023-02-16 16:11:04,477:INFO:Random Forest Classifier Imported successfully
2023-02-16 16:11:04,490:INFO:Starting cross validation
2023-02-16 16:11:04,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:11:05,135:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 16:11:06,841:INFO:Calculating mean and std
2023-02-16 16:11:06,843:INFO:Creating metrics dataframe
2023-02-16 16:11:06,856:INFO:Finalizing model
2023-02-16 16:11:11,587:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:11:11,605:INFO:Uploading results into container
2023-02-16 16:11:11,607:INFO:Uploading model into container now
2023-02-16 16:11:11,607:INFO:_master_model_container: 15
2023-02-16 16:11:11,607:INFO:_display_container: 4
2023-02-16 16:11:11,608:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.4,
                       min_samples_leaf=5, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, n_estimators=160,
                       n_jobs=-1, oob_score=False, random_state=5924, verbose=0,
                       warm_start=False)
2023-02-16 16:11:11,608:INFO:create_model() successfully completed......................................
2023-02-16 16:11:11,866:INFO:SubProcess create_model() end ==================================
2023-02-16 16:11:11,867:INFO:choose_better activated
2023-02-16 16:11:11,872:INFO:SubProcess create_model() called ==================================
2023-02-16 16:11:11,874:INFO:Initializing create_model()
2023-02-16 16:11:11,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 16:11:11,874:INFO:Checking exceptions
2023-02-16 16:11:11,877:INFO:Importing libraries
2023-02-16 16:11:11,877:INFO:Copying training dataset
2023-02-16 16:11:11,921:INFO:Defining folds
2023-02-16 16:11:11,921:INFO:Declaring metric variables
2023-02-16 16:11:11,921:INFO:Importing untrained model
2023-02-16 16:11:11,921:INFO:Declaring custom model
2023-02-16 16:11:11,922:INFO:Random Forest Classifier Imported successfully
2023-02-16 16:11:11,922:INFO:Starting cross validation
2023-02-16 16:11:11,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:11:17,576:INFO:Calculating mean and std
2023-02-16 16:11:17,576:INFO:Creating metrics dataframe
2023-02-16 16:11:17,577:INFO:Finalizing model
2023-02-16 16:11:25,479:INFO:Uploading results into container
2023-02-16 16:11:25,479:INFO:Uploading model into container now
2023-02-16 16:11:25,480:INFO:_master_model_container: 16
2023-02-16 16:11:25,480:INFO:_display_container: 5
2023-02-16 16:11:25,480:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False)
2023-02-16 16:11:25,480:INFO:create_model() successfully completed......................................
2023-02-16 16:11:25,764:INFO:SubProcess create_model() end ==================================
2023-02-16 16:11:25,765:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False) result for Recall is 0.9241
2023-02-16 16:11:25,765:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.4,
                       min_samples_leaf=5, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, n_estimators=160,
                       n_jobs=-1, oob_score=False, random_state=5924, verbose=0,
                       warm_start=False) result for Recall is 0.9
2023-02-16 16:11:25,765:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False) is best model
2023-02-16 16:11:25,765:INFO:choose_better completed
2023-02-16 16:11:25,765:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-16 16:11:26,134:INFO:_master_model_container: 16
2023-02-16 16:11:26,134:INFO:_display_container: 4
2023-02-16 16:11:26,135:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False)
2023-02-16 16:11:26,135:INFO:tune_model() successfully completed......................................
2023-02-16 16:11:26,399:INFO:Initializing tune_model()
2023-02-16 16:11:26,399:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>)
2023-02-16 16:11:26,425:INFO:Checking exceptions
2023-02-16 16:11:26,858:INFO:Copying training dataset
2023-02-16 16:11:26,888:INFO:Checking base model
2023-02-16 16:11:26,888:INFO:Base model : Extra Trees Classifier
2023-02-16 16:11:26,895:INFO:Declaring metric variables
2023-02-16 16:11:26,899:INFO:Defining Hyperparameters
2023-02-16 16:11:27,157:INFO:Tuning with n_jobs=-1
2023-02-16 16:11:27,158:INFO:Initializing RandomizedSearchCV
2023-02-16 16:11:45,057:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:11:47,374:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:11:53,074:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-02-16 16:11:53,075:INFO:Hyperparameter search completed
2023-02-16 16:11:53,076:INFO:SubProcess create_model() called ==================================
2023-02-16 16:11:53,076:INFO:Initializing create_model()
2023-02-16 16:11:53,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFE74E1A90>, model_only=True, return_train_score=False, kwargs={'n_estimators': 160, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.4, 'max_features': 'log2', 'max_depth': 7, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-02-16 16:11:53,077:INFO:Checking exceptions
2023-02-16 16:11:53,077:INFO:Importing libraries
2023-02-16 16:11:53,077:INFO:Copying training dataset
2023-02-16 16:11:53,145:INFO:Defining folds
2023-02-16 16:11:53,145:INFO:Declaring metric variables
2023-02-16 16:11:53,149:INFO:Importing untrained model
2023-02-16 16:11:53,150:INFO:Declaring custom model
2023-02-16 16:11:53,152:INFO:Extra Trees Classifier Imported successfully
2023-02-16 16:11:53,164:INFO:Starting cross validation
2023-02-16 16:11:53,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:11:53,906:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 16:11:55,520:INFO:Calculating mean and std
2023-02-16 16:11:55,522:INFO:Creating metrics dataframe
2023-02-16 16:11:55,529:INFO:Finalizing model
2023-02-16 16:11:56,714:INFO:Uploading results into container
2023-02-16 16:11:56,715:INFO:Uploading model into container now
2023-02-16 16:11:56,717:INFO:_master_model_container: 17
2023-02-16 16:11:56,717:INFO:_display_container: 5
2023-02-16 16:11:56,717:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='entropy',
                     max_depth=7, max_features='log2', max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0.4,
                     min_samples_leaf=5, min_samples_split=10,
                     min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=-1,
                     oob_score=False, random_state=5924, verbose=0,
                     warm_start=False)
2023-02-16 16:11:56,718:INFO:create_model() successfully completed......................................
2023-02-16 16:11:57,074:INFO:SubProcess create_model() end ==================================
2023-02-16 16:11:57,074:INFO:choose_better activated
2023-02-16 16:11:57,074:INFO:SubProcess create_model() called ==================================
2023-02-16 16:11:57,074:INFO:Initializing create_model()
2023-02-16 16:11:57,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 16:11:57,083:INFO:Checking exceptions
2023-02-16 16:11:57,086:INFO:Importing libraries
2023-02-16 16:11:57,086:INFO:Copying training dataset
2023-02-16 16:11:57,129:INFO:Defining folds
2023-02-16 16:11:57,129:INFO:Declaring metric variables
2023-02-16 16:11:57,129:INFO:Importing untrained model
2023-02-16 16:11:57,130:INFO:Declaring custom model
2023-02-16 16:11:57,133:INFO:Extra Trees Classifier Imported successfully
2023-02-16 16:11:57,133:INFO:Starting cross validation
2023-02-16 16:11:57,134:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:12:41,366:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 2.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:12:42,780:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 2.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:12:44,695:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:13:30,343:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 8.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:13:54,388:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 5.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:13:54,389:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 5.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:14:17,081:INFO:Calculating mean and std
2023-02-16 16:14:17,082:INFO:Creating metrics dataframe
2023-02-16 16:14:17,082:INFO:Finalizing model
2023-02-16 16:14:22,315:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:14:22,317:INFO:Uploading results into container
2023-02-16 16:14:22,317:INFO:Uploading model into container now
2023-02-16 16:14:22,318:INFO:_master_model_container: 18
2023-02-16 16:14:22,318:INFO:_display_container: 6
2023-02-16 16:14:22,318:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False)
2023-02-16 16:14:22,318:INFO:create_model() successfully completed......................................
2023-02-16 16:14:22,579:INFO:SubProcess create_model() end ==================================
2023-02-16 16:14:22,579:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False) result for Recall is 0.9224
2023-02-16 16:14:22,579:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='entropy',
                     max_depth=7, max_features='log2', max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0.4,
                     min_samples_leaf=5, min_samples_split=10,
                     min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=-1,
                     oob_score=False, random_state=5924, verbose=0,
                     warm_start=False) result for Recall is 0.9
2023-02-16 16:14:22,579:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False) is best model
2023-02-16 16:14:22,579:INFO:choose_better completed
2023-02-16 16:14:22,579:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-16 16:14:22,681:INFO:_master_model_container: 18
2023-02-16 16:14:22,681:INFO:_display_container: 5
2023-02-16 16:14:22,681:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False)
2023-02-16 16:14:22,681:INFO:tune_model() successfully completed......................................
2023-02-16 16:14:22,939:INFO:Initializing tune_model()
2023-02-16 16:14:22,939:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>)
2023-02-16 16:14:22,972:INFO:Checking exceptions
2023-02-16 16:14:23,094:INFO:Copying training dataset
2023-02-16 16:14:23,124:INFO:Checking base model
2023-02-16 16:14:23,124:INFO:Base model : Decision Tree Classifier
2023-02-16 16:14:23,128:INFO:Declaring metric variables
2023-02-16 16:14:23,132:INFO:Defining Hyperparameters
2023-02-16 16:14:23,388:INFO:Tuning with n_jobs=-1
2023-02-16 16:14:23,389:INFO:Initializing RandomizedSearchCV
2023-02-16 16:34:20,993:INFO:Initializing tune_model()
2023-02-16 16:34:20,994:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>)
2023-02-16 16:34:20,994:INFO:Checking exceptions
2023-02-16 16:34:21,027:INFO:Copying training dataset
2023-02-16 16:34:21,062:INFO:Checking base model
2023-02-16 16:34:21,062:INFO:Base model : Random Forest Classifier
2023-02-16 16:34:21,069:INFO:Declaring metric variables
2023-02-16 16:34:21,075:INFO:Defining Hyperparameters
2023-02-16 16:34:21,358:INFO:Tuning with n_jobs=-1
2023-02-16 16:34:21,359:INFO:Initializing RandomizedSearchCV
2023-02-16 16:34:42,798:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-02-16 16:34:42,800:INFO:Hyperparameter search completed
2023-02-16 16:34:42,800:INFO:SubProcess create_model() called ==================================
2023-02-16 16:34:42,801:INFO:Initializing create_model()
2023-02-16 16:34:42,801:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFE6591B20>, model_only=True, return_train_score=False, kwargs={'n_estimators': 160, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.4, 'max_features': 'log2', 'max_depth': 7, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-02-16 16:34:42,801:INFO:Checking exceptions
2023-02-16 16:34:42,801:INFO:Importing libraries
2023-02-16 16:34:42,801:INFO:Copying training dataset
2023-02-16 16:34:42,850:INFO:Defining folds
2023-02-16 16:34:42,850:INFO:Declaring metric variables
2023-02-16 16:34:42,878:INFO:Importing untrained model
2023-02-16 16:34:42,878:INFO:Declaring custom model
2023-02-16 16:34:43,437:INFO:Random Forest Classifier Imported successfully
2023-02-16 16:34:43,448:INFO:Starting cross validation
2023-02-16 16:34:43,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:34:44,163:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 16:34:45,772:INFO:Calculating mean and std
2023-02-16 16:34:45,773:INFO:Creating metrics dataframe
2023-02-16 16:34:45,780:INFO:Finalizing model
2023-02-16 16:34:45,952:INFO:Uploading results into container
2023-02-16 16:34:45,952:INFO:Uploading model into container now
2023-02-16 16:34:45,953:INFO:_master_model_container: 19
2023-02-16 16:34:45,953:INFO:_display_container: 6
2023-02-16 16:34:45,954:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.4,
                       min_samples_leaf=5, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, n_estimators=160,
                       n_jobs=-1, oob_score=False, random_state=5924, verbose=0,
                       warm_start=False)
2023-02-16 16:34:45,954:INFO:create_model() successfully completed......................................
2023-02-16 16:34:46,227:INFO:SubProcess create_model() end ==================================
2023-02-16 16:34:46,227:INFO:choose_better activated
2023-02-16 16:34:46,231:INFO:SubProcess create_model() called ==================================
2023-02-16 16:34:46,233:INFO:Initializing create_model()
2023-02-16 16:34:46,234:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 16:34:46,234:INFO:Checking exceptions
2023-02-16 16:34:46,235:INFO:Importing libraries
2023-02-16 16:34:46,235:INFO:Copying training dataset
2023-02-16 16:34:46,271:INFO:Defining folds
2023-02-16 16:34:46,271:INFO:Declaring metric variables
2023-02-16 16:34:46,271:INFO:Importing untrained model
2023-02-16 16:34:46,271:INFO:Declaring custom model
2023-02-16 16:34:46,271:INFO:Random Forest Classifier Imported successfully
2023-02-16 16:34:46,271:INFO:Starting cross validation
2023-02-16 16:34:46,271:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:34:51,852:INFO:Calculating mean and std
2023-02-16 16:34:51,853:INFO:Creating metrics dataframe
2023-02-16 16:34:51,856:INFO:Finalizing model
2023-02-16 16:34:54,020:INFO:Uploading results into container
2023-02-16 16:34:54,021:INFO:Uploading model into container now
2023-02-16 16:34:54,021:INFO:_master_model_container: 20
2023-02-16 16:34:54,021:INFO:_display_container: 7
2023-02-16 16:34:54,022:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False)
2023-02-16 16:34:54,022:INFO:create_model() successfully completed......................................
2023-02-16 16:34:54,295:INFO:SubProcess create_model() end ==================================
2023-02-16 16:34:54,296:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False) result for Recall is 0.9241
2023-02-16 16:34:54,298:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.4,
                       min_samples_leaf=5, min_samples_split=10,
                       min_weight_fraction_leaf=0.0, n_estimators=160,
                       n_jobs=-1, oob_score=False, random_state=5924, verbose=0,
                       warm_start=False) result for Recall is 0.9
2023-02-16 16:34:54,298:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False) is best model
2023-02-16 16:34:54,298:INFO:choose_better completed
2023-02-16 16:34:54,298:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-16 16:34:54,311:INFO:_master_model_container: 20
2023-02-16 16:34:54,311:INFO:_display_container: 6
2023-02-16 16:34:54,312:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False)
2023-02-16 16:34:54,312:INFO:tune_model() successfully completed......................................
2023-02-16 16:34:54,581:INFO:Initializing tune_model()
2023-02-16 16:34:54,581:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>)
2023-02-16 16:34:54,581:INFO:Checking exceptions
2023-02-16 16:34:54,620:INFO:Copying training dataset
2023-02-16 16:34:54,658:INFO:Checking base model
2023-02-16 16:34:54,658:INFO:Base model : Extra Trees Classifier
2023-02-16 16:34:54,663:INFO:Declaring metric variables
2023-02-16 16:34:54,666:INFO:Defining Hyperparameters
2023-02-16 16:34:54,961:INFO:Tuning with n_jobs=-1
2023-02-16 16:34:54,961:INFO:Initializing RandomizedSearchCV
2023-02-16 16:35:07,601:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-02-16 16:35:07,602:INFO:Hyperparameter search completed
2023-02-16 16:35:07,602:INFO:SubProcess create_model() called ==================================
2023-02-16 16:35:07,603:INFO:Initializing create_model()
2023-02-16 16:35:07,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFD0E618B0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 160, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.4, 'max_features': 'log2', 'max_depth': 7, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-02-16 16:35:07,603:INFO:Checking exceptions
2023-02-16 16:35:07,604:INFO:Importing libraries
2023-02-16 16:35:07,604:INFO:Copying training dataset
2023-02-16 16:35:07,667:INFO:Defining folds
2023-02-16 16:35:07,667:INFO:Declaring metric variables
2023-02-16 16:35:07,670:INFO:Importing untrained model
2023-02-16 16:35:07,671:INFO:Declaring custom model
2023-02-16 16:35:07,678:INFO:Extra Trees Classifier Imported successfully
2023-02-16 16:35:07,689:INFO:Starting cross validation
2023-02-16 16:35:07,689:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:35:08,773:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 16:35:10,473:INFO:Calculating mean and std
2023-02-16 16:35:10,474:INFO:Creating metrics dataframe
2023-02-16 16:35:10,481:INFO:Finalizing model
2023-02-16 16:35:10,756:INFO:Uploading results into container
2023-02-16 16:35:10,772:INFO:Uploading model into container now
2023-02-16 16:35:10,772:INFO:_master_model_container: 21
2023-02-16 16:35:10,772:INFO:_display_container: 7
2023-02-16 16:35:10,773:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='entropy',
                     max_depth=7, max_features='log2', max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0.4,
                     min_samples_leaf=5, min_samples_split=10,
                     min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=-1,
                     oob_score=False, random_state=5924, verbose=0,
                     warm_start=False)
2023-02-16 16:35:10,773:INFO:create_model() successfully completed......................................
2023-02-16 16:35:11,042:INFO:SubProcess create_model() end ==================================
2023-02-16 16:35:11,042:INFO:choose_better activated
2023-02-16 16:35:11,047:INFO:SubProcess create_model() called ==================================
2023-02-16 16:35:11,048:INFO:Initializing create_model()
2023-02-16 16:35:11,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 16:35:11,049:INFO:Checking exceptions
2023-02-16 16:35:11,051:INFO:Importing libraries
2023-02-16 16:35:11,051:INFO:Copying training dataset
2023-02-16 16:35:11,098:INFO:Defining folds
2023-02-16 16:35:11,098:INFO:Declaring metric variables
2023-02-16 16:35:11,099:INFO:Importing untrained model
2023-02-16 16:35:11,099:INFO:Declaring custom model
2023-02-16 16:35:11,099:INFO:Extra Trees Classifier Imported successfully
2023-02-16 16:35:11,099:INFO:Starting cross validation
2023-02-16 16:35:11,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:35:38,347:INFO:Calculating mean and std
2023-02-16 16:35:38,656:INFO:Creating metrics dataframe
2023-02-16 16:35:40,448:INFO:Finalizing model
2023-02-16 16:35:46,043:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:35:46,077:INFO:Uploading results into container
2023-02-16 16:35:46,095:INFO:Uploading model into container now
2023-02-16 16:35:46,099:INFO:_master_model_container: 22
2023-02-16 16:35:46,099:INFO:_display_container: 8
2023-02-16 16:35:46,099:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False)
2023-02-16 16:35:46,099:INFO:create_model() successfully completed......................................
2023-02-16 16:36:03,826:INFO:SubProcess create_model() end ==================================
2023-02-16 16:36:03,828:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False) result for Recall is 0.9224
2023-02-16 16:36:03,829:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='entropy',
                     max_depth=7, max_features='log2', max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0.4,
                     min_samples_leaf=5, min_samples_split=10,
                     min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=-1,
                     oob_score=False, random_state=5924, verbose=0,
                     warm_start=False) result for Recall is 0.9
2023-02-16 16:36:03,830:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False) is best model
2023-02-16 16:36:03,830:INFO:choose_better completed
2023-02-16 16:36:03,836:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-16 16:36:03,933:INFO:_master_model_container: 22
2023-02-16 16:36:03,934:INFO:_display_container: 7
2023-02-16 16:36:03,934:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False)
2023-02-16 16:36:03,934:INFO:tune_model() successfully completed......................................
2023-02-16 16:36:04,251:INFO:Initializing tune_model()
2023-02-16 16:36:04,252:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>)
2023-02-16 16:36:04,252:INFO:Checking exceptions
2023-02-16 16:36:04,319:INFO:Copying training dataset
2023-02-16 16:36:04,347:INFO:Checking base model
2023-02-16 16:36:04,347:INFO:Base model : Decision Tree Classifier
2023-02-16 16:36:04,348:INFO:Declaring metric variables
2023-02-16 16:36:04,357:INFO:Defining Hyperparameters
2023-02-16 16:36:04,607:INFO:Tuning with n_jobs=-1
2023-02-16 16:36:04,608:INFO:Initializing RandomizedSearchCV
2023-02-16 16:36:11,044:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'entropy'}
2023-02-16 16:36:11,044:INFO:Hyperparameter search completed
2023-02-16 16:36:11,044:INFO:SubProcess create_model() called ==================================
2023-02-16 16:36:11,045:INFO:Initializing create_model()
2023-02-16 16:36:11,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BFE6EDF580>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 9, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.01, 'max_features': 'sqrt', 'max_depth': 4, 'criterion': 'entropy'})
2023-02-16 16:36:11,045:INFO:Checking exceptions
2023-02-16 16:36:11,045:INFO:Importing libraries
2023-02-16 16:36:11,045:INFO:Copying training dataset
2023-02-16 16:36:11,087:INFO:Defining folds
2023-02-16 16:36:11,087:INFO:Declaring metric variables
2023-02-16 16:36:11,107:INFO:Importing untrained model
2023-02-16 16:36:11,108:INFO:Declaring custom model
2023-02-16 16:36:11,119:INFO:Decision Tree Classifier Imported successfully
2023-02-16 16:36:11,130:INFO:Starting cross validation
2023-02-16 16:36:11,131:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:36:12,139:INFO:Calculating mean and std
2023-02-16 16:36:12,143:INFO:Creating metrics dataframe
2023-02-16 16:36:12,160:INFO:Finalizing model
2023-02-16 16:36:12,350:INFO:Uploading results into container
2023-02-16 16:36:12,352:INFO:Uploading model into container now
2023-02-16 16:36:12,352:INFO:_master_model_container: 23
2023-02-16 16:36:12,353:INFO:_display_container: 8
2023-02-16 16:36:12,353:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best')
2023-02-16 16:36:12,353:INFO:create_model() successfully completed......................................
2023-02-16 16:36:12,706:INFO:SubProcess create_model() end ==================================
2023-02-16 16:36:12,706:INFO:choose_better activated
2023-02-16 16:36:12,729:INFO:SubProcess create_model() called ==================================
2023-02-16 16:36:12,729:INFO:Initializing create_model()
2023-02-16 16:36:12,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 16:36:12,730:INFO:Checking exceptions
2023-02-16 16:36:12,732:INFO:Importing libraries
2023-02-16 16:36:12,732:INFO:Copying training dataset
2023-02-16 16:36:12,770:INFO:Defining folds
2023-02-16 16:36:12,770:INFO:Declaring metric variables
2023-02-16 16:36:12,770:INFO:Importing untrained model
2023-02-16 16:36:12,770:INFO:Declaring custom model
2023-02-16 16:36:12,770:INFO:Decision Tree Classifier Imported successfully
2023-02-16 16:36:12,770:INFO:Starting cross validation
2023-02-16 16:36:12,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:36:13,482:INFO:Calculating mean and std
2023-02-16 16:36:13,483:INFO:Creating metrics dataframe
2023-02-16 16:36:13,487:INFO:Finalizing model
2023-02-16 16:36:13,592:INFO:Uploading results into container
2023-02-16 16:36:13,593:INFO:Uploading model into container now
2023-02-16 16:36:13,593:INFO:_master_model_container: 24
2023-02-16 16:36:13,593:INFO:_display_container: 9
2023-02-16 16:36:13,594:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best')
2023-02-16 16:36:13,594:INFO:create_model() successfully completed......................................
2023-02-16 16:36:13,900:INFO:SubProcess create_model() end ==================================
2023-02-16 16:36:13,901:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best') result for Recall is 0.8915
2023-02-16 16:36:13,901:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best') result for Recall is 0.9047
2023-02-16 16:36:13,901:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best') is best model
2023-02-16 16:36:13,901:INFO:choose_better completed
2023-02-16 16:36:13,905:INFO:_master_model_container: 24
2023-02-16 16:36:13,905:INFO:_display_container: 8
2023-02-16 16:36:13,905:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best')
2023-02-16 16:36:13,905:INFO:tune_model() successfully completed......................................
2023-02-16 16:36:14,293:INFO:Initializing blend_models()
2023-02-16 16:36:14,330:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator_list=[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5924, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5924, verbose=0, warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       random_state=5924, splitter='best')], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-02-16 16:36:14,330:INFO:Checking exceptions
2023-02-16 16:36:14,393:INFO:Importing libraries
2023-02-16 16:36:14,393:INFO:Copying training dataset
2023-02-16 16:36:14,400:INFO:Getting model names
2023-02-16 16:36:14,424:INFO:SubProcess create_model() called ==================================
2023-02-16 16:36:14,470:INFO:Initializing create_model()
2023-02-16 16:36:14,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BFEA042E20>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='auto',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False...
                             ('Decision Tree Classifier',
                              DecisionTreeClassifier(ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='entropy',
                                                     max_depth=4,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     min_impurity_decrease=0.01,
                                                     min_samples_leaf=2,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     random_state=5924,
                                                     splitter='best'))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C1EDA2BC40>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 16:36:14,507:INFO:Checking exceptions
2023-02-16 16:36:14,508:INFO:Importing libraries
2023-02-16 16:36:14,508:INFO:Copying training dataset
2023-02-16 16:36:14,548:INFO:Defining folds
2023-02-16 16:36:14,548:INFO:Declaring metric variables
2023-02-16 16:36:14,552:INFO:Importing untrained model
2023-02-16 16:36:14,552:INFO:Declaring custom model
2023-02-16 16:36:14,555:INFO:Voting Classifier Imported successfully
2023-02-16 16:36:14,555:INFO:Starting cross validation
2023-02-16 16:36:14,572:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 16:36:48,141:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:36:48,141:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 16:37:46,110:INFO:Calculating mean and std
2023-02-16 16:37:46,111:INFO:Creating metrics dataframe
2023-02-16 16:37:46,119:INFO:Finalizing model
2023-02-16 17:20:40,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-16 17:20:40,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-16 17:20:40,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-16 17:20:40,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-16 17:20:41,996:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-16 17:30:48,887:INFO:PyCaret ClassificationExperiment
2023-02-16 17:30:48,896:INFO:Logging name: clf-default-name
2023-02-16 17:30:48,896:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-16 17:30:48,896:INFO:version 3.0.0.rc9
2023-02-16 17:30:48,896:INFO:Initializing setup()
2023-02-16 17:30:48,896:INFO:self.USI: 1f92
2023-02-16 17:30:48,897:INFO:self._variable_keys: {'y', 'idx', 'memory', 'fix_imbalance', 'gpu_n_jobs_param', 'seed', 'USI', 'fold_shuffle_param', 'y_test', 'X', 'gpu_param', '_available_plots', 'fold_generator', 'exp_id', 'n_jobs_param', 'y_train', 'data', 'logging_param', 'X_train', 'target_param', 'pipeline', '_ml_usecase', 'html_param', 'log_plots_param', 'X_test', 'is_multiclass', 'exp_name_log', 'fold_groups_param'}
2023-02-16 17:30:48,897:INFO:Checking environment
2023-02-16 17:30:48,897:INFO:python_version: 3.9.15
2023-02-16 17:30:48,897:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-16 17:30:48,897:INFO:machine: AMD64
2023-02-16 17:30:48,897:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-16 17:30:48,897:INFO:Memory: svmem(total=8469581824, available=2688110592, percent=68.3, used=5781471232, free=2688110592)
2023-02-16 17:30:48,897:INFO:Physical Core: 4
2023-02-16 17:30:48,897:INFO:Logical Core: 4
2023-02-16 17:30:48,897:INFO:Checking libraries
2023-02-16 17:30:48,898:INFO:System:
2023-02-16 17:30:48,898:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-16 17:30:48,898:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-16 17:30:48,898:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-16 17:30:48,898:INFO:PyCaret required dependencies:
2023-02-16 17:30:48,898:INFO:                 pip: 22.3.1
2023-02-16 17:30:48,898:INFO:          setuptools: 60.10.0
2023-02-16 17:30:48,898:INFO:             pycaret: 3.0.0rc9
2023-02-16 17:30:48,898:INFO:             IPython: 7.31.1
2023-02-16 17:30:48,898:INFO:          ipywidgets: 7.6.5
2023-02-16 17:30:48,898:INFO:                tqdm: 4.64.1
2023-02-16 17:30:48,898:INFO:               numpy: 1.21.5
2023-02-16 17:30:48,898:INFO:              pandas: 1.4.4
2023-02-16 17:30:48,898:INFO:              jinja2: 2.11.3
2023-02-16 17:30:48,898:INFO:               scipy: 1.9.3
2023-02-16 17:30:48,899:INFO:              joblib: 1.2.0
2023-02-16 17:30:48,899:INFO:             sklearn: 1.0.2
2023-02-16 17:30:48,899:INFO:                pyod: 1.0.7
2023-02-16 17:30:48,899:INFO:            imblearn: 0.10.1
2023-02-16 17:30:48,899:INFO:   category_encoders: 2.6.0
2023-02-16 17:30:48,899:INFO:            lightgbm: 3.3.5
2023-02-16 17:30:48,899:INFO:               numba: 0.56.4
2023-02-16 17:30:48,899:INFO:            requests: 2.28.1
2023-02-16 17:30:48,899:INFO:          matplotlib: 3.6.2
2023-02-16 17:30:48,899:INFO:          scikitplot: 0.3.7
2023-02-16 17:30:48,899:INFO:         yellowbrick: 1.5
2023-02-16 17:30:48,899:INFO:              plotly: 5.9.0
2023-02-16 17:30:48,899:INFO:             kaleido: 0.2.1
2023-02-16 17:30:48,899:INFO:         statsmodels: 0.13.2
2023-02-16 17:30:48,899:INFO:              sktime: 0.16.1
2023-02-16 17:30:48,899:INFO:               tbats: 1.1.2
2023-02-16 17:30:48,899:INFO:            pmdarima: 2.0.2
2023-02-16 17:30:48,899:INFO:              psutil: 5.9.0
2023-02-16 17:30:48,899:INFO:PyCaret optional dependencies:
2023-02-16 17:30:48,917:INFO:                shap: 0.41.0
2023-02-16 17:30:48,917:INFO:           interpret: Not installed
2023-02-16 17:30:48,917:INFO:                umap: Not installed
2023-02-16 17:30:48,917:INFO:    pandas_profiling: 4.0.0
2023-02-16 17:30:48,917:INFO:  explainerdashboard: 0.3.6.2
2023-02-16 17:30:48,917:INFO:             autoviz: 0.1.58
2023-02-16 17:30:48,918:INFO:           fairlearn: Not installed
2023-02-16 17:30:48,918:INFO:             xgboost: 1.7.3
2023-02-16 17:30:48,919:INFO:            catboost: Not installed
2023-02-16 17:30:48,919:INFO:              kmodes: Not installed
2023-02-16 17:30:48,919:INFO:             mlxtend: Not installed
2023-02-16 17:30:48,919:INFO:       statsforecast: Not installed
2023-02-16 17:30:48,919:INFO:        tune_sklearn: Not installed
2023-02-16 17:30:48,919:INFO:                 ray: Not installed
2023-02-16 17:30:48,919:INFO:            hyperopt: Not installed
2023-02-16 17:30:48,919:INFO:              optuna: 2.10.1
2023-02-16 17:30:48,919:INFO:               skopt: Not installed
2023-02-16 17:30:48,919:INFO:              mlflow: Not installed
2023-02-16 17:30:48,919:INFO:              gradio: Not installed
2023-02-16 17:30:48,919:INFO:             fastapi: Not installed
2023-02-16 17:30:48,919:INFO:             uvicorn: Not installed
2023-02-16 17:30:48,919:INFO:              m2cgen: Not installed
2023-02-16 17:30:48,919:INFO:           evidently: Not installed
2023-02-16 17:30:48,919:INFO:               fugue: Not installed
2023-02-16 17:30:48,919:INFO:           streamlit: Not installed
2023-02-16 17:30:48,919:INFO:             prophet: Not installed
2023-02-16 17:30:48,919:INFO:None
2023-02-16 17:30:48,919:INFO:Set up data.
2023-02-16 17:30:48,971:INFO:Set up train/test split.
2023-02-16 17:30:49,068:INFO:Set up index.
2023-02-16 17:30:49,083:INFO:Set up folding strategy.
2023-02-16 17:30:49,083:INFO:Assigning column types.
2023-02-16 17:30:49,107:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-16 17:30:49,190:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 17:30:49,234:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 17:30:49,306:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 17:30:49,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 17:30:49,380:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 17:30:49,381:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 17:30:49,418:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 17:30:49,421:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 17:30:49,421:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-16 17:30:49,490:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 17:30:49,530:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 17:30:49,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 17:30:49,595:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 17:30:49,635:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 17:30:49,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 17:30:49,640:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-16 17:30:49,750:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 17:30:49,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 17:30:49,848:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 17:30:49,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 17:30:49,901:INFO:Finished creating preprocessing pipeline.
2023-02-16 17:30:49,943:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2023-02-16 17:30:49,943:INFO:Creating final display dataframe.
2023-02-16 17:30:50,314:INFO:Setup _display_container:                    Description         Value
0                   Session id          3330
1                       Target        target
2                  Target type        Binary
3          Original data shape  (123202, 11)
4       Transformed data shape  (123202, 11)
5  Transformed train set shape   (86241, 11)
6   Transformed test set shape   (36961, 11)
7             Numeric features            10
2023-02-16 17:30:50,530:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 17:30:50,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 17:30:50,644:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 17:30:50,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 17:30:50,648:INFO:setup() successfully completed in 1.78s...............
2023-02-16 17:30:52,944:INFO:Initializing compare_models()
2023-02-16 17:30:52,944:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-16 17:30:52,944:INFO:Checking exceptions
2023-02-16 17:30:52,969:INFO:Preparing display monitor
2023-02-16 17:30:53,083:INFO:Initializing Logistic Regression
2023-02-16 17:30:53,084:INFO:Total runtime is 1.661380132039388e-05 minutes
2023-02-16 17:30:53,089:INFO:SubProcess create_model() called ==================================
2023-02-16 17:30:53,090:INFO:Initializing create_model()
2023-02-16 17:30:53,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:30:53,091:INFO:Checking exceptions
2023-02-16 17:30:53,091:INFO:Importing libraries
2023-02-16 17:30:53,091:INFO:Copying training dataset
2023-02-16 17:30:53,152:INFO:Defining folds
2023-02-16 17:30:53,152:INFO:Declaring metric variables
2023-02-16 17:30:53,163:INFO:Importing untrained model
2023-02-16 17:30:53,168:INFO:Logistic Regression Imported successfully
2023-02-16 17:30:53,183:INFO:Starting cross validation
2023-02-16 17:30:53,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:31:10,662:INFO:Calculating mean and std
2023-02-16 17:31:10,664:INFO:Creating metrics dataframe
2023-02-16 17:31:10,667:INFO:Uploading results into container
2023-02-16 17:31:10,670:INFO:Uploading model into container now
2023-02-16 17:31:10,671:INFO:_master_model_container: 1
2023-02-16 17:31:10,671:INFO:_display_container: 2
2023-02-16 17:31:10,671:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3330, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-16 17:31:10,671:INFO:create_model() successfully completed......................................
2023-02-16 17:31:10,882:INFO:SubProcess create_model() end ==================================
2023-02-16 17:31:10,882:INFO:Creating metrics dataframe
2023-02-16 17:31:10,882:INFO:Initializing K Neighbors Classifier
2023-02-16 17:31:10,882:INFO:Total runtime is 0.2966466546058655 minutes
2023-02-16 17:31:10,897:INFO:SubProcess create_model() called ==================================
2023-02-16 17:31:10,897:INFO:Initializing create_model()
2023-02-16 17:31:10,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:31:10,897:INFO:Checking exceptions
2023-02-16 17:31:10,897:INFO:Importing libraries
2023-02-16 17:31:10,897:INFO:Copying training dataset
2023-02-16 17:31:10,935:INFO:Defining folds
2023-02-16 17:31:10,935:INFO:Declaring metric variables
2023-02-16 17:31:10,939:INFO:Importing untrained model
2023-02-16 17:31:10,945:INFO:K Neighbors Classifier Imported successfully
2023-02-16 17:31:10,951:INFO:Starting cross validation
2023-02-16 17:31:10,954:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:31:11,638:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 17:31:11,654:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 17:31:11,797:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 17:31:11,819:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 17:31:12,872:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 17:31:12,951:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 17:31:12,980:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 17:31:13,081:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 17:31:14,117:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 17:31:14,227:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 17:31:14,692:INFO:Calculating mean and std
2023-02-16 17:31:14,692:INFO:Creating metrics dataframe
2023-02-16 17:31:14,699:INFO:Uploading results into container
2023-02-16 17:31:14,699:INFO:Uploading model into container now
2023-02-16 17:31:14,701:INFO:_master_model_container: 2
2023-02-16 17:31:14,701:INFO:_display_container: 2
2023-02-16 17:31:14,701:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-16 17:31:14,701:INFO:create_model() successfully completed......................................
2023-02-16 17:31:14,850:INFO:SubProcess create_model() end ==================================
2023-02-16 17:31:14,850:INFO:Creating metrics dataframe
2023-02-16 17:31:14,862:INFO:Initializing Naive Bayes
2023-02-16 17:31:14,862:INFO:Total runtime is 0.3629718780517578 minutes
2023-02-16 17:31:14,866:INFO:SubProcess create_model() called ==================================
2023-02-16 17:31:14,867:INFO:Initializing create_model()
2023-02-16 17:31:14,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:31:14,868:INFO:Checking exceptions
2023-02-16 17:31:14,868:INFO:Importing libraries
2023-02-16 17:31:14,868:INFO:Copying training dataset
2023-02-16 17:31:14,906:INFO:Defining folds
2023-02-16 17:31:14,906:INFO:Declaring metric variables
2023-02-16 17:31:14,910:INFO:Importing untrained model
2023-02-16 17:31:14,915:INFO:Naive Bayes Imported successfully
2023-02-16 17:31:14,925:INFO:Starting cross validation
2023-02-16 17:31:14,926:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:31:15,360:INFO:Calculating mean and std
2023-02-16 17:31:15,360:INFO:Creating metrics dataframe
2023-02-16 17:31:15,360:INFO:Uploading results into container
2023-02-16 17:31:15,366:INFO:Uploading model into container now
2023-02-16 17:31:15,366:INFO:_master_model_container: 3
2023-02-16 17:31:15,367:INFO:_display_container: 2
2023-02-16 17:31:15,367:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-16 17:31:15,367:INFO:create_model() successfully completed......................................
2023-02-16 17:31:15,495:INFO:SubProcess create_model() end ==================================
2023-02-16 17:31:15,510:INFO:Creating metrics dataframe
2023-02-16 17:31:15,520:INFO:Initializing Decision Tree Classifier
2023-02-16 17:31:15,520:INFO:Total runtime is 0.3739488363265991 minutes
2023-02-16 17:31:15,524:INFO:SubProcess create_model() called ==================================
2023-02-16 17:31:15,524:INFO:Initializing create_model()
2023-02-16 17:31:15,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:31:15,526:INFO:Checking exceptions
2023-02-16 17:31:15,526:INFO:Importing libraries
2023-02-16 17:31:15,526:INFO:Copying training dataset
2023-02-16 17:31:15,559:INFO:Defining folds
2023-02-16 17:31:15,559:INFO:Declaring metric variables
2023-02-16 17:31:15,568:INFO:Importing untrained model
2023-02-16 17:31:15,572:INFO:Decision Tree Classifier Imported successfully
2023-02-16 17:31:15,583:INFO:Starting cross validation
2023-02-16 17:31:15,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:31:17,794:INFO:Calculating mean and std
2023-02-16 17:31:17,794:INFO:Creating metrics dataframe
2023-02-16 17:31:17,797:INFO:Uploading results into container
2023-02-16 17:31:17,797:INFO:Uploading model into container now
2023-02-16 17:31:17,797:INFO:_master_model_container: 4
2023-02-16 17:31:17,801:INFO:_display_container: 2
2023-02-16 17:31:17,801:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3330, splitter='best')
2023-02-16 17:31:17,801:INFO:create_model() successfully completed......................................
2023-02-16 17:31:17,944:INFO:SubProcess create_model() end ==================================
2023-02-16 17:31:17,944:INFO:Creating metrics dataframe
2023-02-16 17:31:17,959:INFO:Initializing SVM - Linear Kernel
2023-02-16 17:31:17,959:INFO:Total runtime is 0.41460243463516233 minutes
2023-02-16 17:31:17,962:INFO:SubProcess create_model() called ==================================
2023-02-16 17:31:17,962:INFO:Initializing create_model()
2023-02-16 17:31:17,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:31:17,962:INFO:Checking exceptions
2023-02-16 17:31:17,962:INFO:Importing libraries
2023-02-16 17:31:17,962:INFO:Copying training dataset
2023-02-16 17:31:17,993:INFO:Defining folds
2023-02-16 17:31:17,993:INFO:Declaring metric variables
2023-02-16 17:31:18,010:INFO:Importing untrained model
2023-02-16 17:31:18,017:INFO:SVM - Linear Kernel Imported successfully
2023-02-16 17:31:18,027:INFO:Starting cross validation
2023-02-16 17:31:18,027:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:31:29,583:INFO:Calculating mean and std
2023-02-16 17:31:29,584:INFO:Creating metrics dataframe
2023-02-16 17:31:29,588:INFO:Uploading results into container
2023-02-16 17:31:29,588:INFO:Uploading model into container now
2023-02-16 17:31:29,589:INFO:_master_model_container: 5
2023-02-16 17:31:29,589:INFO:_display_container: 2
2023-02-16 17:31:29,590:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3330, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-16 17:31:29,590:INFO:create_model() successfully completed......................................
2023-02-16 17:31:29,735:INFO:SubProcess create_model() end ==================================
2023-02-16 17:31:29,735:INFO:Creating metrics dataframe
2023-02-16 17:31:29,743:INFO:Initializing Ridge Classifier
2023-02-16 17:31:29,743:INFO:Total runtime is 0.6109946091969808 minutes
2023-02-16 17:31:29,756:INFO:SubProcess create_model() called ==================================
2023-02-16 17:31:29,756:INFO:Initializing create_model()
2023-02-16 17:31:29,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:31:29,756:INFO:Checking exceptions
2023-02-16 17:31:29,757:INFO:Importing libraries
2023-02-16 17:31:29,757:INFO:Copying training dataset
2023-02-16 17:31:29,790:INFO:Defining folds
2023-02-16 17:31:29,790:INFO:Declaring metric variables
2023-02-16 17:31:29,798:INFO:Importing untrained model
2023-02-16 17:31:29,803:INFO:Ridge Classifier Imported successfully
2023-02-16 17:31:29,811:INFO:Starting cross validation
2023-02-16 17:31:29,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:31:30,279:INFO:Calculating mean and std
2023-02-16 17:31:30,281:INFO:Creating metrics dataframe
2023-02-16 17:31:30,285:INFO:Uploading results into container
2023-02-16 17:31:30,286:INFO:Uploading model into container now
2023-02-16 17:31:30,286:INFO:_master_model_container: 6
2023-02-16 17:31:30,286:INFO:_display_container: 2
2023-02-16 17:31:30,286:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=3330, solver='auto', tol=0.001)
2023-02-16 17:31:30,286:INFO:create_model() successfully completed......................................
2023-02-16 17:31:30,424:INFO:SubProcess create_model() end ==================================
2023-02-16 17:31:30,424:INFO:Creating metrics dataframe
2023-02-16 17:31:30,441:INFO:Initializing Random Forest Classifier
2023-02-16 17:31:30,442:INFO:Total runtime is 0.6226512591044108 minutes
2023-02-16 17:31:30,447:INFO:SubProcess create_model() called ==================================
2023-02-16 17:31:30,447:INFO:Initializing create_model()
2023-02-16 17:31:30,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:31:30,448:INFO:Checking exceptions
2023-02-16 17:31:30,448:INFO:Importing libraries
2023-02-16 17:31:30,448:INFO:Copying training dataset
2023-02-16 17:31:30,487:INFO:Defining folds
2023-02-16 17:31:30,487:INFO:Declaring metric variables
2023-02-16 17:31:30,490:INFO:Importing untrained model
2023-02-16 17:31:30,494:INFO:Random Forest Classifier Imported successfully
2023-02-16 17:31:30,503:INFO:Starting cross validation
2023-02-16 17:31:30,505:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:32:17,028:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 17:32:19,740:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 2.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 17:32:22,632:INFO:Calculating mean and std
2023-02-16 17:32:22,635:INFO:Creating metrics dataframe
2023-02-16 17:32:22,640:INFO:Uploading results into container
2023-02-16 17:32:22,650:INFO:Uploading model into container now
2023-02-16 17:32:22,651:INFO:_master_model_container: 7
2023-02-16 17:32:22,651:INFO:_display_container: 2
2023-02-16 17:32:22,652:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False)
2023-02-16 17:32:22,652:INFO:create_model() successfully completed......................................
2023-02-16 17:32:22,813:INFO:SubProcess create_model() end ==================================
2023-02-16 17:32:22,814:INFO:Creating metrics dataframe
2023-02-16 17:32:22,847:INFO:Initializing Quadratic Discriminant Analysis
2023-02-16 17:32:22,847:INFO:Total runtime is 1.4960607926050822 minutes
2023-02-16 17:32:22,853:INFO:SubProcess create_model() called ==================================
2023-02-16 17:32:22,853:INFO:Initializing create_model()
2023-02-16 17:32:22,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:32:22,854:INFO:Checking exceptions
2023-02-16 17:32:22,854:INFO:Importing libraries
2023-02-16 17:32:22,854:INFO:Copying training dataset
2023-02-16 17:32:22,894:INFO:Defining folds
2023-02-16 17:32:22,894:INFO:Declaring metric variables
2023-02-16 17:32:22,898:INFO:Importing untrained model
2023-02-16 17:32:22,904:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-16 17:32:22,915:INFO:Starting cross validation
2023-02-16 17:32:22,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:32:24,643:INFO:Calculating mean and std
2023-02-16 17:32:24,644:INFO:Creating metrics dataframe
2023-02-16 17:32:24,649:INFO:Uploading results into container
2023-02-16 17:32:24,650:INFO:Uploading model into container now
2023-02-16 17:32:24,651:INFO:_master_model_container: 8
2023-02-16 17:32:24,651:INFO:_display_container: 2
2023-02-16 17:32:24,652:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-16 17:32:24,652:INFO:create_model() successfully completed......................................
2023-02-16 17:32:24,793:INFO:SubProcess create_model() end ==================================
2023-02-16 17:32:24,793:INFO:Creating metrics dataframe
2023-02-16 17:32:24,804:INFO:Initializing Ada Boost Classifier
2023-02-16 17:32:24,804:INFO:Total runtime is 1.5286769032478333 minutes
2023-02-16 17:32:24,810:INFO:SubProcess create_model() called ==================================
2023-02-16 17:32:24,811:INFO:Initializing create_model()
2023-02-16 17:32:24,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:32:24,812:INFO:Checking exceptions
2023-02-16 17:32:24,812:INFO:Importing libraries
2023-02-16 17:32:24,812:INFO:Copying training dataset
2023-02-16 17:32:24,851:INFO:Defining folds
2023-02-16 17:32:24,851:INFO:Declaring metric variables
2023-02-16 17:32:24,856:INFO:Importing untrained model
2023-02-16 17:32:24,863:INFO:Ada Boost Classifier Imported successfully
2023-02-16 17:32:24,872:INFO:Starting cross validation
2023-02-16 17:32:24,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:32:41,621:INFO:Calculating mean and std
2023-02-16 17:32:41,622:INFO:Creating metrics dataframe
2023-02-16 17:32:41,629:INFO:Uploading results into container
2023-02-16 17:32:41,630:INFO:Uploading model into container now
2023-02-16 17:32:41,631:INFO:_master_model_container: 9
2023-02-16 17:32:41,631:INFO:_display_container: 2
2023-02-16 17:32:41,631:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3330)
2023-02-16 17:32:41,631:INFO:create_model() successfully completed......................................
2023-02-16 17:32:41,794:INFO:SubProcess create_model() end ==================================
2023-02-16 17:32:41,794:INFO:Creating metrics dataframe
2023-02-16 17:32:41,810:INFO:Initializing Gradient Boosting Classifier
2023-02-16 17:32:41,810:INFO:Total runtime is 1.8121054569880168 minutes
2023-02-16 17:32:41,813:INFO:SubProcess create_model() called ==================================
2023-02-16 17:32:41,814:INFO:Initializing create_model()
2023-02-16 17:32:41,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:32:41,814:INFO:Checking exceptions
2023-02-16 17:32:41,814:INFO:Importing libraries
2023-02-16 17:32:41,814:INFO:Copying training dataset
2023-02-16 17:32:41,856:INFO:Defining folds
2023-02-16 17:32:41,856:INFO:Declaring metric variables
2023-02-16 17:32:41,864:INFO:Importing untrained model
2023-02-16 17:32:41,869:INFO:Gradient Boosting Classifier Imported successfully
2023-02-16 17:32:41,879:INFO:Starting cross validation
2023-02-16 17:32:41,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:33:34,961:INFO:Calculating mean and std
2023-02-16 17:33:34,961:INFO:Creating metrics dataframe
2023-02-16 17:33:34,967:INFO:Uploading results into container
2023-02-16 17:33:34,968:INFO:Uploading model into container now
2023-02-16 17:33:34,968:INFO:_master_model_container: 10
2023-02-16 17:33:34,968:INFO:_display_container: 2
2023-02-16 17:33:34,970:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3330, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-16 17:33:34,970:INFO:create_model() successfully completed......................................
2023-02-16 17:33:35,120:INFO:SubProcess create_model() end ==================================
2023-02-16 17:33:35,120:INFO:Creating metrics dataframe
2023-02-16 17:33:35,135:INFO:Initializing Linear Discriminant Analysis
2023-02-16 17:33:35,135:INFO:Total runtime is 2.7008628606796266 minutes
2023-02-16 17:33:35,139:INFO:SubProcess create_model() called ==================================
2023-02-16 17:33:35,139:INFO:Initializing create_model()
2023-02-16 17:33:35,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:33:35,139:INFO:Checking exceptions
2023-02-16 17:33:35,140:INFO:Importing libraries
2023-02-16 17:33:35,140:INFO:Copying training dataset
2023-02-16 17:33:35,180:INFO:Defining folds
2023-02-16 17:33:35,180:INFO:Declaring metric variables
2023-02-16 17:33:35,186:INFO:Importing untrained model
2023-02-16 17:33:35,193:INFO:Linear Discriminant Analysis Imported successfully
2023-02-16 17:33:35,202:INFO:Starting cross validation
2023-02-16 17:33:35,203:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:33:36,187:INFO:Calculating mean and std
2023-02-16 17:33:36,189:INFO:Creating metrics dataframe
2023-02-16 17:33:36,195:INFO:Uploading results into container
2023-02-16 17:33:36,196:INFO:Uploading model into container now
2023-02-16 17:33:36,196:INFO:_master_model_container: 11
2023-02-16 17:33:36,196:INFO:_display_container: 2
2023-02-16 17:33:36,196:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-16 17:33:36,196:INFO:create_model() successfully completed......................................
2023-02-16 17:33:36,479:INFO:SubProcess create_model() end ==================================
2023-02-16 17:33:36,479:INFO:Creating metrics dataframe
2023-02-16 17:33:36,496:INFO:Initializing Extra Trees Classifier
2023-02-16 17:33:36,496:INFO:Total runtime is 2.7235416372617087 minutes
2023-02-16 17:33:36,500:INFO:SubProcess create_model() called ==================================
2023-02-16 17:33:36,500:INFO:Initializing create_model()
2023-02-16 17:33:36,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:33:36,500:INFO:Checking exceptions
2023-02-16 17:33:36,500:INFO:Importing libraries
2023-02-16 17:33:36,501:INFO:Copying training dataset
2023-02-16 17:33:36,543:INFO:Defining folds
2023-02-16 17:33:36,543:INFO:Declaring metric variables
2023-02-16 17:33:36,547:INFO:Importing untrained model
2023-02-16 17:33:36,552:INFO:Extra Trees Classifier Imported successfully
2023-02-16 17:33:36,561:INFO:Starting cross validation
2023-02-16 17:33:36,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:33:47,428:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 17:33:47,430:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 17:33:47,564:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 17:33:58,553:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 17:34:07,485:INFO:Calculating mean and std
2023-02-16 17:34:07,487:INFO:Creating metrics dataframe
2023-02-16 17:34:07,493:INFO:Uploading results into container
2023-02-16 17:34:07,493:INFO:Uploading model into container now
2023-02-16 17:34:07,494:INFO:_master_model_container: 12
2023-02-16 17:34:07,494:INFO:_display_container: 2
2023-02-16 17:34:07,495:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3330, verbose=0, warm_start=False)
2023-02-16 17:34:07,495:INFO:create_model() successfully completed......................................
2023-02-16 17:34:07,672:INFO:SubProcess create_model() end ==================================
2023-02-16 17:34:07,673:INFO:Creating metrics dataframe
2023-02-16 17:34:07,721:INFO:Initializing Extreme Gradient Boosting
2023-02-16 17:34:07,721:INFO:Total runtime is 3.243968987464905 minutes
2023-02-16 17:34:07,727:INFO:SubProcess create_model() called ==================================
2023-02-16 17:34:07,727:INFO:Initializing create_model()
2023-02-16 17:34:07,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:34:07,728:INFO:Checking exceptions
2023-02-16 17:34:07,728:INFO:Importing libraries
2023-02-16 17:34:07,728:INFO:Copying training dataset
2023-02-16 17:34:07,769:INFO:Defining folds
2023-02-16 17:34:07,770:INFO:Declaring metric variables
2023-02-16 17:34:07,776:INFO:Importing untrained model
2023-02-16 17:34:07,781:INFO:Extreme Gradient Boosting Imported successfully
2023-02-16 17:34:07,789:INFO:Starting cross validation
2023-02-16 17:34:07,790:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:34:08,188:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-16 17:34:08,267:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\queues.py", line 125, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 211, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 204, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py", line 446, in __call__
    for dumped_filename in dump(a, filename):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 553, in dump
    NumpyPickler(f, protocol=protocol).dump(value)
  File "c:\Users\pedro\anaconda3\lib\pickle.py", line 487, in dump
    self.save(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 352, in save
    wrapper.write_array(obj, self)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 134, in write_array
    pickler.file_handle.write(chunk.tobytes('C'))
OSError: [Errno 28] No space left on device
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 446, in result
    return self.__get_result()
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2023-02-16 17:34:08,267:INFO:Initializing create_model()
2023-02-16 17:34:08,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:34:08,267:INFO:Checking exceptions
2023-02-16 17:34:08,268:INFO:Importing libraries
2023-02-16 17:34:08,268:INFO:Copying training dataset
2023-02-16 17:34:08,310:INFO:Defining folds
2023-02-16 17:34:08,310:INFO:Declaring metric variables
2023-02-16 17:34:08,314:INFO:Importing untrained model
2023-02-16 17:34:08,321:INFO:Extreme Gradient Boosting Imported successfully
2023-02-16 17:34:08,331:INFO:Starting cross validation
2023-02-16 17:34:08,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:34:08,485:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2023-02-16 17:34:08,486:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\queues.py", line 125, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 211, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 204, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py", line 446, in __call__
    for dumped_filename in dump(a, filename):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 553, in dump
    NumpyPickler(f, protocol=protocol).dump(value)
  File "c:\Users\pedro\anaconda3\lib\pickle.py", line 487, in dump
    self.save(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 352, in save
    wrapper.write_array(obj, self)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 134, in write_array
    pickler.file_handle.write(chunk.tobytes('C'))
OSError: [Errno 28] No space left on device
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 446, in result
    return self.__get_result()
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2023-02-16 17:34:08,486:INFO:Initializing Light Gradient Boosting Machine
2023-02-16 17:34:08,486:INFO:Total runtime is 3.256718981266022 minutes
2023-02-16 17:34:08,492:INFO:SubProcess create_model() called ==================================
2023-02-16 17:34:08,492:INFO:Initializing create_model()
2023-02-16 17:34:08,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:34:08,493:INFO:Checking exceptions
2023-02-16 17:34:08,493:INFO:Importing libraries
2023-02-16 17:34:08,493:INFO:Copying training dataset
2023-02-16 17:34:08,538:INFO:Defining folds
2023-02-16 17:34:08,538:INFO:Declaring metric variables
2023-02-16 17:34:08,544:INFO:Importing untrained model
2023-02-16 17:34:08,549:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-16 17:34:08,560:INFO:Starting cross validation
2023-02-16 17:34:08,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:34:08,725:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-16 17:34:08,725:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\queues.py", line 125, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 211, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 204, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py", line 446, in __call__
    for dumped_filename in dump(a, filename):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 553, in dump
    NumpyPickler(f, protocol=protocol).dump(value)
  File "c:\Users\pedro\anaconda3\lib\pickle.py", line 487, in dump
    self.save(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 352, in save
    wrapper.write_array(obj, self)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 134, in write_array
    pickler.file_handle.write(chunk.tobytes('C'))
OSError: [Errno 28] No space left on device
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 446, in result
    return self.__get_result()
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2023-02-16 17:34:08,726:INFO:Initializing create_model()
2023-02-16 17:34:08,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:34:08,726:INFO:Checking exceptions
2023-02-16 17:34:08,726:INFO:Importing libraries
2023-02-16 17:34:08,726:INFO:Copying training dataset
2023-02-16 17:34:08,769:INFO:Defining folds
2023-02-16 17:34:08,769:INFO:Declaring metric variables
2023-02-16 17:34:08,773:INFO:Importing untrained model
2023-02-16 17:34:08,780:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-16 17:34:08,789:INFO:Starting cross validation
2023-02-16 17:34:08,790:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:34:08,944:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2023-02-16 17:34:08,945:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\queues.py", line 125, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 211, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 204, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py", line 446, in __call__
    for dumped_filename in dump(a, filename):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 553, in dump
    NumpyPickler(f, protocol=protocol).dump(value)
  File "c:\Users\pedro\anaconda3\lib\pickle.py", line 487, in dump
    self.save(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 352, in save
    wrapper.write_array(obj, self)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 134, in write_array
    pickler.file_handle.write(chunk.tobytes('C'))
OSError: [Errno 28] No space left on device
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 446, in result
    return self.__get_result()
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2023-02-16 17:34:08,945:INFO:Initializing Dummy Classifier
2023-02-16 17:34:08,946:INFO:Total runtime is 3.2643540620803835 minutes
2023-02-16 17:34:08,950:INFO:SubProcess create_model() called ==================================
2023-02-16 17:34:08,950:INFO:Initializing create_model()
2023-02-16 17:34:08,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:34:08,950:INFO:Checking exceptions
2023-02-16 17:34:08,951:INFO:Importing libraries
2023-02-16 17:34:08,951:INFO:Copying training dataset
2023-02-16 17:34:08,997:INFO:Defining folds
2023-02-16 17:34:08,997:INFO:Declaring metric variables
2023-02-16 17:34:09,003:INFO:Importing untrained model
2023-02-16 17:34:09,009:INFO:Dummy Classifier Imported successfully
2023-02-16 17:34:09,020:INFO:Starting cross validation
2023-02-16 17:34:09,021:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:34:09,169:WARNING:create_model() for dummy raised an exception or returned all 0.0, trying without fit_kwargs:
2023-02-16 17:34:09,169:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\queues.py", line 125, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 211, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 204, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py", line 446, in __call__
    for dumped_filename in dump(a, filename):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 553, in dump
    NumpyPickler(f, protocol=protocol).dump(value)
  File "c:\Users\pedro\anaconda3\lib\pickle.py", line 487, in dump
    self.save(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 352, in save
    wrapper.write_array(obj, self)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 134, in write_array
    pickler.file_handle.write(chunk.tobytes('C'))
OSError: [Errno 28] No space left on device
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 446, in result
    return self.__get_result()
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2023-02-16 17:34:09,170:INFO:Initializing create_model()
2023-02-16 17:34:09,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7922F790>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:34:09,170:INFO:Checking exceptions
2023-02-16 17:34:09,170:INFO:Importing libraries
2023-02-16 17:34:09,170:INFO:Copying training dataset
2023-02-16 17:34:09,213:INFO:Defining folds
2023-02-16 17:34:09,214:INFO:Declaring metric variables
2023-02-16 17:34:09,218:INFO:Importing untrained model
2023-02-16 17:34:09,230:INFO:Dummy Classifier Imported successfully
2023-02-16 17:34:09,238:INFO:Starting cross validation
2023-02-16 17:34:09,239:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 17:34:09,421:ERROR:create_model() for dummy raised an exception or returned all 0.0:
2023-02-16 17:34:09,421:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\queues.py", line 125, in _feed
    obj_ = dumps(obj, reducers=reducers)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 211, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\loky\backend\reduction.py", line 204, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\externals\cloudpickle\cloudpickle_fast.py", line 632, in dump
    return Pickler.dump(self, obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py", line 446, in __call__
    for dumped_filename in dump(a, filename):
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 553, in dump
    NumpyPickler(f, protocol=protocol).dump(value)
  File "c:\Users\pedro\anaconda3\lib\pickle.py", line 487, in dump
    self.save(obj)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 352, in save
    wrapper.write_array(obj, self)
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\numpy_pickle.py", line 134, in write_array
    pickler.file_handle.write(chunk.tobytes('C'))
OSError: [Errno 28] No space left on device
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "c:\Users\pedro\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 446, in result
    return self.__get_result()
  File "c:\Users\pedro\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
_pickle.PicklingError: Could not pickle the task to send it to the workers.

2023-02-16 17:34:09,435:INFO:Initializing create_model()
2023-02-16 17:34:09,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:34:09,435:INFO:Checking exceptions
2023-02-16 17:34:09,439:INFO:Importing libraries
2023-02-16 17:34:09,439:INFO:Copying training dataset
2023-02-16 17:34:09,488:INFO:Defining folds
2023-02-16 17:34:09,488:INFO:Declaring metric variables
2023-02-16 17:34:09,488:INFO:Importing untrained model
2023-02-16 17:34:09,488:INFO:Declaring custom model
2023-02-16 17:34:09,489:INFO:Random Forest Classifier Imported successfully
2023-02-16 17:34:09,489:INFO:Cross validation set to False
2023-02-16 17:34:09,491:INFO:Fitting Model
2023-02-16 17:34:16,027:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False)
2023-02-16 17:34:16,027:INFO:create_model() successfully completed......................................
2023-02-16 17:34:16,210:INFO:Initializing create_model()
2023-02-16 17:34:16,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3330, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:34:16,210:INFO:Checking exceptions
2023-02-16 17:34:16,212:INFO:Importing libraries
2023-02-16 17:34:16,212:INFO:Copying training dataset
2023-02-16 17:34:16,259:INFO:Defining folds
2023-02-16 17:34:16,259:INFO:Declaring metric variables
2023-02-16 17:34:16,259:INFO:Importing untrained model
2023-02-16 17:34:16,259:INFO:Declaring custom model
2023-02-16 17:34:16,260:INFO:Extra Trees Classifier Imported successfully
2023-02-16 17:34:16,261:INFO:Cross validation set to False
2023-02-16 17:34:16,261:INFO:Fitting Model
2023-02-16 17:34:19,713:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3330, verbose=0, warm_start=False)
2023-02-16 17:34:19,713:INFO:create_model() successfully completed......................................
2023-02-16 17:34:19,887:INFO:Initializing create_model()
2023-02-16 17:34:19,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3330, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 17:34:19,888:INFO:Checking exceptions
2023-02-16 17:34:19,896:INFO:Importing libraries
2023-02-16 17:34:19,896:INFO:Copying training dataset
2023-02-16 17:34:19,950:INFO:Defining folds
2023-02-16 17:34:19,950:INFO:Declaring metric variables
2023-02-16 17:34:19,951:INFO:Importing untrained model
2023-02-16 17:34:19,951:INFO:Declaring custom model
2023-02-16 17:34:19,951:INFO:Decision Tree Classifier Imported successfully
2023-02-16 17:34:19,952:INFO:Cross validation set to False
2023-02-16 17:34:19,952:INFO:Fitting Model
2023-02-16 17:34:20,740:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3330, splitter='best')
2023-02-16 17:34:20,740:INFO:create_model() successfully completed......................................
2023-02-16 17:34:20,939:INFO:_master_model_container: 12
2023-02-16 17:34:20,939:INFO:_display_container: 2
2023-02-16 17:34:20,941:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3330, verbose=0, warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3330, splitter='best')]
2023-02-16 17:34:20,941:INFO:compare_models() successfully completed......................................
2023-02-16 17:34:21,464:INFO:Initializing tune_model()
2023-02-16 17:34:21,464:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>)
2023-02-16 17:34:21,464:INFO:Checking exceptions
2023-02-16 17:34:21,465:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-16 17:34:21,550:INFO:Copying training dataset
2023-02-16 17:34:21,578:INFO:Checking base model
2023-02-16 17:34:21,578:INFO:Base model : Random Forest Classifier
2023-02-16 17:34:21,583:INFO:Declaring metric variables
2023-02-16 17:34:21,588:INFO:Defining Hyperparameters
2023-02-16 17:34:21,792:INFO:Tuning with n_jobs=-1
2023-02-16 17:34:21,795:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 17:34:21,795:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 17:34:21,797:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-02-16 17:34:21,797:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-16 17:34:22,058:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-16 17:34:22,082:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-16 17:35:05,796:INFO:Initializing tune_model()
2023-02-16 17:35:05,796:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>)
2023-02-16 17:35:05,796:INFO:Checking exceptions
2023-02-16 17:35:05,796:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-16 17:35:05,834:INFO:Copying training dataset
2023-02-16 17:35:05,862:INFO:Checking base model
2023-02-16 17:35:05,862:INFO:Base model : Random Forest Classifier
2023-02-16 17:35:05,878:INFO:Declaring metric variables
2023-02-16 17:35:05,885:INFO:Defining Hyperparameters
2023-02-16 17:35:06,204:INFO:Tuning with n_jobs=-1
2023-02-16 17:35:06,204:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 17:35:06,205:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 17:35:06,205:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-02-16 17:35:06,206:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-16 17:35:06,206:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-16 17:35:06,241:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-16 17:53:10,009:INFO:Initializing tune_model()
2023-02-16 17:53:10,009:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>)
2023-02-16 17:53:10,012:INFO:Checking exceptions
2023-02-16 17:53:10,012:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-16 17:53:10,075:INFO:Copying training dataset
2023-02-16 17:53:10,152:INFO:Checking base model
2023-02-16 17:53:10,153:INFO:Base model : Random Forest Classifier
2023-02-16 17:53:10,202:INFO:Declaring metric variables
2023-02-16 17:53:10,215:INFO:Defining Hyperparameters
2023-02-16 17:53:10,439:INFO:Tuning with n_jobs=-1
2023-02-16 17:53:10,439:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 17:53:10,439:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 17:53:10,439:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-02-16 17:53:10,439:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-16 17:53:10,439:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-16 17:53:10,449:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-16 18:01:49,208:INFO:best_params: {'actual_estimator__n_estimators': 95, 'actual_estimator__max_depth': 11, 'actual_estimator__min_impurity_decrease': 0.014474122480774974, 'actual_estimator__max_features': 0.4755096174186535, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__bootstrap': False, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample'}
2023-02-16 18:01:49,208:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-16 18:01:49,209:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-16 18:01:49,209:INFO:Hyperparameter search completed
2023-02-16 18:01:49,210:INFO:SubProcess create_model() called ==================================
2023-02-16 18:01:49,210:INFO:Initializing create_model()
2023-02-16 18:01:49,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7C21AD90>, model_only=True, return_train_score=False, kwargs={'n_estimators': 95, 'max_depth': 11, 'min_impurity_decrease': 0.014474122480774974, 'max_features': 0.4755096174186535, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced_subsample'})
2023-02-16 18:01:49,211:INFO:Checking exceptions
2023-02-16 18:01:49,211:INFO:Importing libraries
2023-02-16 18:01:49,211:INFO:Copying training dataset
2023-02-16 18:01:49,251:INFO:Defining folds
2023-02-16 18:01:49,251:INFO:Declaring metric variables
2023-02-16 18:01:49,257:INFO:Importing untrained model
2023-02-16 18:01:49,257:INFO:Declaring custom model
2023-02-16 18:01:49,264:INFO:Random Forest Classifier Imported successfully
2023-02-16 18:01:49,278:INFO:Starting cross validation
2023-02-16 18:01:49,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:01:53,821:INFO:Calculating mean and std
2023-02-16 18:01:53,823:INFO:Creating metrics dataframe
2023-02-16 18:01:53,831:INFO:Finalizing model
2023-02-16 18:01:57,047:INFO:Uploading results into container
2023-02-16 18:01:57,048:INFO:Uploading model into container now
2023-02-16 18:01:57,048:INFO:_master_model_container: 13
2023-02-16 18:01:57,048:INFO:_display_container: 3
2023-02-16 18:01:57,073:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features=0.4755096174186535,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.014474122480774974,
                       min_samples_leaf=2, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, n_estimators=95, n_jobs=-1,
                       oob_score=False, random_state=3330, verbose=0,
                       warm_start=False)
2023-02-16 18:01:57,073:INFO:create_model() successfully completed......................................
2023-02-16 18:01:57,237:INFO:SubProcess create_model() end ==================================
2023-02-16 18:01:57,237:INFO:choose_better activated
2023-02-16 18:01:57,243:INFO:SubProcess create_model() called ==================================
2023-02-16 18:01:57,244:INFO:Initializing create_model()
2023-02-16 18:01:57,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:01:57,244:INFO:Checking exceptions
2023-02-16 18:01:57,246:INFO:Importing libraries
2023-02-16 18:01:57,246:INFO:Copying training dataset
2023-02-16 18:01:57,285:INFO:Defining folds
2023-02-16 18:01:57,285:INFO:Declaring metric variables
2023-02-16 18:01:57,285:INFO:Importing untrained model
2023-02-16 18:01:57,285:INFO:Declaring custom model
2023-02-16 18:01:57,286:INFO:Random Forest Classifier Imported successfully
2023-02-16 18:01:57,287:INFO:Starting cross validation
2023-02-16 18:01:57,287:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:02:04,012:INFO:Calculating mean and std
2023-02-16 18:02:04,013:INFO:Creating metrics dataframe
2023-02-16 18:02:04,015:INFO:Finalizing model
2023-02-16 18:02:09,571:INFO:Uploading results into container
2023-02-16 18:02:09,571:INFO:Uploading model into container now
2023-02-16 18:02:09,574:INFO:_master_model_container: 14
2023-02-16 18:02:09,574:INFO:_display_container: 4
2023-02-16 18:02:09,574:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False)
2023-02-16 18:02:09,574:INFO:create_model() successfully completed......................................
2023-02-16 18:02:09,762:INFO:SubProcess create_model() end ==================================
2023-02-16 18:02:09,763:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False) result for Recall is 0.926
2023-02-16 18:02:09,782:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features=0.4755096174186535,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.014474122480774974,
                       min_samples_leaf=2, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, n_estimators=95, n_jobs=-1,
                       oob_score=False, random_state=3330, verbose=0,
                       warm_start=False) result for Recall is 0.8652
2023-02-16 18:02:09,783:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False) is best model
2023-02-16 18:02:09,783:INFO:choose_better completed
2023-02-16 18:02:09,783:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-16 18:02:09,818:INFO:_master_model_container: 14
2023-02-16 18:02:09,818:INFO:_display_container: 3
2023-02-16 18:02:09,819:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3330, verbose=0, warm_start=False)
2023-02-16 18:02:09,819:INFO:tune_model() successfully completed......................................
2023-02-16 18:02:09,998:INFO:Initializing tune_model()
2023-02-16 18:02:09,998:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3330, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>)
2023-02-16 18:02:09,998:INFO:Checking exceptions
2023-02-16 18:02:09,998:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-16 18:02:10,035:INFO:Copying training dataset
2023-02-16 18:02:10,066:INFO:Checking base model
2023-02-16 18:02:10,066:INFO:Base model : Extra Trees Classifier
2023-02-16 18:02:10,071:INFO:Declaring metric variables
2023-02-16 18:02:10,075:INFO:Defining Hyperparameters
2023-02-16 18:02:10,309:INFO:Tuning with n_jobs=-1
2023-02-16 18:02:10,316:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 18:02:10,316:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 18:02:10,317:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-02-16 18:02:10,317:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-16 18:02:10,317:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-16 18:02:10,323:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-16 18:02:52,662:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:03:06,696:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:04:34,238:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:04:35,744:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:05:38,350:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:06:43,203:INFO:best_params: {'actual_estimator__n_estimators': 204, 'actual_estimator__max_depth': 11, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__max_features': 0.8879393966568535, 'actual_estimator__min_impurity_decrease': 2.6631771169308267e-06, 'actual_estimator__criterion': 'entropy', 'actual_estimator__bootstrap': True, 'actual_estimator__class_weight': {}}
2023-02-16 18:06:43,204:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-16 18:06:43,204:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-16 18:06:43,206:INFO:Hyperparameter search completed
2023-02-16 18:06:43,206:INFO:SubProcess create_model() called ==================================
2023-02-16 18:06:43,207:INFO:Initializing create_model()
2023-02-16 18:06:43,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3330, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B5D61A5E0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 204, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 0.8879393966568535, 'min_impurity_decrease': 2.6631771169308267e-06, 'criterion': 'entropy', 'bootstrap': True, 'class_weight': {}})
2023-02-16 18:06:43,207:INFO:Checking exceptions
2023-02-16 18:06:43,208:INFO:Importing libraries
2023-02-16 18:06:43,208:INFO:Copying training dataset
2023-02-16 18:06:43,245:INFO:Defining folds
2023-02-16 18:06:43,245:INFO:Declaring metric variables
2023-02-16 18:06:43,248:INFO:Importing untrained model
2023-02-16 18:06:43,248:INFO:Declaring custom model
2023-02-16 18:06:43,256:INFO:Extra Trees Classifier Imported successfully
2023-02-16 18:06:43,266:INFO:Starting cross validation
2023-02-16 18:06:43,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:06:47,181:INFO:Calculating mean and std
2023-02-16 18:06:47,183:INFO:Creating metrics dataframe
2023-02-16 18:06:47,191:INFO:Finalizing model
2023-02-16 18:06:51,484:INFO:Uploading results into container
2023-02-16 18:06:51,487:INFO:Uploading model into container now
2023-02-16 18:06:51,487:INFO:_master_model_container: 15
2023-02-16 18:06:51,487:INFO:_display_container: 4
2023-02-16 18:06:51,488:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='entropy', max_depth=11,
                     max_features=0.8879393966568535, max_leaf_nodes=None,
                     max_samples=None,
                     min_impurity_decrease=2.6631771169308267e-06,
                     min_samples_leaf=5, min_samples_split=5,
                     min_weight_fraction_leaf=0.0, n_estimators=204, n_jobs=-1,
                     oob_score=False, random_state=3330, verbose=0,
                     warm_start=False)
2023-02-16 18:06:51,488:INFO:create_model() successfully completed......................................
2023-02-16 18:06:51,665:INFO:SubProcess create_model() end ==================================
2023-02-16 18:06:51,665:INFO:choose_better activated
2023-02-16 18:06:51,672:INFO:SubProcess create_model() called ==================================
2023-02-16 18:06:51,673:INFO:Initializing create_model()
2023-02-16 18:06:51,673:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3330, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:06:51,673:INFO:Checking exceptions
2023-02-16 18:06:51,675:INFO:Importing libraries
2023-02-16 18:06:51,676:INFO:Copying training dataset
2023-02-16 18:06:51,717:INFO:Defining folds
2023-02-16 18:06:51,717:INFO:Declaring metric variables
2023-02-16 18:06:51,718:INFO:Importing untrained model
2023-02-16 18:06:51,718:INFO:Declaring custom model
2023-02-16 18:06:51,720:INFO:Extra Trees Classifier Imported successfully
2023-02-16 18:06:51,721:INFO:Starting cross validation
2023-02-16 18:06:51,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:07:56,088:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 10.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:07:56,210:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 10.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:07:58,122:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 26.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:07:58,864:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 11.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:08:12,876:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:08:15,027:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:08:15,028:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 3.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:08:20,146:INFO:Calculating mean and std
2023-02-16 18:08:20,147:INFO:Creating metrics dataframe
2023-02-16 18:08:20,149:INFO:Finalizing model
2023-02-16 18:08:22,953:INFO:Uploading results into container
2023-02-16 18:08:22,954:INFO:Uploading model into container now
2023-02-16 18:08:22,955:INFO:_master_model_container: 16
2023-02-16 18:08:22,955:INFO:_display_container: 5
2023-02-16 18:08:22,955:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3330, verbose=0, warm_start=False)
2023-02-16 18:08:22,955:INFO:create_model() successfully completed......................................
2023-02-16 18:08:23,131:INFO:SubProcess create_model() end ==================================
2023-02-16 18:08:23,131:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3330, verbose=0, warm_start=False) result for Recall is 0.9228
2023-02-16 18:08:23,132:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='entropy', max_depth=11,
                     max_features=0.8879393966568535, max_leaf_nodes=None,
                     max_samples=None,
                     min_impurity_decrease=2.6631771169308267e-06,
                     min_samples_leaf=5, min_samples_split=5,
                     min_weight_fraction_leaf=0.0, n_estimators=204, n_jobs=-1,
                     oob_score=False, random_state=3330, verbose=0,
                     warm_start=False) result for Recall is 0.8307
2023-02-16 18:08:23,132:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3330, verbose=0, warm_start=False) is best model
2023-02-16 18:08:23,133:INFO:choose_better completed
2023-02-16 18:08:23,133:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-16 18:08:23,534:INFO:_master_model_container: 16
2023-02-16 18:08:23,534:INFO:_display_container: 4
2023-02-16 18:08:23,536:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3330, verbose=0, warm_start=False)
2023-02-16 18:08:23,536:INFO:tune_model() successfully completed......................................
2023-02-16 18:08:23,721:INFO:Initializing tune_model()
2023-02-16 18:08:23,721:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3330, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>)
2023-02-16 18:08:23,721:INFO:Checking exceptions
2023-02-16 18:08:23,721:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-16 18:08:23,766:INFO:Copying training dataset
2023-02-16 18:08:23,801:INFO:Checking base model
2023-02-16 18:08:23,801:INFO:Base model : Decision Tree Classifier
2023-02-16 18:08:23,809:INFO:Declaring metric variables
2023-02-16 18:08:23,815:INFO:Defining Hyperparameters
2023-02-16 18:08:24,042:INFO:Tuning with n_jobs=-1
2023-02-16 18:08:24,048:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 18:08:24,048:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 18:08:24,050:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-16 18:08:24,050:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-16 18:08:24,059:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-16 18:08:35,595:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:08:37,763:INFO:best_params: {'actual_estimator__max_depth': 1, 'actual_estimator__max_features': 0.9192152719692316, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_impurity_decrease': 1.764889230890383e-09, 'actual_estimator__criterion': 'entropy'}
2023-02-16 18:08:37,763:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-16 18:08:37,763:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-16 18:08:37,764:INFO:Hyperparameter search completed
2023-02-16 18:08:37,765:INFO:SubProcess create_model() called ==================================
2023-02-16 18:08:37,765:INFO:Initializing create_model()
2023-02-16 18:08:37,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B78F52670>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3330, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B7C21AD90>, model_only=True, return_train_score=False, kwargs={'max_depth': 1, 'max_features': 0.9192152719692316, 'min_samples_leaf': 5, 'min_samples_split': 2, 'min_impurity_decrease': 1.764889230890383e-09, 'criterion': 'entropy'})
2023-02-16 18:08:37,766:INFO:Checking exceptions
2023-02-16 18:08:37,766:INFO:Importing libraries
2023-02-16 18:08:37,767:INFO:Copying training dataset
2023-02-16 18:08:37,808:INFO:Defining folds
2023-02-16 18:08:37,808:INFO:Declaring metric variables
2023-02-16 18:08:37,812:INFO:Importing untrained model
2023-02-16 18:08:37,813:INFO:Declaring custom model
2023-02-16 18:08:37,819:INFO:Decision Tree Classifier Imported successfully
2023-02-16 18:08:37,830:INFO:Starting cross validation
2023-02-16 18:08:37,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:54:07,785:INFO:PyCaret ClassificationExperiment
2023-02-16 18:54:07,804:INFO:Logging name: clf-default-name
2023-02-16 18:54:07,826:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-16 18:54:07,826:INFO:version 3.0.0.rc9
2023-02-16 18:54:07,826:INFO:Initializing setup()
2023-02-16 18:54:07,826:INFO:self.USI: e0b7
2023-02-16 18:54:07,843:INFO:self._variable_keys: {'y', 'idx', 'memory', 'fix_imbalance', 'gpu_n_jobs_param', 'seed', 'USI', 'fold_shuffle_param', 'y_test', 'X', 'gpu_param', '_available_plots', 'fold_generator', 'exp_id', 'n_jobs_param', 'y_train', 'data', 'logging_param', 'X_train', 'target_param', 'pipeline', '_ml_usecase', 'html_param', 'log_plots_param', 'X_test', 'is_multiclass', 'exp_name_log', 'fold_groups_param'}
2023-02-16 18:54:07,861:INFO:Checking environment
2023-02-16 18:54:07,862:INFO:python_version: 3.9.15
2023-02-16 18:54:07,862:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-16 18:54:07,863:INFO:machine: AMD64
2023-02-16 18:54:07,864:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-16 18:54:07,876:INFO:Memory: svmem(total=8469581824, available=1246515200, percent=85.3, used=7223066624, free=1246515200)
2023-02-16 18:54:07,876:INFO:Physical Core: 4
2023-02-16 18:54:07,876:INFO:Logical Core: 4
2023-02-16 18:54:07,876:INFO:Checking libraries
2023-02-16 18:54:07,903:INFO:System:
2023-02-16 18:54:07,903:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-16 18:54:07,903:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-16 18:54:07,903:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-16 18:54:07,903:INFO:PyCaret required dependencies:
2023-02-16 18:54:07,907:INFO:                 pip: 22.3.1
2023-02-16 18:54:07,907:INFO:          setuptools: 60.10.0
2023-02-16 18:54:07,907:INFO:             pycaret: 3.0.0rc9
2023-02-16 18:54:07,907:INFO:             IPython: 7.31.1
2023-02-16 18:54:07,907:INFO:          ipywidgets: 7.6.5
2023-02-16 18:54:07,907:INFO:                tqdm: 4.64.1
2023-02-16 18:54:07,907:INFO:               numpy: 1.21.5
2023-02-16 18:54:07,908:INFO:              pandas: 1.4.4
2023-02-16 18:54:07,908:INFO:              jinja2: 2.11.3
2023-02-16 18:54:07,908:INFO:               scipy: 1.9.3
2023-02-16 18:54:07,908:INFO:              joblib: 1.2.0
2023-02-16 18:54:07,908:INFO:             sklearn: 1.0.2
2023-02-16 18:54:07,908:INFO:                pyod: 1.0.7
2023-02-16 18:54:07,908:INFO:            imblearn: 0.10.1
2023-02-16 18:54:07,908:INFO:   category_encoders: 2.6.0
2023-02-16 18:54:07,908:INFO:            lightgbm: 3.3.5
2023-02-16 18:54:07,908:INFO:               numba: 0.56.4
2023-02-16 18:54:07,908:INFO:            requests: 2.28.1
2023-02-16 18:54:07,908:INFO:          matplotlib: 3.6.2
2023-02-16 18:54:07,908:INFO:          scikitplot: 0.3.7
2023-02-16 18:54:07,909:INFO:         yellowbrick: 1.5
2023-02-16 18:54:07,909:INFO:              plotly: 5.9.0
2023-02-16 18:54:07,909:INFO:             kaleido: 0.2.1
2023-02-16 18:54:07,909:INFO:         statsmodels: 0.13.2
2023-02-16 18:54:07,909:INFO:              sktime: 0.16.1
2023-02-16 18:54:07,909:INFO:               tbats: 1.1.2
2023-02-16 18:54:07,909:INFO:            pmdarima: 2.0.2
2023-02-16 18:54:07,909:INFO:              psutil: 5.9.0
2023-02-16 18:54:07,909:INFO:PyCaret optional dependencies:
2023-02-16 18:54:07,909:INFO:                shap: 0.41.0
2023-02-16 18:54:07,909:INFO:           interpret: Not installed
2023-02-16 18:54:07,909:INFO:                umap: Not installed
2023-02-16 18:54:07,909:INFO:    pandas_profiling: 4.0.0
2023-02-16 18:54:07,909:INFO:  explainerdashboard: 0.3.6.2
2023-02-16 18:54:07,909:INFO:             autoviz: 0.1.58
2023-02-16 18:54:07,909:INFO:           fairlearn: Not installed
2023-02-16 18:54:07,910:INFO:             xgboost: 1.7.3
2023-02-16 18:54:07,910:INFO:            catboost: Not installed
2023-02-16 18:54:07,910:INFO:              kmodes: Not installed
2023-02-16 18:54:07,910:INFO:             mlxtend: Not installed
2023-02-16 18:54:07,910:INFO:       statsforecast: Not installed
2023-02-16 18:54:07,910:INFO:        tune_sklearn: Not installed
2023-02-16 18:54:07,910:INFO:                 ray: Not installed
2023-02-16 18:54:07,910:INFO:            hyperopt: Not installed
2023-02-16 18:54:07,910:INFO:              optuna: 2.10.1
2023-02-16 18:54:07,910:INFO:               skopt: Not installed
2023-02-16 18:54:07,910:INFO:              mlflow: Not installed
2023-02-16 18:54:07,910:INFO:              gradio: Not installed
2023-02-16 18:54:07,910:INFO:             fastapi: Not installed
2023-02-16 18:54:07,910:INFO:             uvicorn: Not installed
2023-02-16 18:54:07,910:INFO:              m2cgen: Not installed
2023-02-16 18:54:07,910:INFO:           evidently: Not installed
2023-02-16 18:54:07,910:INFO:               fugue: Not installed
2023-02-16 18:54:07,910:INFO:           streamlit: Not installed
2023-02-16 18:54:07,910:INFO:             prophet: Not installed
2023-02-16 18:54:07,910:INFO:None
2023-02-16 18:54:07,920:INFO:Set up data.
2023-02-16 18:54:08,806:INFO:Set up train/test split.
2023-02-16 18:54:09,428:INFO:Set up index.
2023-02-16 18:54:09,475:INFO:Set up folding strategy.
2023-02-16 18:54:09,486:INFO:Assigning column types.
2023-02-16 18:54:09,541:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-16 18:54:09,744:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 18:54:09,787:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 18:54:09,862:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 18:54:09,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 18:54:10,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 18:54:10,049:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 18:54:10,100:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 18:54:10,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 18:54:10,104:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-16 18:54:10,168:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 18:54:10,214:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 18:54:10,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 18:54:10,284:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 18:54:10,321:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 18:54:10,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 18:54:10,325:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-16 18:54:10,431:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 18:54:10,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 18:54:10,565:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 18:54:10,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 18:54:10,760:INFO:Finished creating preprocessing pipeline.
2023-02-16 18:54:10,767:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2023-02-16 18:54:10,767:INFO:Creating final display dataframe.
2023-02-16 18:54:11,142:INFO:Setup _display_container:                    Description         Value
0                   Session id          3675
1                       Target        target
2                  Target type        Binary
3          Original data shape  (123202, 11)
4       Transformed data shape  (123202, 11)
5  Transformed train set shape   (86241, 11)
6   Transformed test set shape   (36961, 11)
7             Numeric features            10
2023-02-16 18:54:11,415:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 18:54:11,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 18:54:11,554:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 18:54:11,558:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 18:54:11,570:INFO:setup() successfully completed in 4.23s...............
2023-02-16 18:54:11,759:INFO:Initializing compare_models()
2023-02-16 18:54:11,759:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-16 18:54:11,760:INFO:Checking exceptions
2023-02-16 18:54:11,785:INFO:Preparing display monitor
2023-02-16 18:54:11,957:INFO:Initializing Logistic Regression
2023-02-16 18:54:11,958:INFO:Total runtime is 9.457270304361979e-06 minutes
2023-02-16 18:54:11,964:INFO:SubProcess create_model() called ==================================
2023-02-16 18:54:11,986:INFO:Initializing create_model()
2023-02-16 18:54:11,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:54:11,986:INFO:Checking exceptions
2023-02-16 18:54:11,986:INFO:Importing libraries
2023-02-16 18:54:11,986:INFO:Copying training dataset
2023-02-16 18:54:12,053:INFO:Defining folds
2023-02-16 18:54:12,053:INFO:Declaring metric variables
2023-02-16 18:54:12,059:INFO:Importing untrained model
2023-02-16 18:54:12,069:INFO:Logistic Regression Imported successfully
2023-02-16 18:54:12,096:INFO:Starting cross validation
2023-02-16 18:54:12,098:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:54:45,267:INFO:Calculating mean and std
2023-02-16 18:54:45,290:INFO:Creating metrics dataframe
2023-02-16 18:54:45,415:INFO:Uploading results into container
2023-02-16 18:54:45,416:INFO:Uploading model into container now
2023-02-16 18:54:45,429:INFO:_master_model_container: 1
2023-02-16 18:54:45,429:INFO:_display_container: 2
2023-02-16 18:54:45,430:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3675, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-16 18:54:45,430:INFO:create_model() successfully completed......................................
2023-02-16 18:54:53,836:INFO:SubProcess create_model() end ==================================
2023-02-16 18:54:53,836:INFO:Creating metrics dataframe
2023-02-16 18:54:53,990:INFO:Initializing K Neighbors Classifier
2023-02-16 18:54:53,990:INFO:Total runtime is 0.7005385875701904 minutes
2023-02-16 18:54:53,995:INFO:SubProcess create_model() called ==================================
2023-02-16 18:54:53,996:INFO:Initializing create_model()
2023-02-16 18:54:53,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:54:53,996:INFO:Checking exceptions
2023-02-16 18:54:53,996:INFO:Importing libraries
2023-02-16 18:54:53,996:INFO:Copying training dataset
2023-02-16 18:54:54,502:INFO:Defining folds
2023-02-16 18:54:54,502:INFO:Declaring metric variables
2023-02-16 18:54:54,508:INFO:Importing untrained model
2023-02-16 18:54:54,514:INFO:K Neighbors Classifier Imported successfully
2023-02-16 18:54:54,532:INFO:Starting cross validation
2023-02-16 18:54:54,534:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:55:00,735:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 18:55:00,796:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 18:55:00,830:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 18:55:02,764:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 18:55:02,769:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 18:55:02,883:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 18:55:03,199:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 18:55:04,538:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 18:55:04,602:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 18:55:07,895:INFO:Calculating mean and std
2023-02-16 18:55:07,898:INFO:Creating metrics dataframe
2023-02-16 18:55:07,903:INFO:Uploading results into container
2023-02-16 18:55:07,903:INFO:Uploading model into container now
2023-02-16 18:55:07,904:INFO:_master_model_container: 2
2023-02-16 18:55:07,907:INFO:_display_container: 2
2023-02-16 18:55:07,908:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-16 18:55:07,908:INFO:create_model() successfully completed......................................
2023-02-16 18:55:08,160:INFO:SubProcess create_model() end ==================================
2023-02-16 18:55:08,161:INFO:Creating metrics dataframe
2023-02-16 18:55:08,191:INFO:Initializing Naive Bayes
2023-02-16 18:55:08,191:INFO:Total runtime is 0.9372271339098612 minutes
2023-02-16 18:55:08,196:INFO:SubProcess create_model() called ==================================
2023-02-16 18:55:08,197:INFO:Initializing create_model()
2023-02-16 18:55:08,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:55:08,197:INFO:Checking exceptions
2023-02-16 18:55:08,197:INFO:Importing libraries
2023-02-16 18:55:08,197:INFO:Copying training dataset
2023-02-16 18:55:08,258:INFO:Defining folds
2023-02-16 18:55:08,258:INFO:Declaring metric variables
2023-02-16 18:55:08,264:INFO:Importing untrained model
2023-02-16 18:55:08,269:INFO:Naive Bayes Imported successfully
2023-02-16 18:55:08,289:INFO:Starting cross validation
2023-02-16 18:55:08,290:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:55:09,103:INFO:Calculating mean and std
2023-02-16 18:55:09,107:INFO:Creating metrics dataframe
2023-02-16 18:55:09,115:INFO:Uploading results into container
2023-02-16 18:55:09,116:INFO:Uploading model into container now
2023-02-16 18:55:09,117:INFO:_master_model_container: 3
2023-02-16 18:55:09,117:INFO:_display_container: 2
2023-02-16 18:55:09,117:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-16 18:55:09,117:INFO:create_model() successfully completed......................................
2023-02-16 18:55:09,296:INFO:SubProcess create_model() end ==================================
2023-02-16 18:55:09,296:INFO:Creating metrics dataframe
2023-02-16 18:55:09,383:INFO:Initializing Decision Tree Classifier
2023-02-16 18:55:09,383:INFO:Total runtime is 0.9570987582206726 minutes
2023-02-16 18:55:09,387:INFO:SubProcess create_model() called ==================================
2023-02-16 18:55:09,387:INFO:Initializing create_model()
2023-02-16 18:55:09,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:55:09,442:INFO:Checking exceptions
2023-02-16 18:55:09,442:INFO:Importing libraries
2023-02-16 18:55:09,442:INFO:Copying training dataset
2023-02-16 18:55:09,544:INFO:Defining folds
2023-02-16 18:55:09,544:INFO:Declaring metric variables
2023-02-16 18:55:09,549:INFO:Importing untrained model
2023-02-16 18:55:09,554:INFO:Decision Tree Classifier Imported successfully
2023-02-16 18:55:09,565:INFO:Starting cross validation
2023-02-16 18:55:09,566:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:55:15,346:INFO:Calculating mean and std
2023-02-16 18:55:15,348:INFO:Creating metrics dataframe
2023-02-16 18:55:15,361:INFO:Uploading results into container
2023-02-16 18:55:15,362:INFO:Uploading model into container now
2023-02-16 18:55:15,363:INFO:_master_model_container: 4
2023-02-16 18:55:15,363:INFO:_display_container: 2
2023-02-16 18:55:15,364:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3675, splitter='best')
2023-02-16 18:55:15,364:INFO:create_model() successfully completed......................................
2023-02-16 18:55:15,557:INFO:SubProcess create_model() end ==================================
2023-02-16 18:55:15,557:INFO:Creating metrics dataframe
2023-02-16 18:55:15,607:INFO:Initializing SVM - Linear Kernel
2023-02-16 18:55:15,608:INFO:Total runtime is 1.060839871565501 minutes
2023-02-16 18:55:15,614:INFO:SubProcess create_model() called ==================================
2023-02-16 18:55:15,615:INFO:Initializing create_model()
2023-02-16 18:55:15,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:55:15,615:INFO:Checking exceptions
2023-02-16 18:55:15,616:INFO:Importing libraries
2023-02-16 18:55:15,616:INFO:Copying training dataset
2023-02-16 18:55:15,665:INFO:Defining folds
2023-02-16 18:55:15,665:INFO:Declaring metric variables
2023-02-16 18:55:15,671:INFO:Importing untrained model
2023-02-16 18:55:15,677:INFO:SVM - Linear Kernel Imported successfully
2023-02-16 18:55:15,688:INFO:Starting cross validation
2023-02-16 18:55:15,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:55:34,442:INFO:Calculating mean and std
2023-02-16 18:55:34,443:INFO:Creating metrics dataframe
2023-02-16 18:55:34,450:INFO:Uploading results into container
2023-02-16 18:55:34,452:INFO:Uploading model into container now
2023-02-16 18:55:34,452:INFO:_master_model_container: 5
2023-02-16 18:55:34,452:INFO:_display_container: 2
2023-02-16 18:55:34,460:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3675, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-16 18:55:34,460:INFO:create_model() successfully completed......................................
2023-02-16 18:55:34,615:INFO:SubProcess create_model() end ==================================
2023-02-16 18:55:34,615:INFO:Creating metrics dataframe
2023-02-16 18:55:34,782:INFO:Initializing Ridge Classifier
2023-02-16 18:55:34,782:INFO:Total runtime is 1.3804145455360413 minutes
2023-02-16 18:55:34,787:INFO:SubProcess create_model() called ==================================
2023-02-16 18:55:34,788:INFO:Initializing create_model()
2023-02-16 18:55:34,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:55:34,789:INFO:Checking exceptions
2023-02-16 18:55:34,789:INFO:Importing libraries
2023-02-16 18:55:34,789:INFO:Copying training dataset
2023-02-16 18:55:34,845:INFO:Defining folds
2023-02-16 18:55:34,845:INFO:Declaring metric variables
2023-02-16 18:55:34,850:INFO:Importing untrained model
2023-02-16 18:55:34,861:INFO:Ridge Classifier Imported successfully
2023-02-16 18:55:34,870:INFO:Starting cross validation
2023-02-16 18:55:34,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:55:35,457:INFO:Calculating mean and std
2023-02-16 18:55:35,459:INFO:Creating metrics dataframe
2023-02-16 18:55:35,463:INFO:Uploading results into container
2023-02-16 18:55:35,464:INFO:Uploading model into container now
2023-02-16 18:55:35,464:INFO:_master_model_container: 6
2023-02-16 18:55:35,465:INFO:_display_container: 2
2023-02-16 18:55:35,465:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=3675, solver='auto', tol=0.001)
2023-02-16 18:55:35,465:INFO:create_model() successfully completed......................................
2023-02-16 18:55:35,630:INFO:SubProcess create_model() end ==================================
2023-02-16 18:55:35,630:INFO:Creating metrics dataframe
2023-02-16 18:55:35,683:INFO:Initializing Random Forest Classifier
2023-02-16 18:55:35,683:INFO:Total runtime is 1.395433259010315 minutes
2023-02-16 18:55:35,689:INFO:SubProcess create_model() called ==================================
2023-02-16 18:55:35,690:INFO:Initializing create_model()
2023-02-16 18:55:35,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:55:35,691:INFO:Checking exceptions
2023-02-16 18:55:35,691:INFO:Importing libraries
2023-02-16 18:55:35,691:INFO:Copying training dataset
2023-02-16 18:55:35,743:INFO:Defining folds
2023-02-16 18:55:35,744:INFO:Declaring metric variables
2023-02-16 18:55:35,748:INFO:Importing untrained model
2023-02-16 18:55:35,753:INFO:Random Forest Classifier Imported successfully
2023-02-16 18:55:35,762:INFO:Starting cross validation
2023-02-16 18:55:35,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:56:28,769:INFO:Calculating mean and std
2023-02-16 18:56:28,771:INFO:Creating metrics dataframe
2023-02-16 18:56:28,776:INFO:Uploading results into container
2023-02-16 18:56:28,777:INFO:Uploading model into container now
2023-02-16 18:56:28,778:INFO:_master_model_container: 7
2023-02-16 18:56:28,778:INFO:_display_container: 2
2023-02-16 18:56:28,779:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3675, verbose=0, warm_start=False)
2023-02-16 18:56:28,779:INFO:create_model() successfully completed......................................
2023-02-16 18:56:28,933:INFO:SubProcess create_model() end ==================================
2023-02-16 18:56:28,933:INFO:Creating metrics dataframe
2023-02-16 18:56:29,237:INFO:Initializing Quadratic Discriminant Analysis
2023-02-16 18:56:29,238:INFO:Total runtime is 2.2880173643430073 minutes
2023-02-16 18:56:29,246:INFO:SubProcess create_model() called ==================================
2023-02-16 18:56:29,247:INFO:Initializing create_model()
2023-02-16 18:56:29,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:56:29,247:INFO:Checking exceptions
2023-02-16 18:56:29,247:INFO:Importing libraries
2023-02-16 18:56:29,248:INFO:Copying training dataset
2023-02-16 18:56:29,288:INFO:Defining folds
2023-02-16 18:56:29,289:INFO:Declaring metric variables
2023-02-16 18:56:29,294:INFO:Importing untrained model
2023-02-16 18:56:29,297:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-16 18:56:29,317:INFO:Starting cross validation
2023-02-16 18:56:29,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:56:30,395:INFO:Calculating mean and std
2023-02-16 18:56:30,399:INFO:Creating metrics dataframe
2023-02-16 18:56:30,403:INFO:Uploading results into container
2023-02-16 18:56:30,403:INFO:Uploading model into container now
2023-02-16 18:56:30,404:INFO:_master_model_container: 8
2023-02-16 18:56:30,404:INFO:_display_container: 2
2023-02-16 18:56:30,406:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-16 18:56:30,407:INFO:create_model() successfully completed......................................
2023-02-16 18:56:30,703:INFO:SubProcess create_model() end ==================================
2023-02-16 18:56:30,703:INFO:Creating metrics dataframe
2023-02-16 18:56:30,720:INFO:Initializing Ada Boost Classifier
2023-02-16 18:56:30,720:INFO:Total runtime is 2.312706065177917 minutes
2023-02-16 18:56:30,726:INFO:SubProcess create_model() called ==================================
2023-02-16 18:56:30,726:INFO:Initializing create_model()
2023-02-16 18:56:30,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:56:30,727:INFO:Checking exceptions
2023-02-16 18:56:30,727:INFO:Importing libraries
2023-02-16 18:56:30,727:INFO:Copying training dataset
2023-02-16 18:56:30,860:INFO:Defining folds
2023-02-16 18:56:30,861:INFO:Declaring metric variables
2023-02-16 18:56:30,865:INFO:Importing untrained model
2023-02-16 18:56:30,871:INFO:Ada Boost Classifier Imported successfully
2023-02-16 18:56:30,895:INFO:Starting cross validation
2023-02-16 18:56:30,897:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:56:46,107:INFO:Calculating mean and std
2023-02-16 18:56:46,110:INFO:Creating metrics dataframe
2023-02-16 18:56:46,115:INFO:Uploading results into container
2023-02-16 18:56:46,116:INFO:Uploading model into container now
2023-02-16 18:56:46,116:INFO:_master_model_container: 9
2023-02-16 18:56:46,116:INFO:_display_container: 2
2023-02-16 18:56:46,116:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3675)
2023-02-16 18:56:46,117:INFO:create_model() successfully completed......................................
2023-02-16 18:56:46,381:INFO:SubProcess create_model() end ==================================
2023-02-16 18:56:46,382:INFO:Creating metrics dataframe
2023-02-16 18:56:46,414:INFO:Initializing Gradient Boosting Classifier
2023-02-16 18:56:46,415:INFO:Total runtime is 2.5742900252342222 minutes
2023-02-16 18:56:46,426:INFO:SubProcess create_model() called ==================================
2023-02-16 18:56:46,427:INFO:Initializing create_model()
2023-02-16 18:56:46,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:56:46,427:INFO:Checking exceptions
2023-02-16 18:56:46,428:INFO:Importing libraries
2023-02-16 18:56:46,428:INFO:Copying training dataset
2023-02-16 18:56:46,475:INFO:Defining folds
2023-02-16 18:56:46,475:INFO:Declaring metric variables
2023-02-16 18:56:46,481:INFO:Importing untrained model
2023-02-16 18:56:46,487:INFO:Gradient Boosting Classifier Imported successfully
2023-02-16 18:56:46,497:INFO:Starting cross validation
2023-02-16 18:56:46,498:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:57:40,915:INFO:Calculating mean and std
2023-02-16 18:57:40,916:INFO:Creating metrics dataframe
2023-02-16 18:57:40,923:INFO:Uploading results into container
2023-02-16 18:57:40,924:INFO:Uploading model into container now
2023-02-16 18:57:40,924:INFO:_master_model_container: 10
2023-02-16 18:57:40,924:INFO:_display_container: 2
2023-02-16 18:57:40,925:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3675, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-16 18:57:40,925:INFO:create_model() successfully completed......................................
2023-02-16 18:57:41,092:INFO:SubProcess create_model() end ==================================
2023-02-16 18:57:41,092:INFO:Creating metrics dataframe
2023-02-16 18:57:41,122:INFO:Initializing Linear Discriminant Analysis
2023-02-16 18:57:41,122:INFO:Total runtime is 3.48608603477478 minutes
2023-02-16 18:57:41,126:INFO:SubProcess create_model() called ==================================
2023-02-16 18:57:41,127:INFO:Initializing create_model()
2023-02-16 18:57:41,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:57:41,127:INFO:Checking exceptions
2023-02-16 18:57:41,127:INFO:Importing libraries
2023-02-16 18:57:41,127:INFO:Copying training dataset
2023-02-16 18:57:41,167:INFO:Defining folds
2023-02-16 18:57:41,167:INFO:Declaring metric variables
2023-02-16 18:57:41,173:INFO:Importing untrained model
2023-02-16 18:57:41,179:INFO:Linear Discriminant Analysis Imported successfully
2023-02-16 18:57:41,190:INFO:Starting cross validation
2023-02-16 18:57:41,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:57:42,165:INFO:Calculating mean and std
2023-02-16 18:57:42,167:INFO:Creating metrics dataframe
2023-02-16 18:57:42,171:INFO:Uploading results into container
2023-02-16 18:57:42,172:INFO:Uploading model into container now
2023-02-16 18:57:42,174:INFO:_master_model_container: 11
2023-02-16 18:57:42,174:INFO:_display_container: 2
2023-02-16 18:57:42,174:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-16 18:57:42,174:INFO:create_model() successfully completed......................................
2023-02-16 18:57:42,411:INFO:SubProcess create_model() end ==================================
2023-02-16 18:57:42,412:INFO:Creating metrics dataframe
2023-02-16 18:57:42,463:INFO:Initializing Extra Trees Classifier
2023-02-16 18:57:42,463:INFO:Total runtime is 3.508432281017303 minutes
2023-02-16 18:57:42,468:INFO:SubProcess create_model() called ==================================
2023-02-16 18:57:42,468:INFO:Initializing create_model()
2023-02-16 18:57:42,468:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:57:42,468:INFO:Checking exceptions
2023-02-16 18:57:42,469:INFO:Importing libraries
2023-02-16 18:57:42,469:INFO:Copying training dataset
2023-02-16 18:57:42,512:INFO:Defining folds
2023-02-16 18:57:42,512:INFO:Declaring metric variables
2023-02-16 18:57:42,516:INFO:Importing untrained model
2023-02-16 18:57:42,522:INFO:Extra Trees Classifier Imported successfully
2023-02-16 18:57:42,529:INFO:Starting cross validation
2023-02-16 18:57:42,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:58:12,543:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 3.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:58:12,543:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:58:13,292:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:58:13,817:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 3.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 18:58:46,495:INFO:Calculating mean and std
2023-02-16 18:58:46,497:INFO:Creating metrics dataframe
2023-02-16 18:58:46,504:INFO:Uploading results into container
2023-02-16 18:58:46,505:INFO:Uploading model into container now
2023-02-16 18:58:46,505:INFO:_master_model_container: 12
2023-02-16 18:58:46,505:INFO:_display_container: 2
2023-02-16 18:58:46,686:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3675, verbose=0, warm_start=False)
2023-02-16 18:58:46,687:INFO:create_model() successfully completed......................................
2023-02-16 18:58:46,860:INFO:SubProcess create_model() end ==================================
2023-02-16 18:58:46,861:INFO:Creating metrics dataframe
2023-02-16 18:58:47,099:INFO:Initializing Extreme Gradient Boosting
2023-02-16 18:58:47,099:INFO:Total runtime is 4.585696971416473 minutes
2023-02-16 18:58:47,105:INFO:SubProcess create_model() called ==================================
2023-02-16 18:58:47,106:INFO:Initializing create_model()
2023-02-16 18:58:47,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:58:47,107:INFO:Checking exceptions
2023-02-16 18:58:47,107:INFO:Importing libraries
2023-02-16 18:58:47,107:INFO:Copying training dataset
2023-02-16 18:58:47,147:INFO:Defining folds
2023-02-16 18:58:47,147:INFO:Declaring metric variables
2023-02-16 18:58:47,172:INFO:Importing untrained model
2023-02-16 18:58:47,179:INFO:Extreme Gradient Boosting Imported successfully
2023-02-16 18:58:47,192:INFO:Starting cross validation
2023-02-16 18:58:47,194:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:59:31,999:INFO:Calculating mean and std
2023-02-16 18:59:32,001:INFO:Creating metrics dataframe
2023-02-16 18:59:32,007:INFO:Uploading results into container
2023-02-16 18:59:32,008:INFO:Uploading model into container now
2023-02-16 18:59:32,008:INFO:_master_model_container: 13
2023-02-16 18:59:32,009:INFO:_display_container: 2
2023-02-16 18:59:32,010:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-16 18:59:32,017:INFO:create_model() successfully completed......................................
2023-02-16 18:59:32,193:INFO:SubProcess create_model() end ==================================
2023-02-16 18:59:32,193:INFO:Creating metrics dataframe
2023-02-16 18:59:32,287:INFO:Initializing Light Gradient Boosting Machine
2023-02-16 18:59:32,288:INFO:Total runtime is 5.338842725753784 minutes
2023-02-16 18:59:32,292:INFO:SubProcess create_model() called ==================================
2023-02-16 18:59:32,292:INFO:Initializing create_model()
2023-02-16 18:59:32,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:59:32,293:INFO:Checking exceptions
2023-02-16 18:59:32,293:INFO:Importing libraries
2023-02-16 18:59:32,293:INFO:Copying training dataset
2023-02-16 18:59:32,345:INFO:Defining folds
2023-02-16 18:59:32,346:INFO:Declaring metric variables
2023-02-16 18:59:32,351:INFO:Importing untrained model
2023-02-16 18:59:32,358:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-16 18:59:32,367:INFO:Starting cross validation
2023-02-16 18:59:32,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:59:46,714:INFO:Calculating mean and std
2023-02-16 18:59:46,716:INFO:Creating metrics dataframe
2023-02-16 18:59:46,722:INFO:Uploading results into container
2023-02-16 18:59:46,723:INFO:Uploading model into container now
2023-02-16 18:59:46,723:INFO:_master_model_container: 14
2023-02-16 18:59:46,723:INFO:_display_container: 2
2023-02-16 18:59:46,724:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-16 18:59:46,724:INFO:create_model() successfully completed......................................
2023-02-16 18:59:46,880:INFO:SubProcess create_model() end ==================================
2023-02-16 18:59:46,880:INFO:Creating metrics dataframe
2023-02-16 18:59:46,959:INFO:Initializing Dummy Classifier
2023-02-16 18:59:46,969:INFO:Total runtime is 5.58352042833964 minutes
2023-02-16 18:59:46,974:INFO:SubProcess create_model() called ==================================
2023-02-16 18:59:46,974:INFO:Initializing create_model()
2023-02-16 18:59:46,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B74D9B6D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:59:46,974:INFO:Checking exceptions
2023-02-16 18:59:46,974:INFO:Importing libraries
2023-02-16 18:59:46,975:INFO:Copying training dataset
2023-02-16 18:59:47,023:INFO:Defining folds
2023-02-16 18:59:47,024:INFO:Declaring metric variables
2023-02-16 18:59:47,029:INFO:Importing untrained model
2023-02-16 18:59:47,036:INFO:Dummy Classifier Imported successfully
2023-02-16 18:59:47,047:INFO:Starting cross validation
2023-02-16 18:59:47,048:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 18:59:47,165:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 18:59:47,540:INFO:Calculating mean and std
2023-02-16 18:59:47,542:INFO:Creating metrics dataframe
2023-02-16 18:59:47,546:INFO:Uploading results into container
2023-02-16 18:59:47,547:INFO:Uploading model into container now
2023-02-16 18:59:47,548:INFO:_master_model_container: 15
2023-02-16 18:59:47,548:INFO:_display_container: 2
2023-02-16 18:59:47,549:INFO:DummyClassifier(constant=None, random_state=3675, strategy='prior')
2023-02-16 18:59:47,549:INFO:create_model() successfully completed......................................
2023-02-16 18:59:47,713:INFO:SubProcess create_model() end ==================================
2023-02-16 18:59:47,713:INFO:Creating metrics dataframe
2023-02-16 18:59:47,774:INFO:Initializing create_model()
2023-02-16 18:59:47,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:59:47,775:INFO:Checking exceptions
2023-02-16 18:59:47,779:INFO:Importing libraries
2023-02-16 18:59:47,779:INFO:Copying training dataset
2023-02-16 18:59:47,825:INFO:Defining folds
2023-02-16 18:59:47,826:INFO:Declaring metric variables
2023-02-16 18:59:47,826:INFO:Importing untrained model
2023-02-16 18:59:47,826:INFO:Declaring custom model
2023-02-16 18:59:47,827:INFO:Extreme Gradient Boosting Imported successfully
2023-02-16 18:59:47,828:INFO:Cross validation set to False
2023-02-16 18:59:47,828:INFO:Fitting Model
2023-02-16 18:59:53,702:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-16 18:59:53,702:INFO:create_model() successfully completed......................................
2023-02-16 18:59:53,863:INFO:Initializing create_model()
2023-02-16 18:59:53,863:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:59:53,863:INFO:Checking exceptions
2023-02-16 18:59:53,866:INFO:Importing libraries
2023-02-16 18:59:53,866:INFO:Copying training dataset
2023-02-16 18:59:53,908:INFO:Defining folds
2023-02-16 18:59:53,908:INFO:Declaring metric variables
2023-02-16 18:59:53,908:INFO:Importing untrained model
2023-02-16 18:59:53,908:INFO:Declaring custom model
2023-02-16 18:59:53,909:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-16 18:59:53,909:INFO:Cross validation set to False
2023-02-16 18:59:53,909:INFO:Fitting Model
2023-02-16 18:59:54,997:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-16 18:59:54,997:INFO:create_model() successfully completed......................................
2023-02-16 18:59:55,265:INFO:Initializing create_model()
2023-02-16 18:59:55,265:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3675, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 18:59:55,265:INFO:Checking exceptions
2023-02-16 18:59:55,267:INFO:Importing libraries
2023-02-16 18:59:55,268:INFO:Copying training dataset
2023-02-16 18:59:55,341:INFO:Defining folds
2023-02-16 18:59:55,341:INFO:Declaring metric variables
2023-02-16 18:59:55,342:INFO:Importing untrained model
2023-02-16 18:59:55,342:INFO:Declaring custom model
2023-02-16 18:59:55,343:INFO:Random Forest Classifier Imported successfully
2023-02-16 18:59:55,343:INFO:Cross validation set to False
2023-02-16 18:59:55,343:INFO:Fitting Model
2023-02-16 19:00:01,322:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3675, verbose=0, warm_start=False)
2023-02-16 19:00:01,322:INFO:create_model() successfully completed......................................
2023-02-16 19:00:01,543:INFO:_master_model_container: 15
2023-02-16 19:00:01,543:INFO:_display_container: 2
2023-02-16 19:00:01,545:INFO:[XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3675, verbose=0, warm_start=False)]
2023-02-16 19:00:01,546:INFO:compare_models() successfully completed......................................
2023-02-16 19:00:02,109:INFO:Initializing tune_model()
2023-02-16 19:00:02,109:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>)
2023-02-16 19:00:02,109:INFO:Checking exceptions
2023-02-16 19:00:02,109:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-16 19:00:02,148:INFO:Copying training dataset
2023-02-16 19:00:02,178:INFO:Checking base model
2023-02-16 19:00:02,178:INFO:Base model : Extreme Gradient Boosting
2023-02-16 19:00:02,184:INFO:Declaring metric variables
2023-02-16 19:00:02,191:INFO:Defining Hyperparameters
2023-02-16 19:00:02,364:INFO:Tuning with n_jobs=-1
2023-02-16 19:00:02,416:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 19:00:02,416:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 19:00:02,435:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-16 19:00:02,435:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-16 19:00:02,456:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-16 19:10:24,280:INFO:best_params: {'actual_estimator__learning_rate': 0.0044204375602208724, 'actual_estimator__n_estimators': 149, 'actual_estimator__subsample': 0.9301304394878664, 'actual_estimator__max_depth': 2, 'actual_estimator__colsample_bytree': 0.5989459975414475, 'actual_estimator__min_child_weight': 1, 'actual_estimator__reg_alpha': 0.0016561391636375695, 'actual_estimator__reg_lambda': 2.2171717083366978e-05, 'actual_estimator__scale_pos_weight': 48.567525301728956}
2023-02-16 19:10:24,280:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-16 19:10:24,307:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-16 19:10:24,308:INFO:Hyperparameter search completed
2023-02-16 19:10:24,309:INFO:SubProcess create_model() called ==================================
2023-02-16 19:10:24,310:INFO:Initializing create_model()
2023-02-16 19:10:24,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B79720C40>, model_only=True, return_train_score=False, kwargs={'learning_rate': 0.0044204375602208724, 'n_estimators': 149, 'subsample': 0.9301304394878664, 'max_depth': 2, 'colsample_bytree': 0.5989459975414475, 'min_child_weight': 1, 'reg_alpha': 0.0016561391636375695, 'reg_lambda': 2.2171717083366978e-05, 'scale_pos_weight': 48.567525301728956})
2023-02-16 19:10:24,310:INFO:Checking exceptions
2023-02-16 19:10:24,310:INFO:Importing libraries
2023-02-16 19:10:24,310:INFO:Copying training dataset
2023-02-16 19:10:24,357:INFO:Defining folds
2023-02-16 19:10:24,357:INFO:Declaring metric variables
2023-02-16 19:10:24,365:INFO:Importing untrained model
2023-02-16 19:10:24,365:INFO:Declaring custom model
2023-02-16 19:10:24,371:INFO:Extreme Gradient Boosting Imported successfully
2023-02-16 19:10:24,382:INFO:Starting cross validation
2023-02-16 19:10:24,384:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:10:34,552:INFO:Calculating mean and std
2023-02-16 19:10:34,554:INFO:Creating metrics dataframe
2023-02-16 19:10:34,565:INFO:Finalizing model
2023-02-16 19:10:37,505:INFO:Uploading results into container
2023-02-16 19:10:37,507:INFO:Uploading model into container now
2023-02-16 19:10:37,508:INFO:_master_model_container: 16
2023-02-16 19:10:37,508:INFO:_display_container: 3
2023-02-16 19:10:37,509:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5989459975414475, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0044204375602208724,
              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=2, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              n_estimators=149, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-16 19:10:37,509:INFO:create_model() successfully completed......................................
2023-02-16 19:10:37,691:INFO:SubProcess create_model() end ==================================
2023-02-16 19:10:37,696:INFO:choose_better activated
2023-02-16 19:10:37,701:INFO:SubProcess create_model() called ==================================
2023-02-16 19:10:37,703:INFO:Initializing create_model()
2023-02-16 19:10:37,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:10:37,703:INFO:Checking exceptions
2023-02-16 19:10:37,705:INFO:Importing libraries
2023-02-16 19:10:37,706:INFO:Copying training dataset
2023-02-16 19:10:37,744:INFO:Defining folds
2023-02-16 19:10:37,744:INFO:Declaring metric variables
2023-02-16 19:10:37,745:INFO:Importing untrained model
2023-02-16 19:10:37,745:INFO:Declaring custom model
2023-02-16 19:10:37,747:INFO:Extreme Gradient Boosting Imported successfully
2023-02-16 19:10:37,747:INFO:Starting cross validation
2023-02-16 19:10:37,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:10:38,492:INFO:Calculating mean and std
2023-02-16 19:10:38,492:INFO:Creating metrics dataframe
2023-02-16 19:10:38,495:INFO:Finalizing model
2023-02-16 19:10:38,555:INFO:Uploading results into container
2023-02-16 19:10:38,555:INFO:Uploading model into container now
2023-02-16 19:10:38,556:INFO:_master_model_container: 17
2023-02-16 19:10:38,556:INFO:_display_container: 4
2023-02-16 19:10:38,556:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-16 19:10:38,556:INFO:create_model() successfully completed......................................
2023-02-16 19:10:38,704:INFO:SubProcess create_model() end ==================================
2023-02-16 19:10:38,705:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for Recall is 0.9205
2023-02-16 19:10:38,706:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5989459975414475, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0044204375602208724,
              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=2, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              n_estimators=149, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for Recall is 1.0
2023-02-16 19:10:38,707:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5989459975414475, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0044204375602208724,
              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=2, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              n_estimators=149, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) is best model
2023-02-16 19:10:38,707:INFO:choose_better completed
2023-02-16 19:10:38,721:INFO:_master_model_container: 17
2023-02-16 19:10:38,721:INFO:_display_container: 3
2023-02-16 19:10:38,723:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5989459975414475, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.0044204375602208724,
              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=2, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              n_estimators=149, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-16 19:10:38,723:INFO:tune_model() successfully completed......................................
2023-02-16 19:10:39,005:INFO:Initializing tune_model()
2023-02-16 19:10:39,005:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>)
2023-02-16 19:10:39,005:INFO:Checking exceptions
2023-02-16 19:10:39,005:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-16 19:10:39,037:INFO:Copying training dataset
2023-02-16 19:10:39,071:INFO:Checking base model
2023-02-16 19:10:39,071:INFO:Base model : Light Gradient Boosting Machine
2023-02-16 19:10:39,110:INFO:Declaring metric variables
2023-02-16 19:10:39,116:INFO:Defining Hyperparameters
2023-02-16 19:10:39,336:INFO:Tuning with n_jobs=-1
2023-02-16 19:10:39,337:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 19:10:39,338:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 19:10:39,338:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-16 19:10:39,338:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-16 19:10:39,345:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-16 19:13:00,824:INFO:best_params: {'actual_estimator__num_leaves': 236, 'actual_estimator__learning_rate': 0.215383914577164, 'actual_estimator__n_estimators': 290, 'actual_estimator__min_split_gain': 0.8424510662116289, 'actual_estimator__reg_alpha': 6.626086624833129e-07, 'actual_estimator__reg_lambda': 1.8389184064209232e-08, 'actual_estimator__feature_fraction': 0.9568768440973149, 'actual_estimator__bagging_fraction': 0.8624804351264481, 'actual_estimator__bagging_freq': 1, 'actual_estimator__min_child_samples': 85}
2023-02-16 19:13:00,824:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-16 19:13:00,824:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-16 19:13:00,827:INFO:Hyperparameter search completed
2023-02-16 19:13:00,827:INFO:SubProcess create_model() called ==================================
2023-02-16 19:13:00,828:INFO:Initializing create_model()
2023-02-16 19:13:00,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B65954850>, model_only=True, return_train_score=False, kwargs={'num_leaves': 236, 'learning_rate': 0.215383914577164, 'n_estimators': 290, 'min_split_gain': 0.8424510662116289, 'reg_alpha': 6.626086624833129e-07, 'reg_lambda': 1.8389184064209232e-08, 'feature_fraction': 0.9568768440973149, 'bagging_fraction': 0.8624804351264481, 'bagging_freq': 1, 'min_child_samples': 85})
2023-02-16 19:13:00,828:INFO:Checking exceptions
2023-02-16 19:13:00,829:INFO:Importing libraries
2023-02-16 19:13:00,829:INFO:Copying training dataset
2023-02-16 19:13:00,867:INFO:Defining folds
2023-02-16 19:13:00,868:INFO:Declaring metric variables
2023-02-16 19:13:00,875:INFO:Importing untrained model
2023-02-16 19:13:00,876:INFO:Declaring custom model
2023-02-16 19:13:00,881:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-16 19:13:00,891:INFO:Starting cross validation
2023-02-16 19:13:00,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:13:04,192:INFO:Calculating mean and std
2023-02-16 19:13:04,194:INFO:Creating metrics dataframe
2023-02-16 19:13:04,201:INFO:Finalizing model
2023-02-16 19:13:05,922:INFO:Uploading results into container
2023-02-16 19:13:05,923:INFO:Uploading model into container now
2023-02-16 19:13:05,924:INFO:_master_model_container: 18
2023-02-16 19:13:05,924:INFO:_display_container: 4
2023-02-16 19:13:05,924:INFO:LGBMClassifier(bagging_fraction=0.8624804351264481, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9568768440973149, importance_type='split',
               learning_rate=0.215383914577164, max_depth=-1,
               min_child_samples=85, min_child_weight=0.001,
               min_split_gain=0.8424510662116289, n_estimators=290, n_jobs=-1,
               num_leaves=236, objective=None, random_state=3675,
               reg_alpha=6.626086624833129e-07,
               reg_lambda=1.8389184064209232e-08, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-02-16 19:13:05,925:INFO:create_model() successfully completed......................................
2023-02-16 19:13:06,079:INFO:SubProcess create_model() end ==================================
2023-02-16 19:13:06,079:INFO:choose_better activated
2023-02-16 19:13:06,084:INFO:SubProcess create_model() called ==================================
2023-02-16 19:13:06,085:INFO:Initializing create_model()
2023-02-16 19:13:06,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:13:06,085:INFO:Checking exceptions
2023-02-16 19:13:06,089:INFO:Importing libraries
2023-02-16 19:13:06,089:INFO:Copying training dataset
2023-02-16 19:13:06,128:INFO:Defining folds
2023-02-16 19:13:06,129:INFO:Declaring metric variables
2023-02-16 19:13:06,129:INFO:Importing untrained model
2023-02-16 19:13:06,129:INFO:Declaring custom model
2023-02-16 19:13:06,131:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-16 19:13:06,131:INFO:Starting cross validation
2023-02-16 19:13:06,132:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:13:07,221:INFO:Calculating mean and std
2023-02-16 19:13:07,223:INFO:Creating metrics dataframe
2023-02-16 19:13:07,228:INFO:Finalizing model
2023-02-16 19:13:07,268:INFO:Uploading results into container
2023-02-16 19:13:07,268:INFO:Uploading model into container now
2023-02-16 19:13:07,269:INFO:_master_model_container: 19
2023-02-16 19:13:07,269:INFO:_display_container: 5
2023-02-16 19:13:07,269:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-16 19:13:07,269:INFO:create_model() successfully completed......................................
2023-02-16 19:13:07,506:INFO:SubProcess create_model() end ==================================
2023-02-16 19:13:07,508:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.9017
2023-02-16 19:13:07,509:INFO:LGBMClassifier(bagging_fraction=0.8624804351264481, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9568768440973149, importance_type='split',
               learning_rate=0.215383914577164, max_depth=-1,
               min_child_samples=85, min_child_weight=0.001,
               min_split_gain=0.8424510662116289, n_estimators=290, n_jobs=-1,
               num_leaves=236, objective=None, random_state=3675,
               reg_alpha=6.626086624833129e-07,
               reg_lambda=1.8389184064209232e-08, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.9321
2023-02-16 19:13:07,510:INFO:LGBMClassifier(bagging_fraction=0.8624804351264481, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9568768440973149, importance_type='split',
               learning_rate=0.215383914577164, max_depth=-1,
               min_child_samples=85, min_child_weight=0.001,
               min_split_gain=0.8424510662116289, n_estimators=290, n_jobs=-1,
               num_leaves=236, objective=None, random_state=3675,
               reg_alpha=6.626086624833129e-07,
               reg_lambda=1.8389184064209232e-08, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-02-16 19:13:07,510:INFO:choose_better completed
2023-02-16 19:13:07,521:INFO:_master_model_container: 19
2023-02-16 19:13:07,521:INFO:_display_container: 4
2023-02-16 19:13:07,522:INFO:LGBMClassifier(bagging_fraction=0.8624804351264481, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9568768440973149, importance_type='split',
               learning_rate=0.215383914577164, max_depth=-1,
               min_child_samples=85, min_child_weight=0.001,
               min_split_gain=0.8424510662116289, n_estimators=290, n_jobs=-1,
               num_leaves=236, objective=None, random_state=3675,
               reg_alpha=6.626086624833129e-07,
               reg_lambda=1.8389184064209232e-08, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-02-16 19:13:07,522:INFO:tune_model() successfully completed......................................
2023-02-16 19:13:07,697:INFO:Initializing tune_model()
2023-02-16 19:13:07,697:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3675, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>)
2023-02-16 19:13:07,697:INFO:Checking exceptions
2023-02-16 19:13:07,697:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-16 19:13:07,729:INFO:Copying training dataset
2023-02-16 19:13:07,762:INFO:Checking base model
2023-02-16 19:13:07,762:INFO:Base model : Random Forest Classifier
2023-02-16 19:13:07,767:INFO:Declaring metric variables
2023-02-16 19:13:07,774:INFO:Defining Hyperparameters
2023-02-16 19:13:07,932:INFO:Tuning with n_jobs=-1
2023-02-16 19:13:07,933:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 19:13:07,933:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 19:13:07,934:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-02-16 19:13:07,934:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-16 19:13:07,934:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-16 19:13:07,940:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-16 19:19:40,584:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 19:22:04,500:INFO:best_params: {'actual_estimator__n_estimators': 32, 'actual_estimator__max_depth': 1, 'actual_estimator__min_impurity_decrease': 0.004047869132216079, 'actual_estimator__max_features': 0.5226203983273896, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__bootstrap': False, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced'}
2023-02-16 19:22:04,500:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-16 19:22:04,501:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-16 19:22:04,504:INFO:Hyperparameter search completed
2023-02-16 19:22:04,505:INFO:SubProcess create_model() called ==================================
2023-02-16 19:22:04,505:INFO:Initializing create_model()
2023-02-16 19:22:04,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3675, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B72396250>, model_only=True, return_train_score=False, kwargs={'n_estimators': 32, 'max_depth': 1, 'min_impurity_decrease': 0.004047869132216079, 'max_features': 0.5226203983273896, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced'})
2023-02-16 19:22:04,505:INFO:Checking exceptions
2023-02-16 19:22:04,506:INFO:Importing libraries
2023-02-16 19:22:04,506:INFO:Copying training dataset
2023-02-16 19:22:04,556:INFO:Defining folds
2023-02-16 19:22:04,556:INFO:Declaring metric variables
2023-02-16 19:22:04,561:INFO:Importing untrained model
2023-02-16 19:22:04,562:INFO:Declaring custom model
2023-02-16 19:22:04,568:INFO:Random Forest Classifier Imported successfully
2023-02-16 19:22:04,580:INFO:Starting cross validation
2023-02-16 19:22:04,581:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:22:05,396:INFO:Calculating mean and std
2023-02-16 19:22:05,398:INFO:Creating metrics dataframe
2023-02-16 19:22:05,405:INFO:Finalizing model
2023-02-16 19:22:05,978:INFO:Uploading results into container
2023-02-16 19:22:05,979:INFO:Uploading model into container now
2023-02-16 19:22:05,980:INFO:_master_model_container: 20
2023-02-16 19:22:05,980:INFO:_display_container: 5
2023-02-16 19:22:05,981:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=1,
                       max_features=0.5226203983273896, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.004047869132216079,
                       min_samples_leaf=2, min_samples_split=3,
                       min_weight_fraction_leaf=0.0, n_estimators=32, n_jobs=-1,
                       oob_score=False, random_state=3675, verbose=0,
                       warm_start=False)
2023-02-16 19:22:05,981:INFO:create_model() successfully completed......................................
2023-02-16 19:22:06,184:INFO:SubProcess create_model() end ==================================
2023-02-16 19:22:06,184:INFO:choose_better activated
2023-02-16 19:22:06,196:INFO:SubProcess create_model() called ==================================
2023-02-16 19:22:06,197:INFO:Initializing create_model()
2023-02-16 19:22:06,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3675, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:22:06,198:INFO:Checking exceptions
2023-02-16 19:22:06,200:INFO:Importing libraries
2023-02-16 19:22:06,200:INFO:Copying training dataset
2023-02-16 19:22:06,250:INFO:Defining folds
2023-02-16 19:22:06,250:INFO:Declaring metric variables
2023-02-16 19:22:06,250:INFO:Importing untrained model
2023-02-16 19:22:06,251:INFO:Declaring custom model
2023-02-16 19:22:06,251:INFO:Random Forest Classifier Imported successfully
2023-02-16 19:22:06,252:INFO:Starting cross validation
2023-02-16 19:22:06,254:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:22:11,904:INFO:Calculating mean and std
2023-02-16 19:22:11,905:INFO:Creating metrics dataframe
2023-02-16 19:22:11,907:INFO:Finalizing model
2023-02-16 19:22:12,365:INFO:Uploading results into container
2023-02-16 19:22:12,366:INFO:Uploading model into container now
2023-02-16 19:22:12,366:INFO:_master_model_container: 21
2023-02-16 19:22:12,366:INFO:_display_container: 6
2023-02-16 19:22:12,368:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3675, verbose=0, warm_start=False)
2023-02-16 19:22:12,368:INFO:create_model() successfully completed......................................
2023-02-16 19:22:12,565:INFO:SubProcess create_model() end ==================================
2023-02-16 19:22:12,565:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3675, verbose=0, warm_start=False) result for Recall is 0.9255
2023-02-16 19:22:12,566:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=1,
                       max_features=0.5226203983273896, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.004047869132216079,
                       min_samples_leaf=2, min_samples_split=3,
                       min_weight_fraction_leaf=0.0, n_estimators=32, n_jobs=-1,
                       oob_score=False, random_state=3675, verbose=0,
                       warm_start=False) result for Recall is 0.86
2023-02-16 19:22:12,566:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3675, verbose=0, warm_start=False) is best model
2023-02-16 19:22:12,566:INFO:choose_better completed
2023-02-16 19:22:12,567:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-16 19:22:12,581:INFO:_master_model_container: 21
2023-02-16 19:22:12,581:INFO:_display_container: 5
2023-02-16 19:22:12,582:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3675, verbose=0, warm_start=False)
2023-02-16 19:22:12,582:INFO:tune_model() successfully completed......................................
2023-02-16 19:22:12,766:INFO:Initializing automl()
2023-02-16 19:22:12,766:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, optimize=AUC, use_holdout=False, turbo=True, return_train_score=False)
2023-02-16 19:22:12,766:INFO:Model Selection Basis : CV Results on Training set
2023-02-16 19:22:12,766:INFO:Checking model 0
2023-02-16 19:22:12,766:INFO:Checking model 1
2023-02-16 19:22:12,767:INFO:Checking model 2
2023-02-16 19:22:12,767:INFO:Checking model 3
2023-02-16 19:22:12,767:INFO:Checking model 4
2023-02-16 19:22:12,767:INFO:Checking model 5
2023-02-16 19:22:12,767:INFO:Checking model 6
2023-02-16 19:22:12,767:INFO:Checking model 7
2023-02-16 19:22:12,768:INFO:Checking model 8
2023-02-16 19:22:12,768:INFO:Checking model 9
2023-02-16 19:22:12,768:INFO:Checking model 10
2023-02-16 19:22:12,768:INFO:Checking model 11
2023-02-16 19:22:12,769:INFO:Checking model 12
2023-02-16 19:22:12,770:INFO:Checking model 13
2023-02-16 19:22:12,770:INFO:Checking model 14
2023-02-16 19:22:12,771:INFO:Checking model 15
2023-02-16 19:22:12,771:INFO:Checking model 16
2023-02-16 19:22:12,771:INFO:Checking model 17
2023-02-16 19:22:12,771:INFO:Checking model 18
2023-02-16 19:22:12,771:INFO:Checking model 19
2023-02-16 19:22:12,771:INFO:Checking model 20
2023-02-16 19:22:12,772:INFO:Initializing create_model()
2023-02-16 19:22:12,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=LGBMClassifier(bagging_fraction=0.8624804351264481, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9568768440973149, importance_type='split',
               learning_rate=0.215383914577164, max_depth=-1,
               min_child_samples=85, min_child_weight=0.001,
               min_split_gain=0.8424510662116289, n_estimators=290, n_jobs=-1,
               num_leaves=236, objective=None, random_state=3675,
               reg_alpha=6.626086624833129e-07,
               reg_lambda=1.8389184064209232e-08, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:22:12,772:INFO:Checking exceptions
2023-02-16 19:22:12,774:INFO:Importing libraries
2023-02-16 19:22:12,775:INFO:Copying training dataset
2023-02-16 19:22:12,810:INFO:Defining folds
2023-02-16 19:22:12,811:INFO:Declaring metric variables
2023-02-16 19:22:12,811:INFO:Importing untrained model
2023-02-16 19:22:12,811:INFO:Declaring custom model
2023-02-16 19:22:12,812:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-16 19:22:12,812:INFO:Cross validation set to False
2023-02-16 19:22:12,812:INFO:Fitting Model
2023-02-16 19:22:13,008:INFO:LGBMClassifier(bagging_fraction=0.8624804351264481, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9568768440973149, importance_type='split',
               learning_rate=0.215383914577164, max_depth=-1,
               min_child_samples=85, min_child_weight=0.001,
               min_split_gain=0.8424510662116289, n_estimators=290, n_jobs=-1,
               num_leaves=236, objective=None, random_state=3675,
               reg_alpha=6.626086624833129e-07,
               reg_lambda=1.8389184064209232e-08, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-02-16 19:22:13,008:INFO:create_model() successfully completed......................................
2023-02-16 19:22:13,306:INFO:LGBMClassifier(bagging_fraction=0.8624804351264481, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9568768440973149, importance_type='split',
               learning_rate=0.215383914577164, max_depth=-1,
               min_child_samples=85, min_child_weight=0.001,
               min_split_gain=0.8424510662116289, n_estimators=290, n_jobs=-1,
               num_leaves=236, objective=None, random_state=3675,
               reg_alpha=6.626086624833129e-07,
               reg_lambda=1.8389184064209232e-08, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-02-16 19:22:13,307:INFO:automl() successfully completed......................................
2023-02-16 19:22:13,307:INFO:Initializing finalize_model()
2023-02-16 19:22:13,307:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=LGBMClassifier(bagging_fraction=0.8624804351264481, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9568768440973149, importance_type='split',
               learning_rate=0.215383914577164, max_depth=-1,
               min_child_samples=85, min_child_weight=0.001,
               min_split_gain=0.8424510662116289, n_estimators=290, n_jobs=-1,
               num_leaves=236, objective=None, random_state=3675,
               reg_alpha=6.626086624833129e-07,
               reg_lambda=1.8389184064209232e-08, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-02-16 19:22:13,308:INFO:Finalizing LGBMClassifier(bagging_fraction=0.8624804351264481, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9568768440973149, importance_type='split',
               learning_rate=0.215383914577164, max_depth=-1,
               min_child_samples=85, min_child_weight=0.001,
               min_split_gain=0.8424510662116289, n_estimators=290, n_jobs=-1,
               num_leaves=236, objective=None, random_state=3675,
               reg_alpha=6.626086624833129e-07,
               reg_lambda=1.8389184064209232e-08, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-02-16 19:22:13,324:INFO:Initializing create_model()
2023-02-16 19:22:13,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B6E760D30>, estimator=LGBMClassifier(bagging_fraction=0.8624804351264481, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9568768440973149, importance_type='split',
               learning_rate=0.215383914577164, max_depth=-1,
               min_child_samples=85, min_child_weight=0.001,
               min_split_gain=0.8424510662116289, n_estimators=290, n_jobs=-1,
               num_leaves=236, objective=None, random_state=3675,
               reg_alpha=6.626086624833129e-07,
               reg_lambda=1.8389184064209232e-08, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-02-16 19:22:13,324:INFO:Checking exceptions
2023-02-16 19:22:13,326:INFO:Importing libraries
2023-02-16 19:22:13,326:INFO:Copying training dataset
2023-02-16 19:22:13,327:INFO:Defining folds
2023-02-16 19:22:13,327:INFO:Declaring metric variables
2023-02-16 19:22:13,327:INFO:Importing untrained model
2023-02-16 19:22:13,327:INFO:Declaring custom model
2023-02-16 19:22:13,328:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-16 19:22:13,328:INFO:Cross validation set to False
2023-02-16 19:22:13,329:INFO:Fitting Model
2023-02-16 19:22:15,514:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.8624804351264481,
                                bagging_freq=1, boosting_type='gbdt',
                                class_weight=None, colsample_bytree=1.0,
                                feature_fraction=0.9568768440973149,
                                importance_type='split',
                                learning_rate=0.215383914577164, max_depth=-1,
                                min_child_samples=85, min_child_weight=0.001,
                                min_split_gain=0.8424510662116289,
                                n_estimators=290, n_jobs=-1, num_leaves=236,
                                objective=None, random_state=3675,
                                reg_alpha=6.626086624833129e-07,
                                reg_lambda=1.8389184064209232e-08,
                                silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-02-16 19:22:15,514:INFO:create_model() successfully completed......................................
2023-02-16 19:22:15,651:INFO:_master_model_container: 21
2023-02-16 19:22:15,651:INFO:_display_container: 5
2023-02-16 19:22:15,654:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.8624804351264481,
                                bagging_freq=1, boosting_type='gbdt',
                                class_weight=None, colsample_bytree=1.0,
                                feature_fraction=0.9568768440973149,
                                importance_type='split',
                                learning_rate=0.215383914577164, max_depth=-1,
                                min_child_samples=85, min_child_weight=0.001,
                                min_split_gain=0.8424510662116289,
                                n_estimators=290, n_jobs=-1, num_leaves=236,
                                objective=None, random_state=3675,
                                reg_alpha=6.626086624833129e-07,
                                reg_lambda=1.8389184064209232e-08,
                                silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-02-16 19:22:15,654:INFO:finalize_model() successfully completed......................................
2023-02-16 19:27:14,775:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 19:27:14,788:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 19:27:14,794:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 19:27:23,394:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 19:27:23,408:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 19:27:23,413:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 19:46:51,755:INFO:PyCaret ClassificationExperiment
2023-02-16 19:46:51,757:INFO:Logging name: clf-default-name
2023-02-16 19:46:51,757:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-16 19:46:51,757:INFO:version 3.0.0.rc9
2023-02-16 19:46:51,757:INFO:Initializing setup()
2023-02-16 19:46:51,757:INFO:self.USI: fef7
2023-02-16 19:46:51,757:INFO:self._variable_keys: {'y', 'idx', 'memory', 'fix_imbalance', 'gpu_n_jobs_param', 'seed', 'USI', 'fold_shuffle_param', 'y_test', 'X', 'gpu_param', '_available_plots', 'fold_generator', 'exp_id', 'n_jobs_param', 'y_train', 'data', 'logging_param', 'X_train', 'target_param', 'pipeline', '_ml_usecase', 'html_param', 'log_plots_param', 'X_test', 'is_multiclass', 'exp_name_log', 'fold_groups_param'}
2023-02-16 19:46:51,757:INFO:Checking environment
2023-02-16 19:46:51,757:INFO:python_version: 3.9.15
2023-02-16 19:46:51,757:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-16 19:46:51,776:INFO:machine: AMD64
2023-02-16 19:46:51,776:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-16 19:46:51,777:INFO:Memory: svmem(total=8469581824, available=3264712704, percent=61.5, used=5204869120, free=3264712704)
2023-02-16 19:46:51,777:INFO:Physical Core: 4
2023-02-16 19:46:51,777:INFO:Logical Core: 4
2023-02-16 19:46:51,777:INFO:Checking libraries
2023-02-16 19:46:51,777:INFO:System:
2023-02-16 19:46:51,777:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-16 19:46:51,777:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-16 19:46:51,777:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-16 19:46:51,778:INFO:PyCaret required dependencies:
2023-02-16 19:46:51,778:INFO:                 pip: 22.3.1
2023-02-16 19:46:51,778:INFO:          setuptools: 60.10.0
2023-02-16 19:46:51,778:INFO:             pycaret: 3.0.0rc9
2023-02-16 19:46:51,778:INFO:             IPython: 7.31.1
2023-02-16 19:46:51,778:INFO:          ipywidgets: 7.6.5
2023-02-16 19:46:51,778:INFO:                tqdm: 4.64.1
2023-02-16 19:46:51,778:INFO:               numpy: 1.21.5
2023-02-16 19:46:51,778:INFO:              pandas: 1.4.4
2023-02-16 19:46:51,778:INFO:              jinja2: 2.11.3
2023-02-16 19:46:51,778:INFO:               scipy: 1.9.3
2023-02-16 19:46:51,779:INFO:              joblib: 1.2.0
2023-02-16 19:46:51,779:INFO:             sklearn: 1.0.2
2023-02-16 19:46:51,779:INFO:                pyod: 1.0.7
2023-02-16 19:46:51,779:INFO:            imblearn: 0.10.1
2023-02-16 19:46:51,779:INFO:   category_encoders: 2.6.0
2023-02-16 19:46:51,779:INFO:            lightgbm: 3.3.5
2023-02-16 19:46:51,779:INFO:               numba: 0.56.4
2023-02-16 19:46:51,779:INFO:            requests: 2.28.1
2023-02-16 19:46:51,779:INFO:          matplotlib: 3.6.2
2023-02-16 19:46:51,779:INFO:          scikitplot: 0.3.7
2023-02-16 19:46:51,779:INFO:         yellowbrick: 1.5
2023-02-16 19:46:51,779:INFO:              plotly: 5.9.0
2023-02-16 19:46:51,779:INFO:             kaleido: 0.2.1
2023-02-16 19:46:51,779:INFO:         statsmodels: 0.13.2
2023-02-16 19:46:51,779:INFO:              sktime: 0.16.1
2023-02-16 19:46:51,779:INFO:               tbats: 1.1.2
2023-02-16 19:46:51,779:INFO:            pmdarima: 2.0.2
2023-02-16 19:46:51,779:INFO:              psutil: 5.9.0
2023-02-16 19:46:51,780:INFO:PyCaret optional dependencies:
2023-02-16 19:46:51,780:INFO:                shap: 0.41.0
2023-02-16 19:46:51,780:INFO:           interpret: Not installed
2023-02-16 19:46:51,780:INFO:                umap: Not installed
2023-02-16 19:46:51,780:INFO:    pandas_profiling: 4.0.0
2023-02-16 19:46:51,780:INFO:  explainerdashboard: 0.3.6.2
2023-02-16 19:46:51,780:INFO:             autoviz: 0.1.58
2023-02-16 19:46:51,780:INFO:           fairlearn: Not installed
2023-02-16 19:46:51,780:INFO:             xgboost: 1.7.3
2023-02-16 19:46:51,780:INFO:            catboost: Not installed
2023-02-16 19:46:51,781:INFO:              kmodes: Not installed
2023-02-16 19:46:51,781:INFO:             mlxtend: Not installed
2023-02-16 19:46:51,781:INFO:       statsforecast: Not installed
2023-02-16 19:46:51,781:INFO:        tune_sklearn: Not installed
2023-02-16 19:46:51,781:INFO:                 ray: Not installed
2023-02-16 19:46:51,781:INFO:            hyperopt: Not installed
2023-02-16 19:46:51,781:INFO:              optuna: 2.10.1
2023-02-16 19:46:51,781:INFO:               skopt: Not installed
2023-02-16 19:46:51,781:INFO:              mlflow: Not installed
2023-02-16 19:46:51,781:INFO:              gradio: Not installed
2023-02-16 19:46:51,781:INFO:             fastapi: Not installed
2023-02-16 19:46:51,781:INFO:             uvicorn: Not installed
2023-02-16 19:46:51,781:INFO:              m2cgen: Not installed
2023-02-16 19:46:51,782:INFO:           evidently: Not installed
2023-02-16 19:46:51,782:INFO:               fugue: Not installed
2023-02-16 19:46:51,782:INFO:           streamlit: Not installed
2023-02-16 19:46:51,782:INFO:             prophet: Not installed
2023-02-16 19:46:51,782:INFO:None
2023-02-16 19:46:51,782:INFO:Set up data.
2023-02-16 19:46:51,997:INFO:Set up train/test split.
2023-02-16 19:46:52,208:INFO:Set up index.
2023-02-16 19:46:52,214:INFO:Set up folding strategy.
2023-02-16 19:46:52,214:INFO:Assigning column types.
2023-02-16 19:46:52,257:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-16 19:46:52,333:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 19:46:52,361:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 19:46:52,396:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 19:46:52,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 19:46:52,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-16 19:46:52,455:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 19:46:52,486:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 19:46:52,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 19:46:52,490:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-16 19:46:52,544:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 19:46:52,579:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 19:46:52,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 19:46:52,675:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-16 19:46:52,715:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 19:46:52,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 19:46:52,718:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-16 19:46:52,881:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 19:46:52,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 19:46:52,984:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 19:46:52,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 19:46:53,084:INFO:Finished creating preprocessing pipeline.
2023-02-16 19:46:53,084:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2023-02-16 19:46:53,084:INFO:Creating final display dataframe.
2023-02-16 19:46:53,446:INFO:Setup _display_container:                    Description         Value
0                   Session id          2276
1                       Target  inadimplente
2                  Target type        Binary
3          Original data shape  (164270, 11)
4       Transformed data shape  (164270, 11)
5  Transformed train set shape  (114988, 11)
6   Transformed test set shape   (49282, 11)
7             Numeric features            10
2023-02-16 19:46:53,558:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 19:46:53,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 19:46:53,646:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-16 19:46:53,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-16 19:46:53,651:INFO:setup() successfully completed in 1.97s...............
2023-02-16 19:46:53,777:INFO:Initializing compare_models()
2023-02-16 19:46:53,778:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-16 19:46:53,778:INFO:Checking exceptions
2023-02-16 19:46:53,809:INFO:Preparing display monitor
2023-02-16 19:46:53,862:INFO:Initializing Logistic Regression
2023-02-16 19:46:53,862:INFO:Total runtime is 3.0040740966796874e-06 minutes
2023-02-16 19:46:53,867:INFO:SubProcess create_model() called ==================================
2023-02-16 19:46:53,877:INFO:Initializing create_model()
2023-02-16 19:46:53,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:46:53,877:INFO:Checking exceptions
2023-02-16 19:46:53,877:INFO:Importing libraries
2023-02-16 19:46:53,877:INFO:Copying training dataset
2023-02-16 19:46:53,938:INFO:Defining folds
2023-02-16 19:46:53,938:INFO:Declaring metric variables
2023-02-16 19:46:53,943:INFO:Importing untrained model
2023-02-16 19:46:53,949:INFO:Logistic Regression Imported successfully
2023-02-16 19:46:53,958:INFO:Starting cross validation
2023-02-16 19:46:53,959:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:47:15,854:INFO:Calculating mean and std
2023-02-16 19:47:15,855:INFO:Creating metrics dataframe
2023-02-16 19:47:15,860:INFO:Uploading results into container
2023-02-16 19:47:15,861:INFO:Uploading model into container now
2023-02-16 19:47:15,862:INFO:_master_model_container: 1
2023-02-16 19:47:15,863:INFO:_display_container: 2
2023-02-16 19:47:15,863:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2276, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-16 19:47:15,863:INFO:create_model() successfully completed......................................
2023-02-16 19:47:16,096:INFO:SubProcess create_model() end ==================================
2023-02-16 19:47:16,096:INFO:Creating metrics dataframe
2023-02-16 19:47:16,140:INFO:Initializing K Neighbors Classifier
2023-02-16 19:47:16,140:INFO:Total runtime is 0.37130048672358196 minutes
2023-02-16 19:47:16,171:INFO:SubProcess create_model() called ==================================
2023-02-16 19:47:16,172:INFO:Initializing create_model()
2023-02-16 19:47:16,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:47:16,173:INFO:Checking exceptions
2023-02-16 19:47:16,173:INFO:Importing libraries
2023-02-16 19:47:16,173:INFO:Copying training dataset
2023-02-16 19:47:16,223:INFO:Defining folds
2023-02-16 19:47:16,224:INFO:Declaring metric variables
2023-02-16 19:47:16,232:INFO:Importing untrained model
2023-02-16 19:47:16,237:INFO:K Neighbors Classifier Imported successfully
2023-02-16 19:47:16,247:INFO:Starting cross validation
2023-02-16 19:47:16,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:47:17,376:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 19:47:17,429:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 19:47:17,707:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 19:47:17,833:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 19:47:19,584:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 19:47:19,756:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 19:47:19,974:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 19:47:20,101:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 19:47:21,467:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 19:47:21,789:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-16 19:47:22,450:INFO:Calculating mean and std
2023-02-16 19:47:22,451:INFO:Creating metrics dataframe
2023-02-16 19:47:22,457:INFO:Uploading results into container
2023-02-16 19:47:22,457:INFO:Uploading model into container now
2023-02-16 19:47:22,458:INFO:_master_model_container: 2
2023-02-16 19:47:22,458:INFO:_display_container: 2
2023-02-16 19:47:22,458:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-16 19:47:22,458:INFO:create_model() successfully completed......................................
2023-02-16 19:47:22,658:INFO:SubProcess create_model() end ==================================
2023-02-16 19:47:22,658:INFO:Creating metrics dataframe
2023-02-16 19:47:22,670:INFO:Initializing Naive Bayes
2023-02-16 19:47:22,670:INFO:Total runtime is 0.48014634052912397 minutes
2023-02-16 19:47:22,676:INFO:SubProcess create_model() called ==================================
2023-02-16 19:47:22,676:INFO:Initializing create_model()
2023-02-16 19:47:22,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:47:22,676:INFO:Checking exceptions
2023-02-16 19:47:22,677:INFO:Importing libraries
2023-02-16 19:47:22,677:INFO:Copying training dataset
2023-02-16 19:47:22,730:INFO:Defining folds
2023-02-16 19:47:22,730:INFO:Declaring metric variables
2023-02-16 19:47:22,735:INFO:Importing untrained model
2023-02-16 19:47:22,741:INFO:Naive Bayes Imported successfully
2023-02-16 19:47:22,748:INFO:Starting cross validation
2023-02-16 19:47:22,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:47:23,520:INFO:Calculating mean and std
2023-02-16 19:47:23,523:INFO:Creating metrics dataframe
2023-02-16 19:47:23,528:INFO:Uploading results into container
2023-02-16 19:47:23,528:INFO:Uploading model into container now
2023-02-16 19:47:23,529:INFO:_master_model_container: 3
2023-02-16 19:47:23,529:INFO:_display_container: 2
2023-02-16 19:47:23,529:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-16 19:47:23,529:INFO:create_model() successfully completed......................................
2023-02-16 19:47:23,687:INFO:SubProcess create_model() end ==================================
2023-02-16 19:47:23,687:INFO:Creating metrics dataframe
2023-02-16 19:47:23,712:INFO:Initializing Decision Tree Classifier
2023-02-16 19:47:23,712:INFO:Total runtime is 0.49751303990681967 minutes
2023-02-16 19:47:23,717:INFO:SubProcess create_model() called ==================================
2023-02-16 19:47:23,717:INFO:Initializing create_model()
2023-02-16 19:47:23,717:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:47:23,719:INFO:Checking exceptions
2023-02-16 19:47:23,719:INFO:Importing libraries
2023-02-16 19:47:23,719:INFO:Copying training dataset
2023-02-16 19:47:23,772:INFO:Defining folds
2023-02-16 19:47:23,772:INFO:Declaring metric variables
2023-02-16 19:47:23,780:INFO:Importing untrained model
2023-02-16 19:47:23,784:INFO:Decision Tree Classifier Imported successfully
2023-02-16 19:47:23,794:INFO:Starting cross validation
2023-02-16 19:47:23,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:47:27,354:INFO:Calculating mean and std
2023-02-16 19:47:27,356:INFO:Creating metrics dataframe
2023-02-16 19:47:27,361:INFO:Uploading results into container
2023-02-16 19:47:27,362:INFO:Uploading model into container now
2023-02-16 19:47:27,363:INFO:_master_model_container: 4
2023-02-16 19:47:27,363:INFO:_display_container: 2
2023-02-16 19:47:27,364:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2276, splitter='best')
2023-02-16 19:47:27,364:INFO:create_model() successfully completed......................................
2023-02-16 19:47:27,517:INFO:SubProcess create_model() end ==================================
2023-02-16 19:47:27,517:INFO:Creating metrics dataframe
2023-02-16 19:47:27,530:INFO:Initializing SVM - Linear Kernel
2023-02-16 19:47:27,530:INFO:Total runtime is 0.561146859327952 minutes
2023-02-16 19:47:27,534:INFO:SubProcess create_model() called ==================================
2023-02-16 19:47:27,536:INFO:Initializing create_model()
2023-02-16 19:47:27,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:47:27,537:INFO:Checking exceptions
2023-02-16 19:47:27,537:INFO:Importing libraries
2023-02-16 19:47:27,537:INFO:Copying training dataset
2023-02-16 19:47:27,588:INFO:Defining folds
2023-02-16 19:47:27,588:INFO:Declaring metric variables
2023-02-16 19:47:27,594:INFO:Importing untrained model
2023-02-16 19:47:27,598:INFO:SVM - Linear Kernel Imported successfully
2023-02-16 19:47:27,609:INFO:Starting cross validation
2023-02-16 19:47:27,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:47:46,875:INFO:Calculating mean and std
2023-02-16 19:47:46,877:INFO:Creating metrics dataframe
2023-02-16 19:47:46,883:INFO:Uploading results into container
2023-02-16 19:47:46,884:INFO:Uploading model into container now
2023-02-16 19:47:46,884:INFO:_master_model_container: 5
2023-02-16 19:47:46,884:INFO:_display_container: 2
2023-02-16 19:47:46,885:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2276, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-16 19:47:46,885:INFO:create_model() successfully completed......................................
2023-02-16 19:47:47,057:INFO:SubProcess create_model() end ==================================
2023-02-16 19:47:47,057:INFO:Creating metrics dataframe
2023-02-16 19:47:47,069:INFO:Initializing Ridge Classifier
2023-02-16 19:47:47,070:INFO:Total runtime is 0.886809492111206 minutes
2023-02-16 19:47:47,075:INFO:SubProcess create_model() called ==================================
2023-02-16 19:47:47,075:INFO:Initializing create_model()
2023-02-16 19:47:47,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:47:47,076:INFO:Checking exceptions
2023-02-16 19:47:47,076:INFO:Importing libraries
2023-02-16 19:47:47,077:INFO:Copying training dataset
2023-02-16 19:47:47,130:INFO:Defining folds
2023-02-16 19:47:47,130:INFO:Declaring metric variables
2023-02-16 19:47:47,136:INFO:Importing untrained model
2023-02-16 19:47:47,142:INFO:Ridge Classifier Imported successfully
2023-02-16 19:47:47,154:INFO:Starting cross validation
2023-02-16 19:47:47,155:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:47:47,733:INFO:Calculating mean and std
2023-02-16 19:47:47,734:INFO:Creating metrics dataframe
2023-02-16 19:47:47,739:INFO:Uploading results into container
2023-02-16 19:47:47,740:INFO:Uploading model into container now
2023-02-16 19:47:47,741:INFO:_master_model_container: 6
2023-02-16 19:47:47,741:INFO:_display_container: 2
2023-02-16 19:47:47,743:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2276, solver='auto', tol=0.001)
2023-02-16 19:47:47,743:INFO:create_model() successfully completed......................................
2023-02-16 19:47:47,897:INFO:SubProcess create_model() end ==================================
2023-02-16 19:47:47,897:INFO:Creating metrics dataframe
2023-02-16 19:47:47,911:INFO:Initializing Random Forest Classifier
2023-02-16 19:47:47,912:INFO:Total runtime is 0.9008387486139933 minutes
2023-02-16 19:47:47,917:INFO:SubProcess create_model() called ==================================
2023-02-16 19:47:47,918:INFO:Initializing create_model()
2023-02-16 19:47:47,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:47:47,918:INFO:Checking exceptions
2023-02-16 19:47:47,918:INFO:Importing libraries
2023-02-16 19:47:47,918:INFO:Copying training dataset
2023-02-16 19:47:47,971:INFO:Defining folds
2023-02-16 19:47:47,971:INFO:Declaring metric variables
2023-02-16 19:47:47,976:INFO:Importing untrained model
2023-02-16 19:47:47,980:INFO:Random Forest Classifier Imported successfully
2023-02-16 19:47:47,991:INFO:Starting cross validation
2023-02-16 19:47:47,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:48:15,548:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 19:48:15,565:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 19:48:51,937:INFO:Calculating mean and std
2023-02-16 19:48:51,938:INFO:Creating metrics dataframe
2023-02-16 19:48:51,944:INFO:Uploading results into container
2023-02-16 19:48:51,945:INFO:Uploading model into container now
2023-02-16 19:48:51,945:INFO:_master_model_container: 7
2023-02-16 19:48:51,946:INFO:_display_container: 2
2023-02-16 19:48:51,946:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2276, verbose=0, warm_start=False)
2023-02-16 19:48:51,947:INFO:create_model() successfully completed......................................
2023-02-16 19:48:52,108:INFO:SubProcess create_model() end ==================================
2023-02-16 19:48:52,108:INFO:Creating metrics dataframe
2023-02-16 19:48:52,132:INFO:Initializing Quadratic Discriminant Analysis
2023-02-16 19:48:52,132:INFO:Total runtime is 1.9711820205052693 minutes
2023-02-16 19:48:52,139:INFO:SubProcess create_model() called ==================================
2023-02-16 19:48:52,140:INFO:Initializing create_model()
2023-02-16 19:48:52,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:48:52,140:INFO:Checking exceptions
2023-02-16 19:48:52,140:INFO:Importing libraries
2023-02-16 19:48:52,140:INFO:Copying training dataset
2023-02-16 19:48:52,188:INFO:Defining folds
2023-02-16 19:48:52,189:INFO:Declaring metric variables
2023-02-16 19:48:52,195:INFO:Importing untrained model
2023-02-16 19:48:52,199:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-16 19:48:52,209:INFO:Starting cross validation
2023-02-16 19:48:52,210:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:48:54,855:INFO:Calculating mean and std
2023-02-16 19:48:54,857:INFO:Creating metrics dataframe
2023-02-16 19:48:54,860:INFO:Uploading results into container
2023-02-16 19:48:54,860:INFO:Uploading model into container now
2023-02-16 19:48:54,861:INFO:_master_model_container: 8
2023-02-16 19:48:54,861:INFO:_display_container: 2
2023-02-16 19:48:54,861:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-16 19:48:54,861:INFO:create_model() successfully completed......................................
2023-02-16 19:48:55,022:INFO:SubProcess create_model() end ==================================
2023-02-16 19:48:55,022:INFO:Creating metrics dataframe
2023-02-16 19:48:55,038:INFO:Initializing Ada Boost Classifier
2023-02-16 19:48:55,038:INFO:Total runtime is 2.0196136474609374 minutes
2023-02-16 19:48:55,043:INFO:SubProcess create_model() called ==================================
2023-02-16 19:48:55,044:INFO:Initializing create_model()
2023-02-16 19:48:55,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:48:55,044:INFO:Checking exceptions
2023-02-16 19:48:55,044:INFO:Importing libraries
2023-02-16 19:48:55,044:INFO:Copying training dataset
2023-02-16 19:48:55,094:INFO:Defining folds
2023-02-16 19:48:55,095:INFO:Declaring metric variables
2023-02-16 19:48:55,099:INFO:Importing untrained model
2023-02-16 19:48:55,106:INFO:Ada Boost Classifier Imported successfully
2023-02-16 19:48:55,116:INFO:Starting cross validation
2023-02-16 19:48:55,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:49:11,508:INFO:Calculating mean and std
2023-02-16 19:49:11,509:INFO:Creating metrics dataframe
2023-02-16 19:49:11,515:INFO:Uploading results into container
2023-02-16 19:49:11,516:INFO:Uploading model into container now
2023-02-16 19:49:11,516:INFO:_master_model_container: 9
2023-02-16 19:49:11,516:INFO:_display_container: 2
2023-02-16 19:49:11,516:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2276)
2023-02-16 19:49:11,516:INFO:create_model() successfully completed......................................
2023-02-16 19:49:11,675:INFO:SubProcess create_model() end ==================================
2023-02-16 19:49:11,676:INFO:Creating metrics dataframe
2023-02-16 19:49:11,690:INFO:Initializing Gradient Boosting Classifier
2023-02-16 19:49:11,690:INFO:Total runtime is 2.29713503519694 minutes
2023-02-16 19:49:11,694:INFO:SubProcess create_model() called ==================================
2023-02-16 19:49:11,694:INFO:Initializing create_model()
2023-02-16 19:49:11,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:49:11,695:INFO:Checking exceptions
2023-02-16 19:49:11,695:INFO:Importing libraries
2023-02-16 19:49:11,695:INFO:Copying training dataset
2023-02-16 19:49:11,743:INFO:Defining folds
2023-02-16 19:49:11,745:INFO:Declaring metric variables
2023-02-16 19:49:11,750:INFO:Importing untrained model
2023-02-16 19:49:11,756:INFO:Gradient Boosting Classifier Imported successfully
2023-02-16 19:49:11,765:INFO:Starting cross validation
2023-02-16 19:49:11,766:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:50:19,668:INFO:Calculating mean and std
2023-02-16 19:50:19,671:INFO:Creating metrics dataframe
2023-02-16 19:50:19,675:INFO:Uploading results into container
2023-02-16 19:50:19,676:INFO:Uploading model into container now
2023-02-16 19:50:19,676:INFO:_master_model_container: 10
2023-02-16 19:50:19,676:INFO:_display_container: 2
2023-02-16 19:50:19,677:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2276, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-16 19:50:19,677:INFO:create_model() successfully completed......................................
2023-02-16 19:50:19,835:INFO:SubProcess create_model() end ==================================
2023-02-16 19:50:19,836:INFO:Creating metrics dataframe
2023-02-16 19:50:19,852:INFO:Initializing Linear Discriminant Analysis
2023-02-16 19:50:19,852:INFO:Total runtime is 3.4331763943036395 minutes
2023-02-16 19:50:19,856:INFO:SubProcess create_model() called ==================================
2023-02-16 19:50:19,857:INFO:Initializing create_model()
2023-02-16 19:50:19,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:50:19,857:INFO:Checking exceptions
2023-02-16 19:50:19,857:INFO:Importing libraries
2023-02-16 19:50:19,857:INFO:Copying training dataset
2023-02-16 19:50:19,907:INFO:Defining folds
2023-02-16 19:50:19,907:INFO:Declaring metric variables
2023-02-16 19:50:19,911:INFO:Importing untrained model
2023-02-16 19:50:19,918:INFO:Linear Discriminant Analysis Imported successfully
2023-02-16 19:50:19,926:INFO:Starting cross validation
2023-02-16 19:50:19,928:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:50:21,147:INFO:Calculating mean and std
2023-02-16 19:50:21,148:INFO:Creating metrics dataframe
2023-02-16 19:50:21,180:INFO:Uploading results into container
2023-02-16 19:50:21,181:INFO:Uploading model into container now
2023-02-16 19:50:21,182:INFO:_master_model_container: 11
2023-02-16 19:50:21,182:INFO:_display_container: 2
2023-02-16 19:50:21,182:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-16 19:50:21,182:INFO:create_model() successfully completed......................................
2023-02-16 19:50:21,461:INFO:SubProcess create_model() end ==================================
2023-02-16 19:50:21,461:INFO:Creating metrics dataframe
2023-02-16 19:50:21,487:INFO:Initializing Extra Trees Classifier
2023-02-16 19:50:21,488:INFO:Total runtime is 3.460446548461914 minutes
2023-02-16 19:50:21,492:INFO:SubProcess create_model() called ==================================
2023-02-16 19:50:21,493:INFO:Initializing create_model()
2023-02-16 19:50:21,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:50:21,493:INFO:Checking exceptions
2023-02-16 19:50:21,493:INFO:Importing libraries
2023-02-16 19:50:21,493:INFO:Copying training dataset
2023-02-16 19:50:21,545:INFO:Defining folds
2023-02-16 19:50:21,546:INFO:Declaring metric variables
2023-02-16 19:50:21,552:INFO:Importing untrained model
2023-02-16 19:50:21,556:INFO:Extra Trees Classifier Imported successfully
2023-02-16 19:50:21,567:INFO:Starting cross validation
2023-02-16 19:50:21,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:50:57,549:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 19:50:57,699:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 19:51:00,187:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 19:51:31,862:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 19:51:33,601:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-16 19:51:47,279:INFO:Calculating mean and std
2023-02-16 19:51:47,281:INFO:Creating metrics dataframe
2023-02-16 19:51:47,286:INFO:Uploading results into container
2023-02-16 19:51:47,287:INFO:Uploading model into container now
2023-02-16 19:51:47,288:INFO:_master_model_container: 12
2023-02-16 19:51:47,288:INFO:_display_container: 2
2023-02-16 19:51:47,299:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2276, verbose=0, warm_start=False)
2023-02-16 19:51:47,300:INFO:create_model() successfully completed......................................
2023-02-16 19:51:47,673:INFO:SubProcess create_model() end ==================================
2023-02-16 19:51:47,673:INFO:Creating metrics dataframe
2023-02-16 19:51:47,726:INFO:Initializing Extreme Gradient Boosting
2023-02-16 19:51:47,726:INFO:Total runtime is 4.897748736540477 minutes
2023-02-16 19:51:47,743:INFO:SubProcess create_model() called ==================================
2023-02-16 19:51:47,743:INFO:Initializing create_model()
2023-02-16 19:51:47,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:51:47,744:INFO:Checking exceptions
2023-02-16 19:51:47,744:INFO:Importing libraries
2023-02-16 19:51:47,744:INFO:Copying training dataset
2023-02-16 19:51:47,791:INFO:Defining folds
2023-02-16 19:51:47,792:INFO:Declaring metric variables
2023-02-16 19:51:47,797:INFO:Importing untrained model
2023-02-16 19:51:47,802:INFO:Extreme Gradient Boosting Imported successfully
2023-02-16 19:51:47,809:INFO:Starting cross validation
2023-02-16 19:51:47,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:52:36,417:INFO:Calculating mean and std
2023-02-16 19:52:36,418:INFO:Creating metrics dataframe
2023-02-16 19:52:36,423:INFO:Uploading results into container
2023-02-16 19:52:36,424:INFO:Uploading model into container now
2023-02-16 19:52:36,424:INFO:_master_model_container: 13
2023-02-16 19:52:36,424:INFO:_display_container: 2
2023-02-16 19:52:36,439:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-16 19:52:36,449:INFO:create_model() successfully completed......................................
2023-02-16 19:52:36,593:INFO:SubProcess create_model() end ==================================
2023-02-16 19:52:36,593:INFO:Creating metrics dataframe
2023-02-16 19:52:36,649:INFO:Initializing Light Gradient Boosting Machine
2023-02-16 19:52:36,649:INFO:Total runtime is 5.713129468758901 minutes
2023-02-16 19:52:36,655:INFO:SubProcess create_model() called ==================================
2023-02-16 19:52:36,655:INFO:Initializing create_model()
2023-02-16 19:52:36,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:52:36,656:INFO:Checking exceptions
2023-02-16 19:52:36,656:INFO:Importing libraries
2023-02-16 19:52:36,656:INFO:Copying training dataset
2023-02-16 19:52:36,703:INFO:Defining folds
2023-02-16 19:52:36,703:INFO:Declaring metric variables
2023-02-16 19:52:36,707:INFO:Importing untrained model
2023-02-16 19:52:36,713:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-16 19:52:36,723:INFO:Starting cross validation
2023-02-16 19:52:36,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:52:43,578:INFO:Calculating mean and std
2023-02-16 19:52:43,580:INFO:Creating metrics dataframe
2023-02-16 19:52:43,586:INFO:Uploading results into container
2023-02-16 19:52:43,587:INFO:Uploading model into container now
2023-02-16 19:52:43,587:INFO:_master_model_container: 14
2023-02-16 19:52:43,587:INFO:_display_container: 2
2023-02-16 19:52:43,588:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2276, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-16 19:52:43,588:INFO:create_model() successfully completed......................................
2023-02-16 19:52:43,731:INFO:SubProcess create_model() end ==================================
2023-02-16 19:52:43,732:INFO:Creating metrics dataframe
2023-02-16 19:52:43,837:INFO:Initializing Dummy Classifier
2023-02-16 19:52:43,848:INFO:Total runtime is 5.833112458388011 minutes
2023-02-16 19:52:43,853:INFO:SubProcess create_model() called ==================================
2023-02-16 19:52:43,853:INFO:Initializing create_model()
2023-02-16 19:52:43,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B774BFC10>, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:52:43,853:INFO:Checking exceptions
2023-02-16 19:52:43,853:INFO:Importing libraries
2023-02-16 19:52:43,853:INFO:Copying training dataset
2023-02-16 19:52:43,903:INFO:Defining folds
2023-02-16 19:52:43,903:INFO:Declaring metric variables
2023-02-16 19:52:43,907:INFO:Importing untrained model
2023-02-16 19:52:43,913:INFO:Dummy Classifier Imported successfully
2023-02-16 19:52:43,923:INFO:Starting cross validation
2023-02-16 19:52:43,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:52:44,145:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 19:52:44,153:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 19:52:44,161:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 19:52:44,179:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 19:52:44,210:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 19:52:44,219:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-16 19:52:44,346:INFO:Calculating mean and std
2023-02-16 19:52:44,348:INFO:Creating metrics dataframe
2023-02-16 19:52:44,353:INFO:Uploading results into container
2023-02-16 19:52:44,354:INFO:Uploading model into container now
2023-02-16 19:52:44,355:INFO:_master_model_container: 15
2023-02-16 19:52:44,355:INFO:_display_container: 2
2023-02-16 19:52:44,356:INFO:DummyClassifier(constant=None, random_state=2276, strategy='prior')
2023-02-16 19:52:44,357:INFO:create_model() successfully completed......................................
2023-02-16 19:52:44,497:INFO:SubProcess create_model() end ==================================
2023-02-16 19:52:44,497:INFO:Creating metrics dataframe
2023-02-16 19:52:44,592:INFO:Initializing create_model()
2023-02-16 19:52:44,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:52:44,593:INFO:Checking exceptions
2023-02-16 19:52:44,597:INFO:Importing libraries
2023-02-16 19:52:44,597:INFO:Copying training dataset
2023-02-16 19:52:44,643:INFO:Defining folds
2023-02-16 19:52:44,643:INFO:Declaring metric variables
2023-02-16 19:52:44,643:INFO:Importing untrained model
2023-02-16 19:52:44,644:INFO:Declaring custom model
2023-02-16 19:52:44,645:INFO:Extreme Gradient Boosting Imported successfully
2023-02-16 19:52:44,646:INFO:Cross validation set to False
2023-02-16 19:52:44,646:INFO:Fitting Model
2023-02-16 19:52:52,703:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-16 19:52:52,703:INFO:create_model() successfully completed......................................
2023-02-16 19:52:52,856:INFO:Initializing create_model()
2023-02-16 19:52:52,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2276, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:52:52,857:INFO:Checking exceptions
2023-02-16 19:52:52,859:INFO:Importing libraries
2023-02-16 19:52:52,860:INFO:Copying training dataset
2023-02-16 19:52:52,934:INFO:Defining folds
2023-02-16 19:52:52,934:INFO:Declaring metric variables
2023-02-16 19:52:52,934:INFO:Importing untrained model
2023-02-16 19:52:52,934:INFO:Declaring custom model
2023-02-16 19:52:52,935:INFO:Random Forest Classifier Imported successfully
2023-02-16 19:52:52,936:INFO:Cross validation set to False
2023-02-16 19:52:52,936:INFO:Fitting Model
2023-02-16 19:53:01,302:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2276, verbose=0, warm_start=False)
2023-02-16 19:53:01,302:INFO:create_model() successfully completed......................................
2023-02-16 19:53:01,493:INFO:Initializing create_model()
2023-02-16 19:53:01,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2276, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:53:01,496:INFO:Checking exceptions
2023-02-16 19:53:01,499:INFO:Importing libraries
2023-02-16 19:53:01,499:INFO:Copying training dataset
2023-02-16 19:53:01,558:INFO:Defining folds
2023-02-16 19:53:01,558:INFO:Declaring metric variables
2023-02-16 19:53:01,558:INFO:Importing untrained model
2023-02-16 19:53:01,558:INFO:Declaring custom model
2023-02-16 19:53:01,559:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-16 19:53:01,559:INFO:Cross validation set to False
2023-02-16 19:53:01,559:INFO:Fitting Model
2023-02-16 19:53:06,191:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2276, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-16 19:53:06,191:INFO:create_model() successfully completed......................................
2023-02-16 19:53:06,401:INFO:_master_model_container: 15
2023-02-16 19:53:06,402:INFO:_display_container: 2
2023-02-16 19:53:06,404:INFO:[XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2276, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2276, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)]
2023-02-16 19:53:06,404:INFO:compare_models() successfully completed......................................
2023-02-16 19:53:10,642:INFO:Initializing tune_model()
2023-02-16 19:53:10,642:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>)
2023-02-16 19:53:10,642:INFO:Checking exceptions
2023-02-16 19:53:10,642:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-16 19:53:10,818:INFO:Copying training dataset
2023-02-16 19:53:10,860:INFO:Checking base model
2023-02-16 19:53:10,861:INFO:Base model : Extreme Gradient Boosting
2023-02-16 19:53:10,868:INFO:Declaring metric variables
2023-02-16 19:53:10,872:INFO:Defining Hyperparameters
2023-02-16 19:53:11,024:INFO:Tuning with n_jobs=-1
2023-02-16 19:53:11,026:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 19:53:11,026:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 19:53:11,038:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-16 19:53:11,038:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-16 19:53:11,162:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-16 19:58:08,288:INFO:best_params: {'actual_estimator__learning_rate': 0.00017844556963876785, 'actual_estimator__n_estimators': 33, 'actual_estimator__subsample': 0.8305866533978532, 'actual_estimator__max_depth': 4, 'actual_estimator__colsample_bytree': 0.6661434764572317, 'actual_estimator__min_child_weight': 3, 'actual_estimator__reg_alpha': 0.003154994686394082, 'actual_estimator__reg_lambda': 0.10620216861288509, 'actual_estimator__scale_pos_weight': 23.829267001247793}
2023-02-16 19:58:08,288:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-16 19:58:08,289:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-16 19:58:08,290:INFO:Hyperparameter search completed
2023-02-16 19:58:08,291:INFO:SubProcess create_model() called ==================================
2023-02-16 19:58:08,292:INFO:Initializing create_model()
2023-02-16 19:58:08,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B0115D970>, model_only=True, return_train_score=False, kwargs={'learning_rate': 0.00017844556963876785, 'n_estimators': 33, 'subsample': 0.8305866533978532, 'max_depth': 4, 'colsample_bytree': 0.6661434764572317, 'min_child_weight': 3, 'reg_alpha': 0.003154994686394082, 'reg_lambda': 0.10620216861288509, 'scale_pos_weight': 23.829267001247793})
2023-02-16 19:58:08,292:INFO:Checking exceptions
2023-02-16 19:58:08,293:INFO:Importing libraries
2023-02-16 19:58:08,293:INFO:Copying training dataset
2023-02-16 19:58:08,345:INFO:Defining folds
2023-02-16 19:58:08,345:INFO:Declaring metric variables
2023-02-16 19:58:08,349:INFO:Importing untrained model
2023-02-16 19:58:08,350:INFO:Declaring custom model
2023-02-16 19:58:08,355:INFO:Extreme Gradient Boosting Imported successfully
2023-02-16 19:58:08,363:INFO:Starting cross validation
2023-02-16 19:58:08,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:58:17,740:INFO:Calculating mean and std
2023-02-16 19:58:17,741:INFO:Creating metrics dataframe
2023-02-16 19:58:17,750:INFO:Finalizing model
2023-02-16 19:58:18,919:INFO:Uploading results into container
2023-02-16 19:58:18,920:INFO:Uploading model into container now
2023-02-16 19:58:18,921:INFO:_master_model_container: 16
2023-02-16 19:58:18,921:INFO:_display_container: 3
2023-02-16 19:58:18,922:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6661434764572317, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None,
              learning_rate=0.00017844556963876785, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              n_estimators=33, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-16 19:58:18,922:INFO:create_model() successfully completed......................................
2023-02-16 19:58:19,175:INFO:SubProcess create_model() end ==================================
2023-02-16 19:58:19,190:INFO:choose_better activated
2023-02-16 19:58:19,194:INFO:SubProcess create_model() called ==================================
2023-02-16 19:58:19,196:INFO:Initializing create_model()
2023-02-16 19:58:19,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-16 19:58:19,196:INFO:Checking exceptions
2023-02-16 19:58:19,198:INFO:Importing libraries
2023-02-16 19:58:19,199:INFO:Copying training dataset
2023-02-16 19:58:19,282:INFO:Defining folds
2023-02-16 19:58:19,282:INFO:Declaring metric variables
2023-02-16 19:58:19,282:INFO:Importing untrained model
2023-02-16 19:58:19,283:INFO:Declaring custom model
2023-02-16 19:58:19,284:INFO:Extreme Gradient Boosting Imported successfully
2023-02-16 19:58:19,285:INFO:Starting cross validation
2023-02-16 19:58:19,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-16 19:58:20,604:INFO:Calculating mean and std
2023-02-16 19:58:20,604:INFO:Creating metrics dataframe
2023-02-16 19:58:20,606:INFO:Finalizing model
2023-02-16 19:58:20,820:INFO:Uploading results into container
2023-02-16 19:58:20,820:INFO:Uploading model into container now
2023-02-16 19:58:20,820:INFO:_master_model_container: 17
2023-02-16 19:58:20,821:INFO:_display_container: 4
2023-02-16 19:58:20,822:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-16 19:58:20,822:INFO:create_model() successfully completed......................................
2023-02-16 19:58:20,968:INFO:SubProcess create_model() end ==================================
2023-02-16 19:58:20,969:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for Recall is 0.9159
2023-02-16 19:58:20,970:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6661434764572317, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None,
              learning_rate=0.00017844556963876785, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              n_estimators=33, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for Recall is 0.9999
2023-02-16 19:58:20,971:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6661434764572317, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None,
              learning_rate=0.00017844556963876785, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              n_estimators=33, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) is best model
2023-02-16 19:58:20,971:INFO:choose_better completed
2023-02-16 19:58:21,017:INFO:_master_model_container: 17
2023-02-16 19:58:21,017:INFO:_display_container: 3
2023-02-16 19:58:21,018:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.6661434764572317, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None,
              learning_rate=0.00017844556963876785, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=4, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              n_estimators=33, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-16 19:58:21,018:INFO:tune_model() successfully completed......................................
2023-02-16 19:58:21,169:INFO:Initializing tune_model()
2023-02-16 19:58:21,169:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2276, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B05015160>)
2023-02-16 19:58:21,169:INFO:Checking exceptions
2023-02-16 19:58:21,169:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-16 19:58:21,212:INFO:Copying training dataset
2023-02-16 19:58:21,252:INFO:Checking base model
2023-02-16 19:58:21,252:INFO:Base model : Random Forest Classifier
2023-02-16 19:58:21,262:INFO:Declaring metric variables
2023-02-16 19:58:21,267:INFO:Defining Hyperparameters
2023-02-16 19:58:21,416:INFO:Tuning with n_jobs=-1
2023-02-16 19:58:21,418:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 19:58:21,418:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-16 19:58:21,418:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-02-16 19:58:21,418:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-16 19:58:21,419:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-16 19:58:21,425:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-16 20:02:57,218:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:15:42,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-17 09:15:42,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-17 09:15:42,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-17 09:15:42,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-17 09:15:48,871:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-17 09:24:33,083:INFO:PyCaret ClassificationExperiment
2023-02-17 09:24:33,148:INFO:Logging name: clf-default-name
2023-02-17 09:24:33,148:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-17 09:24:33,148:INFO:version 3.0.0.rc9
2023-02-17 09:24:33,148:INFO:Initializing setup()
2023-02-17 09:24:33,148:INFO:self.USI: c784
2023-02-17 09:24:33,148:INFO:self._variable_keys: {'pipeline', 'exp_name_log', 'fold_groups_param', 'y_test', 'gpu_param', 'exp_id', 'X_test', 'y', 'target_param', 'fix_imbalance', 'n_jobs_param', 'X_train', 'fold_generator', 'is_multiclass', 'fold_shuffle_param', 'memory', '_ml_usecase', 'gpu_n_jobs_param', 'USI', '_available_plots', 'X', 'logging_param', 'seed', 'data', 'y_train', 'html_param', 'log_plots_param', 'idx'}
2023-02-17 09:24:33,148:INFO:Checking environment
2023-02-17 09:24:33,148:INFO:python_version: 3.9.15
2023-02-17 09:24:33,148:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-17 09:24:33,148:INFO:machine: AMD64
2023-02-17 09:24:33,148:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-17 09:24:33,149:INFO:Memory: svmem(total=8469581824, available=3888971776, percent=54.1, used=4580610048, free=3888971776)
2023-02-17 09:24:33,149:INFO:Physical Core: 4
2023-02-17 09:24:33,149:INFO:Logical Core: 4
2023-02-17 09:24:33,149:INFO:Checking libraries
2023-02-17 09:24:33,149:INFO:System:
2023-02-17 09:24:33,149:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-17 09:24:33,149:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-17 09:24:33,149:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-17 09:24:33,149:INFO:PyCaret required dependencies:
2023-02-17 09:24:33,149:INFO:                 pip: 22.3.1
2023-02-17 09:24:33,149:INFO:          setuptools: 60.10.0
2023-02-17 09:24:33,149:INFO:             pycaret: 3.0.0rc9
2023-02-17 09:24:33,149:INFO:             IPython: 7.31.1
2023-02-17 09:24:33,149:INFO:          ipywidgets: 7.6.5
2023-02-17 09:24:33,150:INFO:                tqdm: 4.64.1
2023-02-17 09:24:33,150:INFO:               numpy: 1.21.5
2023-02-17 09:24:33,150:INFO:              pandas: 1.4.4
2023-02-17 09:24:33,150:INFO:              jinja2: 2.11.3
2023-02-17 09:24:33,150:INFO:               scipy: 1.9.3
2023-02-17 09:24:33,150:INFO:              joblib: 1.2.0
2023-02-17 09:24:33,150:INFO:             sklearn: 1.0.2
2023-02-17 09:24:33,150:INFO:                pyod: 1.0.7
2023-02-17 09:24:33,150:INFO:            imblearn: 0.10.1
2023-02-17 09:24:33,150:INFO:   category_encoders: 2.6.0
2023-02-17 09:24:33,150:INFO:            lightgbm: 3.3.5
2023-02-17 09:24:33,150:INFO:               numba: 0.56.4
2023-02-17 09:24:33,150:INFO:            requests: 2.28.1
2023-02-17 09:24:33,150:INFO:          matplotlib: 3.6.2
2023-02-17 09:24:33,150:INFO:          scikitplot: 0.3.7
2023-02-17 09:24:33,150:INFO:         yellowbrick: 1.5
2023-02-17 09:24:33,150:INFO:              plotly: 5.9.0
2023-02-17 09:24:33,150:INFO:             kaleido: 0.2.1
2023-02-17 09:24:33,150:INFO:         statsmodels: 0.13.2
2023-02-17 09:24:33,150:INFO:              sktime: 0.16.1
2023-02-17 09:24:33,151:INFO:               tbats: 1.1.2
2023-02-17 09:24:33,151:INFO:            pmdarima: 2.0.2
2023-02-17 09:24:33,151:INFO:              psutil: 5.9.0
2023-02-17 09:24:33,151:INFO:PyCaret optional dependencies:
2023-02-17 09:24:33,180:INFO:                shap: 0.41.0
2023-02-17 09:24:33,180:INFO:           interpret: Not installed
2023-02-17 09:24:33,180:INFO:                umap: Not installed
2023-02-17 09:24:33,180:INFO:    pandas_profiling: 4.0.0
2023-02-17 09:24:33,180:INFO:  explainerdashboard: 0.3.6.2
2023-02-17 09:24:33,180:INFO:             autoviz: 0.1.58
2023-02-17 09:24:33,180:INFO:           fairlearn: Not installed
2023-02-17 09:24:33,181:INFO:             xgboost: 1.7.3
2023-02-17 09:24:33,181:INFO:            catboost: Not installed
2023-02-17 09:24:33,181:INFO:              kmodes: Not installed
2023-02-17 09:24:33,181:INFO:             mlxtend: Not installed
2023-02-17 09:24:33,181:INFO:       statsforecast: Not installed
2023-02-17 09:24:33,181:INFO:        tune_sklearn: Not installed
2023-02-17 09:24:33,181:INFO:                 ray: Not installed
2023-02-17 09:24:33,181:INFO:            hyperopt: Not installed
2023-02-17 09:24:33,181:INFO:              optuna: 2.10.1
2023-02-17 09:24:33,181:INFO:               skopt: Not installed
2023-02-17 09:24:33,181:INFO:              mlflow: Not installed
2023-02-17 09:24:33,181:INFO:              gradio: Not installed
2023-02-17 09:24:33,181:INFO:             fastapi: Not installed
2023-02-17 09:24:33,181:INFO:             uvicorn: Not installed
2023-02-17 09:24:33,181:INFO:              m2cgen: Not installed
2023-02-17 09:24:33,181:INFO:           evidently: Not installed
2023-02-17 09:24:33,181:INFO:               fugue: Not installed
2023-02-17 09:24:33,181:INFO:           streamlit: Not installed
2023-02-17 09:24:33,181:INFO:             prophet: Not installed
2023-02-17 09:24:33,181:INFO:None
2023-02-17 09:24:33,181:INFO:Set up data.
2023-02-17 09:24:33,246:INFO:Set up train/test split.
2023-02-17 09:24:33,324:INFO:Set up index.
2023-02-17 09:24:33,330:INFO:Set up folding strategy.
2023-02-17 09:24:33,330:INFO:Assigning column types.
2023-02-17 09:24:33,355:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-17 09:24:33,405:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-17 09:24:33,431:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 09:24:33,488:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 09:24:33,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 09:24:33,541:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-17 09:24:33,542:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 09:24:33,576:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 09:24:33,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 09:24:33,579:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-17 09:24:33,661:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 09:24:33,694:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 09:24:33,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 09:24:33,748:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 09:24:33,778:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 09:24:33,781:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 09:24:33,781:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-17 09:24:33,870:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 09:24:33,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 09:24:34,013:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 09:24:34,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 09:24:34,054:INFO:Finished creating preprocessing pipeline.
2023-02-17 09:24:34,058:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2023-02-17 09:24:34,058:INFO:Creating final display dataframe.
2023-02-17 09:24:34,351:INFO:Setup _display_container:                    Description         Value
0                   Session id          2224
1                       Target  inadimplente
2                  Target type        Binary
3          Original data shape  (164270, 11)
4       Transformed data shape  (164270, 11)
5  Transformed train set shape  (114988, 11)
6   Transformed test set shape   (49282, 11)
7             Numeric features            10
2023-02-17 09:24:34,450:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 09:24:34,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 09:24:34,541:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 09:24:34,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 09:24:34,544:INFO:setup() successfully completed in 1.51s...............
2023-02-17 09:24:34,691:INFO:Initializing compare_models()
2023-02-17 09:24:34,691:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-17 09:24:34,691:INFO:Checking exceptions
2023-02-17 09:24:34,722:INFO:Preparing display monitor
2023-02-17 09:24:34,853:INFO:Initializing Logistic Regression
2023-02-17 09:24:34,854:INFO:Total runtime is 1.666545867919922e-05 minutes
2023-02-17 09:24:34,858:INFO:SubProcess create_model() called ==================================
2023-02-17 09:24:34,858:INFO:Initializing create_model()
2023-02-17 09:24:34,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:24:34,858:INFO:Checking exceptions
2023-02-17 09:24:34,858:INFO:Importing libraries
2023-02-17 09:24:34,858:INFO:Copying training dataset
2023-02-17 09:24:34,905:INFO:Defining folds
2023-02-17 09:24:34,905:INFO:Declaring metric variables
2023-02-17 09:24:34,910:INFO:Importing untrained model
2023-02-17 09:24:34,914:INFO:Logistic Regression Imported successfully
2023-02-17 09:24:34,923:INFO:Starting cross validation
2023-02-17 09:24:34,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:25:07,381:INFO:Calculating mean and std
2023-02-17 09:25:07,382:INFO:Creating metrics dataframe
2023-02-17 09:25:07,387:INFO:Uploading results into container
2023-02-17 09:25:07,387:INFO:Uploading model into container now
2023-02-17 09:25:07,388:INFO:_master_model_container: 1
2023-02-17 09:25:07,388:INFO:_display_container: 2
2023-02-17 09:25:07,389:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2224, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-17 09:25:07,390:INFO:create_model() successfully completed......................................
2023-02-17 09:25:07,525:INFO:SubProcess create_model() end ==================================
2023-02-17 09:25:07,525:INFO:Creating metrics dataframe
2023-02-17 09:25:07,525:INFO:Initializing K Neighbors Classifier
2023-02-17 09:25:07,525:INFO:Total runtime is 0.5445442676544189 minutes
2023-02-17 09:25:07,544:INFO:SubProcess create_model() called ==================================
2023-02-17 09:25:07,545:INFO:Initializing create_model()
2023-02-17 09:25:07,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:25:07,545:INFO:Checking exceptions
2023-02-17 09:25:07,545:INFO:Importing libraries
2023-02-17 09:25:07,545:INFO:Copying training dataset
2023-02-17 09:25:07,596:INFO:Defining folds
2023-02-17 09:25:07,597:INFO:Declaring metric variables
2023-02-17 09:25:07,601:INFO:Importing untrained model
2023-02-17 09:25:07,605:INFO:K Neighbors Classifier Imported successfully
2023-02-17 09:25:07,607:INFO:Starting cross validation
2023-02-17 09:25:07,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:25:08,657:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 09:25:08,658:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 09:25:08,791:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 09:25:09,046:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 09:25:10,581:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 09:25:10,684:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 09:25:10,880:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 09:25:11,004:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 09:25:12,389:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 09:25:12,586:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 09:25:13,277:INFO:Calculating mean and std
2023-02-17 09:25:13,279:INFO:Creating metrics dataframe
2023-02-17 09:25:13,284:INFO:Uploading results into container
2023-02-17 09:25:13,285:INFO:Uploading model into container now
2023-02-17 09:25:13,286:INFO:_master_model_container: 2
2023-02-17 09:25:13,286:INFO:_display_container: 2
2023-02-17 09:25:13,287:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-17 09:25:13,287:INFO:create_model() successfully completed......................................
2023-02-17 09:25:13,390:INFO:SubProcess create_model() end ==================================
2023-02-17 09:25:13,390:INFO:Creating metrics dataframe
2023-02-17 09:25:13,409:INFO:Initializing Naive Bayes
2023-02-17 09:25:13,409:INFO:Total runtime is 0.6425998250643412 minutes
2023-02-17 09:25:13,415:INFO:SubProcess create_model() called ==================================
2023-02-17 09:25:13,415:INFO:Initializing create_model()
2023-02-17 09:25:13,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:25:13,415:INFO:Checking exceptions
2023-02-17 09:25:13,416:INFO:Importing libraries
2023-02-17 09:25:13,416:INFO:Copying training dataset
2023-02-17 09:25:13,456:INFO:Defining folds
2023-02-17 09:25:13,456:INFO:Declaring metric variables
2023-02-17 09:25:13,473:INFO:Importing untrained model
2023-02-17 09:25:13,477:INFO:Naive Bayes Imported successfully
2023-02-17 09:25:13,486:INFO:Starting cross validation
2023-02-17 09:25:13,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:25:14,009:INFO:Calculating mean and std
2023-02-17 09:25:14,011:INFO:Creating metrics dataframe
2023-02-17 09:25:14,017:INFO:Uploading results into container
2023-02-17 09:25:14,018:INFO:Uploading model into container now
2023-02-17 09:25:14,018:INFO:_master_model_container: 3
2023-02-17 09:25:14,018:INFO:_display_container: 2
2023-02-17 09:25:14,018:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-17 09:25:14,018:INFO:create_model() successfully completed......................................
2023-02-17 09:25:14,138:INFO:SubProcess create_model() end ==================================
2023-02-17 09:25:14,138:INFO:Creating metrics dataframe
2023-02-17 09:25:14,138:INFO:Initializing Decision Tree Classifier
2023-02-17 09:25:14,138:INFO:Total runtime is 0.6547595540682475 minutes
2023-02-17 09:25:14,156:INFO:SubProcess create_model() called ==================================
2023-02-17 09:25:14,157:INFO:Initializing create_model()
2023-02-17 09:25:14,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:25:14,157:INFO:Checking exceptions
2023-02-17 09:25:14,157:INFO:Importing libraries
2023-02-17 09:25:14,157:INFO:Copying training dataset
2023-02-17 09:25:14,205:INFO:Defining folds
2023-02-17 09:25:14,205:INFO:Declaring metric variables
2023-02-17 09:25:14,205:INFO:Importing untrained model
2023-02-17 09:25:14,205:INFO:Decision Tree Classifier Imported successfully
2023-02-17 09:25:14,229:INFO:Starting cross validation
2023-02-17 09:25:14,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:25:17,990:INFO:Calculating mean and std
2023-02-17 09:25:17,991:INFO:Creating metrics dataframe
2023-02-17 09:25:17,995:INFO:Uploading results into container
2023-02-17 09:25:17,995:INFO:Uploading model into container now
2023-02-17 09:25:17,996:INFO:_master_model_container: 4
2023-02-17 09:25:17,996:INFO:_display_container: 2
2023-02-17 09:25:17,997:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2224, splitter='best')
2023-02-17 09:25:17,997:INFO:create_model() successfully completed......................................
2023-02-17 09:25:18,130:INFO:SubProcess create_model() end ==================================
2023-02-17 09:25:18,130:INFO:Creating metrics dataframe
2023-02-17 09:25:18,133:INFO:Initializing SVM - Linear Kernel
2023-02-17 09:25:18,133:INFO:Total runtime is 0.7213334282239279 minutes
2023-02-17 09:25:18,133:INFO:SubProcess create_model() called ==================================
2023-02-17 09:25:18,133:INFO:Initializing create_model()
2023-02-17 09:25:18,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:25:18,133:INFO:Checking exceptions
2023-02-17 09:25:18,133:INFO:Importing libraries
2023-02-17 09:25:18,133:INFO:Copying training dataset
2023-02-17 09:25:18,182:INFO:Defining folds
2023-02-17 09:25:18,182:INFO:Declaring metric variables
2023-02-17 09:25:18,201:INFO:Importing untrained model
2023-02-17 09:25:18,206:INFO:SVM - Linear Kernel Imported successfully
2023-02-17 09:25:18,213:INFO:Starting cross validation
2023-02-17 09:25:18,215:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:25:35,922:INFO:Calculating mean and std
2023-02-17 09:25:35,924:INFO:Creating metrics dataframe
2023-02-17 09:25:35,929:INFO:Uploading results into container
2023-02-17 09:25:35,930:INFO:Uploading model into container now
2023-02-17 09:25:35,931:INFO:_master_model_container: 5
2023-02-17 09:25:35,931:INFO:_display_container: 2
2023-02-17 09:25:35,932:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2224, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-17 09:25:35,932:INFO:create_model() successfully completed......................................
2023-02-17 09:25:36,036:INFO:SubProcess create_model() end ==================================
2023-02-17 09:25:36,036:INFO:Creating metrics dataframe
2023-02-17 09:25:36,062:INFO:Initializing Ridge Classifier
2023-02-17 09:25:36,062:INFO:Total runtime is 1.0201630791028342 minutes
2023-02-17 09:25:36,067:INFO:SubProcess create_model() called ==================================
2023-02-17 09:25:36,067:INFO:Initializing create_model()
2023-02-17 09:25:36,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:25:36,067:INFO:Checking exceptions
2023-02-17 09:25:36,067:INFO:Importing libraries
2023-02-17 09:25:36,067:INFO:Copying training dataset
2023-02-17 09:25:36,118:INFO:Defining folds
2023-02-17 09:25:36,119:INFO:Declaring metric variables
2023-02-17 09:25:36,123:INFO:Importing untrained model
2023-02-17 09:25:36,126:INFO:Ridge Classifier Imported successfully
2023-02-17 09:25:36,126:INFO:Starting cross validation
2023-02-17 09:25:36,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:25:36,656:INFO:Calculating mean and std
2023-02-17 09:25:36,657:INFO:Creating metrics dataframe
2023-02-17 09:25:36,662:INFO:Uploading results into container
2023-02-17 09:25:36,663:INFO:Uploading model into container now
2023-02-17 09:25:36,664:INFO:_master_model_container: 6
2023-02-17 09:25:36,664:INFO:_display_container: 2
2023-02-17 09:25:36,665:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2224, solver='auto', tol=0.001)
2023-02-17 09:25:36,665:INFO:create_model() successfully completed......................................
2023-02-17 09:25:36,768:INFO:SubProcess create_model() end ==================================
2023-02-17 09:25:36,768:INFO:Creating metrics dataframe
2023-02-17 09:25:36,792:INFO:Initializing Random Forest Classifier
2023-02-17 09:25:36,792:INFO:Total runtime is 1.0323314785957338 minutes
2023-02-17 09:25:36,797:INFO:SubProcess create_model() called ==================================
2023-02-17 09:25:36,798:INFO:Initializing create_model()
2023-02-17 09:25:36,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:25:36,798:INFO:Checking exceptions
2023-02-17 09:25:36,798:INFO:Importing libraries
2023-02-17 09:25:36,798:INFO:Copying training dataset
2023-02-17 09:25:36,853:INFO:Defining folds
2023-02-17 09:25:36,853:INFO:Declaring metric variables
2023-02-17 09:25:36,858:INFO:Importing untrained model
2023-02-17 09:25:36,863:INFO:Random Forest Classifier Imported successfully
2023-02-17 09:25:36,865:INFO:Starting cross validation
2023-02-17 09:25:36,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:26:05,994:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:26:06,664:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:26:08,559:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:26:30,723:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:26:32,717:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 3.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:26:35,330:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:26:43,675:INFO:Calculating mean and std
2023-02-17 09:26:43,677:INFO:Creating metrics dataframe
2023-02-17 09:26:43,681:INFO:Uploading results into container
2023-02-17 09:26:43,682:INFO:Uploading model into container now
2023-02-17 09:26:43,682:INFO:_master_model_container: 7
2023-02-17 09:26:43,683:INFO:_display_container: 2
2023-02-17 09:26:43,683:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2224, verbose=0, warm_start=False)
2023-02-17 09:26:43,684:INFO:create_model() successfully completed......................................
2023-02-17 09:26:43,804:INFO:SubProcess create_model() end ==================================
2023-02-17 09:26:43,805:INFO:Creating metrics dataframe
2023-02-17 09:26:43,821:INFO:Initializing Quadratic Discriminant Analysis
2023-02-17 09:26:43,821:INFO:Total runtime is 2.1494673728942875 minutes
2023-02-17 09:26:43,839:INFO:SubProcess create_model() called ==================================
2023-02-17 09:26:43,840:INFO:Initializing create_model()
2023-02-17 09:26:43,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:26:43,840:INFO:Checking exceptions
2023-02-17 09:26:43,841:INFO:Importing libraries
2023-02-17 09:26:43,841:INFO:Copying training dataset
2023-02-17 09:26:43,894:INFO:Defining folds
2023-02-17 09:26:43,894:INFO:Declaring metric variables
2023-02-17 09:26:43,899:INFO:Importing untrained model
2023-02-17 09:26:43,904:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-17 09:26:43,904:INFO:Starting cross validation
2023-02-17 09:26:43,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:26:52,155:INFO:Calculating mean and std
2023-02-17 09:26:52,157:INFO:Creating metrics dataframe
2023-02-17 09:26:52,162:INFO:Uploading results into container
2023-02-17 09:26:52,163:INFO:Uploading model into container now
2023-02-17 09:26:52,163:INFO:_master_model_container: 8
2023-02-17 09:26:52,163:INFO:_display_container: 2
2023-02-17 09:26:52,164:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-17 09:26:52,164:INFO:create_model() successfully completed......................................
2023-02-17 09:26:52,268:INFO:SubProcess create_model() end ==================================
2023-02-17 09:26:52,268:INFO:Creating metrics dataframe
2023-02-17 09:26:52,295:INFO:Initializing Ada Boost Classifier
2023-02-17 09:26:52,295:INFO:Total runtime is 2.290701830387116 minutes
2023-02-17 09:26:52,300:INFO:SubProcess create_model() called ==================================
2023-02-17 09:26:52,300:INFO:Initializing create_model()
2023-02-17 09:26:52,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:26:52,300:INFO:Checking exceptions
2023-02-17 09:26:52,300:INFO:Importing libraries
2023-02-17 09:26:52,300:INFO:Copying training dataset
2023-02-17 09:26:52,354:INFO:Defining folds
2023-02-17 09:26:52,354:INFO:Declaring metric variables
2023-02-17 09:26:52,360:INFO:Importing untrained model
2023-02-17 09:26:52,363:INFO:Ada Boost Classifier Imported successfully
2023-02-17 09:26:52,363:INFO:Starting cross validation
2023-02-17 09:26:52,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:27:11,803:INFO:Calculating mean and std
2023-02-17 09:27:11,805:INFO:Creating metrics dataframe
2023-02-17 09:27:11,809:INFO:Uploading results into container
2023-02-17 09:27:11,809:INFO:Uploading model into container now
2023-02-17 09:27:11,810:INFO:_master_model_container: 9
2023-02-17 09:27:11,810:INFO:_display_container: 2
2023-02-17 09:27:11,810:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2224)
2023-02-17 09:27:11,811:INFO:create_model() successfully completed......................................
2023-02-17 09:27:11,935:INFO:SubProcess create_model() end ==================================
2023-02-17 09:27:11,935:INFO:Creating metrics dataframe
2023-02-17 09:27:11,947:INFO:Initializing Gradient Boosting Classifier
2023-02-17 09:27:11,948:INFO:Total runtime is 2.6182504773139956 minutes
2023-02-17 09:27:11,953:INFO:SubProcess create_model() called ==================================
2023-02-17 09:27:11,953:INFO:Initializing create_model()
2023-02-17 09:27:11,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:27:11,953:INFO:Checking exceptions
2023-02-17 09:27:11,954:INFO:Importing libraries
2023-02-17 09:27:11,954:INFO:Copying training dataset
2023-02-17 09:27:12,004:INFO:Defining folds
2023-02-17 09:27:12,005:INFO:Declaring metric variables
2023-02-17 09:27:12,009:INFO:Importing untrained model
2023-02-17 09:27:12,014:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 09:27:12,022:INFO:Starting cross validation
2023-02-17 09:27:12,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:28:25,036:INFO:Calculating mean and std
2023-02-17 09:28:25,037:INFO:Creating metrics dataframe
2023-02-17 09:28:25,044:INFO:Uploading results into container
2023-02-17 09:28:25,045:INFO:Uploading model into container now
2023-02-17 09:28:25,045:INFO:_master_model_container: 10
2023-02-17 09:28:25,046:INFO:_display_container: 2
2023-02-17 09:28:25,046:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2224, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 09:28:25,046:INFO:create_model() successfully completed......................................
2023-02-17 09:28:25,169:INFO:SubProcess create_model() end ==================================
2023-02-17 09:28:25,169:INFO:Creating metrics dataframe
2023-02-17 09:28:25,183:INFO:Initializing Linear Discriminant Analysis
2023-02-17 09:28:25,183:INFO:Total runtime is 3.838838263352712 minutes
2023-02-17 09:28:25,187:INFO:SubProcess create_model() called ==================================
2023-02-17 09:28:25,188:INFO:Initializing create_model()
2023-02-17 09:28:25,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:28:25,188:INFO:Checking exceptions
2023-02-17 09:28:25,188:INFO:Importing libraries
2023-02-17 09:28:25,188:INFO:Copying training dataset
2023-02-17 09:28:25,247:INFO:Defining folds
2023-02-17 09:28:25,248:INFO:Declaring metric variables
2023-02-17 09:28:25,253:INFO:Importing untrained model
2023-02-17 09:28:25,261:INFO:Linear Discriminant Analysis Imported successfully
2023-02-17 09:28:25,270:INFO:Starting cross validation
2023-02-17 09:28:25,271:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:28:26,440:INFO:Calculating mean and std
2023-02-17 09:28:26,445:INFO:Creating metrics dataframe
2023-02-17 09:28:26,449:INFO:Uploading results into container
2023-02-17 09:28:26,449:INFO:Uploading model into container now
2023-02-17 09:28:26,450:INFO:_master_model_container: 11
2023-02-17 09:28:26,450:INFO:_display_container: 2
2023-02-17 09:28:26,450:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-17 09:28:26,450:INFO:create_model() successfully completed......................................
2023-02-17 09:28:26,601:INFO:SubProcess create_model() end ==================================
2023-02-17 09:28:26,602:INFO:Creating metrics dataframe
2023-02-17 09:28:26,615:INFO:Initializing Extra Trees Classifier
2023-02-17 09:28:26,615:INFO:Total runtime is 3.862707765897115 minutes
2023-02-17 09:28:26,619:INFO:SubProcess create_model() called ==================================
2023-02-17 09:28:26,620:INFO:Initializing create_model()
2023-02-17 09:28:26,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:28:26,620:INFO:Checking exceptions
2023-02-17 09:28:26,620:INFO:Importing libraries
2023-02-17 09:28:26,620:INFO:Copying training dataset
2023-02-17 09:28:26,761:INFO:Defining folds
2023-02-17 09:28:26,761:INFO:Declaring metric variables
2023-02-17 09:28:26,767:INFO:Importing untrained model
2023-02-17 09:28:26,772:INFO:Extra Trees Classifier Imported successfully
2023-02-17 09:28:26,783:INFO:Starting cross validation
2023-02-17 09:28:26,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:29:37,590:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:29:37,590:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 3.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:29:37,630:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:31:14,037:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:31:16,940:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:32:22,317:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:32:27,953:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 2.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 09:32:28,674:INFO:Calculating mean and std
2023-02-17 09:32:28,681:INFO:Creating metrics dataframe
2023-02-17 09:32:28,707:INFO:Uploading results into container
2023-02-17 09:32:28,708:INFO:Uploading model into container now
2023-02-17 09:32:28,752:INFO:_master_model_container: 12
2023-02-17 09:32:28,753:INFO:_display_container: 2
2023-02-17 09:32:28,754:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2224, verbose=0, warm_start=False)
2023-02-17 09:32:28,754:INFO:create_model() successfully completed......................................
2023-02-17 09:32:29,177:INFO:SubProcess create_model() end ==================================
2023-02-17 09:32:29,178:INFO:Creating metrics dataframe
2023-02-17 09:32:29,251:INFO:Initializing Extreme Gradient Boosting
2023-02-17 09:32:29,251:INFO:Total runtime is 7.906640140215556 minutes
2023-02-17 09:32:29,256:INFO:SubProcess create_model() called ==================================
2023-02-17 09:32:29,257:INFO:Initializing create_model()
2023-02-17 09:32:29,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:32:29,257:INFO:Checking exceptions
2023-02-17 09:32:29,257:INFO:Importing libraries
2023-02-17 09:32:29,258:INFO:Copying training dataset
2023-02-17 09:32:29,310:INFO:Defining folds
2023-02-17 09:32:29,310:INFO:Declaring metric variables
2023-02-17 09:32:29,380:INFO:Importing untrained model
2023-02-17 09:32:29,385:INFO:Extreme Gradient Boosting Imported successfully
2023-02-17 09:32:29,393:INFO:Starting cross validation
2023-02-17 09:32:29,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:33:21,221:INFO:Calculating mean and std
2023-02-17 09:33:21,222:INFO:Creating metrics dataframe
2023-02-17 09:33:21,225:INFO:Uploading results into container
2023-02-17 09:33:21,226:INFO:Uploading model into container now
2023-02-17 09:33:21,226:INFO:_master_model_container: 13
2023-02-17 09:33:21,226:INFO:_display_container: 2
2023-02-17 09:33:21,228:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-17 09:33:21,229:INFO:create_model() successfully completed......................................
2023-02-17 09:33:21,346:INFO:SubProcess create_model() end ==================================
2023-02-17 09:33:21,346:INFO:Creating metrics dataframe
2023-02-17 09:33:21,457:INFO:Initializing Light Gradient Boosting Machine
2023-02-17 09:33:21,457:INFO:Total runtime is 8.77673894961675 minutes
2023-02-17 09:33:21,463:INFO:SubProcess create_model() called ==================================
2023-02-17 09:33:21,463:INFO:Initializing create_model()
2023-02-17 09:33:21,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:33:21,464:INFO:Checking exceptions
2023-02-17 09:33:21,464:INFO:Importing libraries
2023-02-17 09:33:21,464:INFO:Copying training dataset
2023-02-17 09:33:21,517:INFO:Defining folds
2023-02-17 09:33:21,517:INFO:Declaring metric variables
2023-02-17 09:33:21,522:INFO:Importing untrained model
2023-02-17 09:33:21,531:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 09:33:21,540:INFO:Starting cross validation
2023-02-17 09:33:21,541:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:33:31,178:INFO:Calculating mean and std
2023-02-17 09:33:31,179:INFO:Creating metrics dataframe
2023-02-17 09:33:31,187:INFO:Uploading results into container
2023-02-17 09:33:31,188:INFO:Uploading model into container now
2023-02-17 09:33:31,188:INFO:_master_model_container: 14
2023-02-17 09:33:31,188:INFO:_display_container: 2
2023-02-17 09:33:31,189:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2224, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 09:33:31,189:INFO:create_model() successfully completed......................................
2023-02-17 09:33:31,323:INFO:SubProcess create_model() end ==================================
2023-02-17 09:33:31,323:INFO:Creating metrics dataframe
2023-02-17 09:33:31,339:INFO:Initializing Dummy Classifier
2023-02-17 09:33:31,340:INFO:Total runtime is 8.941449848810832 minutes
2023-02-17 09:33:31,343:INFO:SubProcess create_model() called ==================================
2023-02-17 09:33:31,343:INFO:Initializing create_model()
2023-02-17 09:33:31,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B174BA610>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:33:31,344:INFO:Checking exceptions
2023-02-17 09:33:31,344:INFO:Importing libraries
2023-02-17 09:33:31,344:INFO:Copying training dataset
2023-02-17 09:33:31,403:INFO:Defining folds
2023-02-17 09:33:31,403:INFO:Declaring metric variables
2023-02-17 09:33:31,408:INFO:Importing untrained model
2023-02-17 09:33:31,416:INFO:Dummy Classifier Imported successfully
2023-02-17 09:33:31,425:INFO:Starting cross validation
2023-02-17 09:33:31,427:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:33:31,692:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 09:33:31,696:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 09:33:31,717:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 09:33:31,727:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 09:33:31,755:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 09:33:31,765:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 09:33:31,901:INFO:Calculating mean and std
2023-02-17 09:33:31,903:INFO:Creating metrics dataframe
2023-02-17 09:33:31,907:INFO:Uploading results into container
2023-02-17 09:33:31,908:INFO:Uploading model into container now
2023-02-17 09:33:31,909:INFO:_master_model_container: 15
2023-02-17 09:33:31,909:INFO:_display_container: 2
2023-02-17 09:33:31,909:INFO:DummyClassifier(constant=None, random_state=2224, strategy='prior')
2023-02-17 09:33:31,909:INFO:create_model() successfully completed......................................
2023-02-17 09:33:32,031:INFO:SubProcess create_model() end ==================================
2023-02-17 09:33:32,032:INFO:Creating metrics dataframe
2023-02-17 09:33:32,151:INFO:Initializing create_model()
2023-02-17 09:33:32,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:33:32,151:INFO:Checking exceptions
2023-02-17 09:33:32,217:INFO:Importing libraries
2023-02-17 09:33:32,217:INFO:Copying training dataset
2023-02-17 09:33:32,271:INFO:Defining folds
2023-02-17 09:33:32,271:INFO:Declaring metric variables
2023-02-17 09:33:32,271:INFO:Importing untrained model
2023-02-17 09:33:32,271:INFO:Declaring custom model
2023-02-17 09:33:32,272:INFO:Extreme Gradient Boosting Imported successfully
2023-02-17 09:33:32,273:INFO:Cross validation set to False
2023-02-17 09:33:32,273:INFO:Fitting Model
2023-02-17 09:33:39,626:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-17 09:33:39,627:INFO:create_model() successfully completed......................................
2023-02-17 09:33:39,741:INFO:Initializing create_model()
2023-02-17 09:33:39,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2224, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:33:39,742:INFO:Checking exceptions
2023-02-17 09:33:39,744:INFO:Importing libraries
2023-02-17 09:33:39,744:INFO:Copying training dataset
2023-02-17 09:33:39,792:INFO:Defining folds
2023-02-17 09:33:39,792:INFO:Declaring metric variables
2023-02-17 09:33:39,793:INFO:Importing untrained model
2023-02-17 09:33:39,793:INFO:Declaring custom model
2023-02-17 09:33:39,793:INFO:Random Forest Classifier Imported successfully
2023-02-17 09:33:39,794:INFO:Cross validation set to False
2023-02-17 09:33:39,794:INFO:Fitting Model
2023-02-17 09:33:46,959:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2224, verbose=0, warm_start=False)
2023-02-17 09:33:46,959:INFO:create_model() successfully completed......................................
2023-02-17 09:33:47,081:INFO:Initializing create_model()
2023-02-17 09:33:47,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2224, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:33:47,081:INFO:Checking exceptions
2023-02-17 09:33:47,084:INFO:Importing libraries
2023-02-17 09:33:47,084:INFO:Copying training dataset
2023-02-17 09:33:47,135:INFO:Defining folds
2023-02-17 09:33:47,135:INFO:Declaring metric variables
2023-02-17 09:33:47,135:INFO:Importing untrained model
2023-02-17 09:33:47,135:INFO:Declaring custom model
2023-02-17 09:33:47,137:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 09:33:47,138:INFO:Cross validation set to False
2023-02-17 09:33:47,138:INFO:Fitting Model
2023-02-17 09:33:48,019:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2224, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 09:33:48,019:INFO:create_model() successfully completed......................................
2023-02-17 09:33:48,216:INFO:_master_model_container: 15
2023-02-17 09:33:48,216:INFO:_display_container: 2
2023-02-17 09:33:48,218:INFO:[XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2224, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2224, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)]
2023-02-17 09:33:48,218:INFO:compare_models() successfully completed......................................
2023-02-17 09:33:49,074:INFO:Initializing tune_model()
2023-02-17 09:33:49,074:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>)
2023-02-17 09:33:49,075:INFO:Checking exceptions
2023-02-17 09:33:49,075:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-17 09:33:49,125:INFO:Copying training dataset
2023-02-17 09:33:49,162:INFO:Checking base model
2023-02-17 09:33:49,162:INFO:Base model : Extreme Gradient Boosting
2023-02-17 09:33:49,166:INFO:Declaring metric variables
2023-02-17 09:33:49,172:INFO:Defining Hyperparameters
2023-02-17 09:33:49,291:INFO:Tuning with n_jobs=-1
2023-02-17 09:33:49,304:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 09:33:49,304:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 09:33:49,305:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-17 09:33:49,586:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-17 09:33:49,615:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-17 09:44:20,041:INFO:best_params: {'actual_estimator__learning_rate': 0.00012808973545033744, 'actual_estimator__n_estimators': 231, 'actual_estimator__subsample': 0.23923318430747484, 'actual_estimator__max_depth': 8, 'actual_estimator__colsample_bytree': 0.5621796078837737, 'actual_estimator__min_child_weight': 3, 'actual_estimator__reg_alpha': 1.124181419567019e-09, 'actual_estimator__reg_lambda': 0.4278254229932558, 'actual_estimator__scale_pos_weight': 46.2299544557376}
2023-02-17 09:44:20,041:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-17 09:44:20,042:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-17 09:44:20,043:INFO:Hyperparameter search completed
2023-02-17 09:44:20,043:INFO:SubProcess create_model() called ==================================
2023-02-17 09:44:20,044:INFO:Initializing create_model()
2023-02-17 09:44:20,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B16BD3730>, model_only=True, return_train_score=False, kwargs={'learning_rate': 0.00012808973545033744, 'n_estimators': 231, 'subsample': 0.23923318430747484, 'max_depth': 8, 'colsample_bytree': 0.5621796078837737, 'min_child_weight': 3, 'reg_alpha': 1.124181419567019e-09, 'reg_lambda': 0.4278254229932558, 'scale_pos_weight': 46.2299544557376})
2023-02-17 09:44:20,045:INFO:Checking exceptions
2023-02-17 09:44:20,045:INFO:Importing libraries
2023-02-17 09:44:20,046:INFO:Copying training dataset
2023-02-17 09:44:20,098:INFO:Defining folds
2023-02-17 09:44:20,098:INFO:Declaring metric variables
2023-02-17 09:44:20,103:INFO:Importing untrained model
2023-02-17 09:44:20,103:INFO:Declaring custom model
2023-02-17 09:44:20,109:INFO:Extreme Gradient Boosting Imported successfully
2023-02-17 09:44:20,121:INFO:Starting cross validation
2023-02-17 09:44:20,123:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:44:30,847:INFO:Calculating mean and std
2023-02-17 09:44:30,849:INFO:Creating metrics dataframe
2023-02-17 09:44:30,857:INFO:Finalizing model
2023-02-17 09:44:41,123:INFO:Uploading results into container
2023-02-17 09:44:41,124:INFO:Uploading model into container now
2023-02-17 09:44:41,125:INFO:_master_model_container: 16
2023-02-17 09:44:41,125:INFO:_display_container: 3
2023-02-17 09:44:41,127:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5621796078837737, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None,
              learning_rate=0.00012808973545033744, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              n_estimators=231, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-17 09:44:41,127:INFO:create_model() successfully completed......................................
2023-02-17 09:44:41,274:INFO:SubProcess create_model() end ==================================
2023-02-17 09:44:41,274:INFO:choose_better activated
2023-02-17 09:44:41,278:INFO:SubProcess create_model() called ==================================
2023-02-17 09:44:41,279:INFO:Initializing create_model()
2023-02-17 09:44:41,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:44:41,279:INFO:Checking exceptions
2023-02-17 09:44:41,283:INFO:Importing libraries
2023-02-17 09:44:41,283:INFO:Copying training dataset
2023-02-17 09:44:41,335:INFO:Defining folds
2023-02-17 09:44:41,335:INFO:Declaring metric variables
2023-02-17 09:44:41,335:INFO:Importing untrained model
2023-02-17 09:44:41,335:INFO:Declaring custom model
2023-02-17 09:44:41,337:INFO:Extreme Gradient Boosting Imported successfully
2023-02-17 09:44:41,337:INFO:Starting cross validation
2023-02-17 09:44:41,337:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:44:42,165:INFO:Calculating mean and std
2023-02-17 09:44:42,166:INFO:Creating metrics dataframe
2023-02-17 09:44:42,168:INFO:Finalizing model
2023-02-17 09:44:42,185:INFO:Uploading results into container
2023-02-17 09:44:42,186:INFO:Uploading model into container now
2023-02-17 09:44:42,186:INFO:_master_model_container: 17
2023-02-17 09:44:42,187:INFO:_display_container: 4
2023-02-17 09:44:42,187:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-17 09:44:42,187:INFO:create_model() successfully completed......................................
2023-02-17 09:44:42,342:INFO:SubProcess create_model() end ==================================
2023-02-17 09:44:42,344:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for Recall is 0.9164
2023-02-17 09:44:42,375:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5621796078837737, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None,
              learning_rate=0.00012808973545033744, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              n_estimators=231, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for Recall is 1.0
2023-02-17 09:44:42,376:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5621796078837737, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None,
              learning_rate=0.00012808973545033744, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              n_estimators=231, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) is best model
2023-02-17 09:44:42,376:INFO:choose_better completed
2023-02-17 09:44:42,391:INFO:_master_model_container: 17
2023-02-17 09:44:42,391:INFO:_display_container: 3
2023-02-17 09:44:42,392:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5621796078837737, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None,
              learning_rate=0.00012808973545033744, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              n_estimators=231, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-17 09:44:42,392:INFO:tune_model() successfully completed......................................
2023-02-17 09:44:42,606:INFO:Initializing tune_model()
2023-02-17 09:44:42,606:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2224, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>)
2023-02-17 09:44:42,606:INFO:Checking exceptions
2023-02-17 09:44:42,606:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-17 09:44:42,644:INFO:Copying training dataset
2023-02-17 09:44:42,724:INFO:Checking base model
2023-02-17 09:44:42,725:INFO:Base model : Random Forest Classifier
2023-02-17 09:44:42,730:INFO:Declaring metric variables
2023-02-17 09:44:42,735:INFO:Defining Hyperparameters
2023-02-17 09:44:42,931:INFO:Tuning with n_jobs=-1
2023-02-17 09:44:42,932:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 09:44:42,932:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 09:44:43,114:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-02-17 09:44:43,115:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-17 09:44:43,115:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-17 09:44:43,124:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-17 09:57:25,917:INFO:best_params: {'actual_estimator__n_estimators': 187, 'actual_estimator__max_depth': 1, 'actual_estimator__min_impurity_decrease': 4.2557961348622174e-07, 'actual_estimator__max_features': 0.5830864749256349, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__bootstrap': False, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced'}
2023-02-17 09:57:25,918:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-17 09:57:25,918:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-17 09:57:25,920:INFO:Hyperparameter search completed
2023-02-17 09:57:25,920:INFO:SubProcess create_model() called ==================================
2023-02-17 09:57:25,921:INFO:Initializing create_model()
2023-02-17 09:57:25,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2224, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B03FEBD00>, model_only=True, return_train_score=False, kwargs={'n_estimators': 187, 'max_depth': 1, 'min_impurity_decrease': 4.2557961348622174e-07, 'max_features': 0.5830864749256349, 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced'})
2023-02-17 09:57:25,922:INFO:Checking exceptions
2023-02-17 09:57:25,922:INFO:Importing libraries
2023-02-17 09:57:25,922:INFO:Copying training dataset
2023-02-17 09:57:25,979:INFO:Defining folds
2023-02-17 09:57:25,980:INFO:Declaring metric variables
2023-02-17 09:57:25,986:INFO:Importing untrained model
2023-02-17 09:57:25,987:INFO:Declaring custom model
2023-02-17 09:57:25,994:INFO:Random Forest Classifier Imported successfully
2023-02-17 09:57:26,007:INFO:Starting cross validation
2023-02-17 09:57:26,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:57:29,234:INFO:Calculating mean and std
2023-02-17 09:57:29,235:INFO:Creating metrics dataframe
2023-02-17 09:57:29,245:INFO:Finalizing model
2023-02-17 09:57:35,492:INFO:Uploading results into container
2023-02-17 09:57:35,493:INFO:Uploading model into container now
2023-02-17 09:57:35,494:INFO:_master_model_container: 18
2023-02-17 09:57:35,494:INFO:_display_container: 4
2023-02-17 09:57:35,495:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=1,
                       max_features=0.5830864749256349, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=4.2557961348622174e-07,
                       min_samples_leaf=3, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=187,
                       n_jobs=-1, oob_score=False, random_state=2224, verbose=0,
                       warm_start=False)
2023-02-17 09:57:35,495:INFO:create_model() successfully completed......................................
2023-02-17 09:57:35,675:INFO:SubProcess create_model() end ==================================
2023-02-17 09:57:35,675:INFO:choose_better activated
2023-02-17 09:57:35,679:INFO:SubProcess create_model() called ==================================
2023-02-17 09:57:35,680:INFO:Initializing create_model()
2023-02-17 09:57:35,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2224, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 09:57:35,681:INFO:Checking exceptions
2023-02-17 09:57:35,686:INFO:Importing libraries
2023-02-17 09:57:35,686:INFO:Copying training dataset
2023-02-17 09:57:35,815:INFO:Defining folds
2023-02-17 09:57:35,815:INFO:Declaring metric variables
2023-02-17 09:57:35,816:INFO:Importing untrained model
2023-02-17 09:57:35,817:INFO:Declaring custom model
2023-02-17 09:57:35,818:INFO:Random Forest Classifier Imported successfully
2023-02-17 09:57:35,818:INFO:Starting cross validation
2023-02-17 09:57:35,819:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 09:57:43,766:INFO:Calculating mean and std
2023-02-17 09:57:43,767:INFO:Creating metrics dataframe
2023-02-17 09:57:43,771:INFO:Finalizing model
2023-02-17 09:57:44,384:INFO:Uploading results into container
2023-02-17 09:57:44,386:INFO:Uploading model into container now
2023-02-17 09:57:44,386:INFO:_master_model_container: 19
2023-02-17 09:57:44,386:INFO:_display_container: 5
2023-02-17 09:57:44,387:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2224, verbose=0, warm_start=False)
2023-02-17 09:57:44,387:INFO:create_model() successfully completed......................................
2023-02-17 09:57:44,523:INFO:SubProcess create_model() end ==================================
2023-02-17 09:57:44,523:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2224, verbose=0, warm_start=False) result for Recall is 0.9219
2023-02-17 09:57:44,524:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=1,
                       max_features=0.5830864749256349, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=4.2557961348622174e-07,
                       min_samples_leaf=3, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=187,
                       n_jobs=-1, oob_score=False, random_state=2224, verbose=0,
                       warm_start=False) result for Recall is 0.8816
2023-02-17 09:57:44,524:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2224, verbose=0, warm_start=False) is best model
2023-02-17 09:57:44,524:INFO:choose_better completed
2023-02-17 09:57:44,525:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-17 09:57:44,547:INFO:_master_model_container: 19
2023-02-17 09:57:44,547:INFO:_display_container: 4
2023-02-17 09:57:44,547:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2224, verbose=0, warm_start=False)
2023-02-17 09:57:44,548:INFO:tune_model() successfully completed......................................
2023-02-17 09:57:44,675:INFO:Initializing tune_model()
2023-02-17 09:57:44,675:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2224, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>)
2023-02-17 09:57:44,675:INFO:Checking exceptions
2023-02-17 09:57:44,675:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-17 09:57:44,713:INFO:Copying training dataset
2023-02-17 09:57:44,747:INFO:Checking base model
2023-02-17 09:57:44,747:INFO:Base model : Light Gradient Boosting Machine
2023-02-17 09:57:44,765:INFO:Declaring metric variables
2023-02-17 09:57:44,769:INFO:Defining Hyperparameters
2023-02-17 09:57:44,899:INFO:Tuning with n_jobs=-1
2023-02-17 09:57:44,900:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 09:57:44,900:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 09:57:44,901:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-17 09:57:44,901:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-17 09:57:44,928:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-17 10:00:29,855:INFO:best_params: {'actual_estimator__num_leaves': 131, 'actual_estimator__learning_rate': 0.11865778090787542, 'actual_estimator__n_estimators': 286, 'actual_estimator__min_split_gain': 0.28314297581960346, 'actual_estimator__reg_alpha': 0.01037992813313455, 'actual_estimator__reg_lambda': 1.879706330019462, 'actual_estimator__feature_fraction': 0.539849767124366, 'actual_estimator__bagging_fraction': 0.7290937715593063, 'actual_estimator__bagging_freq': 1, 'actual_estimator__min_child_samples': 78}
2023-02-17 10:00:29,855:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-17 10:00:29,855:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-17 10:00:29,856:INFO:Hyperparameter search completed
2023-02-17 10:00:29,857:INFO:SubProcess create_model() called ==================================
2023-02-17 10:00:29,858:INFO:Initializing create_model()
2023-02-17 10:00:29,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2224, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B01AB3CD0>, model_only=True, return_train_score=False, kwargs={'num_leaves': 131, 'learning_rate': 0.11865778090787542, 'n_estimators': 286, 'min_split_gain': 0.28314297581960346, 'reg_alpha': 0.01037992813313455, 'reg_lambda': 1.879706330019462, 'feature_fraction': 0.539849767124366, 'bagging_fraction': 0.7290937715593063, 'bagging_freq': 1, 'min_child_samples': 78})
2023-02-17 10:00:29,858:INFO:Checking exceptions
2023-02-17 10:00:29,858:INFO:Importing libraries
2023-02-17 10:00:29,858:INFO:Copying training dataset
2023-02-17 10:00:29,927:INFO:Defining folds
2023-02-17 10:00:29,928:INFO:Declaring metric variables
2023-02-17 10:00:29,932:INFO:Importing untrained model
2023-02-17 10:00:29,933:INFO:Declaring custom model
2023-02-17 10:00:29,938:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 10:00:29,950:INFO:Starting cross validation
2023-02-17 10:00:29,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 10:00:39,994:INFO:Calculating mean and std
2023-02-17 10:00:39,999:INFO:Creating metrics dataframe
2023-02-17 10:00:40,005:INFO:Finalizing model
2023-02-17 10:00:45,590:INFO:Uploading results into container
2023-02-17 10:00:45,591:INFO:Uploading model into container now
2023-02-17 10:00:45,591:INFO:_master_model_container: 20
2023-02-17 10:00:45,592:INFO:_display_container: 5
2023-02-17 10:00:45,592:INFO:LGBMClassifier(bagging_fraction=0.7290937715593063, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.539849767124366, importance_type='split',
               learning_rate=0.11865778090787542, max_depth=-1,
               min_child_samples=78, min_child_weight=0.001,
               min_split_gain=0.28314297581960346, n_estimators=286, n_jobs=-1,
               num_leaves=131, objective=None, random_state=2224,
               reg_alpha=0.01037992813313455, reg_lambda=1.879706330019462,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-02-17 10:00:45,592:INFO:create_model() successfully completed......................................
2023-02-17 10:00:45,712:INFO:SubProcess create_model() end ==================================
2023-02-17 10:00:45,712:INFO:choose_better activated
2023-02-17 10:00:45,724:INFO:SubProcess create_model() called ==================================
2023-02-17 10:00:45,727:INFO:Initializing create_model()
2023-02-17 10:00:45,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2224, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 10:00:45,727:INFO:Checking exceptions
2023-02-17 10:00:45,730:INFO:Importing libraries
2023-02-17 10:00:45,730:INFO:Copying training dataset
2023-02-17 10:00:45,794:INFO:Defining folds
2023-02-17 10:00:45,794:INFO:Declaring metric variables
2023-02-17 10:00:45,794:INFO:Importing untrained model
2023-02-17 10:00:45,794:INFO:Declaring custom model
2023-02-17 10:00:45,795:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 10:00:45,795:INFO:Starting cross validation
2023-02-17 10:00:45,796:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 10:00:48,278:INFO:Calculating mean and std
2023-02-17 10:00:48,279:INFO:Creating metrics dataframe
2023-02-17 10:00:48,281:INFO:Finalizing model
2023-02-17 10:00:48,346:INFO:Uploading results into container
2023-02-17 10:00:48,346:INFO:Uploading model into container now
2023-02-17 10:00:48,347:INFO:_master_model_container: 21
2023-02-17 10:00:48,347:INFO:_display_container: 6
2023-02-17 10:00:48,347:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2224, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 10:00:48,347:INFO:create_model() successfully completed......................................
2023-02-17 10:00:48,475:INFO:SubProcess create_model() end ==================================
2023-02-17 10:00:48,475:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2224, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8978
2023-02-17 10:00:48,476:INFO:LGBMClassifier(bagging_fraction=0.7290937715593063, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.539849767124366, importance_type='split',
               learning_rate=0.11865778090787542, max_depth=-1,
               min_child_samples=78, min_child_weight=0.001,
               min_split_gain=0.28314297581960346, n_estimators=286, n_jobs=-1,
               num_leaves=131, objective=None, random_state=2224,
               reg_alpha=0.01037992813313455, reg_lambda=1.879706330019462,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for Recall is 0.9265
2023-02-17 10:00:48,476:INFO:LGBMClassifier(bagging_fraction=0.7290937715593063, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.539849767124366, importance_type='split',
               learning_rate=0.11865778090787542, max_depth=-1,
               min_child_samples=78, min_child_weight=0.001,
               min_split_gain=0.28314297581960346, n_estimators=286, n_jobs=-1,
               num_leaves=131, objective=None, random_state=2224,
               reg_alpha=0.01037992813313455, reg_lambda=1.879706330019462,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) is best model
2023-02-17 10:00:48,476:INFO:choose_better completed
2023-02-17 10:00:48,491:INFO:_master_model_container: 21
2023-02-17 10:00:48,492:INFO:_display_container: 5
2023-02-17 10:00:48,492:INFO:LGBMClassifier(bagging_fraction=0.7290937715593063, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.539849767124366, importance_type='split',
               learning_rate=0.11865778090787542, max_depth=-1,
               min_child_samples=78, min_child_weight=0.001,
               min_split_gain=0.28314297581960346, n_estimators=286, n_jobs=-1,
               num_leaves=131, objective=None, random_state=2224,
               reg_alpha=0.01037992813313455, reg_lambda=1.879706330019462,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-02-17 10:00:48,492:INFO:tune_model() successfully completed......................................
2023-02-17 10:00:48,677:INFO:Initializing automl()
2023-02-17 10:00:48,677:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, optimize=AUC, use_holdout=False, turbo=True, return_train_score=False)
2023-02-17 10:00:48,677:INFO:Model Selection Basis : CV Results on Training set
2023-02-17 10:00:48,678:INFO:Checking model 0
2023-02-17 10:00:48,684:INFO:Checking model 1
2023-02-17 10:00:48,684:INFO:Checking model 2
2023-02-17 10:00:48,684:INFO:Checking model 3
2023-02-17 10:00:48,685:INFO:Checking model 4
2023-02-17 10:00:48,685:INFO:Checking model 5
2023-02-17 10:00:48,685:INFO:Checking model 6
2023-02-17 10:00:48,685:INFO:Checking model 7
2023-02-17 10:00:48,685:INFO:Checking model 8
2023-02-17 10:00:48,686:INFO:Checking model 9
2023-02-17 10:00:48,686:INFO:Checking model 10
2023-02-17 10:00:48,686:INFO:Checking model 11
2023-02-17 10:00:48,686:INFO:Checking model 12
2023-02-17 10:00:48,686:INFO:Checking model 13
2023-02-17 10:00:48,686:INFO:Checking model 14
2023-02-17 10:00:48,687:INFO:Checking model 15
2023-02-17 10:00:48,687:INFO:Checking model 16
2023-02-17 10:00:48,687:INFO:Checking model 17
2023-02-17 10:00:48,687:INFO:Checking model 18
2023-02-17 10:00:48,687:INFO:Checking model 19
2023-02-17 10:00:48,688:INFO:Checking model 20
2023-02-17 10:00:48,688:INFO:Initializing create_model()
2023-02-17 10:00:48,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=LGBMClassifier(bagging_fraction=0.7290937715593063, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.539849767124366, importance_type='split',
               learning_rate=0.11865778090787542, max_depth=-1,
               min_child_samples=78, min_child_weight=0.001,
               min_split_gain=0.28314297581960346, n_estimators=286, n_jobs=-1,
               num_leaves=131, objective=None, random_state=2224,
               reg_alpha=0.01037992813313455, reg_lambda=1.879706330019462,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 10:00:48,688:INFO:Checking exceptions
2023-02-17 10:00:48,690:INFO:Importing libraries
2023-02-17 10:00:48,690:INFO:Copying training dataset
2023-02-17 10:00:48,745:INFO:Defining folds
2023-02-17 10:00:48,745:INFO:Declaring metric variables
2023-02-17 10:00:48,745:INFO:Importing untrained model
2023-02-17 10:00:48,745:INFO:Declaring custom model
2023-02-17 10:00:48,746:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 10:00:48,747:INFO:Cross validation set to False
2023-02-17 10:00:48,747:INFO:Fitting Model
2023-02-17 10:00:48,780:INFO:LGBMClassifier(bagging_fraction=0.7290937715593063, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.539849767124366, importance_type='split',
               learning_rate=0.11865778090787542, max_depth=-1,
               min_child_samples=78, min_child_weight=0.001,
               min_split_gain=0.28314297581960346, n_estimators=286, n_jobs=-1,
               num_leaves=131, objective=None, random_state=2224,
               reg_alpha=0.01037992813313455, reg_lambda=1.879706330019462,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-02-17 10:00:48,780:INFO:create_model() successfully completed......................................
2023-02-17 10:00:49,045:INFO:LGBMClassifier(bagging_fraction=0.7290937715593063, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.539849767124366, importance_type='split',
               learning_rate=0.11865778090787542, max_depth=-1,
               min_child_samples=78, min_child_weight=0.001,
               min_split_gain=0.28314297581960346, n_estimators=286, n_jobs=-1,
               num_leaves=131, objective=None, random_state=2224,
               reg_alpha=0.01037992813313455, reg_lambda=1.879706330019462,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-02-17 10:00:49,045:INFO:automl() successfully completed......................................
2023-02-17 10:00:49,068:INFO:Initializing finalize_model()
2023-02-17 10:00:49,068:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=LGBMClassifier(bagging_fraction=0.7290937715593063, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.539849767124366, importance_type='split',
               learning_rate=0.11865778090787542, max_depth=-1,
               min_child_samples=78, min_child_weight=0.001,
               min_split_gain=0.28314297581960346, n_estimators=286, n_jobs=-1,
               num_leaves=131, objective=None, random_state=2224,
               reg_alpha=0.01037992813313455, reg_lambda=1.879706330019462,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-02-17 10:00:49,070:INFO:Finalizing LGBMClassifier(bagging_fraction=0.7290937715593063, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.539849767124366, importance_type='split',
               learning_rate=0.11865778090787542, max_depth=-1,
               min_child_samples=78, min_child_weight=0.001,
               min_split_gain=0.28314297581960346, n_estimators=286, n_jobs=-1,
               num_leaves=131, objective=None, random_state=2224,
               reg_alpha=0.01037992813313455, reg_lambda=1.879706330019462,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-02-17 10:00:49,094:INFO:Initializing create_model()
2023-02-17 10:00:49,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1AA432B0>, estimator=LGBMClassifier(bagging_fraction=0.7290937715593063, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.539849767124366, importance_type='split',
               learning_rate=0.11865778090787542, max_depth=-1,
               min_child_samples=78, min_child_weight=0.001,
               min_split_gain=0.28314297581960346, n_estimators=286, n_jobs=-1,
               num_leaves=131, objective=None, random_state=2224,
               reg_alpha=0.01037992813313455, reg_lambda=1.879706330019462,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-02-17 10:00:49,094:INFO:Checking exceptions
2023-02-17 10:00:49,096:INFO:Importing libraries
2023-02-17 10:00:49,096:INFO:Copying training dataset
2023-02-17 10:00:49,098:INFO:Defining folds
2023-02-17 10:00:49,098:INFO:Declaring metric variables
2023-02-17 10:00:49,098:INFO:Importing untrained model
2023-02-17 10:00:49,098:INFO:Declaring custom model
2023-02-17 10:00:49,099:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 10:00:49,102:INFO:Cross validation set to False
2023-02-17 10:00:49,102:INFO:Fitting Model
2023-02-17 10:00:53,509:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.7290937715593063,
                                bagging_freq=1, boosting_type='gbdt',
                                class_weight=None, colsample_bytree=1.0,
                                feature_fraction=0.539849767124366,
                                importance_type='split',
                                learning_rate=0.11865778090787542, max_depth=-1,
                                min_child_samples=78, min_child_weight=0.001,
                                min_split_gain=0.28314297581960346,
                                n_estimators=286, n_jobs=-1, num_leaves=131,
                                objective=None, random_state=2224,
                                reg_alpha=0.01037992813313455,
                                reg_lambda=1.879706330019462, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-02-17 10:00:53,509:INFO:create_model() successfully completed......................................
2023-02-17 10:00:53,620:INFO:_master_model_container: 21
2023-02-17 10:00:53,620:INFO:_display_container: 5
2023-02-17 10:00:53,622:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.7290937715593063,
                                bagging_freq=1, boosting_type='gbdt',
                                class_weight=None, colsample_bytree=1.0,
                                feature_fraction=0.539849767124366,
                                importance_type='split',
                                learning_rate=0.11865778090787542, max_depth=-1,
                                min_child_samples=78, min_child_weight=0.001,
                                min_split_gain=0.28314297581960346,
                                n_estimators=286, n_jobs=-1, num_leaves=131,
                                objective=None, random_state=2224,
                                reg_alpha=0.01037992813313455,
                                reg_lambda=1.879706330019462, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-02-17 10:00:53,622:INFO:finalize_model() successfully completed......................................
2023-02-17 11:10:21,458:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\manifold\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  warnings.warn(

2023-02-17 11:10:21,468:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\manifold\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.
  warnings.warn(

2023-02-17 11:14:23,841:INFO:Initializing save_model()
2023-02-17 11:14:23,842:INFO:save_model(model=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), model_name=xgb, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-17 11:14:23,842:INFO:Adding model into prep_pipe
2023-02-17 11:14:24,080:INFO:xgb.pkl saved in current working directory
2023-02-17 11:14:24,095:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('trained_model',
                 XGBClassifier(base_score=None, booster='gbtree',
                               callbacks=None, colsample_bylevel=None,
                               colsample_bynode=None, colsample_bytree=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=None...
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, n_estimators=100,
                               n_jobs=-1, num_parallel_tree=None,
                               objective='binary:logistic', predictor=None, ...))],
         verbose=False)
2023-02-17 11:14:24,095:INFO:save_model() successfully completed......................................
2023-02-17 11:14:24,333:INFO:Initializing save_model()
2023-02-17 11:14:24,334:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2224, verbose=0, warm_start=False), model_name=rf, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-17 11:14:24,334:INFO:Adding model into prep_pipe
2023-02-17 11:14:26,202:INFO:rf.pkl saved in current working directory
2023-02-17 11:14:26,204:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('trained_model',
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='auto',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=2224,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-02-17 11:14:26,204:INFO:save_model() successfully completed......................................
2023-02-17 11:14:26,342:INFO:Initializing save_model()
2023-02-17 11:14:26,343:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2224, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=lgbm, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-17 11:14:26,343:INFO:Adding model into prep_pipe
2023-02-17 11:14:26,432:INFO:lgbm.pkl saved in current working directory
2023-02-17 11:14:26,434:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('trained_model',
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=2224, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-02-17 11:14:26,435:INFO:save_model() successfully completed......................................
2023-02-17 11:20:14,708:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\manifold\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  warnings.warn(

2023-02-17 11:20:14,708:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\manifold\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.
  warnings.warn(

2023-02-17 11:23:32,903:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- inadimplente
Feature names must be in the same order as they were in fit.

  warnings.warn(message, FutureWarning)

2023-02-17 11:36:24,190:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\manifold\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  warnings.warn(

2023-02-17 11:36:24,229:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\manifold\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.
  warnings.warn(

2023-02-17 11:38:14,309:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\manifold\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.
  warnings.warn(

2023-02-17 11:38:14,310:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\manifold\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.
  warnings.warn(

2023-02-17 11:50:27,369:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\internals\blocks.py:402: RuntimeWarning: divide by zero encountered in log
  result = func(self.values, **kwargs)

2023-02-17 11:50:27,484:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\numpy\lib\function_base.py:4009: RuntimeWarning: invalid value encountered in subtract
  diff_b_a = subtract(b, a)

2023-02-17 11:50:27,488:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\matplotlib\cbook\__init__.py:1291: RuntimeWarning: invalid value encountered in less_equal
  wiskhi = x[x <= hival]

2023-02-17 11:50:27,489:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\matplotlib\cbook\__init__.py:1298: RuntimeWarning: invalid value encountered in greater_equal
  wisklo = x[x >= loval]

2023-02-17 11:50:27,491:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\matplotlib\cbook\__init__.py:1306: RuntimeWarning: invalid value encountered in less
  x[x < stats['whislo']],

2023-02-17 11:50:40,053:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pandas\core\internals\blocks.py:402: RuntimeWarning: divide by zero encountered in log
  result = func(self.values, **kwargs)

2023-02-17 11:50:40,159:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\numpy\lib\function_base.py:4009: RuntimeWarning: invalid value encountered in subtract
  diff_b_a = subtract(b, a)

2023-02-17 11:50:40,160:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\matplotlib\cbook\__init__.py:1291: RuntimeWarning: invalid value encountered in less_equal
  wiskhi = x[x <= hival]

2023-02-17 11:50:40,162:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\matplotlib\cbook\__init__.py:1298: RuntimeWarning: invalid value encountered in greater_equal
  wisklo = x[x >= loval]

2023-02-17 11:50:40,163:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\matplotlib\cbook\__init__.py:1306: RuntimeWarning: invalid value encountered in less
  x[x < stats['whislo']],

2023-02-17 12:05:51,824:INFO:PyCaret ClassificationExperiment
2023-02-17 12:05:51,825:INFO:Logging name: clf-default-name
2023-02-17 12:05:51,825:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-17 12:05:51,825:INFO:version 3.0.0.rc9
2023-02-17 12:05:51,825:INFO:Initializing setup()
2023-02-17 12:05:51,825:INFO:self.USI: 9141
2023-02-17 12:05:51,825:INFO:self._variable_keys: {'pipeline', 'exp_name_log', 'fold_groups_param', 'y_test', 'gpu_param', 'exp_id', 'X_test', 'y', 'target_param', 'fix_imbalance', 'n_jobs_param', 'X_train', 'fold_generator', 'is_multiclass', 'fold_shuffle_param', 'memory', '_ml_usecase', 'gpu_n_jobs_param', 'USI', '_available_plots', 'X', 'logging_param', 'seed', 'data', 'y_train', 'html_param', 'log_plots_param', 'idx'}
2023-02-17 12:05:51,825:INFO:Checking environment
2023-02-17 12:05:51,825:INFO:python_version: 3.9.15
2023-02-17 12:05:51,825:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-17 12:05:51,825:INFO:machine: AMD64
2023-02-17 12:05:51,825:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-17 12:05:51,837:INFO:Memory: svmem(total=8469581824, available=3226558464, percent=61.9, used=5243023360, free=3226558464)
2023-02-17 12:05:51,837:INFO:Physical Core: 4
2023-02-17 12:05:51,837:INFO:Logical Core: 4
2023-02-17 12:05:51,837:INFO:Checking libraries
2023-02-17 12:05:51,837:INFO:System:
2023-02-17 12:05:51,837:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-17 12:05:51,837:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-17 12:05:51,838:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-17 12:05:51,838:INFO:PyCaret required dependencies:
2023-02-17 12:05:51,838:INFO:                 pip: 22.3.1
2023-02-17 12:05:51,838:INFO:          setuptools: 60.10.0
2023-02-17 12:05:51,838:INFO:             pycaret: 3.0.0rc9
2023-02-17 12:05:51,838:INFO:             IPython: 7.31.1
2023-02-17 12:05:51,838:INFO:          ipywidgets: 7.6.5
2023-02-17 12:05:51,838:INFO:                tqdm: 4.64.1
2023-02-17 12:05:51,838:INFO:               numpy: 1.21.5
2023-02-17 12:05:51,838:INFO:              pandas: 1.4.4
2023-02-17 12:05:51,838:INFO:              jinja2: 2.11.3
2023-02-17 12:05:51,838:INFO:               scipy: 1.9.3
2023-02-17 12:05:51,838:INFO:              joblib: 1.2.0
2023-02-17 12:05:51,838:INFO:             sklearn: 1.0.2
2023-02-17 12:05:51,838:INFO:                pyod: 1.0.7
2023-02-17 12:05:51,838:INFO:            imblearn: 0.10.1
2023-02-17 12:05:51,838:INFO:   category_encoders: 2.6.0
2023-02-17 12:05:51,838:INFO:            lightgbm: 3.3.5
2023-02-17 12:05:51,838:INFO:               numba: 0.56.4
2023-02-17 12:05:51,839:INFO:            requests: 2.28.1
2023-02-17 12:05:51,839:INFO:          matplotlib: 3.6.2
2023-02-17 12:05:51,839:INFO:          scikitplot: 0.3.7
2023-02-17 12:05:51,839:INFO:         yellowbrick: 1.5
2023-02-17 12:05:51,839:INFO:              plotly: 5.9.0
2023-02-17 12:05:51,839:INFO:             kaleido: 0.2.1
2023-02-17 12:05:51,839:INFO:         statsmodels: 0.13.2
2023-02-17 12:05:51,839:INFO:              sktime: 0.16.1
2023-02-17 12:05:51,839:INFO:               tbats: 1.1.2
2023-02-17 12:05:51,839:INFO:            pmdarima: 2.0.2
2023-02-17 12:05:51,839:INFO:              psutil: 5.9.0
2023-02-17 12:05:51,839:INFO:PyCaret optional dependencies:
2023-02-17 12:05:51,839:INFO:                shap: 0.41.0
2023-02-17 12:05:51,839:INFO:           interpret: Not installed
2023-02-17 12:05:51,839:INFO:                umap: Not installed
2023-02-17 12:05:51,839:INFO:    pandas_profiling: 4.0.0
2023-02-17 12:05:51,839:INFO:  explainerdashboard: 0.3.6.2
2023-02-17 12:05:51,839:INFO:             autoviz: 0.1.58
2023-02-17 12:05:51,839:INFO:           fairlearn: Not installed
2023-02-17 12:05:51,840:INFO:             xgboost: 1.7.3
2023-02-17 12:05:51,840:INFO:            catboost: Not installed
2023-02-17 12:05:51,840:INFO:              kmodes: Not installed
2023-02-17 12:05:51,840:INFO:             mlxtend: Not installed
2023-02-17 12:05:51,840:INFO:       statsforecast: Not installed
2023-02-17 12:05:51,840:INFO:        tune_sklearn: Not installed
2023-02-17 12:05:51,840:INFO:                 ray: Not installed
2023-02-17 12:05:51,840:INFO:            hyperopt: Not installed
2023-02-17 12:05:51,840:INFO:              optuna: 2.10.1
2023-02-17 12:05:51,840:INFO:               skopt: Not installed
2023-02-17 12:05:51,840:INFO:              mlflow: Not installed
2023-02-17 12:05:51,840:INFO:              gradio: Not installed
2023-02-17 12:05:51,840:INFO:             fastapi: Not installed
2023-02-17 12:05:51,840:INFO:             uvicorn: Not installed
2023-02-17 12:05:51,840:INFO:              m2cgen: Not installed
2023-02-17 12:05:51,840:INFO:           evidently: Not installed
2023-02-17 12:05:51,840:INFO:               fugue: Not installed
2023-02-17 12:05:51,840:INFO:           streamlit: Not installed
2023-02-17 12:05:51,841:INFO:             prophet: Not installed
2023-02-17 12:05:51,841:INFO:None
2023-02-17 12:05:51,841:INFO:Set up data.
2023-02-17 12:05:51,881:INFO:Set up train/test split.
2023-02-17 12:05:51,910:INFO:Set up index.
2023-02-17 12:05:51,918:INFO:Set up folding strategy.
2023-02-17 12:05:51,918:INFO:Assigning column types.
2023-02-17 12:05:51,925:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-17 12:05:51,997:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-17 12:05:52,017:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:05:52,051:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:05:52,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:05:52,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-17 12:05:52,135:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:05:52,185:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:05:52,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:05:52,189:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-17 12:05:52,241:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:05:52,273:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:05:52,275:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:05:52,327:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:05:52,363:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:05:52,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:05:52,376:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-17 12:05:52,459:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:05:52,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:05:52,545:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:05:52,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:05:52,592:INFO:Finished creating preprocessing pipeline.
2023-02-17 12:05:52,592:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2023-02-17 12:05:52,592:INFO:Creating final display dataframe.
2023-02-17 12:05:52,810:INFO:Setup _display_container:                    Description        Value
0                   Session id         3561
1                       Target        Class
2                  Target type       Binary
3          Original data shape  (14662, 11)
4       Transformed data shape  (14662, 11)
5  Transformed train set shape  (10263, 11)
6   Transformed test set shape   (4399, 11)
7             Numeric features           10
2023-02-17 12:05:53,000:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:05:53,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:05:53,172:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:05:53,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:05:53,179:INFO:setup() successfully completed in 1.41s...............
2023-02-17 12:05:54,889:INFO:Initializing compare_models()
2023-02-17 12:05:54,889:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-17 12:05:54,890:INFO:Checking exceptions
2023-02-17 12:05:54,918:INFO:Preparing display monitor
2023-02-17 12:05:54,972:INFO:Initializing Logistic Regression
2023-02-17 12:05:54,973:INFO:Total runtime is 1.6621748606363933e-05 minutes
2023-02-17 12:05:54,981:INFO:SubProcess create_model() called ==================================
2023-02-17 12:05:54,982:INFO:Initializing create_model()
2023-02-17 12:05:54,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:05:54,982:INFO:Checking exceptions
2023-02-17 12:05:54,982:INFO:Importing libraries
2023-02-17 12:05:54,982:INFO:Copying training dataset
2023-02-17 12:05:54,993:INFO:Defining folds
2023-02-17 12:05:54,994:INFO:Declaring metric variables
2023-02-17 12:05:54,998:INFO:Importing untrained model
2023-02-17 12:05:55,004:INFO:Logistic Regression Imported successfully
2023-02-17 12:05:55,015:INFO:Starting cross validation
2023-02-17 12:05:55,033:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:05,558:INFO:Calculating mean and std
2023-02-17 12:06:05,560:INFO:Creating metrics dataframe
2023-02-17 12:06:05,564:INFO:Uploading results into container
2023-02-17 12:06:05,564:INFO:Uploading model into container now
2023-02-17 12:06:05,564:INFO:_master_model_container: 1
2023-02-17 12:06:05,565:INFO:_display_container: 2
2023-02-17 12:06:05,565:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3561, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-17 12:06:05,565:INFO:create_model() successfully completed......................................
2023-02-17 12:06:05,725:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:05,725:INFO:Creating metrics dataframe
2023-02-17 12:06:05,818:INFO:Initializing K Neighbors Classifier
2023-02-17 12:06:05,818:INFO:Total runtime is 0.1807620882987976 minutes
2023-02-17 12:06:05,823:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:05,825:INFO:Initializing create_model()
2023-02-17 12:06:05,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:05,825:INFO:Checking exceptions
2023-02-17 12:06:05,825:INFO:Importing libraries
2023-02-17 12:06:05,825:INFO:Copying training dataset
2023-02-17 12:06:05,835:INFO:Defining folds
2023-02-17 12:06:05,835:INFO:Declaring metric variables
2023-02-17 12:06:05,845:INFO:Importing untrained model
2023-02-17 12:06:05,853:INFO:K Neighbors Classifier Imported successfully
2023-02-17 12:06:05,865:INFO:Starting cross validation
2023-02-17 12:06:05,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:06,102:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:06:06,103:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:06:06,124:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:06:06,136:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:06:06,269:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:06:06,297:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:06:06,356:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:06:06,358:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:06:06,498:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:06:06,515:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:06:06,572:INFO:Calculating mean and std
2023-02-17 12:06:06,573:INFO:Creating metrics dataframe
2023-02-17 12:06:06,579:INFO:Uploading results into container
2023-02-17 12:06:06,580:INFO:Uploading model into container now
2023-02-17 12:06:06,580:INFO:_master_model_container: 2
2023-02-17 12:06:06,580:INFO:_display_container: 2
2023-02-17 12:06:06,581:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-17 12:06:06,581:INFO:create_model() successfully completed......................................
2023-02-17 12:06:06,718:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:06,718:INFO:Creating metrics dataframe
2023-02-17 12:06:06,735:INFO:Initializing Naive Bayes
2023-02-17 12:06:06,736:INFO:Total runtime is 0.196057665348053 minutes
2023-02-17 12:06:06,740:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:06,742:INFO:Initializing create_model()
2023-02-17 12:06:06,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:06,742:INFO:Checking exceptions
2023-02-17 12:06:06,742:INFO:Importing libraries
2023-02-17 12:06:06,743:INFO:Copying training dataset
2023-02-17 12:06:06,753:INFO:Defining folds
2023-02-17 12:06:06,753:INFO:Declaring metric variables
2023-02-17 12:06:06,759:INFO:Importing untrained model
2023-02-17 12:06:06,765:INFO:Naive Bayes Imported successfully
2023-02-17 12:06:06,776:INFO:Starting cross validation
2023-02-17 12:06:06,777:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:06,937:INFO:Calculating mean and std
2023-02-17 12:06:06,938:INFO:Creating metrics dataframe
2023-02-17 12:06:06,945:INFO:Uploading results into container
2023-02-17 12:06:06,946:INFO:Uploading model into container now
2023-02-17 12:06:06,946:INFO:_master_model_container: 3
2023-02-17 12:06:06,946:INFO:_display_container: 2
2023-02-17 12:06:06,946:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-17 12:06:06,947:INFO:create_model() successfully completed......................................
2023-02-17 12:06:07,107:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:07,107:INFO:Creating metrics dataframe
2023-02-17 12:06:07,130:INFO:Initializing Decision Tree Classifier
2023-02-17 12:06:07,130:INFO:Total runtime is 0.20262344678243002 minutes
2023-02-17 12:06:07,136:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:07,137:INFO:Initializing create_model()
2023-02-17 12:06:07,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:07,137:INFO:Checking exceptions
2023-02-17 12:06:07,138:INFO:Importing libraries
2023-02-17 12:06:07,138:INFO:Copying training dataset
2023-02-17 12:06:07,149:INFO:Defining folds
2023-02-17 12:06:07,149:INFO:Declaring metric variables
2023-02-17 12:06:07,154:INFO:Importing untrained model
2023-02-17 12:06:07,161:INFO:Decision Tree Classifier Imported successfully
2023-02-17 12:06:07,178:INFO:Starting cross validation
2023-02-17 12:06:07,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:07,550:INFO:Calculating mean and std
2023-02-17 12:06:07,552:INFO:Creating metrics dataframe
2023-02-17 12:06:07,564:INFO:Uploading results into container
2023-02-17 12:06:07,565:INFO:Uploading model into container now
2023-02-17 12:06:07,565:INFO:_master_model_container: 4
2023-02-17 12:06:07,565:INFO:_display_container: 2
2023-02-17 12:06:07,566:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3561, splitter='best')
2023-02-17 12:06:07,566:INFO:create_model() successfully completed......................................
2023-02-17 12:06:07,717:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:07,718:INFO:Creating metrics dataframe
2023-02-17 12:06:07,738:INFO:Initializing SVM - Linear Kernel
2023-02-17 12:06:07,738:INFO:Total runtime is 0.21276300350824992 minutes
2023-02-17 12:06:07,743:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:07,743:INFO:Initializing create_model()
2023-02-17 12:06:07,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:07,744:INFO:Checking exceptions
2023-02-17 12:06:07,744:INFO:Importing libraries
2023-02-17 12:06:07,744:INFO:Copying training dataset
2023-02-17 12:06:07,755:INFO:Defining folds
2023-02-17 12:06:07,756:INFO:Declaring metric variables
2023-02-17 12:06:07,761:INFO:Importing untrained model
2023-02-17 12:06:07,766:INFO:SVM - Linear Kernel Imported successfully
2023-02-17 12:06:07,777:INFO:Starting cross validation
2023-02-17 12:06:07,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:07,965:INFO:Calculating mean and std
2023-02-17 12:06:07,966:INFO:Creating metrics dataframe
2023-02-17 12:06:07,971:INFO:Uploading results into container
2023-02-17 12:06:07,972:INFO:Uploading model into container now
2023-02-17 12:06:07,972:INFO:_master_model_container: 5
2023-02-17 12:06:07,973:INFO:_display_container: 2
2023-02-17 12:06:07,974:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3561, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-17 12:06:07,974:INFO:create_model() successfully completed......................................
2023-02-17 12:06:08,113:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:08,113:INFO:Creating metrics dataframe
2023-02-17 12:06:08,126:INFO:Initializing Ridge Classifier
2023-02-17 12:06:08,127:INFO:Total runtime is 0.21924566030502318 minutes
2023-02-17 12:06:08,130:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:08,131:INFO:Initializing create_model()
2023-02-17 12:06:08,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:08,131:INFO:Checking exceptions
2023-02-17 12:06:08,131:INFO:Importing libraries
2023-02-17 12:06:08,131:INFO:Copying training dataset
2023-02-17 12:06:08,140:INFO:Defining folds
2023-02-17 12:06:08,140:INFO:Declaring metric variables
2023-02-17 12:06:08,147:INFO:Importing untrained model
2023-02-17 12:06:08,151:INFO:Ridge Classifier Imported successfully
2023-02-17 12:06:08,160:INFO:Starting cross validation
2023-02-17 12:06:08,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:08,231:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=4.14072e-10): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:06:08,231:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.06403e-10): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:06:08,254:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.13602e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:06:08,263:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.12954e-10): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:06:08,269:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.1003e-10): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:06:08,279:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.1124e-10): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:06:08,286:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.0435e-10): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:06:08,293:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.12714e-10): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:06:08,305:INFO:Calculating mean and std
2023-02-17 12:06:08,306:INFO:Creating metrics dataframe
2023-02-17 12:06:08,314:INFO:Uploading results into container
2023-02-17 12:06:08,314:INFO:Uploading model into container now
2023-02-17 12:06:08,315:INFO:_master_model_container: 6
2023-02-17 12:06:08,315:INFO:_display_container: 2
2023-02-17 12:06:08,315:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=3561, solver='auto', tol=0.001)
2023-02-17 12:06:08,316:INFO:create_model() successfully completed......................................
2023-02-17 12:06:08,452:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:08,452:INFO:Creating metrics dataframe
2023-02-17 12:06:08,466:INFO:Initializing Random Forest Classifier
2023-02-17 12:06:08,466:INFO:Total runtime is 0.2248972217241923 minutes
2023-02-17 12:06:08,470:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:08,470:INFO:Initializing create_model()
2023-02-17 12:06:08,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:08,471:INFO:Checking exceptions
2023-02-17 12:06:08,471:INFO:Importing libraries
2023-02-17 12:06:08,471:INFO:Copying training dataset
2023-02-17 12:06:08,481:INFO:Defining folds
2023-02-17 12:06:08,481:INFO:Declaring metric variables
2023-02-17 12:06:08,486:INFO:Importing untrained model
2023-02-17 12:06:08,492:INFO:Random Forest Classifier Imported successfully
2023-02-17 12:06:08,500:INFO:Starting cross validation
2023-02-17 12:06:08,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:14,236:INFO:Calculating mean and std
2023-02-17 12:06:14,238:INFO:Creating metrics dataframe
2023-02-17 12:06:14,241:INFO:Uploading results into container
2023-02-17 12:06:14,242:INFO:Uploading model into container now
2023-02-17 12:06:14,242:INFO:_master_model_container: 7
2023-02-17 12:06:14,242:INFO:_display_container: 2
2023-02-17 12:06:14,243:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3561, verbose=0, warm_start=False)
2023-02-17 12:06:14,243:INFO:create_model() successfully completed......................................
2023-02-17 12:06:14,375:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:14,376:INFO:Creating metrics dataframe
2023-02-17 12:06:14,388:INFO:Initializing Quadratic Discriminant Analysis
2023-02-17 12:06:14,388:INFO:Total runtime is 0.3235999902089437 minutes
2023-02-17 12:06:14,392:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:14,392:INFO:Initializing create_model()
2023-02-17 12:06:14,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:14,393:INFO:Checking exceptions
2023-02-17 12:06:14,394:INFO:Importing libraries
2023-02-17 12:06:14,394:INFO:Copying training dataset
2023-02-17 12:06:14,403:INFO:Defining folds
2023-02-17 12:06:14,403:INFO:Declaring metric variables
2023-02-17 12:06:14,409:INFO:Importing untrained model
2023-02-17 12:06:14,414:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-17 12:06:14,421:INFO:Starting cross validation
2023-02-17 12:06:14,423:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:14,583:INFO:Calculating mean and std
2023-02-17 12:06:14,584:INFO:Creating metrics dataframe
2023-02-17 12:06:14,588:INFO:Uploading results into container
2023-02-17 12:06:14,589:INFO:Uploading model into container now
2023-02-17 12:06:14,590:INFO:_master_model_container: 8
2023-02-17 12:06:14,590:INFO:_display_container: 2
2023-02-17 12:06:14,590:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-17 12:06:14,591:INFO:create_model() successfully completed......................................
2023-02-17 12:06:14,715:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:14,715:INFO:Creating metrics dataframe
2023-02-17 12:06:14,731:INFO:Initializing Ada Boost Classifier
2023-02-17 12:06:14,731:INFO:Total runtime is 0.3293014327685038 minutes
2023-02-17 12:06:14,735:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:14,736:INFO:Initializing create_model()
2023-02-17 12:06:14,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:14,736:INFO:Checking exceptions
2023-02-17 12:06:14,736:INFO:Importing libraries
2023-02-17 12:06:14,736:INFO:Copying training dataset
2023-02-17 12:06:14,747:INFO:Defining folds
2023-02-17 12:06:14,747:INFO:Declaring metric variables
2023-02-17 12:06:14,751:INFO:Importing untrained model
2023-02-17 12:06:14,757:INFO:Ada Boost Classifier Imported successfully
2023-02-17 12:06:14,768:INFO:Starting cross validation
2023-02-17 12:06:14,769:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:17,003:INFO:Calculating mean and std
2023-02-17 12:06:17,004:INFO:Creating metrics dataframe
2023-02-17 12:06:17,008:INFO:Uploading results into container
2023-02-17 12:06:17,009:INFO:Uploading model into container now
2023-02-17 12:06:17,009:INFO:_master_model_container: 9
2023-02-17 12:06:17,010:INFO:_display_container: 2
2023-02-17 12:06:17,010:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3561)
2023-02-17 12:06:17,010:INFO:create_model() successfully completed......................................
2023-02-17 12:06:17,136:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:17,136:INFO:Creating metrics dataframe
2023-02-17 12:06:17,150:INFO:Initializing Gradient Boosting Classifier
2023-02-17 12:06:17,150:INFO:Total runtime is 0.36961834828058876 minutes
2023-02-17 12:06:17,154:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:17,154:INFO:Initializing create_model()
2023-02-17 12:06:17,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:17,155:INFO:Checking exceptions
2023-02-17 12:06:17,155:INFO:Importing libraries
2023-02-17 12:06:17,155:INFO:Copying training dataset
2023-02-17 12:06:17,165:INFO:Defining folds
2023-02-17 12:06:17,165:INFO:Declaring metric variables
2023-02-17 12:06:17,170:INFO:Importing untrained model
2023-02-17 12:06:17,175:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 12:06:17,184:INFO:Starting cross validation
2023-02-17 12:06:17,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:22,559:INFO:Calculating mean and std
2023-02-17 12:06:22,560:INFO:Creating metrics dataframe
2023-02-17 12:06:22,566:INFO:Uploading results into container
2023-02-17 12:06:22,567:INFO:Uploading model into container now
2023-02-17 12:06:22,567:INFO:_master_model_container: 10
2023-02-17 12:06:22,567:INFO:_display_container: 2
2023-02-17 12:06:22,568:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3561, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:06:22,568:INFO:create_model() successfully completed......................................
2023-02-17 12:06:22,691:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:22,692:INFO:Creating metrics dataframe
2023-02-17 12:06:22,706:INFO:Initializing Linear Discriminant Analysis
2023-02-17 12:06:22,706:INFO:Total runtime is 0.46222077210744217 minutes
2023-02-17 12:06:22,711:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:22,711:INFO:Initializing create_model()
2023-02-17 12:06:22,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:22,712:INFO:Checking exceptions
2023-02-17 12:06:22,712:INFO:Importing libraries
2023-02-17 12:06:22,712:INFO:Copying training dataset
2023-02-17 12:06:22,722:INFO:Defining folds
2023-02-17 12:06:22,722:INFO:Declaring metric variables
2023-02-17 12:06:22,726:INFO:Importing untrained model
2023-02-17 12:06:22,733:INFO:Linear Discriminant Analysis Imported successfully
2023-02-17 12:06:22,740:INFO:Starting cross validation
2023-02-17 12:06:22,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:22,908:INFO:Calculating mean and std
2023-02-17 12:06:22,909:INFO:Creating metrics dataframe
2023-02-17 12:06:22,915:INFO:Uploading results into container
2023-02-17 12:06:22,915:INFO:Uploading model into container now
2023-02-17 12:06:22,916:INFO:_master_model_container: 11
2023-02-17 12:06:22,916:INFO:_display_container: 2
2023-02-17 12:06:22,917:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-17 12:06:22,917:INFO:create_model() successfully completed......................................
2023-02-17 12:06:23,045:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:23,045:INFO:Creating metrics dataframe
2023-02-17 12:06:23,059:INFO:Initializing Extra Trees Classifier
2023-02-17 12:06:23,060:INFO:Total runtime is 0.4681187709172566 minutes
2023-02-17 12:06:23,065:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:23,066:INFO:Initializing create_model()
2023-02-17 12:06:23,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:23,066:INFO:Checking exceptions
2023-02-17 12:06:23,066:INFO:Importing libraries
2023-02-17 12:06:23,066:INFO:Copying training dataset
2023-02-17 12:06:23,075:INFO:Defining folds
2023-02-17 12:06:23,075:INFO:Declaring metric variables
2023-02-17 12:06:23,080:INFO:Importing untrained model
2023-02-17 12:06:23,087:INFO:Extra Trees Classifier Imported successfully
2023-02-17 12:06:23,096:INFO:Starting cross validation
2023-02-17 12:06:23,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:28,187:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:06:28,194:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:06:29,310:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:06:30,264:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:06:30,922:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:06:31,464:INFO:Calculating mean and std
2023-02-17 12:06:31,465:INFO:Creating metrics dataframe
2023-02-17 12:06:31,471:INFO:Uploading results into container
2023-02-17 12:06:31,472:INFO:Uploading model into container now
2023-02-17 12:06:31,473:INFO:_master_model_container: 12
2023-02-17 12:06:31,473:INFO:_display_container: 2
2023-02-17 12:06:31,473:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3561, verbose=0, warm_start=False)
2023-02-17 12:06:31,473:INFO:create_model() successfully completed......................................
2023-02-17 12:06:31,597:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:31,598:INFO:Creating metrics dataframe
2023-02-17 12:06:31,614:INFO:Initializing Extreme Gradient Boosting
2023-02-17 12:06:31,614:INFO:Total runtime is 0.6106995781262715 minutes
2023-02-17 12:06:31,621:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:31,621:INFO:Initializing create_model()
2023-02-17 12:06:31,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:31,622:INFO:Checking exceptions
2023-02-17 12:06:31,622:INFO:Importing libraries
2023-02-17 12:06:31,622:INFO:Copying training dataset
2023-02-17 12:06:31,631:INFO:Defining folds
2023-02-17 12:06:31,631:INFO:Declaring metric variables
2023-02-17 12:06:31,637:INFO:Importing untrained model
2023-02-17 12:06:31,643:INFO:Extreme Gradient Boosting Imported successfully
2023-02-17 12:06:31,653:INFO:Starting cross validation
2023-02-17 12:06:31,654:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:49,018:INFO:Calculating mean and std
2023-02-17 12:06:49,019:INFO:Creating metrics dataframe
2023-02-17 12:06:49,022:INFO:Uploading results into container
2023-02-17 12:06:49,023:INFO:Uploading model into container now
2023-02-17 12:06:49,024:INFO:_master_model_container: 13
2023-02-17 12:06:49,025:INFO:_display_container: 2
2023-02-17 12:06:49,026:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-17 12:06:49,026:INFO:create_model() successfully completed......................................
2023-02-17 12:06:49,151:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:49,151:INFO:Creating metrics dataframe
2023-02-17 12:06:49,167:INFO:Initializing Light Gradient Boosting Machine
2023-02-17 12:06:49,167:INFO:Total runtime is 0.9032496213912964 minutes
2023-02-17 12:06:49,172:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:49,173:INFO:Initializing create_model()
2023-02-17 12:06:49,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:49,173:INFO:Checking exceptions
2023-02-17 12:06:49,173:INFO:Importing libraries
2023-02-17 12:06:49,174:INFO:Copying training dataset
2023-02-17 12:06:49,184:INFO:Defining folds
2023-02-17 12:06:49,184:INFO:Declaring metric variables
2023-02-17 12:06:49,195:INFO:Importing untrained model
2023-02-17 12:06:49,201:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 12:06:49,213:INFO:Starting cross validation
2023-02-17 12:06:49,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:52,195:INFO:Calculating mean and std
2023-02-17 12:06:52,197:INFO:Creating metrics dataframe
2023-02-17 12:06:52,202:INFO:Uploading results into container
2023-02-17 12:06:52,203:INFO:Uploading model into container now
2023-02-17 12:06:52,203:INFO:_master_model_container: 14
2023-02-17 12:06:52,203:INFO:_display_container: 2
2023-02-17 12:06:52,204:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3561, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 12:06:52,204:INFO:create_model() successfully completed......................................
2023-02-17 12:06:52,335:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:52,335:INFO:Creating metrics dataframe
2023-02-17 12:06:52,349:INFO:Initializing Dummy Classifier
2023-02-17 12:06:52,349:INFO:Total runtime is 0.9562741239865621 minutes
2023-02-17 12:06:52,353:INFO:SubProcess create_model() called ==================================
2023-02-17 12:06:52,353:INFO:Initializing create_model()
2023-02-17 12:06:52,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BCD07F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:52,354:INFO:Checking exceptions
2023-02-17 12:06:52,354:INFO:Importing libraries
2023-02-17 12:06:52,354:INFO:Copying training dataset
2023-02-17 12:06:52,364:INFO:Defining folds
2023-02-17 12:06:52,364:INFO:Declaring metric variables
2023-02-17 12:06:52,368:INFO:Importing untrained model
2023-02-17 12:06:52,375:INFO:Dummy Classifier Imported successfully
2023-02-17 12:06:52,386:INFO:Starting cross validation
2023-02-17 12:06:52,387:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:06:52,653:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:06:52,654:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:06:52,678:INFO:Calculating mean and std
2023-02-17 12:06:52,679:INFO:Creating metrics dataframe
2023-02-17 12:06:52,683:INFO:Uploading results into container
2023-02-17 12:06:52,684:INFO:Uploading model into container now
2023-02-17 12:06:52,685:INFO:_master_model_container: 15
2023-02-17 12:06:52,685:INFO:_display_container: 2
2023-02-17 12:06:52,686:INFO:DummyClassifier(constant=None, random_state=3561, strategy='prior')
2023-02-17 12:06:52,686:INFO:create_model() successfully completed......................................
2023-02-17 12:06:52,806:INFO:SubProcess create_model() end ==================================
2023-02-17 12:06:52,806:INFO:Creating metrics dataframe
2023-02-17 12:06:52,836:INFO:Initializing create_model()
2023-02-17 12:06:52,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3561, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:52,836:INFO:Checking exceptions
2023-02-17 12:06:52,839:INFO:Importing libraries
2023-02-17 12:06:52,839:INFO:Copying training dataset
2023-02-17 12:06:52,851:INFO:Defining folds
2023-02-17 12:06:52,851:INFO:Declaring metric variables
2023-02-17 12:06:52,852:INFO:Importing untrained model
2023-02-17 12:06:52,852:INFO:Declaring custom model
2023-02-17 12:06:52,853:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 12:06:52,855:INFO:Cross validation set to False
2023-02-17 12:06:52,855:INFO:Fitting Model
2023-02-17 12:06:54,920:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3561, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:06:54,920:INFO:create_model() successfully completed......................................
2023-02-17 12:06:55,051:INFO:Initializing create_model()
2023-02-17 12:06:55,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3561, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:55,052:INFO:Checking exceptions
2023-02-17 12:06:55,054:INFO:Importing libraries
2023-02-17 12:06:55,054:INFO:Copying training dataset
2023-02-17 12:06:55,064:INFO:Defining folds
2023-02-17 12:06:55,064:INFO:Declaring metric variables
2023-02-17 12:06:55,064:INFO:Importing untrained model
2023-02-17 12:06:55,064:INFO:Declaring custom model
2023-02-17 12:06:55,065:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 12:06:55,066:INFO:Cross validation set to False
2023-02-17 12:06:55,066:INFO:Fitting Model
2023-02-17 12:06:55,515:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3561, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 12:06:55,515:INFO:create_model() successfully completed......................................
2023-02-17 12:06:55,639:INFO:Initializing create_model()
2023-02-17 12:06:55,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3561, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:06:55,640:INFO:Checking exceptions
2023-02-17 12:06:55,643:INFO:Importing libraries
2023-02-17 12:06:55,643:INFO:Copying training dataset
2023-02-17 12:06:55,651:INFO:Defining folds
2023-02-17 12:06:55,651:INFO:Declaring metric variables
2023-02-17 12:06:55,651:INFO:Importing untrained model
2023-02-17 12:06:55,651:INFO:Declaring custom model
2023-02-17 12:06:55,652:INFO:Random Forest Classifier Imported successfully
2023-02-17 12:06:55,652:INFO:Cross validation set to False
2023-02-17 12:06:55,652:INFO:Fitting Model
2023-02-17 12:06:56,756:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3561, verbose=0, warm_start=False)
2023-02-17 12:06:56,757:INFO:create_model() successfully completed......................................
2023-02-17 12:06:56,929:INFO:_master_model_container: 15
2023-02-17 12:06:56,929:INFO:_display_container: 2
2023-02-17 12:06:56,931:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3561, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3561, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3561, verbose=0, warm_start=False)]
2023-02-17 12:06:56,931:INFO:compare_models() successfully completed......................................
2023-02-17 12:06:57,217:INFO:Initializing tune_model()
2023-02-17 12:06:57,217:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3561, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>)
2023-02-17 12:06:57,218:INFO:Checking exceptions
2023-02-17 12:06:57,218:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-17 12:06:57,239:INFO:Copying training dataset
2023-02-17 12:06:57,248:INFO:Checking base model
2023-02-17 12:06:57,248:INFO:Base model : Gradient Boosting Classifier
2023-02-17 12:06:57,252:INFO:Declaring metric variables
2023-02-17 12:06:57,257:INFO:Defining Hyperparameters
2023-02-17 12:06:57,422:INFO:Tuning with n_jobs=-1
2023-02-17 12:06:57,423:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 12:06:57,423:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 12:06:57,423:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-17 12:06:57,423:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-17 12:06:57,439:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-17 12:09:56,507:INFO:best_params: {'actual_estimator__n_estimators': 27, 'actual_estimator__learning_rate': 2.3610215122960452e-06, 'actual_estimator__subsample': 0.6739637825975584, 'actual_estimator__min_samples_split': 6, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__max_depth': 4, 'actual_estimator__min_impurity_decrease': 1.3382449285151049e-09, 'actual_estimator__max_features': 0.7036171192805354}
2023-02-17 12:09:56,507:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-17 12:09:56,517:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-17 12:09:56,518:INFO:Hyperparameter search completed
2023-02-17 12:09:56,519:INFO:SubProcess create_model() called ==================================
2023-02-17 12:09:56,520:INFO:Initializing create_model()
2023-02-17 12:09:56,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3561, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1E614E80>, model_only=True, return_train_score=False, kwargs={'n_estimators': 27, 'learning_rate': 2.3610215122960452e-06, 'subsample': 0.6739637825975584, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_depth': 4, 'min_impurity_decrease': 1.3382449285151049e-09, 'max_features': 0.7036171192805354})
2023-02-17 12:09:56,520:INFO:Checking exceptions
2023-02-17 12:09:56,521:INFO:Importing libraries
2023-02-17 12:09:56,521:INFO:Copying training dataset
2023-02-17 12:09:56,530:INFO:Defining folds
2023-02-17 12:09:56,530:INFO:Declaring metric variables
2023-02-17 12:09:56,536:INFO:Importing untrained model
2023-02-17 12:09:56,536:INFO:Declaring custom model
2023-02-17 12:09:56,544:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 12:09:56,554:INFO:Starting cross validation
2023-02-17 12:09:56,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:09:57,018:INFO:Calculating mean and std
2023-02-17 12:09:57,019:INFO:Creating metrics dataframe
2023-02-17 12:09:57,028:INFO:Finalizing model
2023-02-17 12:09:57,408:INFO:Uploading results into container
2023-02-17 12:09:57,409:INFO:Uploading model into container now
2023-02-17 12:09:57,410:INFO:_master_model_container: 16
2023-02-17 12:09:57,410:INFO:_display_container: 3
2023-02-17 12:09:57,410:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=2.3610215122960452e-06,
                           loss='deviance', max_depth=4,
                           max_features=0.7036171192805354, max_leaf_nodes=None,
                           min_impurity_decrease=1.3382449285151049e-09,
                           min_samples_leaf=4, min_samples_split=6,
                           min_weight_fraction_leaf=0.0, n_estimators=27,
                           n_iter_no_change=None, random_state=3561,
                           subsample=0.6739637825975584, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:09:57,412:INFO:create_model() successfully completed......................................
2023-02-17 12:09:57,553:INFO:SubProcess create_model() end ==================================
2023-02-17 12:09:57,553:INFO:choose_better activated
2023-02-17 12:09:57,559:INFO:SubProcess create_model() called ==================================
2023-02-17 12:09:57,560:INFO:Initializing create_model()
2023-02-17 12:09:57,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3561, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:09:57,561:INFO:Checking exceptions
2023-02-17 12:09:57,563:INFO:Importing libraries
2023-02-17 12:09:57,563:INFO:Copying training dataset
2023-02-17 12:09:57,574:INFO:Defining folds
2023-02-17 12:09:57,574:INFO:Declaring metric variables
2023-02-17 12:09:57,575:INFO:Importing untrained model
2023-02-17 12:09:57,575:INFO:Declaring custom model
2023-02-17 12:09:57,576:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 12:09:57,577:INFO:Starting cross validation
2023-02-17 12:09:57,577:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:09:58,197:INFO:Calculating mean and std
2023-02-17 12:09:58,198:INFO:Creating metrics dataframe
2023-02-17 12:09:58,200:INFO:Finalizing model
2023-02-17 12:09:58,236:INFO:Uploading results into container
2023-02-17 12:09:58,237:INFO:Uploading model into container now
2023-02-17 12:09:58,237:INFO:_master_model_container: 17
2023-02-17 12:09:58,237:INFO:_display_container: 4
2023-02-17 12:09:58,237:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3561, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:09:58,238:INFO:create_model() successfully completed......................................
2023-02-17 12:09:58,374:INFO:SubProcess create_model() end ==================================
2023-02-17 12:09:58,374:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3561, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Recall is 0.7913
2023-02-17 12:09:58,375:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=2.3610215122960452e-06,
                           loss='deviance', max_depth=4,
                           max_features=0.7036171192805354, max_leaf_nodes=None,
                           min_impurity_decrease=1.3382449285151049e-09,
                           min_samples_leaf=4, min_samples_split=6,
                           min_weight_fraction_leaf=0.0, n_estimators=27,
                           n_iter_no_change=None, random_state=3561,
                           subsample=0.6739637825975584, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Recall is 0.965
2023-02-17 12:09:58,375:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=2.3610215122960452e-06,
                           loss='deviance', max_depth=4,
                           max_features=0.7036171192805354, max_leaf_nodes=None,
                           min_impurity_decrease=1.3382449285151049e-09,
                           min_samples_leaf=4, min_samples_split=6,
                           min_weight_fraction_leaf=0.0, n_estimators=27,
                           n_iter_no_change=None, random_state=3561,
                           subsample=0.6739637825975584, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-02-17 12:09:58,375:INFO:choose_better completed
2023-02-17 12:09:58,387:INFO:_master_model_container: 17
2023-02-17 12:09:58,388:INFO:_display_container: 3
2023-02-17 12:09:58,389:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=2.3610215122960452e-06,
                           loss='deviance', max_depth=4,
                           max_features=0.7036171192805354, max_leaf_nodes=None,
                           min_impurity_decrease=1.3382449285151049e-09,
                           min_samples_leaf=4, min_samples_split=6,
                           min_weight_fraction_leaf=0.0, n_estimators=27,
                           n_iter_no_change=None, random_state=3561,
                           subsample=0.6739637825975584, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:09:58,390:INFO:tune_model() successfully completed......................................
2023-02-17 12:09:58,537:INFO:Initializing tune_model()
2023-02-17 12:09:58,537:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3561, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>)
2023-02-17 12:09:58,538:INFO:Checking exceptions
2023-02-17 12:09:58,538:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-17 12:09:58,567:INFO:Copying training dataset
2023-02-17 12:09:58,574:INFO:Checking base model
2023-02-17 12:09:58,574:INFO:Base model : Light Gradient Boosting Machine
2023-02-17 12:09:58,579:INFO:Declaring metric variables
2023-02-17 12:09:58,586:INFO:Defining Hyperparameters
2023-02-17 12:09:58,734:INFO:Tuning with n_jobs=-1
2023-02-17 12:09:58,735:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 12:09:58,735:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 12:09:58,736:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-17 12:09:58,736:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-17 12:09:58,740:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-17 12:10:27,023:INFO:best_params: {'actual_estimator__num_leaves': 144, 'actual_estimator__learning_rate': 3.4425141431464073e-06, 'actual_estimator__n_estimators': 55, 'actual_estimator__min_split_gain': 0.4503209112922254, 'actual_estimator__reg_alpha': 1.9819296198631634e-06, 'actual_estimator__reg_lambda': 0.23145011464429469, 'actual_estimator__feature_fraction': 0.9208981655056958, 'actual_estimator__bagging_fraction': 0.663432773136228, 'actual_estimator__bagging_freq': 3, 'actual_estimator__min_child_samples': 46}
2023-02-17 12:10:27,023:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-17 12:10:27,024:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-17 12:10:27,025:INFO:Hyperparameter search completed
2023-02-17 12:10:27,026:INFO:SubProcess create_model() called ==================================
2023-02-17 12:10:27,027:INFO:Initializing create_model()
2023-02-17 12:10:27,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3561, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B170036A0>, model_only=True, return_train_score=False, kwargs={'num_leaves': 144, 'learning_rate': 3.4425141431464073e-06, 'n_estimators': 55, 'min_split_gain': 0.4503209112922254, 'reg_alpha': 1.9819296198631634e-06, 'reg_lambda': 0.23145011464429469, 'feature_fraction': 0.9208981655056958, 'bagging_fraction': 0.663432773136228, 'bagging_freq': 3, 'min_child_samples': 46})
2023-02-17 12:10:27,027:INFO:Checking exceptions
2023-02-17 12:10:27,027:INFO:Importing libraries
2023-02-17 12:10:27,027:INFO:Copying training dataset
2023-02-17 12:10:27,037:INFO:Defining folds
2023-02-17 12:10:27,037:INFO:Declaring metric variables
2023-02-17 12:10:27,041:INFO:Importing untrained model
2023-02-17 12:10:27,041:INFO:Declaring custom model
2023-02-17 12:10:27,047:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 12:10:27,060:INFO:Starting cross validation
2023-02-17 12:10:27,061:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:10:27,546:INFO:Calculating mean and std
2023-02-17 12:10:27,548:INFO:Creating metrics dataframe
2023-02-17 12:10:27,559:INFO:Finalizing model
2023-02-17 12:10:27,837:INFO:Uploading results into container
2023-02-17 12:10:27,839:INFO:Uploading model into container now
2023-02-17 12:10:27,839:INFO:_master_model_container: 18
2023-02-17 12:10:27,839:INFO:_display_container: 4
2023-02-17 12:10:27,840:INFO:LGBMClassifier(bagging_fraction=0.663432773136228, bagging_freq=3,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9208981655056958, importance_type='split',
               learning_rate=3.4425141431464073e-06, max_depth=-1,
               min_child_samples=46, min_child_weight=0.001,
               min_split_gain=0.4503209112922254, n_estimators=55, n_jobs=-1,
               num_leaves=144, objective=None, random_state=3561,
               reg_alpha=1.9819296198631634e-06, reg_lambda=0.23145011464429469,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-02-17 12:10:27,840:INFO:create_model() successfully completed......................................
2023-02-17 12:10:27,996:INFO:SubProcess create_model() end ==================================
2023-02-17 12:10:27,996:INFO:choose_better activated
2023-02-17 12:10:28,002:INFO:SubProcess create_model() called ==================================
2023-02-17 12:10:28,003:INFO:Initializing create_model()
2023-02-17 12:10:28,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3561, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:10:28,004:INFO:Checking exceptions
2023-02-17 12:10:28,007:INFO:Importing libraries
2023-02-17 12:10:28,008:INFO:Copying training dataset
2023-02-17 12:10:28,014:INFO:Defining folds
2023-02-17 12:10:28,014:INFO:Declaring metric variables
2023-02-17 12:10:28,015:INFO:Importing untrained model
2023-02-17 12:10:28,015:INFO:Declaring custom model
2023-02-17 12:10:28,017:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 12:10:28,017:INFO:Starting cross validation
2023-02-17 12:10:28,018:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:10:28,354:INFO:Calculating mean and std
2023-02-17 12:10:28,355:INFO:Creating metrics dataframe
2023-02-17 12:10:28,357:INFO:Finalizing model
2023-02-17 12:10:28,375:INFO:Uploading results into container
2023-02-17 12:10:28,375:INFO:Uploading model into container now
2023-02-17 12:10:28,376:INFO:_master_model_container: 19
2023-02-17 12:10:28,376:INFO:_display_container: 5
2023-02-17 12:10:28,376:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3561, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 12:10:28,376:INFO:create_model() successfully completed......................................
2023-02-17 12:10:28,513:INFO:SubProcess create_model() end ==================================
2023-02-17 12:10:28,514:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3561, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.7825
2023-02-17 12:10:28,515:INFO:LGBMClassifier(bagging_fraction=0.663432773136228, bagging_freq=3,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9208981655056958, importance_type='split',
               learning_rate=3.4425141431464073e-06, max_depth=-1,
               min_child_samples=46, min_child_weight=0.001,
               min_split_gain=0.4503209112922254, n_estimators=55, n_jobs=-1,
               num_leaves=144, objective=None, random_state=3561,
               reg_alpha=1.9819296198631634e-06, reg_lambda=0.23145011464429469,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for Recall is 0.9198
2023-02-17 12:10:28,515:INFO:LGBMClassifier(bagging_fraction=0.663432773136228, bagging_freq=3,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9208981655056958, importance_type='split',
               learning_rate=3.4425141431464073e-06, max_depth=-1,
               min_child_samples=46, min_child_weight=0.001,
               min_split_gain=0.4503209112922254, n_estimators=55, n_jobs=-1,
               num_leaves=144, objective=None, random_state=3561,
               reg_alpha=1.9819296198631634e-06, reg_lambda=0.23145011464429469,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) is best model
2023-02-17 12:10:28,515:INFO:choose_better completed
2023-02-17 12:10:28,527:INFO:_master_model_container: 19
2023-02-17 12:10:28,527:INFO:_display_container: 4
2023-02-17 12:10:28,528:INFO:LGBMClassifier(bagging_fraction=0.663432773136228, bagging_freq=3,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9208981655056958, importance_type='split',
               learning_rate=3.4425141431464073e-06, max_depth=-1,
               min_child_samples=46, min_child_weight=0.001,
               min_split_gain=0.4503209112922254, n_estimators=55, n_jobs=-1,
               num_leaves=144, objective=None, random_state=3561,
               reg_alpha=1.9819296198631634e-06, reg_lambda=0.23145011464429469,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-02-17 12:10:28,528:INFO:tune_model() successfully completed......................................
2023-02-17 12:10:28,672:INFO:Initializing tune_model()
2023-02-17 12:10:28,672:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3561, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B08F90400>)
2023-02-17 12:10:28,672:INFO:Checking exceptions
2023-02-17 12:10:28,672:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-17 12:10:28,696:INFO:Copying training dataset
2023-02-17 12:10:28,704:INFO:Checking base model
2023-02-17 12:10:28,704:INFO:Base model : Random Forest Classifier
2023-02-17 12:10:28,709:INFO:Declaring metric variables
2023-02-17 12:10:28,713:INFO:Defining Hyperparameters
2023-02-17 12:10:28,961:INFO:Tuning with n_jobs=-1
2023-02-17 12:10:28,961:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 12:10:28,961:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 12:10:28,962:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\distributions.py:427: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-02-17 12:10:28,963:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-17 12:10:28,963:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-17 12:10:28,966:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-17 12:10:42,007:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:10:42,877:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:10:50,096:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:10:52,645:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:10:55,448:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:11:00,583:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:11:07,372:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:11:08,880:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:11:10,535:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:11:12,602:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:15:32,525:INFO:PyCaret ClassificationExperiment
2023-02-17 12:15:32,581:INFO:Logging name: clf-default-name
2023-02-17 12:15:32,581:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-17 12:15:32,581:INFO:version 3.0.0.rc9
2023-02-17 12:15:32,581:INFO:Initializing setup()
2023-02-17 12:15:32,581:INFO:self.USI: 101b
2023-02-17 12:15:32,590:INFO:self._variable_keys: {'pipeline', 'exp_name_log', 'fold_groups_param', 'y_test', 'gpu_param', 'exp_id', 'X_test', 'y', 'target_param', 'fix_imbalance', 'n_jobs_param', 'X_train', 'fold_generator', 'is_multiclass', 'fold_shuffle_param', 'memory', '_ml_usecase', 'gpu_n_jobs_param', 'USI', '_available_plots', 'X', 'logging_param', 'seed', 'data', 'y_train', 'html_param', 'log_plots_param', 'idx'}
2023-02-17 12:15:32,591:INFO:Checking environment
2023-02-17 12:15:32,592:INFO:python_version: 3.9.15
2023-02-17 12:15:32,592:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-17 12:15:32,608:INFO:machine: AMD64
2023-02-17 12:15:32,629:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-17 12:15:32,784:INFO:Memory: svmem(total=8469581824, available=4475355136, percent=47.2, used=3994226688, free=4475355136)
2023-02-17 12:15:32,797:INFO:Physical Core: 4
2023-02-17 12:15:32,797:INFO:Logical Core: 4
2023-02-17 12:15:32,797:INFO:Checking libraries
2023-02-17 12:15:32,797:INFO:System:
2023-02-17 12:15:32,807:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-17 12:15:32,807:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-17 12:15:32,807:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-17 12:15:32,807:INFO:PyCaret required dependencies:
2023-02-17 12:15:32,861:INFO:                 pip: 22.3.1
2023-02-17 12:15:32,861:INFO:          setuptools: 60.10.0
2023-02-17 12:15:32,861:INFO:             pycaret: 3.0.0rc9
2023-02-17 12:15:32,861:INFO:             IPython: 7.31.1
2023-02-17 12:15:32,861:INFO:          ipywidgets: 7.6.5
2023-02-17 12:15:32,861:INFO:                tqdm: 4.64.1
2023-02-17 12:15:32,861:INFO:               numpy: 1.21.5
2023-02-17 12:15:32,861:INFO:              pandas: 1.4.4
2023-02-17 12:15:32,861:INFO:              jinja2: 2.11.3
2023-02-17 12:15:32,861:INFO:               scipy: 1.9.3
2023-02-17 12:15:32,861:INFO:              joblib: 1.2.0
2023-02-17 12:15:32,861:INFO:             sklearn: 1.0.2
2023-02-17 12:15:32,861:INFO:                pyod: 1.0.7
2023-02-17 12:15:32,861:INFO:            imblearn: 0.10.1
2023-02-17 12:15:32,861:INFO:   category_encoders: 2.6.0
2023-02-17 12:15:32,861:INFO:            lightgbm: 3.3.5
2023-02-17 12:15:32,861:INFO:               numba: 0.56.4
2023-02-17 12:15:32,862:INFO:            requests: 2.28.1
2023-02-17 12:15:32,862:INFO:          matplotlib: 3.6.2
2023-02-17 12:15:32,862:INFO:          scikitplot: 0.3.7
2023-02-17 12:15:32,862:INFO:         yellowbrick: 1.5
2023-02-17 12:15:32,862:INFO:              plotly: 5.9.0
2023-02-17 12:15:32,862:INFO:             kaleido: 0.2.1
2023-02-17 12:15:32,862:INFO:         statsmodels: 0.13.2
2023-02-17 12:15:32,862:INFO:              sktime: 0.16.1
2023-02-17 12:15:32,862:INFO:               tbats: 1.1.2
2023-02-17 12:15:32,862:INFO:            pmdarima: 2.0.2
2023-02-17 12:15:32,862:INFO:              psutil: 5.9.0
2023-02-17 12:15:32,862:INFO:PyCaret optional dependencies:
2023-02-17 12:15:32,863:INFO:                shap: 0.41.0
2023-02-17 12:15:32,863:INFO:           interpret: Not installed
2023-02-17 12:15:32,863:INFO:                umap: Not installed
2023-02-17 12:15:32,863:INFO:    pandas_profiling: 4.0.0
2023-02-17 12:15:32,863:INFO:  explainerdashboard: 0.3.6.2
2023-02-17 12:15:32,863:INFO:             autoviz: 0.1.58
2023-02-17 12:15:32,863:INFO:           fairlearn: Not installed
2023-02-17 12:15:32,863:INFO:             xgboost: 1.7.3
2023-02-17 12:15:32,863:INFO:            catboost: Not installed
2023-02-17 12:15:32,863:INFO:              kmodes: Not installed
2023-02-17 12:15:32,863:INFO:             mlxtend: Not installed
2023-02-17 12:15:32,863:INFO:       statsforecast: Not installed
2023-02-17 12:15:32,863:INFO:        tune_sklearn: Not installed
2023-02-17 12:15:32,863:INFO:                 ray: Not installed
2023-02-17 12:15:32,863:INFO:            hyperopt: Not installed
2023-02-17 12:15:32,863:INFO:              optuna: 2.10.1
2023-02-17 12:15:32,863:INFO:               skopt: Not installed
2023-02-17 12:15:32,864:INFO:              mlflow: Not installed
2023-02-17 12:15:32,864:INFO:              gradio: Not installed
2023-02-17 12:15:32,864:INFO:             fastapi: Not installed
2023-02-17 12:15:32,864:INFO:             uvicorn: Not installed
2023-02-17 12:15:32,864:INFO:              m2cgen: Not installed
2023-02-17 12:15:32,864:INFO:           evidently: Not installed
2023-02-17 12:15:32,864:INFO:               fugue: Not installed
2023-02-17 12:15:32,864:INFO:           streamlit: Not installed
2023-02-17 12:15:32,864:INFO:             prophet: Not installed
2023-02-17 12:15:32,864:INFO:None
2023-02-17 12:15:32,870:INFO:Set up data.
2023-02-17 12:15:33,299:INFO:Set up train/test split.
2023-02-17 12:15:33,670:INFO:Set up index.
2023-02-17 12:15:33,682:INFO:Set up folding strategy.
2023-02-17 12:15:33,709:INFO:Assigning column types.
2023-02-17 12:15:33,766:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-17 12:15:34,113:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-17 12:15:34,293:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:15:34,581:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:15:34,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:15:35,100:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-17 12:15:35,344:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:15:35,456:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:15:35,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:15:35,460:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-17 12:15:35,632:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:15:35,667:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:15:35,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:15:35,745:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:15:35,861:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:15:35,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:15:35,865:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-17 12:15:35,969:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:15:35,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:15:36,172:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:15:36,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:15:36,814:INFO:Finished creating preprocessing pipeline.
2023-02-17 12:15:36,847:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2023-02-17 12:15:36,847:INFO:Creating final display dataframe.
2023-02-17 12:15:37,692:INFO:Setup _display_container:                    Description        Value
0                   Session id         1031
1                       Target        Class
2                  Target type       Binary
3          Original data shape  (14662, 11)
4       Transformed data shape  (14662, 11)
5  Transformed train set shape  (10263, 11)
6   Transformed test set shape   (4399, 11)
7             Numeric features           10
2023-02-17 12:15:38,630:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:15:38,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:15:38,752:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:15:38,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:15:38,778:INFO:setup() successfully completed in 7.22s...............
2023-02-17 12:15:39,035:INFO:Initializing compare_models()
2023-02-17 12:15:39,035:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-17 12:15:39,035:INFO:Checking exceptions
2023-02-17 12:15:39,044:INFO:Preparing display monitor
2023-02-17 12:15:39,329:INFO:Initializing Logistic Regression
2023-02-17 12:15:39,329:INFO:Total runtime is 0.0 minutes
2023-02-17 12:15:39,334:INFO:SubProcess create_model() called ==================================
2023-02-17 12:15:39,352:INFO:Initializing create_model()
2023-02-17 12:15:39,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:15:39,352:INFO:Checking exceptions
2023-02-17 12:15:39,353:INFO:Importing libraries
2023-02-17 12:15:39,353:INFO:Copying training dataset
2023-02-17 12:15:39,364:INFO:Defining folds
2023-02-17 12:15:39,365:INFO:Declaring metric variables
2023-02-17 12:15:39,386:INFO:Importing untrained model
2023-02-17 12:15:39,391:INFO:Logistic Regression Imported successfully
2023-02-17 12:15:39,402:INFO:Starting cross validation
2023-02-17 12:15:39,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:15:41,546:INFO:Calculating mean and std
2023-02-17 12:15:41,565:INFO:Creating metrics dataframe
2023-02-17 12:15:41,622:INFO:Uploading results into container
2023-02-17 12:15:41,623:INFO:Uploading model into container now
2023-02-17 12:15:41,623:INFO:_master_model_container: 1
2023-02-17 12:15:41,623:INFO:_display_container: 2
2023-02-17 12:15:41,624:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1031, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-17 12:15:41,624:INFO:create_model() successfully completed......................................
2023-02-17 12:15:47,990:INFO:SubProcess create_model() end ==================================
2023-02-17 12:15:47,990:INFO:Creating metrics dataframe
2023-02-17 12:15:48,032:INFO:Initializing K Neighbors Classifier
2023-02-17 12:15:48,032:INFO:Total runtime is 0.1450367013613383 minutes
2023-02-17 12:15:48,037:INFO:SubProcess create_model() called ==================================
2023-02-17 12:15:48,037:INFO:Initializing create_model()
2023-02-17 12:15:48,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:15:48,038:INFO:Checking exceptions
2023-02-17 12:15:48,038:INFO:Importing libraries
2023-02-17 12:15:48,038:INFO:Copying training dataset
2023-02-17 12:15:48,074:INFO:Defining folds
2023-02-17 12:15:48,075:INFO:Declaring metric variables
2023-02-17 12:15:48,081:INFO:Importing untrained model
2023-02-17 12:15:48,085:INFO:K Neighbors Classifier Imported successfully
2023-02-17 12:15:48,095:INFO:Starting cross validation
2023-02-17 12:15:48,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:15:48,543:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:15:48,590:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:15:48,596:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:15:48,615:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:15:48,720:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:15:48,732:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:15:48,753:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:15:48,774:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:15:48,888:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:15:48,916:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:15:48,973:INFO:Calculating mean and std
2023-02-17 12:15:48,974:INFO:Creating metrics dataframe
2023-02-17 12:15:48,980:INFO:Uploading results into container
2023-02-17 12:15:48,981:INFO:Uploading model into container now
2023-02-17 12:15:48,981:INFO:_master_model_container: 2
2023-02-17 12:15:48,981:INFO:_display_container: 2
2023-02-17 12:15:48,982:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-17 12:15:48,982:INFO:create_model() successfully completed......................................
2023-02-17 12:15:49,114:INFO:SubProcess create_model() end ==================================
2023-02-17 12:15:49,114:INFO:Creating metrics dataframe
2023-02-17 12:15:49,126:INFO:Initializing Naive Bayes
2023-02-17 12:15:49,126:INFO:Total runtime is 0.1632824222246806 minutes
2023-02-17 12:15:49,132:INFO:SubProcess create_model() called ==================================
2023-02-17 12:15:49,133:INFO:Initializing create_model()
2023-02-17 12:15:49,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:15:49,133:INFO:Checking exceptions
2023-02-17 12:15:49,133:INFO:Importing libraries
2023-02-17 12:15:49,133:INFO:Copying training dataset
2023-02-17 12:15:49,142:INFO:Defining folds
2023-02-17 12:15:49,142:INFO:Declaring metric variables
2023-02-17 12:15:49,149:INFO:Importing untrained model
2023-02-17 12:15:49,153:INFO:Naive Bayes Imported successfully
2023-02-17 12:15:49,163:INFO:Starting cross validation
2023-02-17 12:15:49,163:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:15:49,352:INFO:Calculating mean and std
2023-02-17 12:15:49,353:INFO:Creating metrics dataframe
2023-02-17 12:15:49,359:INFO:Uploading results into container
2023-02-17 12:15:49,359:INFO:Uploading model into container now
2023-02-17 12:15:49,360:INFO:_master_model_container: 3
2023-02-17 12:15:49,360:INFO:_display_container: 2
2023-02-17 12:15:49,360:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-17 12:15:49,360:INFO:create_model() successfully completed......................................
2023-02-17 12:15:49,515:INFO:SubProcess create_model() end ==================================
2023-02-17 12:15:49,515:INFO:Creating metrics dataframe
2023-02-17 12:15:49,529:INFO:Initializing Decision Tree Classifier
2023-02-17 12:15:49,530:INFO:Total runtime is 0.16999780734380088 minutes
2023-02-17 12:15:49,543:INFO:SubProcess create_model() called ==================================
2023-02-17 12:15:49,543:INFO:Initializing create_model()
2023-02-17 12:15:49,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:15:49,543:INFO:Checking exceptions
2023-02-17 12:15:49,543:INFO:Importing libraries
2023-02-17 12:15:49,543:INFO:Copying training dataset
2023-02-17 12:15:49,573:INFO:Defining folds
2023-02-17 12:15:49,573:INFO:Declaring metric variables
2023-02-17 12:15:49,577:INFO:Importing untrained model
2023-02-17 12:15:49,583:INFO:Decision Tree Classifier Imported successfully
2023-02-17 12:15:49,592:INFO:Starting cross validation
2023-02-17 12:15:49,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:15:49,983:INFO:Calculating mean and std
2023-02-17 12:15:49,984:INFO:Creating metrics dataframe
2023-02-17 12:15:49,989:INFO:Uploading results into container
2023-02-17 12:15:49,989:INFO:Uploading model into container now
2023-02-17 12:15:49,990:INFO:_master_model_container: 4
2023-02-17 12:15:49,990:INFO:_display_container: 2
2023-02-17 12:15:49,991:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1031, splitter='best')
2023-02-17 12:15:49,991:INFO:create_model() successfully completed......................................
2023-02-17 12:15:50,122:INFO:SubProcess create_model() end ==================================
2023-02-17 12:15:50,122:INFO:Creating metrics dataframe
2023-02-17 12:15:50,149:INFO:Initializing SVM - Linear Kernel
2023-02-17 12:15:50,149:INFO:Total runtime is 0.18032116492589317 minutes
2023-02-17 12:15:50,154:INFO:SubProcess create_model() called ==================================
2023-02-17 12:15:50,155:INFO:Initializing create_model()
2023-02-17 12:15:50,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:15:50,155:INFO:Checking exceptions
2023-02-17 12:15:50,155:INFO:Importing libraries
2023-02-17 12:15:50,155:INFO:Copying training dataset
2023-02-17 12:15:50,165:INFO:Defining folds
2023-02-17 12:15:50,165:INFO:Declaring metric variables
2023-02-17 12:15:50,170:INFO:Importing untrained model
2023-02-17 12:15:50,176:INFO:SVM - Linear Kernel Imported successfully
2023-02-17 12:15:50,187:INFO:Starting cross validation
2023-02-17 12:15:50,188:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:15:50,413:INFO:Calculating mean and std
2023-02-17 12:15:50,414:INFO:Creating metrics dataframe
2023-02-17 12:15:50,420:INFO:Uploading results into container
2023-02-17 12:15:50,421:INFO:Uploading model into container now
2023-02-17 12:15:50,421:INFO:_master_model_container: 5
2023-02-17 12:15:50,421:INFO:_display_container: 2
2023-02-17 12:15:50,422:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1031, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-17 12:15:50,422:INFO:create_model() successfully completed......................................
2023-02-17 12:15:50,573:INFO:SubProcess create_model() end ==================================
2023-02-17 12:15:50,574:INFO:Creating metrics dataframe
2023-02-17 12:15:50,587:INFO:Initializing Ridge Classifier
2023-02-17 12:15:50,587:INFO:Total runtime is 0.1876183072725932 minutes
2023-02-17 12:15:50,589:INFO:SubProcess create_model() called ==================================
2023-02-17 12:15:50,589:INFO:Initializing create_model()
2023-02-17 12:15:50,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:15:50,590:INFO:Checking exceptions
2023-02-17 12:15:50,590:INFO:Importing libraries
2023-02-17 12:15:50,590:INFO:Copying training dataset
2023-02-17 12:15:50,600:INFO:Defining folds
2023-02-17 12:15:50,600:INFO:Declaring metric variables
2023-02-17 12:15:50,606:INFO:Importing untrained model
2023-02-17 12:15:50,610:INFO:Ridge Classifier Imported successfully
2023-02-17 12:15:50,623:INFO:Starting cross validation
2023-02-17 12:15:50,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:15:50,696:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.28636e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:15:50,707:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.31587e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:15:50,718:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.315e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:15:50,719:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.33005e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:15:50,721:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.55628e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:15:50,730:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.43226e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:15:50,750:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.29184e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:15:50,751:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.38032e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:15:50,756:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.23942e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:15:50,759:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.28105e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:15:50,772:INFO:Calculating mean and std
2023-02-17 12:15:50,773:INFO:Creating metrics dataframe
2023-02-17 12:15:50,777:INFO:Uploading results into container
2023-02-17 12:15:50,777:INFO:Uploading model into container now
2023-02-17 12:15:50,778:INFO:_master_model_container: 6
2023-02-17 12:15:50,778:INFO:_display_container: 2
2023-02-17 12:15:50,779:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1031, solver='auto', tol=0.001)
2023-02-17 12:15:50,780:INFO:create_model() successfully completed......................................
2023-02-17 12:15:50,910:INFO:SubProcess create_model() end ==================================
2023-02-17 12:15:50,910:INFO:Creating metrics dataframe
2023-02-17 12:15:50,924:INFO:Initializing Random Forest Classifier
2023-02-17 12:15:50,925:INFO:Total runtime is 0.19325250387191775 minutes
2023-02-17 12:15:50,930:INFO:SubProcess create_model() called ==================================
2023-02-17 12:15:50,931:INFO:Initializing create_model()
2023-02-17 12:15:50,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:15:50,931:INFO:Checking exceptions
2023-02-17 12:15:50,931:INFO:Importing libraries
2023-02-17 12:15:50,931:INFO:Copying training dataset
2023-02-17 12:15:50,940:INFO:Defining folds
2023-02-17 12:15:50,940:INFO:Declaring metric variables
2023-02-17 12:15:50,947:INFO:Importing untrained model
2023-02-17 12:15:50,951:INFO:Random Forest Classifier Imported successfully
2023-02-17 12:15:50,962:INFO:Starting cross validation
2023-02-17 12:15:50,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:15:53,851:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:15:56,541:INFO:Calculating mean and std
2023-02-17 12:15:56,542:INFO:Creating metrics dataframe
2023-02-17 12:15:56,546:INFO:Uploading results into container
2023-02-17 12:15:56,549:INFO:Uploading model into container now
2023-02-17 12:15:56,550:INFO:_master_model_container: 7
2023-02-17 12:15:56,550:INFO:_display_container: 2
2023-02-17 12:15:56,550:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1031, verbose=0, warm_start=False)
2023-02-17 12:15:56,550:INFO:create_model() successfully completed......................................
2023-02-17 12:15:56,680:INFO:SubProcess create_model() end ==================================
2023-02-17 12:15:56,680:INFO:Creating metrics dataframe
2023-02-17 12:15:56,694:INFO:Initializing Quadratic Discriminant Analysis
2023-02-17 12:15:56,694:INFO:Total runtime is 0.28940459092458093 minutes
2023-02-17 12:15:56,700:INFO:SubProcess create_model() called ==================================
2023-02-17 12:15:56,701:INFO:Initializing create_model()
2023-02-17 12:15:56,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:15:56,701:INFO:Checking exceptions
2023-02-17 12:15:56,701:INFO:Importing libraries
2023-02-17 12:15:56,701:INFO:Copying training dataset
2023-02-17 12:15:56,712:INFO:Defining folds
2023-02-17 12:15:56,712:INFO:Declaring metric variables
2023-02-17 12:15:56,717:INFO:Importing untrained model
2023-02-17 12:15:56,724:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-17 12:15:56,737:INFO:Starting cross validation
2023-02-17 12:15:56,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:15:56,941:INFO:Calculating mean and std
2023-02-17 12:15:56,959:INFO:Creating metrics dataframe
2023-02-17 12:15:56,964:INFO:Uploading results into container
2023-02-17 12:15:56,966:INFO:Uploading model into container now
2023-02-17 12:15:56,966:INFO:_master_model_container: 8
2023-02-17 12:15:56,967:INFO:_display_container: 2
2023-02-17 12:15:56,967:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-17 12:15:56,967:INFO:create_model() successfully completed......................................
2023-02-17 12:15:57,097:INFO:SubProcess create_model() end ==================================
2023-02-17 12:15:57,097:INFO:Creating metrics dataframe
2023-02-17 12:15:57,112:INFO:Initializing Ada Boost Classifier
2023-02-17 12:15:57,112:INFO:Total runtime is 0.2963767528533936 minutes
2023-02-17 12:15:57,119:INFO:SubProcess create_model() called ==================================
2023-02-17 12:15:57,119:INFO:Initializing create_model()
2023-02-17 12:15:57,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:15:57,120:INFO:Checking exceptions
2023-02-17 12:15:57,120:INFO:Importing libraries
2023-02-17 12:15:57,120:INFO:Copying training dataset
2023-02-17 12:15:57,128:INFO:Defining folds
2023-02-17 12:15:57,128:INFO:Declaring metric variables
2023-02-17 12:15:57,136:INFO:Importing untrained model
2023-02-17 12:15:57,142:INFO:Ada Boost Classifier Imported successfully
2023-02-17 12:15:57,152:INFO:Starting cross validation
2023-02-17 12:15:57,153:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:15:59,269:INFO:Calculating mean and std
2023-02-17 12:15:59,270:INFO:Creating metrics dataframe
2023-02-17 12:15:59,273:INFO:Uploading results into container
2023-02-17 12:15:59,274:INFO:Uploading model into container now
2023-02-17 12:15:59,274:INFO:_master_model_container: 9
2023-02-17 12:15:59,274:INFO:_display_container: 2
2023-02-17 12:15:59,275:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1031)
2023-02-17 12:15:59,275:INFO:create_model() successfully completed......................................
2023-02-17 12:15:59,408:INFO:SubProcess create_model() end ==================================
2023-02-17 12:15:59,408:INFO:Creating metrics dataframe
2023-02-17 12:15:59,423:INFO:Initializing Gradient Boosting Classifier
2023-02-17 12:15:59,423:INFO:Total runtime is 0.3348900238672893 minutes
2023-02-17 12:15:59,427:INFO:SubProcess create_model() called ==================================
2023-02-17 12:15:59,428:INFO:Initializing create_model()
2023-02-17 12:15:59,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:15:59,428:INFO:Checking exceptions
2023-02-17 12:15:59,428:INFO:Importing libraries
2023-02-17 12:15:59,428:INFO:Copying training dataset
2023-02-17 12:15:59,439:INFO:Defining folds
2023-02-17 12:15:59,439:INFO:Declaring metric variables
2023-02-17 12:15:59,448:INFO:Importing untrained model
2023-02-17 12:15:59,455:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 12:15:59,464:INFO:Starting cross validation
2023-02-17 12:15:59,465:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:16:04,954:INFO:Calculating mean and std
2023-02-17 12:16:04,956:INFO:Creating metrics dataframe
2023-02-17 12:16:04,962:INFO:Uploading results into container
2023-02-17 12:16:04,963:INFO:Uploading model into container now
2023-02-17 12:16:04,963:INFO:_master_model_container: 10
2023-02-17 12:16:04,963:INFO:_display_container: 2
2023-02-17 12:16:04,964:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1031, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:16:04,964:INFO:create_model() successfully completed......................................
2023-02-17 12:16:05,092:INFO:SubProcess create_model() end ==================================
2023-02-17 12:16:05,092:INFO:Creating metrics dataframe
2023-02-17 12:16:05,106:INFO:Initializing Linear Discriminant Analysis
2023-02-17 12:16:05,106:INFO:Total runtime is 0.4296030640602112 minutes
2023-02-17 12:16:05,111:INFO:SubProcess create_model() called ==================================
2023-02-17 12:16:05,112:INFO:Initializing create_model()
2023-02-17 12:16:05,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:16:05,112:INFO:Checking exceptions
2023-02-17 12:16:05,112:INFO:Importing libraries
2023-02-17 12:16:05,112:INFO:Copying training dataset
2023-02-17 12:16:05,122:INFO:Defining folds
2023-02-17 12:16:05,122:INFO:Declaring metric variables
2023-02-17 12:16:05,126:INFO:Importing untrained model
2023-02-17 12:16:05,132:INFO:Linear Discriminant Analysis Imported successfully
2023-02-17 12:16:05,143:INFO:Starting cross validation
2023-02-17 12:16:05,144:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:16:05,410:INFO:Calculating mean and std
2023-02-17 12:16:05,411:INFO:Creating metrics dataframe
2023-02-17 12:16:05,417:INFO:Uploading results into container
2023-02-17 12:16:05,419:INFO:Uploading model into container now
2023-02-17 12:16:05,419:INFO:_master_model_container: 11
2023-02-17 12:16:05,419:INFO:_display_container: 2
2023-02-17 12:16:05,419:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-17 12:16:05,420:INFO:create_model() successfully completed......................................
2023-02-17 12:16:05,543:INFO:SubProcess create_model() end ==================================
2023-02-17 12:16:05,543:INFO:Creating metrics dataframe
2023-02-17 12:16:05,559:INFO:Initializing Extra Trees Classifier
2023-02-17 12:16:05,559:INFO:Total runtime is 0.437159542242686 minutes
2023-02-17 12:16:05,567:INFO:SubProcess create_model() called ==================================
2023-02-17 12:16:05,568:INFO:Initializing create_model()
2023-02-17 12:16:05,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:16:05,568:INFO:Checking exceptions
2023-02-17 12:16:05,568:INFO:Importing libraries
2023-02-17 12:16:05,569:INFO:Copying training dataset
2023-02-17 12:16:05,579:INFO:Defining folds
2023-02-17 12:16:05,580:INFO:Declaring metric variables
2023-02-17 12:16:05,587:INFO:Importing untrained model
2023-02-17 12:16:05,593:INFO:Extra Trees Classifier Imported successfully
2023-02-17 12:16:05,605:INFO:Starting cross validation
2023-02-17 12:16:05,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:16:06,985:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 12:16:09,913:INFO:Calculating mean and std
2023-02-17 12:16:09,914:INFO:Creating metrics dataframe
2023-02-17 12:16:09,921:INFO:Uploading results into container
2023-02-17 12:16:09,922:INFO:Uploading model into container now
2023-02-17 12:16:09,922:INFO:_master_model_container: 12
2023-02-17 12:16:09,922:INFO:_display_container: 2
2023-02-17 12:16:09,923:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1031, verbose=0, warm_start=False)
2023-02-17 12:16:09,923:INFO:create_model() successfully completed......................................
2023-02-17 12:16:10,060:INFO:SubProcess create_model() end ==================================
2023-02-17 12:16:10,060:INFO:Creating metrics dataframe
2023-02-17 12:16:10,075:INFO:Initializing Extreme Gradient Boosting
2023-02-17 12:16:10,075:INFO:Total runtime is 0.5124249736467997 minutes
2023-02-17 12:16:10,079:INFO:SubProcess create_model() called ==================================
2023-02-17 12:16:10,079:INFO:Initializing create_model()
2023-02-17 12:16:10,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:16:10,079:INFO:Checking exceptions
2023-02-17 12:16:10,080:INFO:Importing libraries
2023-02-17 12:16:10,080:INFO:Copying training dataset
2023-02-17 12:16:10,089:INFO:Defining folds
2023-02-17 12:16:10,090:INFO:Declaring metric variables
2023-02-17 12:16:10,095:INFO:Importing untrained model
2023-02-17 12:16:10,099:INFO:Extreme Gradient Boosting Imported successfully
2023-02-17 12:16:10,110:INFO:Starting cross validation
2023-02-17 12:16:10,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:16:13,978:INFO:Calculating mean and std
2023-02-17 12:16:13,979:INFO:Creating metrics dataframe
2023-02-17 12:16:13,983:INFO:Uploading results into container
2023-02-17 12:16:13,984:INFO:Uploading model into container now
2023-02-17 12:16:13,984:INFO:_master_model_container: 13
2023-02-17 12:16:13,985:INFO:_display_container: 2
2023-02-17 12:16:13,986:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-17 12:16:13,986:INFO:create_model() successfully completed......................................
2023-02-17 12:16:14,128:INFO:SubProcess create_model() end ==================================
2023-02-17 12:16:14,128:INFO:Creating metrics dataframe
2023-02-17 12:16:14,144:INFO:Initializing Light Gradient Boosting Machine
2023-02-17 12:16:14,144:INFO:Total runtime is 0.5802480697631835 minutes
2023-02-17 12:16:14,149:INFO:SubProcess create_model() called ==================================
2023-02-17 12:16:14,149:INFO:Initializing create_model()
2023-02-17 12:16:14,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:16:14,150:INFO:Checking exceptions
2023-02-17 12:16:14,150:INFO:Importing libraries
2023-02-17 12:16:14,150:INFO:Copying training dataset
2023-02-17 12:16:14,160:INFO:Defining folds
2023-02-17 12:16:14,160:INFO:Declaring metric variables
2023-02-17 12:16:14,165:INFO:Importing untrained model
2023-02-17 12:16:14,172:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 12:16:14,182:INFO:Starting cross validation
2023-02-17 12:16:14,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:16:15,098:INFO:Calculating mean and std
2023-02-17 12:16:15,100:INFO:Creating metrics dataframe
2023-02-17 12:16:15,103:INFO:Uploading results into container
2023-02-17 12:16:15,106:INFO:Uploading model into container now
2023-02-17 12:16:15,106:INFO:_master_model_container: 14
2023-02-17 12:16:15,106:INFO:_display_container: 2
2023-02-17 12:16:15,107:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1031, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 12:16:15,107:INFO:create_model() successfully completed......................................
2023-02-17 12:16:15,241:INFO:SubProcess create_model() end ==================================
2023-02-17 12:16:15,241:INFO:Creating metrics dataframe
2023-02-17 12:16:15,257:INFO:Initializing Dummy Classifier
2023-02-17 12:16:15,258:INFO:Total runtime is 0.598816168308258 minutes
2023-02-17 12:16:15,262:INFO:SubProcess create_model() called ==================================
2023-02-17 12:16:15,262:INFO:Initializing create_model()
2023-02-17 12:16:15,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1ABBF220>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B08E72C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:16:15,263:INFO:Checking exceptions
2023-02-17 12:16:15,263:INFO:Importing libraries
2023-02-17 12:16:15,263:INFO:Copying training dataset
2023-02-17 12:16:15,272:INFO:Defining folds
2023-02-17 12:16:15,272:INFO:Declaring metric variables
2023-02-17 12:16:15,277:INFO:Importing untrained model
2023-02-17 12:16:15,281:INFO:Dummy Classifier Imported successfully
2023-02-17 12:16:15,292:INFO:Starting cross validation
2023-02-17 12:16:15,292:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:16:15,329:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:16:15,344:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:16:15,344:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:16:15,361:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:16:15,365:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:16:15,375:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:16:15,378:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:16:15,442:INFO:Calculating mean and std
2023-02-17 12:16:15,443:INFO:Creating metrics dataframe
2023-02-17 12:16:15,447:INFO:Uploading results into container
2023-02-17 12:16:15,447:INFO:Uploading model into container now
2023-02-17 12:16:15,448:INFO:_master_model_container: 15
2023-02-17 12:18:55,675:INFO:PyCaret ClassificationExperiment
2023-02-17 12:18:55,678:INFO:Logging name: clf-default-name
2023-02-17 12:18:55,679:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-17 12:18:55,681:INFO:version 3.0.0.rc9
2023-02-17 12:18:55,682:INFO:Initializing setup()
2023-02-17 12:18:55,684:INFO:self.USI: 22e6
2023-02-17 12:18:55,685:INFO:self._variable_keys: {'pipeline', 'exp_name_log', 'fold_groups_param', 'y_test', 'gpu_param', 'exp_id', 'X_test', 'y', 'target_param', 'fix_imbalance', 'n_jobs_param', 'X_train', 'fold_generator', 'is_multiclass', 'fold_shuffle_param', 'memory', '_ml_usecase', 'gpu_n_jobs_param', 'USI', '_available_plots', 'X', 'logging_param', 'seed', 'data', 'y_train', 'html_param', 'log_plots_param', 'idx'}
2023-02-17 12:18:55,687:INFO:Checking environment
2023-02-17 12:18:55,688:INFO:python_version: 3.9.15
2023-02-17 12:18:55,689:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-17 12:18:55,691:INFO:machine: AMD64
2023-02-17 12:18:55,692:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-17 12:18:55,694:INFO:Memory: svmem(total=8469581824, available=2867269632, percent=66.1, used=5602312192, free=2867269632)
2023-02-17 12:18:55,696:INFO:Physical Core: 4
2023-02-17 12:18:55,697:INFO:Logical Core: 4
2023-02-17 12:18:55,699:INFO:Checking libraries
2023-02-17 12:18:55,700:INFO:System:
2023-02-17 12:18:55,702:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-17 12:18:55,704:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-17 12:18:55,705:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-17 12:18:55,707:INFO:PyCaret required dependencies:
2023-02-17 12:18:55,708:INFO:                 pip: 22.3.1
2023-02-17 12:18:55,710:INFO:          setuptools: 60.10.0
2023-02-17 12:18:55,712:INFO:             pycaret: 3.0.0rc9
2023-02-17 12:18:55,713:INFO:             IPython: 7.31.1
2023-02-17 12:18:55,714:INFO:          ipywidgets: 7.6.5
2023-02-17 12:18:55,716:INFO:                tqdm: 4.64.1
2023-02-17 12:18:55,717:INFO:               numpy: 1.21.5
2023-02-17 12:18:55,719:INFO:              pandas: 1.4.4
2023-02-17 12:18:55,720:INFO:              jinja2: 2.11.3
2023-02-17 12:18:55,722:INFO:               scipy: 1.9.3
2023-02-17 12:18:55,723:INFO:              joblib: 1.2.0
2023-02-17 12:18:55,725:INFO:             sklearn: 1.0.2
2023-02-17 12:18:55,728:INFO:                pyod: 1.0.7
2023-02-17 12:18:55,729:INFO:            imblearn: 0.10.1
2023-02-17 12:18:55,731:INFO:   category_encoders: 2.6.0
2023-02-17 12:18:55,734:INFO:            lightgbm: 3.3.5
2023-02-17 12:18:55,735:INFO:               numba: 0.56.4
2023-02-17 12:18:55,737:INFO:            requests: 2.28.1
2023-02-17 12:18:55,739:INFO:          matplotlib: 3.6.2
2023-02-17 12:18:55,740:INFO:          scikitplot: 0.3.7
2023-02-17 12:18:55,741:INFO:         yellowbrick: 1.5
2023-02-17 12:18:55,744:INFO:              plotly: 5.9.0
2023-02-17 12:18:55,746:INFO:             kaleido: 0.2.1
2023-02-17 12:18:55,747:INFO:         statsmodels: 0.13.2
2023-02-17 12:18:55,749:INFO:              sktime: 0.16.1
2023-02-17 12:18:55,750:INFO:               tbats: 1.1.2
2023-02-17 12:18:55,752:INFO:            pmdarima: 2.0.2
2023-02-17 12:18:55,753:INFO:              psutil: 5.9.0
2023-02-17 12:18:55,754:INFO:PyCaret optional dependencies:
2023-02-17 12:18:55,755:INFO:                shap: 0.41.0
2023-02-17 12:18:55,757:INFO:           interpret: Not installed
2023-02-17 12:18:55,758:INFO:                umap: Not installed
2023-02-17 12:18:55,761:INFO:    pandas_profiling: 4.0.0
2023-02-17 12:18:55,763:INFO:  explainerdashboard: 0.3.6.2
2023-02-17 12:18:55,765:INFO:             autoviz: 0.1.58
2023-02-17 12:18:55,766:INFO:           fairlearn: Not installed
2023-02-17 12:18:55,768:INFO:             xgboost: 1.7.3
2023-02-17 12:18:55,769:INFO:            catboost: Not installed
2023-02-17 12:18:55,770:INFO:              kmodes: Not installed
2023-02-17 12:18:55,772:INFO:             mlxtend: Not installed
2023-02-17 12:18:55,773:INFO:       statsforecast: Not installed
2023-02-17 12:18:55,774:INFO:        tune_sklearn: Not installed
2023-02-17 12:18:55,775:INFO:                 ray: Not installed
2023-02-17 12:18:55,779:INFO:            hyperopt: Not installed
2023-02-17 12:18:55,780:INFO:              optuna: 2.10.1
2023-02-17 12:18:55,783:INFO:               skopt: Not installed
2023-02-17 12:18:55,790:INFO:              mlflow: Not installed
2023-02-17 12:18:55,796:INFO:              gradio: Not installed
2023-02-17 12:18:55,798:INFO:             fastapi: Not installed
2023-02-17 12:18:55,799:INFO:             uvicorn: Not installed
2023-02-17 12:18:55,801:INFO:              m2cgen: Not installed
2023-02-17 12:18:55,802:INFO:           evidently: Not installed
2023-02-17 12:18:55,803:INFO:               fugue: Not installed
2023-02-17 12:18:55,804:INFO:           streamlit: Not installed
2023-02-17 12:18:55,806:INFO:             prophet: Not installed
2023-02-17 12:18:55,807:INFO:None
2023-02-17 12:18:55,808:INFO:Set up data.
2023-02-17 12:18:55,818:INFO:Set up train/test split.
2023-02-17 12:18:55,829:INFO:Set up index.
2023-02-17 12:18:55,831:INFO:Set up folding strategy.
2023-02-17 12:18:55,833:INFO:Assigning column types.
2023-02-17 12:18:55,887:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-17 12:18:55,972:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-17 12:18:55,976:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:18:56,038:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:18:56,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:18:56,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-17 12:18:56,115:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:18:56,151:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:18:56,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:18:56,158:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-17 12:18:56,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:18:56,255:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:18:56,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:18:56,333:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:18:56,404:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:18:56,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:18:56,411:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-17 12:18:56,526:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:18:56,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:18:56,711:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:18:56,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:18:56,725:INFO:Finished creating preprocessing pipeline.
2023-02-17 12:19:31,447:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3373)
2023-02-17 12:19:31,447:INFO:create_model() successfully completed......................................
2023-02-17 12:19:31,586:INFO:Initializing create_model()
2023-02-17 12:19:31,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3373, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:19:31,587:INFO:Checking exceptions
2023-02-17 12:19:31,591:INFO:Importing libraries
2023-02-17 12:19:31,591:INFO:Copying training dataset
2023-02-17 12:19:31,597:INFO:Defining folds
2023-02-17 12:19:31,597:INFO:Declaring metric variables
2023-02-17 12:19:31,598:INFO:Importing untrained model
2023-02-17 12:19:31,598:INFO:Declaring custom model
2023-02-17 12:19:31,598:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 12:19:31,599:INFO:Cross validation set to False
2023-02-17 12:19:31,599:INFO:Fitting Model
2023-02-17 12:19:31,729:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3373, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 12:19:31,729:INFO:create_model() successfully completed......................................
2023-02-17 12:19:31,896:INFO:_master_model_container: 15
2023-02-17 12:19:31,896:INFO:_display_container: 2
2023-02-17 12:19:31,898:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3373), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3373, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)]
2023-02-17 12:19:31,898:INFO:compare_models() successfully completed......................................
2023-02-17 12:19:44,416:INFO:Initializing tune_model()
2023-02-17 12:19:44,417:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>)
2023-02-17 12:19:44,417:INFO:Checking exceptions
2023-02-17 12:19:44,417:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-17 12:19:44,440:INFO:Copying training dataset
2023-02-17 12:19:44,449:INFO:Checking base model
2023-02-17 12:19:44,449:INFO:Base model : Gradient Boosting Classifier
2023-02-17 12:19:44,453:INFO:Declaring metric variables
2023-02-17 12:19:44,457:INFO:Defining Hyperparameters
2023-02-17 12:19:44,691:INFO:Tuning with n_jobs=-1
2023-02-17 12:19:44,692:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 12:19:44,694:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 12:19:44,695:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-17 12:19:44,695:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-17 12:19:44,698:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-17 12:22:13,173:INFO:best_params: {'actual_estimator__n_estimators': 225, 'actual_estimator__learning_rate': 7.141154965758335e-05, 'actual_estimator__subsample': 0.3293424439792051, 'actual_estimator__min_samples_split': 8, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 8, 'actual_estimator__min_impurity_decrease': 1.3164532592394293e-08, 'actual_estimator__max_features': 0.5861063461056326}
2023-02-17 12:22:13,174:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-17 12:22:13,174:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-17 12:22:13,177:INFO:Hyperparameter search completed
2023-02-17 12:22:13,177:INFO:SubProcess create_model() called ==================================
2023-02-17 12:22:13,179:INFO:Initializing create_model()
2023-02-17 12:22:13,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B75D45700>, model_only=True, return_train_score=False, kwargs={'n_estimators': 225, 'learning_rate': 7.141154965758335e-05, 'subsample': 0.3293424439792051, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_depth': 8, 'min_impurity_decrease': 1.3164532592394293e-08, 'max_features': 0.5861063461056326})
2023-02-17 12:22:13,180:INFO:Checking exceptions
2023-02-17 12:22:13,180:INFO:Importing libraries
2023-02-17 12:22:13,180:INFO:Copying training dataset
2023-02-17 12:22:13,188:INFO:Defining folds
2023-02-17 12:22:13,188:INFO:Declaring metric variables
2023-02-17 12:22:13,192:INFO:Importing untrained model
2023-02-17 12:22:13,192:INFO:Declaring custom model
2023-02-17 12:22:13,199:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 12:22:13,209:INFO:Starting cross validation
2023-02-17 12:22:13,210:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:22:19,962:INFO:Calculating mean and std
2023-02-17 12:22:19,963:INFO:Creating metrics dataframe
2023-02-17 12:22:19,973:INFO:Finalizing model
2023-02-17 12:22:22,839:INFO:Uploading results into container
2023-02-17 12:22:22,841:INFO:Uploading model into container now
2023-02-17 12:22:22,842:INFO:_master_model_container: 16
2023-02-17 12:22:22,842:INFO:_display_container: 3
2023-02-17 12:22:22,842:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=7.141154965758335e-05, loss='deviance',
                           max_depth=8, max_features=0.5861063461056326,
                           max_leaf_nodes=None,
                           min_impurity_decrease=1.3164532592394293e-08,
                           min_samples_leaf=1, min_samples_split=8,
                           min_weight_fraction_leaf=0.0, n_estimators=225,
                           n_iter_no_change=None, random_state=3373,
                           subsample=0.3293424439792051, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:22:22,842:INFO:create_model() successfully completed......................................
2023-02-17 12:22:22,984:INFO:SubProcess create_model() end ==================================
2023-02-17 12:22:22,984:INFO:choose_better activated
2023-02-17 12:22:22,988:INFO:SubProcess create_model() called ==================================
2023-02-17 12:22:22,989:INFO:Initializing create_model()
2023-02-17 12:22:22,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:22:22,989:INFO:Checking exceptions
2023-02-17 12:22:22,992:INFO:Importing libraries
2023-02-17 12:22:22,992:INFO:Copying training dataset
2023-02-17 12:22:22,997:INFO:Defining folds
2023-02-17 12:22:22,997:INFO:Declaring metric variables
2023-02-17 12:22:22,998:INFO:Importing untrained model
2023-02-17 12:22:22,998:INFO:Declaring custom model
2023-02-17 12:22:23,000:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 12:22:23,000:INFO:Starting cross validation
2023-02-17 12:22:23,001:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:22:27,547:INFO:Calculating mean and std
2023-02-17 12:22:27,548:INFO:Creating metrics dataframe
2023-02-17 12:22:27,550:INFO:Finalizing model
2023-02-17 12:22:28,850:INFO:Uploading results into container
2023-02-17 12:22:28,852:INFO:Uploading model into container now
2023-02-17 12:22:28,852:INFO:_master_model_container: 17
2023-02-17 12:22:28,852:INFO:_display_container: 4
2023-02-17 12:22:28,853:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:22:28,853:INFO:create_model() successfully completed......................................
2023-02-17 12:22:29,005:INFO:SubProcess create_model() end ==================================
2023-02-17 12:22:29,006:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Recall is 0.7715
2023-02-17 12:22:29,007:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=7.141154965758335e-05, loss='deviance',
                           max_depth=8, max_features=0.5861063461056326,
                           max_leaf_nodes=None,
                           min_impurity_decrease=1.3164532592394293e-08,
                           min_samples_leaf=1, min_samples_split=8,
                           min_weight_fraction_leaf=0.0, n_estimators=225,
                           n_iter_no_change=None, random_state=3373,
                           subsample=0.3293424439792051, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Recall is 0.7785
2023-02-17 12:22:29,007:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=7.141154965758335e-05, loss='deviance',
                           max_depth=8, max_features=0.5861063461056326,
                           max_leaf_nodes=None,
                           min_impurity_decrease=1.3164532592394293e-08,
                           min_samples_leaf=1, min_samples_split=8,
                           min_weight_fraction_leaf=0.0, n_estimators=225,
                           n_iter_no_change=None, random_state=3373,
                           subsample=0.3293424439792051, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-02-17 12:22:29,007:INFO:choose_better completed
2023-02-17 12:22:29,021:INFO:_master_model_container: 17
2023-02-17 12:22:29,021:INFO:_display_container: 3
2023-02-17 12:22:29,022:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=7.141154965758335e-05, loss='deviance',
                           max_depth=8, max_features=0.5861063461056326,
                           max_leaf_nodes=None,
                           min_impurity_decrease=1.3164532592394293e-08,
                           min_samples_leaf=1, min_samples_split=8,
                           min_weight_fraction_leaf=0.0, n_estimators=225,
                           n_iter_no_change=None, random_state=3373,
                           subsample=0.3293424439792051, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:22:29,022:INFO:tune_model() successfully completed......................................
2023-02-17 12:22:29,164:INFO:Initializing tune_model()
2023-02-17 12:22:29,164:INFO:tune_model(estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3373), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>)
2023-02-17 12:22:29,164:INFO:Checking exceptions
2023-02-17 12:22:29,164:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-17 12:22:29,187:INFO:Copying training dataset
2023-02-17 12:22:29,195:INFO:Checking base model
2023-02-17 12:22:29,195:INFO:Base model : Ada Boost Classifier
2023-02-17 12:22:29,200:INFO:Declaring metric variables
2023-02-17 12:22:29,206:INFO:Defining Hyperparameters
2023-02-17 12:22:29,415:INFO:Tuning with n_jobs=-1
2023-02-17 12:22:29,416:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 12:22:29,416:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 12:22:29,417:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-17 12:22:29,418:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-17 12:22:29,422:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-17 12:23:28,323:INFO:best_params: {'actual_estimator__n_estimators': 181, 'actual_estimator__learning_rate': 0.18202338960571585, 'actual_estimator__algorithm': 'SAMME'}
2023-02-17 12:23:28,323:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-17 12:23:28,324:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-17 12:23:28,325:INFO:Hyperparameter search completed
2023-02-17 12:23:28,325:INFO:SubProcess create_model() called ==================================
2023-02-17 12:23:28,325:INFO:Initializing create_model()
2023-02-17 12:23:28,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3373), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BEEFD00>, model_only=True, return_train_score=False, kwargs={'n_estimators': 181, 'learning_rate': 0.18202338960571585, 'algorithm': 'SAMME'})
2023-02-17 12:23:28,326:INFO:Checking exceptions
2023-02-17 12:23:28,326:INFO:Importing libraries
2023-02-17 12:23:28,326:INFO:Copying training dataset
2023-02-17 12:23:28,333:INFO:Defining folds
2023-02-17 12:23:28,334:INFO:Declaring metric variables
2023-02-17 12:23:28,339:INFO:Importing untrained model
2023-02-17 12:23:28,340:INFO:Declaring custom model
2023-02-17 12:23:28,346:INFO:Ada Boost Classifier Imported successfully
2023-02-17 12:23:28,357:INFO:Starting cross validation
2023-02-17 12:23:28,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:23:33,814:INFO:Calculating mean and std
2023-02-17 12:23:33,815:INFO:Creating metrics dataframe
2023-02-17 12:23:33,821:INFO:Finalizing model
2023-02-17 12:23:35,319:INFO:Uploading results into container
2023-02-17 12:23:35,320:INFO:Uploading model into container now
2023-02-17 12:23:35,320:INFO:_master_model_container: 18
2023-02-17 12:23:35,320:INFO:_display_container: 4
2023-02-17 12:23:35,321:INFO:AdaBoostClassifier(algorithm='SAMME', base_estimator=None,
                   learning_rate=0.18202338960571585, n_estimators=181,
                   random_state=3373)
2023-02-17 12:23:35,321:INFO:create_model() successfully completed......................................
2023-02-17 12:23:35,506:INFO:SubProcess create_model() end ==================================
2023-02-17 12:23:35,506:INFO:choose_better activated
2023-02-17 12:23:35,515:INFO:SubProcess create_model() called ==================================
2023-02-17 12:23:35,516:INFO:Initializing create_model()
2023-02-17 12:23:35,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3373), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:23:35,516:INFO:Checking exceptions
2023-02-17 12:23:35,519:INFO:Importing libraries
2023-02-17 12:23:35,519:INFO:Copying training dataset
2023-02-17 12:23:35,529:INFO:Defining folds
2023-02-17 12:23:35,530:INFO:Declaring metric variables
2023-02-17 12:23:35,530:INFO:Importing untrained model
2023-02-17 12:23:35,530:INFO:Declaring custom model
2023-02-17 12:23:35,531:INFO:Ada Boost Classifier Imported successfully
2023-02-17 12:23:35,531:INFO:Starting cross validation
2023-02-17 12:23:35,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:23:37,353:INFO:Calculating mean and std
2023-02-17 12:23:37,354:INFO:Creating metrics dataframe
2023-02-17 12:23:37,357:INFO:Finalizing model
2023-02-17 12:23:37,389:INFO:Uploading results into container
2023-02-17 12:23:37,390:INFO:Uploading model into container now
2023-02-17 12:23:37,391:INFO:_master_model_container: 19
2023-02-17 12:23:37,391:INFO:_display_container: 5
2023-02-17 12:23:37,392:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3373)
2023-02-17 12:23:37,392:INFO:create_model() successfully completed......................................
2023-02-17 12:23:37,522:INFO:SubProcess create_model() end ==================================
2023-02-17 12:23:37,522:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3373) result for Recall is 0.7488
2023-02-17 12:23:37,523:INFO:AdaBoostClassifier(algorithm='SAMME', base_estimator=None,
                   learning_rate=0.18202338960571585, n_estimators=181,
                   random_state=3373) result for Recall is 0.7525
2023-02-17 12:23:37,523:INFO:AdaBoostClassifier(algorithm='SAMME', base_estimator=None,
                   learning_rate=0.18202338960571585, n_estimators=181,
                   random_state=3373) is best model
2023-02-17 12:23:37,523:INFO:choose_better completed
2023-02-17 12:23:37,535:INFO:_master_model_container: 19
2023-02-17 12:23:37,535:INFO:_display_container: 4
2023-02-17 12:23:37,536:INFO:AdaBoostClassifier(algorithm='SAMME', base_estimator=None,
                   learning_rate=0.18202338960571585, n_estimators=181,
                   random_state=3373)
2023-02-17 12:23:37,536:INFO:tune_model() successfully completed......................................
2023-02-17 12:23:37,679:INFO:Initializing tune_model()
2023-02-17 12:23:37,679:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3373, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>)
2023-02-17 12:23:37,679:INFO:Checking exceptions
2023-02-17 12:23:37,679:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-17 12:23:37,700:INFO:Copying training dataset
2023-02-17 12:23:37,707:INFO:Checking base model
2023-02-17 12:23:37,707:INFO:Base model : Light Gradient Boosting Machine
2023-02-17 12:23:37,713:INFO:Declaring metric variables
2023-02-17 12:23:37,718:INFO:Defining Hyperparameters
2023-02-17 12:23:37,889:INFO:Tuning with n_jobs=-1
2023-02-17 12:23:37,890:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 12:23:37,891:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 12:23:37,891:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-17 12:23:37,891:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-17 12:23:37,895:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-17 12:24:12,361:INFO:best_params: {'actual_estimator__num_leaves': 78, 'actual_estimator__learning_rate': 0.00041589295662335037, 'actual_estimator__n_estimators': 101, 'actual_estimator__min_split_gain': 0.944811372416943, 'actual_estimator__reg_alpha': 3.1313425466523377e-09, 'actual_estimator__reg_lambda': 4.3518369262392935e-06, 'actual_estimator__feature_fraction': 0.7451530772482083, 'actual_estimator__bagging_fraction': 0.8126891728330194, 'actual_estimator__bagging_freq': 0, 'actual_estimator__min_child_samples': 32}
2023-02-17 12:24:12,362:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-17 12:24:12,362:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-17 12:24:12,364:INFO:Hyperparameter search completed
2023-02-17 12:24:12,364:INFO:SubProcess create_model() called ==================================
2023-02-17 12:24:12,366:INFO:Initializing create_model()
2023-02-17 12:24:12,366:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3373, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B1BF97580>, model_only=True, return_train_score=False, kwargs={'num_leaves': 78, 'learning_rate': 0.00041589295662335037, 'n_estimators': 101, 'min_split_gain': 0.944811372416943, 'reg_alpha': 3.1313425466523377e-09, 'reg_lambda': 4.3518369262392935e-06, 'feature_fraction': 0.7451530772482083, 'bagging_fraction': 0.8126891728330194, 'bagging_freq': 0, 'min_child_samples': 32})
2023-02-17 12:24:12,366:INFO:Checking exceptions
2023-02-17 12:24:12,366:INFO:Importing libraries
2023-02-17 12:24:12,366:INFO:Copying training dataset
2023-02-17 12:24:12,375:INFO:Defining folds
2023-02-17 12:24:12,375:INFO:Declaring metric variables
2023-02-17 12:24:12,379:INFO:Importing untrained model
2023-02-17 12:24:12,379:INFO:Declaring custom model
2023-02-17 12:24:12,384:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 12:24:12,396:INFO:Starting cross validation
2023-02-17 12:24:12,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:24:14,410:INFO:Calculating mean and std
2023-02-17 12:24:14,412:INFO:Creating metrics dataframe
2023-02-17 12:24:14,419:INFO:Finalizing model
2023-02-17 12:24:14,866:INFO:Uploading results into container
2023-02-17 12:24:14,868:INFO:Uploading model into container now
2023-02-17 12:24:14,868:INFO:_master_model_container: 20
2023-02-17 12:24:14,868:INFO:_display_container: 5
2023-02-17 12:24:14,869:INFO:LGBMClassifier(bagging_fraction=0.8126891728330194, bagging_freq=0,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7451530772482083, importance_type='split',
               learning_rate=0.00041589295662335037, max_depth=-1,
               min_child_samples=32, min_child_weight=0.001,
               min_split_gain=0.944811372416943, n_estimators=101, n_jobs=-1,
               num_leaves=78, objective=None, random_state=3373,
               reg_alpha=3.1313425466523377e-09,
               reg_lambda=4.3518369262392935e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-02-17 12:24:14,869:INFO:create_model() successfully completed......................................
2023-02-17 12:24:15,024:INFO:SubProcess create_model() end ==================================
2023-02-17 12:24:15,024:INFO:choose_better activated
2023-02-17 12:24:15,028:INFO:SubProcess create_model() called ==================================
2023-02-17 12:24:15,029:INFO:Initializing create_model()
2023-02-17 12:24:15,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3373, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:24:15,030:INFO:Checking exceptions
2023-02-17 12:24:15,032:INFO:Importing libraries
2023-02-17 12:24:15,033:INFO:Copying training dataset
2023-02-17 12:24:15,041:INFO:Defining folds
2023-02-17 12:24:15,042:INFO:Declaring metric variables
2023-02-17 12:24:15,042:INFO:Importing untrained model
2023-02-17 12:24:15,042:INFO:Declaring custom model
2023-02-17 12:24:15,043:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 12:24:15,043:INFO:Starting cross validation
2023-02-17 12:24:15,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:24:16,016:INFO:Calculating mean and std
2023-02-17 12:24:16,016:INFO:Creating metrics dataframe
2023-02-17 12:24:16,019:INFO:Finalizing model
2023-02-17 12:24:16,174:INFO:Uploading results into container
2023-02-17 12:24:16,175:INFO:Uploading model into container now
2023-02-17 12:24:16,176:INFO:_master_model_container: 21
2023-02-17 12:24:16,176:INFO:_display_container: 6
2023-02-17 12:24:16,176:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3373, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 12:24:16,177:INFO:create_model() successfully completed......................................
2023-02-17 12:24:16,340:INFO:SubProcess create_model() end ==================================
2023-02-17 12:24:16,341:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3373, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.7588
2023-02-17 12:24:16,342:INFO:LGBMClassifier(bagging_fraction=0.8126891728330194, bagging_freq=0,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7451530772482083, importance_type='split',
               learning_rate=0.00041589295662335037, max_depth=-1,
               min_child_samples=32, min_child_weight=0.001,
               min_split_gain=0.944811372416943, n_estimators=101, n_jobs=-1,
               num_leaves=78, objective=None, random_state=3373,
               reg_alpha=3.1313425466523377e-09,
               reg_lambda=4.3518369262392935e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.7725
2023-02-17 12:24:16,342:INFO:LGBMClassifier(bagging_fraction=0.8126891728330194, bagging_freq=0,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7451530772482083, importance_type='split',
               learning_rate=0.00041589295662335037, max_depth=-1,
               min_child_samples=32, min_child_weight=0.001,
               min_split_gain=0.944811372416943, n_estimators=101, n_jobs=-1,
               num_leaves=78, objective=None, random_state=3373,
               reg_alpha=3.1313425466523377e-09,
               reg_lambda=4.3518369262392935e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-02-17 12:24:16,343:INFO:choose_better completed
2023-02-17 12:24:16,353:INFO:_master_model_container: 21
2023-02-17 12:24:16,353:INFO:_display_container: 5
2023-02-17 12:24:16,353:INFO:LGBMClassifier(bagging_fraction=0.8126891728330194, bagging_freq=0,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7451530772482083, importance_type='split',
               learning_rate=0.00041589295662335037, max_depth=-1,
               min_child_samples=32, min_child_weight=0.001,
               min_split_gain=0.944811372416943, n_estimators=101, n_jobs=-1,
               num_leaves=78, objective=None, random_state=3373,
               reg_alpha=3.1313425466523377e-09,
               reg_lambda=4.3518369262392935e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-02-17 12:24:16,354:INFO:tune_model() successfully completed......................................
2023-02-17 12:24:16,556:INFO:Initializing automl()
2023-02-17 12:24:16,556:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>, optimize=AUC, use_holdout=False, turbo=True, return_train_score=False)
2023-02-17 12:24:16,556:INFO:Model Selection Basis : CV Results on Training set
2023-02-17 12:24:16,556:INFO:Checking model 0
2023-02-17 12:24:16,556:INFO:Checking model 1
2023-02-17 12:24:16,557:INFO:Checking model 2
2023-02-17 12:24:16,557:INFO:Checking model 3
2023-02-17 12:24:16,557:INFO:Checking model 4
2023-02-17 12:24:16,557:INFO:Checking model 5
2023-02-17 12:24:16,557:INFO:Checking model 6
2023-02-17 12:24:16,558:INFO:Checking model 7
2023-02-17 12:24:16,558:INFO:Checking model 8
2023-02-17 12:24:16,558:INFO:Checking model 9
2023-02-17 12:24:16,558:INFO:Checking model 10
2023-02-17 12:24:16,558:INFO:Checking model 11
2023-02-17 12:24:16,559:INFO:Checking model 12
2023-02-17 12:24:16,559:INFO:Checking model 13
2023-02-17 12:24:16,559:INFO:Checking model 14
2023-02-17 12:24:16,559:INFO:Checking model 15
2023-02-17 12:24:16,559:INFO:Checking model 16
2023-02-17 12:24:16,559:INFO:Checking model 17
2023-02-17 12:24:16,560:INFO:Checking model 18
2023-02-17 12:24:16,560:INFO:Checking model 19
2023-02-17 12:24:16,560:INFO:Checking model 20
2023-02-17 12:24:16,561:INFO:Initializing create_model()
2023-02-17 12:24:16,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:24:16,561:INFO:Checking exceptions
2023-02-17 12:24:16,562:INFO:Importing libraries
2023-02-17 12:24:16,562:INFO:Copying training dataset
2023-02-17 12:24:16,569:INFO:Defining folds
2023-02-17 12:24:16,569:INFO:Declaring metric variables
2023-02-17 12:24:16,569:INFO:Importing untrained model
2023-02-17 12:24:16,569:INFO:Declaring custom model
2023-02-17 12:24:16,570:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 12:24:16,570:INFO:Cross validation set to False
2023-02-17 12:24:16,570:INFO:Fitting Model
2023-02-17 12:24:17,976:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:24:17,976:INFO:create_model() successfully completed......................................
2023-02-17 12:24:18,262:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:24:18,262:INFO:automl() successfully completed......................................
2023-02-17 12:24:18,944:INFO:Initializing finalize_model()
2023-02-17 12:24:18,944:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-02-17 12:24:18,944:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:24:18,948:INFO:Initializing create_model()
2023-02-17 12:24:18,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B0DBBB220>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3373, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-02-17 12:24:18,948:INFO:Checking exceptions
2023-02-17 12:24:18,950:INFO:Importing libraries
2023-02-17 12:24:18,950:INFO:Copying training dataset
2023-02-17 12:24:18,950:INFO:Defining folds
2023-02-17 12:24:18,950:INFO:Declaring metric variables
2023-02-17 12:24:18,950:INFO:Importing untrained model
2023-02-17 12:24:18,950:INFO:Declaring custom model
2023-02-17 12:24:18,951:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 12:24:18,952:INFO:Cross validation set to False
2023-02-17 12:24:18,952:INFO:Fitting Model
2023-02-17 12:24:20,800:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('actual_estimator',
                 GradientBoostingClassifier(ccp_alpha=0.0,
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=3373, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-02-17 12:24:20,800:INFO:create_model() successfully completed......................................
2023-02-17 12:24:20,932:INFO:_master_model_container: 21
2023-02-17 12:24:20,932:INFO:_display_container: 5
2023-02-17 12:24:20,933:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('actual_estimator',
                 GradientBoostingClassifier(ccp_alpha=0.0,
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=3373, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-02-17 12:24:20,934:INFO:finalize_model() successfully completed......................................
2023-02-17 12:16:15,403:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:19:05,552:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:19:05,820:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:19:07,696:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.16859e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:19:07,720:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.21366e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:19:07,750:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.23407e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:19:28,999:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:19:29,031:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:19:05,538:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:19:05,827:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:19:06,003:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:19:07,702:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.48045e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:19:07,740:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.20638e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:19:28,988:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:19:29,025:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:19:29,049:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:16:15,403:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:19:05,552:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:19:05,806:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:19:06,000:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:19:07,689:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.14651e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:19:07,732:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.27962e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:19:07,760:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.19393e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:19:29,011:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:19:29,037:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:16:15,403:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:19:05,537:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:19:05,832:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:19:07,686:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.18834e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:19:07,751:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.23496e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:19:28,980:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:19:29,014:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:19:29,043:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 12:32:46,953:INFO:PyCaret ClassificationExperiment
2023-02-17 12:32:46,954:INFO:Logging name: clf-default-name
2023-02-17 12:32:46,954:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-17 12:32:46,954:INFO:version 3.0.0.rc9
2023-02-17 12:32:46,954:INFO:Initializing setup()
2023-02-17 12:32:46,954:INFO:self.USI: ea06
2023-02-17 12:32:46,954:INFO:self._variable_keys: {'pipeline', 'exp_name_log', 'fold_groups_param', 'y_test', 'gpu_param', 'exp_id', 'X_test', 'y', 'target_param', 'fix_imbalance', 'n_jobs_param', 'X_train', 'fold_generator', 'is_multiclass', 'fold_shuffle_param', 'memory', '_ml_usecase', 'gpu_n_jobs_param', 'USI', '_available_plots', 'X', 'logging_param', 'seed', 'data', 'y_train', 'html_param', 'log_plots_param', 'idx'}
2023-02-17 12:32:46,955:INFO:Checking environment
2023-02-17 12:32:46,955:INFO:python_version: 3.9.15
2023-02-17 12:32:46,955:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-17 12:32:46,958:INFO:machine: AMD64
2023-02-17 12:32:46,959:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-17 12:32:46,960:INFO:Memory: svmem(total=8469581824, available=3995066368, percent=52.8, used=4474515456, free=3995066368)
2023-02-17 12:32:46,960:INFO:Physical Core: 4
2023-02-17 12:32:46,960:INFO:Logical Core: 4
2023-02-17 12:32:46,960:INFO:Checking libraries
2023-02-17 12:32:46,960:INFO:System:
2023-02-17 12:32:46,960:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-17 12:32:46,960:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-17 12:32:46,961:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-17 12:32:46,961:INFO:PyCaret required dependencies:
2023-02-17 12:32:46,962:INFO:                 pip: 22.3.1
2023-02-17 12:32:46,962:INFO:          setuptools: 60.10.0
2023-02-17 12:32:46,962:INFO:             pycaret: 3.0.0rc9
2023-02-17 12:32:46,962:INFO:             IPython: 7.31.1
2023-02-17 12:32:46,962:INFO:          ipywidgets: 7.6.5
2023-02-17 12:32:46,962:INFO:                tqdm: 4.64.1
2023-02-17 12:32:46,963:INFO:               numpy: 1.21.5
2023-02-17 12:32:46,963:INFO:              pandas: 1.4.4
2023-02-17 12:32:46,963:INFO:              jinja2: 2.11.3
2023-02-17 12:32:46,963:INFO:               scipy: 1.9.3
2023-02-17 12:32:46,963:INFO:              joblib: 1.2.0
2023-02-17 12:32:46,963:INFO:             sklearn: 1.0.2
2023-02-17 12:32:46,963:INFO:                pyod: 1.0.7
2023-02-17 12:32:46,963:INFO:            imblearn: 0.10.1
2023-02-17 12:32:46,963:INFO:   category_encoders: 2.6.0
2023-02-17 12:32:46,963:INFO:            lightgbm: 3.3.5
2023-02-17 12:32:46,963:INFO:               numba: 0.56.4
2023-02-17 12:32:46,963:INFO:            requests: 2.28.1
2023-02-17 12:32:46,963:INFO:          matplotlib: 3.6.2
2023-02-17 12:32:46,963:INFO:          scikitplot: 0.3.7
2023-02-17 12:32:46,963:INFO:         yellowbrick: 1.5
2023-02-17 12:32:46,963:INFO:              plotly: 5.9.0
2023-02-17 12:32:46,963:INFO:             kaleido: 0.2.1
2023-02-17 12:32:46,963:INFO:         statsmodels: 0.13.2
2023-02-17 12:32:46,964:INFO:              sktime: 0.16.1
2023-02-17 12:32:46,964:INFO:               tbats: 1.1.2
2023-02-17 12:32:46,964:INFO:            pmdarima: 2.0.2
2023-02-17 12:32:46,964:INFO:              psutil: 5.9.0
2023-02-17 12:32:46,964:INFO:PyCaret optional dependencies:
2023-02-17 12:32:46,964:INFO:                shap: 0.41.0
2023-02-17 12:32:46,964:INFO:           interpret: Not installed
2023-02-17 12:32:46,964:INFO:                umap: Not installed
2023-02-17 12:32:46,964:INFO:    pandas_profiling: 4.0.0
2023-02-17 12:32:46,964:INFO:  explainerdashboard: 0.3.6.2
2023-02-17 12:32:46,964:INFO:             autoviz: 0.1.58
2023-02-17 12:32:46,964:INFO:           fairlearn: Not installed
2023-02-17 12:32:46,964:INFO:             xgboost: 1.7.3
2023-02-17 12:32:46,964:INFO:            catboost: Not installed
2023-02-17 12:32:46,964:INFO:              kmodes: Not installed
2023-02-17 12:32:46,964:INFO:             mlxtend: Not installed
2023-02-17 12:32:46,964:INFO:       statsforecast: Not installed
2023-02-17 12:32:46,965:INFO:        tune_sklearn: Not installed
2023-02-17 12:32:46,965:INFO:                 ray: Not installed
2023-02-17 12:32:46,965:INFO:            hyperopt: Not installed
2023-02-17 12:32:46,965:INFO:              optuna: 2.10.1
2023-02-17 12:32:46,965:INFO:               skopt: Not installed
2023-02-17 12:32:46,965:INFO:              mlflow: Not installed
2023-02-17 12:32:46,965:INFO:              gradio: Not installed
2023-02-17 12:32:46,965:INFO:             fastapi: Not installed
2023-02-17 12:32:46,965:INFO:             uvicorn: Not installed
2023-02-17 12:32:46,965:INFO:              m2cgen: Not installed
2023-02-17 12:32:46,965:INFO:           evidently: Not installed
2023-02-17 12:32:46,965:INFO:               fugue: Not installed
2023-02-17 12:32:46,965:INFO:           streamlit: Not installed
2023-02-17 12:32:46,965:INFO:             prophet: Not installed
2023-02-17 12:32:46,965:INFO:None
2023-02-17 12:32:46,965:INFO:Set up data.
2023-02-17 12:32:47,046:INFO:Set up train/test split.
2023-02-17 12:32:47,101:INFO:Set up index.
2023-02-17 12:32:47,102:INFO:Set up folding strategy.
2023-02-17 12:32:47,103:INFO:Assigning column types.
2023-02-17 12:32:47,110:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-17 12:32:47,207:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-17 12:32:47,215:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:32:47,265:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:32:47,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:32:47,352:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-17 12:32:47,353:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:32:47,398:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:32:47,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:32:47,403:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-17 12:32:47,519:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:32:47,557:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:32:47,560:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:32:47,730:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 12:32:47,771:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:32:47,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:32:47,774:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-17 12:32:47,916:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:32:47,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:32:48,058:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:32:48,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:32:48,082:INFO:Finished creating preprocessing pipeline.
2023-02-17 12:32:48,084:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2023-02-17 12:32:48,084:INFO:Creating final display dataframe.
2023-02-17 12:32:48,245:INFO:Setup _display_container:                    Description        Value
0                   Session id          910
1                       Target        Class
2                  Target type       Binary
3          Original data shape  (11730, 11)
4       Transformed data shape  (11730, 11)
5  Transformed train set shape   (8211, 11)
6   Transformed test set shape   (3519, 11)
7             Numeric features           10
2023-02-17 12:32:48,454:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:32:48,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:32:48,581:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 12:32:48,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 12:32:48,588:INFO:setup() successfully completed in 1.7s...............
2023-02-17 12:32:48,708:INFO:Initializing compare_models()
2023-02-17 12:32:48,708:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-17 12:32:48,708:INFO:Checking exceptions
2023-02-17 12:32:48,716:INFO:Preparing display monitor
2023-02-17 12:32:48,756:INFO:Initializing Logistic Regression
2023-02-17 12:32:48,756:INFO:Total runtime is 0.0 minutes
2023-02-17 12:32:48,761:INFO:SubProcess create_model() called ==================================
2023-02-17 12:32:48,761:INFO:Initializing create_model()
2023-02-17 12:32:48,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B0F16CD00>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:32:48,762:INFO:Checking exceptions
2023-02-17 12:32:48,762:INFO:Importing libraries
2023-02-17 12:32:48,762:INFO:Copying training dataset
2023-02-17 12:32:48,773:INFO:Defining folds
2023-02-17 12:32:48,774:INFO:Declaring metric variables
2023-02-17 12:32:48,778:INFO:Importing untrained model
2023-02-17 12:32:48,784:INFO:Logistic Regression Imported successfully
2023-02-17 12:32:48,794:INFO:Starting cross validation
2023-02-17 12:32:48,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:33:00,988:INFO:Calculating mean and std
2023-02-17 12:33:00,991:INFO:Creating metrics dataframe
2023-02-17 12:33:00,997:INFO:Uploading results into container
2023-02-17 12:33:00,998:INFO:Uploading model into container now
2023-02-17 12:33:00,998:INFO:_master_model_container: 1
2023-02-17 12:33:00,998:INFO:_display_container: 2
2023-02-17 12:33:00,999:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=910, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-17 12:33:00,999:INFO:create_model() successfully completed......................................
2023-02-17 12:33:02,092:INFO:SubProcess create_model() end ==================================
2023-02-17 12:33:02,092:INFO:Creating metrics dataframe
2023-02-17 12:33:02,108:INFO:Initializing K Neighbors Classifier
2023-02-17 12:33:02,109:INFO:Total runtime is 0.22255013386408487 minutes
2023-02-17 12:33:02,113:INFO:SubProcess create_model() called ==================================
2023-02-17 12:33:02,113:INFO:Initializing create_model()
2023-02-17 12:33:02,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B0F16CD00>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:33:02,114:INFO:Checking exceptions
2023-02-17 12:33:02,114:INFO:Importing libraries
2023-02-17 12:33:02,114:INFO:Copying training dataset
2023-02-17 12:33:02,124:INFO:Defining folds
2023-02-17 12:33:02,124:INFO:Declaring metric variables
2023-02-17 12:33:02,129:INFO:Importing untrained model
2023-02-17 12:33:02,134:INFO:K Neighbors Classifier Imported successfully
2023-02-17 12:33:02,145:INFO:Starting cross validation
2023-02-17 12:33:02,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:33:02,243:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:33:02,245:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:33:02,246:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:33:02,277:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:33:02,400:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:33:02,401:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:33:02,437:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:33:02,459:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:33:02,542:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:33:02,559:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 12:33:02,614:INFO:Calculating mean and std
2023-02-17 12:33:02,616:INFO:Creating metrics dataframe
2023-02-17 12:33:02,621:INFO:Uploading results into container
2023-02-17 12:33:02,624:INFO:Uploading model into container now
2023-02-17 12:33:02,624:INFO:_master_model_container: 2
2023-02-17 12:33:02,624:INFO:_display_container: 2
2023-02-17 12:33:02,625:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-17 12:33:02,625:INFO:create_model() successfully completed......................................
2023-02-17 12:33:02,760:INFO:SubProcess create_model() end ==================================
2023-02-17 12:33:02,761:INFO:Creating metrics dataframe
2023-02-17 12:33:02,776:INFO:Initializing Naive Bayes
2023-02-17 12:33:02,776:INFO:Total runtime is 0.23367041746775308 minutes
2023-02-17 12:33:02,780:INFO:SubProcess create_model() called ==================================
2023-02-17 12:33:02,780:INFO:Initializing create_model()
2023-02-17 12:33:02,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B0F16CD00>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:33:02,781:INFO:Checking exceptions
2023-02-17 12:33:02,781:INFO:Importing libraries
2023-02-17 12:33:02,781:INFO:Copying training dataset
2023-02-17 12:33:02,791:INFO:Defining folds
2023-02-17 12:33:02,791:INFO:Declaring metric variables
2023-02-17 12:33:02,797:INFO:Importing untrained model
2023-02-17 12:33:02,802:INFO:Naive Bayes Imported successfully
2023-02-17 12:33:02,813:INFO:Starting cross validation
2023-02-17 12:33:02,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:33:02,961:INFO:Calculating mean and std
2023-02-17 12:33:02,963:INFO:Creating metrics dataframe
2023-02-17 12:33:02,969:INFO:Uploading results into container
2023-02-17 12:33:02,970:INFO:Uploading model into container now
2023-02-17 12:33:02,970:INFO:_master_model_container: 3
2023-02-17 12:33:02,970:INFO:_display_container: 2
2023-02-17 12:33:02,970:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-17 12:33:02,970:INFO:create_model() successfully completed......................................
2023-02-17 12:33:03,114:INFO:SubProcess create_model() end ==================================
2023-02-17 12:33:03,114:INFO:Creating metrics dataframe
2023-02-17 12:33:03,133:INFO:Initializing Decision Tree Classifier
2023-02-17 12:33:03,133:INFO:Total runtime is 0.23962115446726479 minutes
2023-02-17 12:33:03,138:INFO:SubProcess create_model() called ==================================
2023-02-17 12:33:03,139:INFO:Initializing create_model()
2023-02-17 12:33:03,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B0F16CD00>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:33:03,140:INFO:Checking exceptions
2023-02-17 12:33:03,140:INFO:Importing libraries
2023-02-17 12:33:03,140:INFO:Copying training dataset
2023-02-17 12:33:03,148:INFO:Defining folds
2023-02-17 12:33:03,148:INFO:Declaring metric variables
2023-02-17 12:33:03,153:INFO:Importing untrained model
2023-02-17 12:33:03,159:INFO:Decision Tree Classifier Imported successfully
2023-02-17 12:33:03,171:INFO:Starting cross validation
2023-02-17 12:33:03,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:33:03,437:INFO:Calculating mean and std
2023-02-17 12:33:03,438:INFO:Creating metrics dataframe
2023-02-17 12:33:03,445:INFO:Uploading results into container
2023-02-17 12:33:03,445:INFO:Uploading model into container now
2023-02-17 12:33:03,446:INFO:_master_model_container: 4
2023-02-17 12:33:03,446:INFO:_display_container: 2
2023-02-17 12:33:03,446:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=910, splitter='best')
2023-02-17 12:33:03,446:INFO:create_model() successfully completed......................................
2023-02-17 12:33:03,577:INFO:SubProcess create_model() end ==================================
2023-02-17 12:33:03,577:INFO:Creating metrics dataframe
2023-02-17 12:33:03,588:INFO:Initializing SVM - Linear Kernel
2023-02-17 12:33:03,589:INFO:Total runtime is 0.24721752405166622 minutes
2023-02-17 12:33:03,595:INFO:SubProcess create_model() called ==================================
2023-02-17 12:33:03,596:INFO:Initializing create_model()
2023-02-17 12:33:03,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B0F16CD00>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:33:03,596:INFO:Checking exceptions
2023-02-17 12:33:03,596:INFO:Importing libraries
2023-02-17 12:33:03,596:INFO:Copying training dataset
2023-02-17 12:33:03,604:INFO:Defining folds
2023-02-17 12:33:03,604:INFO:Declaring metric variables
2023-02-17 12:33:03,610:INFO:Importing untrained model
2023-02-17 12:33:03,616:INFO:SVM - Linear Kernel Imported successfully
2023-02-17 12:33:03,628:INFO:Starting cross validation
2023-02-17 12:33:03,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:33:03,786:INFO:Calculating mean and std
2023-02-17 12:33:03,787:INFO:Creating metrics dataframe
2023-02-17 12:33:03,793:INFO:Uploading results into container
2023-02-17 12:33:03,793:INFO:Uploading model into container now
2023-02-17 12:33:03,794:INFO:_master_model_container: 5
2023-02-17 12:33:03,795:INFO:_display_container: 2
2023-02-17 12:33:03,796:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=910, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-17 12:33:03,796:INFO:create_model() successfully completed......................................
2023-02-17 12:33:03,928:INFO:SubProcess create_model() end ==================================
2023-02-17 12:33:03,928:INFO:Creating metrics dataframe
2023-02-17 12:33:03,940:INFO:Initializing Ridge Classifier
2023-02-17 12:33:03,941:INFO:Total runtime is 0.253085180123647 minutes
2023-02-17 12:33:03,945:INFO:SubProcess create_model() called ==================================
2023-02-17 12:33:03,946:INFO:Initializing create_model()
2023-02-17 12:33:03,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B0F16CD00>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:33:03,946:INFO:Checking exceptions
2023-02-17 12:33:03,946:INFO:Importing libraries
2023-02-17 12:33:03,946:INFO:Copying training dataset
2023-02-17 12:33:03,955:INFO:Defining folds
2023-02-17 12:33:03,956:INFO:Declaring metric variables
2023-02-17 12:33:03,961:INFO:Importing untrained model
2023-02-17 12:33:03,967:INFO:Ridge Classifier Imported successfully
2023-02-17 12:33:03,979:INFO:Starting cross validation
2023-02-17 12:33:03,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:33:04,057:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.80919e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:33:04,057:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.79075e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:33:04,058:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.69154e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:33:04,058:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.73652e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:33:04,078:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.78189e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:33:04,086:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.71332e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:33:04,096:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.30986e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:33:04,100:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.83484e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:33:04,111:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.89457e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:33:04,117:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.76503e-09): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-02-17 12:33:04,128:INFO:Calculating mean and std
2023-02-17 12:33:04,129:INFO:Creating metrics dataframe
2023-02-17 12:33:04,133:INFO:Uploading results into container
2023-02-17 12:33:04,134:INFO:Uploading model into container now
2023-02-17 12:33:04,134:INFO:_master_model_container: 6
2023-02-17 12:33:04,134:INFO:_display_container: 2
2023-02-17 12:33:04,135:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=910, solver='auto', tol=0.001)
2023-02-17 12:33:04,135:INFO:create_model() successfully completed......................................
2023-02-17 12:33:04,269:INFO:SubProcess create_model() end ==================================
2023-02-17 12:33:04,269:INFO:Creating metrics dataframe
2023-02-17 12:33:04,284:INFO:Initializing Random Forest Classifier
2023-02-17 12:33:04,284:INFO:Total runtime is 0.2588032007217407 minutes
2023-02-17 12:33:04,290:INFO:SubProcess create_model() called ==================================
2023-02-17 12:33:04,291:INFO:Initializing create_model()
2023-02-17 12:33:04,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B0F16CD00>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:33:04,291:INFO:Checking exceptions
2023-02-17 12:33:04,291:INFO:Importing libraries
2023-02-17 12:33:04,291:INFO:Copying training dataset
2023-02-17 12:33:04,299:INFO:Defining folds
2023-02-17 12:33:04,300:INFO:Declaring metric variables
2023-02-17 12:33:04,307:INFO:Importing untrained model
2023-02-17 12:33:04,313:INFO:Random Forest Classifier Imported successfully
2023-02-17 12:33:04,322:INFO:Starting cross validation
2023-02-17 12:33:04,325:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:33:09,669:INFO:Calculating mean and std
2023-02-17 12:33:09,671:INFO:Creating metrics dataframe
2023-02-17 12:33:09,676:INFO:Uploading results into container
2023-02-17 12:33:09,677:INFO:Uploading model into container now
2023-02-17 12:33:09,677:INFO:_master_model_container: 7
2023-02-17 12:33:09,677:INFO:_display_container: 2
2023-02-17 12:33:09,678:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=910, verbose=0, warm_start=False)
2023-02-17 12:33:09,678:INFO:create_model() successfully completed......................................
2023-02-17 12:33:09,838:INFO:SubProcess create_model() end ==================================
2023-02-17 12:33:09,838:INFO:Creating metrics dataframe
2023-02-17 12:33:09,854:INFO:Initializing Quadratic Discriminant Analysis
2023-02-17 12:33:09,854:INFO:Total runtime is 0.3516383330027262 minutes
2023-02-17 12:33:09,861:INFO:SubProcess create_model() called ==================================
2023-02-17 12:33:09,861:INFO:Initializing create_model()
2023-02-17 12:33:09,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B0F16CD00>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:33:09,862:INFO:Checking exceptions
2023-02-17 12:33:09,862:INFO:Importing libraries
2023-02-17 12:33:09,862:INFO:Copying training dataset
2023-02-17 12:33:09,871:INFO:Defining folds
2023-02-17 12:33:09,872:INFO:Declaring metric variables
2023-02-17 12:33:09,878:INFO:Importing untrained model
2023-02-17 12:33:09,883:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-17 12:33:09,893:INFO:Starting cross validation
2023-02-17 12:33:09,894:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:33:10,121:INFO:Calculating mean and std
2023-02-17 12:33:10,123:INFO:Creating metrics dataframe
2023-02-17 12:33:10,128:INFO:Uploading results into container
2023-02-17 12:33:10,129:INFO:Uploading model into container now
2023-02-17 12:33:10,129:INFO:_master_model_container: 8
2023-02-17 12:33:10,129:INFO:_display_container: 2
2023-02-17 12:33:10,130:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-17 12:33:10,130:INFO:create_model() successfully completed......................................
2023-02-17 12:33:10,317:INFO:SubProcess create_model() end ==================================
2023-02-17 12:33:10,317:INFO:Creating metrics dataframe
2023-02-17 12:33:10,333:INFO:Initializing Ada Boost Classifier
2023-02-17 12:33:10,333:INFO:Total runtime is 0.35961699485778803 minutes
2023-02-17 12:33:10,337:INFO:SubProcess create_model() called ==================================
2023-02-17 12:33:10,338:INFO:Initializing create_model()
2023-02-17 12:33:10,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B0F16CD00>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:33:10,339:INFO:Checking exceptions
2023-02-17 12:33:10,339:INFO:Importing libraries
2023-02-17 12:33:10,339:INFO:Copying training dataset
2023-02-17 12:33:10,353:INFO:Defining folds
2023-02-17 12:33:10,353:INFO:Declaring metric variables
2023-02-17 12:33:10,362:INFO:Importing untrained model
2023-02-17 12:33:10,366:INFO:Ada Boost Classifier Imported successfully
2023-02-17 12:33:10,374:INFO:Starting cross validation
2023-02-17 12:33:10,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:33:12,590:INFO:Calculating mean and std
2023-02-17 12:33:12,591:INFO:Creating metrics dataframe
2023-02-17 12:33:12,597:INFO:Uploading results into container
2023-02-17 12:33:12,598:INFO:Uploading model into container now
2023-02-17 12:33:12,599:INFO:_master_model_container: 9
2023-02-17 12:33:12,599:INFO:_display_container: 2
2023-02-17 12:33:12,599:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=910)
2023-02-17 12:33:12,599:INFO:create_model() successfully completed......................................
2023-02-17 12:33:12,730:INFO:SubProcess create_model() end ==================================
2023-02-17 12:33:12,730:INFO:Creating metrics dataframe
2023-02-17 12:33:12,744:INFO:Initializing Gradient Boosting Classifier
2023-02-17 12:33:12,744:INFO:Total runtime is 0.39980954726537066 minutes
2023-02-17 12:33:12,749:INFO:SubProcess create_model() called ==================================
2023-02-17 12:33:12,749:INFO:Initializing create_model()
2023-02-17 12:33:12,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B0F16CD00>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:33:12,750:INFO:Checking exceptions
2023-02-17 12:33:12,750:INFO:Importing libraries
2023-02-17 12:33:12,750:INFO:Copying training dataset
2023-02-17 12:33:12,757:INFO:Defining folds
2023-02-17 12:33:12,758:INFO:Declaring metric variables
2023-02-17 12:33:12,765:INFO:Importing untrained model
2023-02-17 12:33:12,770:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 12:33:12,781:INFO:Starting cross validation
2023-02-17 12:33:12,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 12:33:17,109:INFO:Calculating mean and std
2023-02-17 12:33:17,110:INFO:Creating metrics dataframe
2023-02-17 12:33:17,116:INFO:Uploading results into container
2023-02-17 12:33:17,117:INFO:Uploading model into container now
2023-02-17 12:33:17,117:INFO:_master_model_container: 10
2023-02-17 12:33:17,117:INFO:_display_container: 2
2023-02-17 12:33:17,118:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=910, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 12:33:17,118:INFO:create_model() successfully completed......................................
2023-02-17 12:33:17,249:INFO:SubProcess create_model() end ==================================
2023-02-17 12:33:17,249:INFO:Creating metrics dataframe
2023-02-17 12:33:17,264:INFO:Initializing Linear Discriminant Analysis
2023-02-17 12:33:17,264:INFO:Total runtime is 0.4751414696375529 minutes
2023-02-17 12:33:17,268:INFO:SubProcess create_model() called ==================================
2023-02-17 12:33:17,269:INFO:Initializing create_model()
2023-02-17 12:33:17,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000011B1C20BBE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011B0F16CD00>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 12:33:17,269:INFO:Checking exceptions
2023-02-17 12:33:17,269:INFO:Importing libraries
2023-02-17 12:33:17,269:INFO:Copying training dataset
2023-02-17 12:33:17,279:INFO:Defining folds
2023-02-17 19:06:42,702:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-17 19:06:42,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-17 19:06:42,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-17 19:06:42,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-17 19:06:45,096:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-17 19:12:22,649:INFO:PyCaret ClassificationExperiment
2023-02-17 19:12:22,650:INFO:Logging name: clf-default-name
2023-02-17 19:12:22,650:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-02-17 19:12:22,651:INFO:version 3.0.0.rc9
2023-02-17 19:12:22,651:INFO:Initializing setup()
2023-02-17 19:12:22,651:INFO:self.USI: f343
2023-02-17 19:12:22,651:INFO:self._variable_keys: {'seed', 'fold_generator', 'is_multiclass', 'USI', 'y_test', 'memory', 'gpu_n_jobs_param', 'X_test', 'fold_groups_param', 'logging_param', 'target_param', 'fix_imbalance', 'idx', 'exp_name_log', 'html_param', 'exp_id', 'n_jobs_param', 'fold_shuffle_param', 'data', 'y', 'y_train', 'X', '_ml_usecase', '_available_plots', 'pipeline', 'X_train', 'gpu_param', 'log_plots_param'}
2023-02-17 19:12:22,651:INFO:Checking environment
2023-02-17 19:12:22,651:INFO:python_version: 3.9.15
2023-02-17 19:12:22,651:INFO:python_build: ('main', 'Nov 24 2022 14:39:17')
2023-02-17 19:12:22,651:INFO:machine: AMD64
2023-02-17 19:12:22,651:INFO:platform: Windows-10-10.0.19041-SP0
2023-02-17 19:12:22,652:INFO:Memory: svmem(total=8469581824, available=2952282112, percent=65.1, used=5517299712, free=2952282112)
2023-02-17 19:12:22,652:INFO:Physical Core: 4
2023-02-17 19:12:22,652:INFO:Logical Core: 4
2023-02-17 19:12:22,652:INFO:Checking libraries
2023-02-17 19:12:22,652:INFO:System:
2023-02-17 19:12:22,652:INFO:    python: 3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]
2023-02-17 19:12:22,652:INFO:executable: c:\Users\pedro\anaconda3\python.exe
2023-02-17 19:12:22,652:INFO:   machine: Windows-10-10.0.19041-SP0
2023-02-17 19:12:22,652:INFO:PyCaret required dependencies:
2023-02-17 19:12:22,652:INFO:                 pip: 22.3.1
2023-02-17 19:12:22,652:INFO:          setuptools: 60.10.0
2023-02-17 19:12:22,652:INFO:             pycaret: 3.0.0rc9
2023-02-17 19:12:22,652:INFO:             IPython: 7.31.1
2023-02-17 19:12:22,652:INFO:          ipywidgets: 7.6.5
2023-02-17 19:12:22,652:INFO:                tqdm: 4.64.1
2023-02-17 19:12:22,652:INFO:               numpy: 1.21.5
2023-02-17 19:12:22,653:INFO:              pandas: 1.4.4
2023-02-17 19:12:22,653:INFO:              jinja2: 2.11.3
2023-02-17 19:12:22,653:INFO:               scipy: 1.9.3
2023-02-17 19:12:22,653:INFO:              joblib: 1.2.0
2023-02-17 19:12:22,653:INFO:             sklearn: 1.0.2
2023-02-17 19:12:22,653:INFO:                pyod: 1.0.7
2023-02-17 19:12:22,653:INFO:            imblearn: 0.10.1
2023-02-17 19:12:22,653:INFO:   category_encoders: 2.6.0
2023-02-17 19:12:22,653:INFO:            lightgbm: 3.3.5
2023-02-17 19:12:22,653:INFO:               numba: 0.56.4
2023-02-17 19:12:22,653:INFO:            requests: 2.28.1
2023-02-17 19:12:22,653:INFO:          matplotlib: 3.6.2
2023-02-17 19:12:22,653:INFO:          scikitplot: 0.3.7
2023-02-17 19:12:22,653:INFO:         yellowbrick: 1.5
2023-02-17 19:12:22,653:INFO:              plotly: 5.9.0
2023-02-17 19:12:22,653:INFO:             kaleido: 0.2.1
2023-02-17 19:12:22,653:INFO:         statsmodels: 0.13.2
2023-02-17 19:12:22,653:INFO:              sktime: 0.16.1
2023-02-17 19:12:22,654:INFO:               tbats: 1.1.2
2023-02-17 19:12:22,654:INFO:            pmdarima: 2.0.2
2023-02-17 19:12:22,654:INFO:              psutil: 5.9.0
2023-02-17 19:12:22,654:INFO:PyCaret optional dependencies:
2023-02-17 19:12:22,686:INFO:                shap: 0.41.0
2023-02-17 19:12:22,686:INFO:           interpret: Not installed
2023-02-17 19:12:22,686:INFO:                umap: Not installed
2023-02-17 19:12:22,686:INFO:    pandas_profiling: 4.0.0
2023-02-17 19:12:22,686:INFO:  explainerdashboard: 0.3.6.2
2023-02-17 19:12:22,686:INFO:             autoviz: 0.1.58
2023-02-17 19:12:22,686:INFO:           fairlearn: Not installed
2023-02-17 19:12:22,686:INFO:             xgboost: 1.7.3
2023-02-17 19:12:22,686:INFO:            catboost: Not installed
2023-02-17 19:12:22,686:INFO:              kmodes: Not installed
2023-02-17 19:12:22,686:INFO:             mlxtend: Not installed
2023-02-17 19:12:22,686:INFO:       statsforecast: Not installed
2023-02-17 19:12:22,687:INFO:        tune_sklearn: Not installed
2023-02-17 19:12:22,687:INFO:                 ray: Not installed
2023-02-17 19:12:22,687:INFO:            hyperopt: Not installed
2023-02-17 19:12:22,687:INFO:              optuna: 2.10.1
2023-02-17 19:12:22,687:INFO:               skopt: Not installed
2023-02-17 19:12:22,687:INFO:              mlflow: Not installed
2023-02-17 19:12:22,687:INFO:              gradio: Not installed
2023-02-17 19:12:22,687:INFO:             fastapi: Not installed
2023-02-17 19:12:22,687:INFO:             uvicorn: Not installed
2023-02-17 19:12:22,687:INFO:              m2cgen: Not installed
2023-02-17 19:12:22,687:INFO:           evidently: Not installed
2023-02-17 19:12:22,687:INFO:               fugue: Not installed
2023-02-17 19:12:22,687:INFO:           streamlit: Not installed
2023-02-17 19:12:22,687:INFO:             prophet: Not installed
2023-02-17 19:12:22,687:INFO:None
2023-02-17 19:12:22,687:INFO:Set up data.
2023-02-17 19:12:22,702:INFO:Set up train/test split.
2023-02-17 19:12:22,720:INFO:Set up index.
2023-02-17 19:12:22,720:INFO:Set up folding strategy.
2023-02-17 19:12:22,720:INFO:Assigning column types.
2023-02-17 19:12:22,725:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-17 19:12:22,781:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-17 19:12:22,792:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 19:12:22,844:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 19:12:22,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 19:12:22,903:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-17 19:12:22,905:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 19:12:22,945:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 19:12:22,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 19:12:22,948:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-17 19:12:23,006:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 19:12:23,040:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 19:12:23,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 19:12:23,099:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-02-17 19:12:23,135:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 19:12:23,139:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 19:12:23,148:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-02-17 19:12:23,254:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 19:12:23,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 19:12:23,353:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 19:12:23,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 19:12:23,379:INFO:Finished creating preprocessing pipeline.
2023-02-17 19:12:23,395:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2023-02-17 19:12:23,395:INFO:Creating final display dataframe.
2023-02-17 19:12:23,532:INFO:Setup _display_container:                    Description         Value
0                   Session id          5963
1                       Target  inadimplente
2                  Target type        Binary
3          Original data shape   (11730, 11)
4       Transformed data shape   (11730, 11)
5  Transformed train set shape    (8211, 11)
6   Transformed test set shape    (3519, 11)
7             Numeric features            10
2023-02-17 19:12:23,678:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 19:12:23,681:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 19:12:23,847:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-17 19:12:23,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-17 19:12:23,861:INFO:setup() successfully completed in 1.28s...............
2023-02-17 19:12:24,001:INFO:Initializing compare_models()
2023-02-17 19:12:24,002:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-02-17 19:12:24,002:INFO:Checking exceptions
2023-02-17 19:12:24,009:INFO:Preparing display monitor
2023-02-17 19:12:24,178:INFO:Initializing Logistic Regression
2023-02-17 19:12:24,178:INFO:Total runtime is 1.6637643178304036e-05 minutes
2023-02-17 19:12:24,185:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:24,185:INFO:Initializing create_model()
2023-02-17 19:12:24,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:24,186:INFO:Checking exceptions
2023-02-17 19:12:24,186:INFO:Importing libraries
2023-02-17 19:12:24,186:INFO:Copying training dataset
2023-02-17 19:12:24,194:INFO:Defining folds
2023-02-17 19:12:24,194:INFO:Declaring metric variables
2023-02-17 19:12:24,198:INFO:Importing untrained model
2023-02-17 19:12:24,204:INFO:Logistic Regression Imported successfully
2023-02-17 19:12:24,228:INFO:Starting cross validation
2023-02-17 19:12:24,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:12:35,796:INFO:Calculating mean and std
2023-02-17 19:12:35,797:INFO:Creating metrics dataframe
2023-02-17 19:12:35,801:INFO:Uploading results into container
2023-02-17 19:12:35,802:INFO:Uploading model into container now
2023-02-17 19:12:35,802:INFO:_master_model_container: 1
2023-02-17 19:12:35,802:INFO:_display_container: 2
2023-02-17 19:12:35,803:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5963, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-02-17 19:12:35,803:INFO:create_model() successfully completed......................................
2023-02-17 19:12:35,952:INFO:SubProcess create_model() end ==================================
2023-02-17 19:12:35,953:INFO:Creating metrics dataframe
2023-02-17 19:12:35,965:INFO:Initializing K Neighbors Classifier
2023-02-17 19:12:35,965:INFO:Total runtime is 0.19646726846694945 minutes
2023-02-17 19:12:35,969:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:35,969:INFO:Initializing create_model()
2023-02-17 19:12:35,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:35,969:INFO:Checking exceptions
2023-02-17 19:12:35,969:INFO:Importing libraries
2023-02-17 19:12:35,970:INFO:Copying training dataset
2023-02-17 19:12:35,980:INFO:Defining folds
2023-02-17 19:12:35,980:INFO:Declaring metric variables
2023-02-17 19:12:35,986:INFO:Importing untrained model
2023-02-17 19:12:35,995:INFO:K Neighbors Classifier Imported successfully
2023-02-17 19:12:36,005:INFO:Starting cross validation
2023-02-17 19:12:36,007:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:12:36,110:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 19:12:36,110:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 19:12:36,120:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 19:12:36,143:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 19:12:36,230:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 19:12:36,245:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 19:12:36,268:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 19:12:36,269:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 19:12:36,360:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 19:12:36,375:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-02-17 19:12:36,429:INFO:Calculating mean and std
2023-02-17 19:12:36,430:INFO:Creating metrics dataframe
2023-02-17 19:12:36,434:INFO:Uploading results into container
2023-02-17 19:12:36,434:INFO:Uploading model into container now
2023-02-17 19:12:36,434:INFO:_master_model_container: 2
2023-02-17 19:12:36,435:INFO:_display_container: 2
2023-02-17 19:12:36,435:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-02-17 19:12:36,436:INFO:create_model() successfully completed......................................
2023-02-17 19:12:36,552:INFO:SubProcess create_model() end ==================================
2023-02-17 19:12:36,552:INFO:Creating metrics dataframe
2023-02-17 19:12:36,564:INFO:Initializing Naive Bayes
2023-02-17 19:12:36,564:INFO:Total runtime is 0.2064548373222351 minutes
2023-02-17 19:12:36,568:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:36,568:INFO:Initializing create_model()
2023-02-17 19:12:36,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:36,569:INFO:Checking exceptions
2023-02-17 19:12:36,569:INFO:Importing libraries
2023-02-17 19:12:36,569:INFO:Copying training dataset
2023-02-17 19:12:36,580:INFO:Defining folds
2023-02-17 19:12:36,580:INFO:Declaring metric variables
2023-02-17 19:12:36,585:INFO:Importing untrained model
2023-02-17 19:12:36,592:INFO:Naive Bayes Imported successfully
2023-02-17 19:12:36,603:INFO:Starting cross validation
2023-02-17 19:12:36,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:12:36,763:INFO:Calculating mean and std
2023-02-17 19:12:36,764:INFO:Creating metrics dataframe
2023-02-17 19:12:36,768:INFO:Uploading results into container
2023-02-17 19:12:36,768:INFO:Uploading model into container now
2023-02-17 19:12:36,769:INFO:_master_model_container: 3
2023-02-17 19:12:36,769:INFO:_display_container: 2
2023-02-17 19:12:36,769:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-02-17 19:12:36,771:INFO:create_model() successfully completed......................................
2023-02-17 19:12:36,893:INFO:SubProcess create_model() end ==================================
2023-02-17 19:12:36,895:INFO:Creating metrics dataframe
2023-02-17 19:12:36,906:INFO:Initializing Decision Tree Classifier
2023-02-17 19:12:36,907:INFO:Total runtime is 0.21216035683949788 minutes
2023-02-17 19:12:36,912:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:36,912:INFO:Initializing create_model()
2023-02-17 19:12:36,912:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:36,913:INFO:Checking exceptions
2023-02-17 19:12:36,913:INFO:Importing libraries
2023-02-17 19:12:36,913:INFO:Copying training dataset
2023-02-17 19:12:36,920:INFO:Defining folds
2023-02-17 19:12:36,920:INFO:Declaring metric variables
2023-02-17 19:12:36,927:INFO:Importing untrained model
2023-02-17 19:12:36,933:INFO:Decision Tree Classifier Imported successfully
2023-02-17 19:12:36,946:INFO:Starting cross validation
2023-02-17 19:12:36,947:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:12:37,220:INFO:Calculating mean and std
2023-02-17 19:12:37,223:INFO:Creating metrics dataframe
2023-02-17 19:12:37,228:INFO:Uploading results into container
2023-02-17 19:12:37,229:INFO:Uploading model into container now
2023-02-17 19:12:37,229:INFO:_master_model_container: 4
2023-02-17 19:12:37,229:INFO:_display_container: 2
2023-02-17 19:12:37,230:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5963, splitter='best')
2023-02-17 19:12:37,230:INFO:create_model() successfully completed......................................
2023-02-17 19:12:37,358:INFO:SubProcess create_model() end ==================================
2023-02-17 19:12:37,359:INFO:Creating metrics dataframe
2023-02-17 19:12:37,371:INFO:Initializing SVM - Linear Kernel
2023-02-17 19:12:37,371:INFO:Total runtime is 0.21990682681401572 minutes
2023-02-17 19:12:37,377:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:37,378:INFO:Initializing create_model()
2023-02-17 19:12:37,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:37,378:INFO:Checking exceptions
2023-02-17 19:12:37,378:INFO:Importing libraries
2023-02-17 19:12:37,378:INFO:Copying training dataset
2023-02-17 19:12:37,385:INFO:Defining folds
2023-02-17 19:12:37,386:INFO:Declaring metric variables
2023-02-17 19:12:37,392:INFO:Importing untrained model
2023-02-17 19:12:37,398:INFO:SVM - Linear Kernel Imported successfully
2023-02-17 19:12:37,413:INFO:Starting cross validation
2023-02-17 19:12:37,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:12:38,064:INFO:Calculating mean and std
2023-02-17 19:12:38,065:INFO:Creating metrics dataframe
2023-02-17 19:12:38,069:INFO:Uploading results into container
2023-02-17 19:12:38,070:INFO:Uploading model into container now
2023-02-17 19:12:38,071:INFO:_master_model_container: 5
2023-02-17 19:12:38,074:INFO:_display_container: 2
2023-02-17 19:12:38,075:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5963, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-02-17 19:12:38,075:INFO:create_model() successfully completed......................................
2023-02-17 19:12:38,193:INFO:SubProcess create_model() end ==================================
2023-02-17 19:12:38,193:INFO:Creating metrics dataframe
2023-02-17 19:12:38,205:INFO:Initializing Ridge Classifier
2023-02-17 19:12:38,207:INFO:Total runtime is 0.23383299509684247 minutes
2023-02-17 19:12:38,211:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:38,211:INFO:Initializing create_model()
2023-02-17 19:12:38,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:38,211:INFO:Checking exceptions
2023-02-17 19:12:38,212:INFO:Importing libraries
2023-02-17 19:12:38,212:INFO:Copying training dataset
2023-02-17 19:12:38,219:INFO:Defining folds
2023-02-17 19:12:38,219:INFO:Declaring metric variables
2023-02-17 19:12:38,225:INFO:Importing untrained model
2023-02-17 19:12:38,231:INFO:Ridge Classifier Imported successfully
2023-02-17 19:12:38,243:INFO:Starting cross validation
2023-02-17 19:12:38,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:12:38,386:INFO:Calculating mean and std
2023-02-17 19:12:38,387:INFO:Creating metrics dataframe
2023-02-17 19:12:38,393:INFO:Uploading results into container
2023-02-17 19:12:38,393:INFO:Uploading model into container now
2023-02-17 19:12:38,394:INFO:_master_model_container: 6
2023-02-17 19:12:38,394:INFO:_display_container: 2
2023-02-17 19:12:38,394:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=5963, solver='auto', tol=0.001)
2023-02-17 19:12:38,395:INFO:create_model() successfully completed......................................
2023-02-17 19:12:38,513:INFO:SubProcess create_model() end ==================================
2023-02-17 19:12:38,513:INFO:Creating metrics dataframe
2023-02-17 19:12:38,526:INFO:Initializing Random Forest Classifier
2023-02-17 19:12:38,526:INFO:Total runtime is 0.23914932012557985 minutes
2023-02-17 19:12:38,531:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:38,531:INFO:Initializing create_model()
2023-02-17 19:12:38,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:38,532:INFO:Checking exceptions
2023-02-17 19:12:38,532:INFO:Importing libraries
2023-02-17 19:12:38,532:INFO:Copying training dataset
2023-02-17 19:12:38,540:INFO:Defining folds
2023-02-17 19:12:38,541:INFO:Declaring metric variables
2023-02-17 19:12:38,546:INFO:Importing untrained model
2023-02-17 19:12:38,552:INFO:Random Forest Classifier Imported successfully
2023-02-17 19:12:38,563:INFO:Starting cross validation
2023-02-17 19:12:38,564:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:12:43,100:INFO:Calculating mean and std
2023-02-17 19:12:43,101:INFO:Creating metrics dataframe
2023-02-17 19:12:43,105:INFO:Uploading results into container
2023-02-17 19:12:43,108:INFO:Uploading model into container now
2023-02-17 19:12:43,109:INFO:_master_model_container: 7
2023-02-17 19:12:43,109:INFO:_display_container: 2
2023-02-17 19:12:43,109:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5963, verbose=0, warm_start=False)
2023-02-17 19:12:43,110:INFO:create_model() successfully completed......................................
2023-02-17 19:12:43,261:INFO:SubProcess create_model() end ==================================
2023-02-17 19:12:43,261:INFO:Creating metrics dataframe
2023-02-17 19:12:43,275:INFO:Initializing Quadratic Discriminant Analysis
2023-02-17 19:12:43,275:INFO:Total runtime is 0.31830660899480184 minutes
2023-02-17 19:12:43,280:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:43,281:INFO:Initializing create_model()
2023-02-17 19:12:43,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:43,281:INFO:Checking exceptions
2023-02-17 19:12:43,281:INFO:Importing libraries
2023-02-17 19:12:43,281:INFO:Copying training dataset
2023-02-17 19:12:43,289:INFO:Defining folds
2023-02-17 19:12:43,289:INFO:Declaring metric variables
2023-02-17 19:12:43,297:INFO:Importing untrained model
2023-02-17 19:12:43,302:INFO:Quadratic Discriminant Analysis Imported successfully
2023-02-17 19:12:43,314:INFO:Starting cross validation
2023-02-17 19:12:43,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:12:43,514:INFO:Calculating mean and std
2023-02-17 19:12:43,515:INFO:Creating metrics dataframe
2023-02-17 19:12:43,518:INFO:Uploading results into container
2023-02-17 19:12:43,519:INFO:Uploading model into container now
2023-02-17 19:12:43,519:INFO:_master_model_container: 8
2023-02-17 19:12:43,519:INFO:_display_container: 2
2023-02-17 19:12:43,520:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-02-17 19:12:43,520:INFO:create_model() successfully completed......................................
2023-02-17 19:12:43,637:INFO:SubProcess create_model() end ==================================
2023-02-17 19:12:43,637:INFO:Creating metrics dataframe
2023-02-17 19:12:43,652:INFO:Initializing Ada Boost Classifier
2023-02-17 19:12:43,652:INFO:Total runtime is 0.32458544969558717 minutes
2023-02-17 19:12:43,658:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:43,659:INFO:Initializing create_model()
2023-02-17 19:12:43,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:43,659:INFO:Checking exceptions
2023-02-17 19:12:43,659:INFO:Importing libraries
2023-02-17 19:12:43,659:INFO:Copying training dataset
2023-02-17 19:12:43,667:INFO:Defining folds
2023-02-17 19:12:43,667:INFO:Declaring metric variables
2023-02-17 19:12:43,674:INFO:Importing untrained model
2023-02-17 19:12:43,680:INFO:Ada Boost Classifier Imported successfully
2023-02-17 19:12:43,692:INFO:Starting cross validation
2023-02-17 19:12:43,693:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:12:45,671:INFO:Calculating mean and std
2023-02-17 19:12:45,672:INFO:Creating metrics dataframe
2023-02-17 19:12:45,678:INFO:Uploading results into container
2023-02-17 19:12:45,678:INFO:Uploading model into container now
2023-02-17 19:12:45,679:INFO:_master_model_container: 9
2023-02-17 19:12:45,679:INFO:_display_container: 2
2023-02-17 19:12:45,680:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5963)
2023-02-17 19:12:45,680:INFO:create_model() successfully completed......................................
2023-02-17 19:12:45,797:INFO:SubProcess create_model() end ==================================
2023-02-17 19:12:45,797:INFO:Creating metrics dataframe
2023-02-17 19:12:45,812:INFO:Initializing Gradient Boosting Classifier
2023-02-17 19:12:45,812:INFO:Total runtime is 0.3605936368306478 minutes
2023-02-17 19:12:45,817:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:45,818:INFO:Initializing create_model()
2023-02-17 19:12:45,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:45,818:INFO:Checking exceptions
2023-02-17 19:12:45,818:INFO:Importing libraries
2023-02-17 19:12:45,818:INFO:Copying training dataset
2023-02-17 19:12:45,826:INFO:Defining folds
2023-02-17 19:12:45,826:INFO:Declaring metric variables
2023-02-17 19:12:45,831:INFO:Importing untrained model
2023-02-17 19:12:45,837:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 19:12:45,851:INFO:Starting cross validation
2023-02-17 19:12:45,852:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:12:50,083:INFO:Calculating mean and std
2023-02-17 19:12:50,084:INFO:Creating metrics dataframe
2023-02-17 19:12:50,088:INFO:Uploading results into container
2023-02-17 19:12:50,089:INFO:Uploading model into container now
2023-02-17 19:12:50,089:INFO:_master_model_container: 10
2023-02-17 19:12:50,089:INFO:_display_container: 2
2023-02-17 19:12:50,090:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5963, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 19:12:50,090:INFO:create_model() successfully completed......................................
2023-02-17 19:12:50,211:INFO:SubProcess create_model() end ==================================
2023-02-17 19:12:50,211:INFO:Creating metrics dataframe
2023-02-17 19:12:50,224:INFO:Initializing Linear Discriminant Analysis
2023-02-17 19:12:50,224:INFO:Total runtime is 0.43412315448125205 minutes
2023-02-17 19:12:50,229:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:50,230:INFO:Initializing create_model()
2023-02-17 19:12:50,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:50,230:INFO:Checking exceptions
2023-02-17 19:12:50,230:INFO:Importing libraries
2023-02-17 19:12:50,230:INFO:Copying training dataset
2023-02-17 19:12:50,238:INFO:Defining folds
2023-02-17 19:12:50,238:INFO:Declaring metric variables
2023-02-17 19:12:50,245:INFO:Importing untrained model
2023-02-17 19:12:50,251:INFO:Linear Discriminant Analysis Imported successfully
2023-02-17 19:12:50,262:INFO:Starting cross validation
2023-02-17 19:12:50,263:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:12:50,435:INFO:Calculating mean and std
2023-02-17 19:12:50,436:INFO:Creating metrics dataframe
2023-02-17 19:12:50,439:INFO:Uploading results into container
2023-02-17 19:12:50,440:INFO:Uploading model into container now
2023-02-17 19:12:50,440:INFO:_master_model_container: 11
2023-02-17 19:12:50,440:INFO:_display_container: 2
2023-02-17 19:12:50,441:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-02-17 19:12:50,441:INFO:create_model() successfully completed......................................
2023-02-17 19:12:50,558:INFO:SubProcess create_model() end ==================================
2023-02-17 19:12:50,558:INFO:Creating metrics dataframe
2023-02-17 19:12:50,573:INFO:Initializing Extra Trees Classifier
2023-02-17 19:12:50,573:INFO:Total runtime is 0.43994546333948775 minutes
2023-02-17 19:12:50,579:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:50,580:INFO:Initializing create_model()
2023-02-17 19:12:50,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:50,580:INFO:Checking exceptions
2023-02-17 19:12:50,580:INFO:Importing libraries
2023-02-17 19:12:50,581:INFO:Copying training dataset
2023-02-17 19:12:50,588:INFO:Defining folds
2023-02-17 19:12:50,589:INFO:Declaring metric variables
2023-02-17 19:12:50,598:INFO:Importing untrained model
2023-02-17 19:12:50,604:INFO:Extra Trees Classifier Imported successfully
2023-02-17 19:12:50,615:INFO:Starting cross validation
2023-02-17 19:12:50,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:12:53,270:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 19:12:53,281:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 19:12:54,957:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-17 19:12:55,582:INFO:Calculating mean and std
2023-02-17 19:12:55,583:INFO:Creating metrics dataframe
2023-02-17 19:12:55,586:INFO:Uploading results into container
2023-02-17 19:12:55,587:INFO:Uploading model into container now
2023-02-17 19:12:55,587:INFO:_master_model_container: 12
2023-02-17 19:12:55,587:INFO:_display_container: 2
2023-02-17 19:12:55,588:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5963, verbose=0, warm_start=False)
2023-02-17 19:12:55,588:INFO:create_model() successfully completed......................................
2023-02-17 19:12:55,710:INFO:SubProcess create_model() end ==================================
2023-02-17 19:12:55,710:INFO:Creating metrics dataframe
2023-02-17 19:12:55,741:INFO:Initializing Extreme Gradient Boosting
2023-02-17 19:12:55,741:INFO:Total runtime is 0.5260760227839152 minutes
2023-02-17 19:12:55,749:INFO:SubProcess create_model() called ==================================
2023-02-17 19:12:55,749:INFO:Initializing create_model()
2023-02-17 19:12:55,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:12:55,749:INFO:Checking exceptions
2023-02-17 19:12:55,750:INFO:Importing libraries
2023-02-17 19:12:55,750:INFO:Copying training dataset
2023-02-17 19:12:55,758:INFO:Defining folds
2023-02-17 19:12:55,758:INFO:Declaring metric variables
2023-02-17 19:12:55,764:INFO:Importing untrained model
2023-02-17 19:12:55,771:INFO:Extreme Gradient Boosting Imported successfully
2023-02-17 19:12:55,789:INFO:Starting cross validation
2023-02-17 19:12:55,790:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:13:00,190:INFO:Calculating mean and std
2023-02-17 19:13:00,191:INFO:Creating metrics dataframe
2023-02-17 19:13:00,195:INFO:Uploading results into container
2023-02-17 19:13:00,197:INFO:Uploading model into container now
2023-02-17 19:13:00,198:INFO:_master_model_container: 13
2023-02-17 19:13:00,198:INFO:_display_container: 2
2023-02-17 19:13:00,200:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-17 19:13:00,200:INFO:create_model() successfully completed......................................
2023-02-17 19:13:00,321:INFO:SubProcess create_model() end ==================================
2023-02-17 19:13:00,321:INFO:Creating metrics dataframe
2023-02-17 19:13:00,343:INFO:Initializing Light Gradient Boosting Machine
2023-02-17 19:13:00,343:INFO:Total runtime is 0.6027657906214396 minutes
2023-02-17 19:13:00,348:INFO:SubProcess create_model() called ==================================
2023-02-17 19:13:00,349:INFO:Initializing create_model()
2023-02-17 19:13:00,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:13:00,349:INFO:Checking exceptions
2023-02-17 19:13:00,350:INFO:Importing libraries
2023-02-17 19:13:00,350:INFO:Copying training dataset
2023-02-17 19:13:00,357:INFO:Defining folds
2023-02-17 19:13:00,357:INFO:Declaring metric variables
2023-02-17 19:13:00,362:INFO:Importing untrained model
2023-02-17 19:13:00,370:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 19:13:00,384:INFO:Starting cross validation
2023-02-17 19:13:00,385:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:13:03,006:INFO:Calculating mean and std
2023-02-17 19:13:03,008:INFO:Creating metrics dataframe
2023-02-17 19:13:03,011:INFO:Uploading results into container
2023-02-17 19:13:03,012:INFO:Uploading model into container now
2023-02-17 19:13:03,013:INFO:_master_model_container: 14
2023-02-17 19:13:03,015:INFO:_display_container: 2
2023-02-17 19:13:03,016:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 19:13:03,016:INFO:create_model() successfully completed......................................
2023-02-17 19:13:03,136:INFO:SubProcess create_model() end ==================================
2023-02-17 19:13:03,136:INFO:Creating metrics dataframe
2023-02-17 19:13:03,167:INFO:Initializing Dummy Classifier
2023-02-17 19:13:03,168:INFO:Total runtime is 0.6498453458150228 minutes
2023-02-17 19:13:03,171:INFO:SubProcess create_model() called ==================================
2023-02-17 19:13:03,171:INFO:Initializing create_model()
2023-02-17 19:13:03,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69E2F9AC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:13:03,172:INFO:Checking exceptions
2023-02-17 19:13:03,172:INFO:Importing libraries
2023-02-17 19:13:03,172:INFO:Copying training dataset
2023-02-17 19:13:03,182:INFO:Defining folds
2023-02-17 19:13:03,182:INFO:Declaring metric variables
2023-02-17 19:13:03,188:INFO:Importing untrained model
2023-02-17 19:13:03,194:INFO:Dummy Classifier Imported successfully
2023-02-17 19:13:03,206:INFO:Starting cross validation
2023-02-17 19:13:03,207:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:13:03,255:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 19:13:03,257:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 19:13:03,262:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 19:13:03,278:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 19:13:03,285:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 19:13:03,294:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 19:13:03,300:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 19:13:03,300:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 19:13:03,317:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 19:13:03,341:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-17 19:13:03,346:INFO:Calculating mean and std
2023-02-17 19:13:03,349:INFO:Creating metrics dataframe
2023-02-17 19:13:03,354:INFO:Uploading results into container
2023-02-17 19:13:03,356:INFO:Uploading model into container now
2023-02-17 19:13:03,356:INFO:_master_model_container: 15
2023-02-17 19:13:03,356:INFO:_display_container: 2
2023-02-17 19:13:03,357:INFO:DummyClassifier(constant=None, random_state=5963, strategy='prior')
2023-02-17 19:13:03,357:INFO:create_model() successfully completed......................................
2023-02-17 19:13:03,484:INFO:SubProcess create_model() end ==================================
2023-02-17 19:13:03,485:INFO:Creating metrics dataframe
2023-02-17 19:13:03,512:INFO:Initializing create_model()
2023-02-17 19:13:03,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:13:03,513:INFO:Checking exceptions
2023-02-17 19:13:03,517:INFO:Importing libraries
2023-02-17 19:13:03,517:INFO:Copying training dataset
2023-02-17 19:13:03,526:INFO:Defining folds
2023-02-17 19:13:03,526:INFO:Declaring metric variables
2023-02-17 19:13:03,526:INFO:Importing untrained model
2023-02-17 19:13:03,526:INFO:Declaring custom model
2023-02-17 19:13:03,527:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 19:13:03,528:INFO:Cross validation set to False
2023-02-17 19:13:03,528:INFO:Fitting Model
2023-02-17 19:13:03,729:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 19:13:03,729:INFO:create_model() successfully completed......................................
2023-02-17 19:13:03,855:INFO:Initializing create_model()
2023-02-17 19:13:03,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5963, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:13:03,855:INFO:Checking exceptions
2023-02-17 19:13:03,857:INFO:Importing libraries
2023-02-17 19:13:03,858:INFO:Copying training dataset
2023-02-17 19:13:03,865:INFO:Defining folds
2023-02-17 19:13:03,865:INFO:Declaring metric variables
2023-02-17 19:13:03,866:INFO:Importing untrained model
2023-02-17 19:13:03,866:INFO:Declaring custom model
2023-02-17 19:13:03,867:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 19:13:03,867:INFO:Cross validation set to False
2023-02-17 19:13:03,867:INFO:Fitting Model
2023-02-17 19:13:05,140:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5963, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 19:13:05,140:INFO:create_model() successfully completed......................................
2023-02-17 19:13:05,390:INFO:Initializing create_model()
2023-02-17 19:13:05,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:13:05,391:INFO:Checking exceptions
2023-02-17 19:13:05,393:INFO:Importing libraries
2023-02-17 19:13:05,393:INFO:Copying training dataset
2023-02-17 19:13:05,402:INFO:Defining folds
2023-02-17 19:13:05,402:INFO:Declaring metric variables
2023-02-17 19:13:05,403:INFO:Importing untrained model
2023-02-17 19:13:05,403:INFO:Declaring custom model
2023-02-17 19:13:05,405:INFO:Extreme Gradient Boosting Imported successfully
2023-02-17 19:13:05,405:INFO:Cross validation set to False
2023-02-17 19:13:05,405:INFO:Fitting Model
2023-02-17 19:13:05,961:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-17 19:13:05,961:INFO:create_model() successfully completed......................................
2023-02-17 19:13:06,122:INFO:_master_model_container: 15
2023-02-17 19:13:06,122:INFO:_display_container: 2
2023-02-17 19:13:06,124:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5963, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)]
2023-02-17 19:13:06,124:INFO:compare_models() successfully completed......................................
2023-02-17 19:13:06,344:INFO:Initializing tune_model()
2023-02-17 19:13:06,344:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>)
2023-02-17 19:13:06,344:INFO:Checking exceptions
2023-02-17 19:13:06,344:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-17 19:13:06,366:INFO:Copying training dataset
2023-02-17 19:13:06,373:INFO:Checking base model
2023-02-17 19:13:06,373:INFO:Base model : Light Gradient Boosting Machine
2023-02-17 19:13:06,377:INFO:Declaring metric variables
2023-02-17 19:13:06,380:INFO:Defining Hyperparameters
2023-02-17 19:13:06,517:INFO:Tuning with n_jobs=-1
2023-02-17 19:13:06,526:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 19:13:06,526:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 19:13:06,526:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-17 19:13:06,541:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-17 19:13:06,550:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-17 19:13:45,559:INFO:best_params: {'actual_estimator__num_leaves': 149, 'actual_estimator__learning_rate': 0.0034543364327440295, 'actual_estimator__n_estimators': 165, 'actual_estimator__min_split_gain': 0.09794868127014156, 'actual_estimator__reg_alpha': 0.1100002757147358, 'actual_estimator__reg_lambda': 0.20423945010551356, 'actual_estimator__feature_fraction': 0.5454160450217252, 'actual_estimator__bagging_fraction': 0.47404957304645157, 'actual_estimator__bagging_freq': 5, 'actual_estimator__min_child_samples': 15}
2023-02-17 19:13:45,568:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-17 19:13:45,569:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-17 19:13:45,570:INFO:Hyperparameter search completed
2023-02-17 19:13:45,570:INFO:SubProcess create_model() called ==================================
2023-02-17 19:13:45,572:INFO:Initializing create_model()
2023-02-17 19:13:45,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69DA6E6A0>, model_only=True, return_train_score=False, kwargs={'num_leaves': 149, 'learning_rate': 0.0034543364327440295, 'n_estimators': 165, 'min_split_gain': 0.09794868127014156, 'reg_alpha': 0.1100002757147358, 'reg_lambda': 0.20423945010551356, 'feature_fraction': 0.5454160450217252, 'bagging_fraction': 0.47404957304645157, 'bagging_freq': 5, 'min_child_samples': 15})
2023-02-17 19:13:45,572:INFO:Checking exceptions
2023-02-17 19:13:45,572:INFO:Importing libraries
2023-02-17 19:13:45,572:INFO:Copying training dataset
2023-02-17 19:13:45,580:INFO:Defining folds
2023-02-17 19:13:45,580:INFO:Declaring metric variables
2023-02-17 19:13:45,584:INFO:Importing untrained model
2023-02-17 19:13:45,584:INFO:Declaring custom model
2023-02-17 19:13:45,588:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 19:13:45,597:INFO:Starting cross validation
2023-02-17 19:13:45,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:13:47,228:INFO:Calculating mean and std
2023-02-17 19:13:47,231:INFO:Creating metrics dataframe
2023-02-17 19:13:47,238:INFO:Finalizing model
2023-02-17 19:13:47,895:INFO:Uploading results into container
2023-02-17 19:13:47,898:INFO:Uploading model into container now
2023-02-17 19:13:47,899:INFO:_master_model_container: 16
2023-02-17 19:13:47,899:INFO:_display_container: 3
2023-02-17 19:13:47,900:INFO:LGBMClassifier(bagging_fraction=0.47404957304645157, bagging_freq=5,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.5454160450217252, importance_type='split',
               learning_rate=0.0034543364327440295, max_depth=-1,
               min_child_samples=15, min_child_weight=0.001,
               min_split_gain=0.09794868127014156, n_estimators=165, n_jobs=-1,
               num_leaves=149, objective=None, random_state=5963,
               reg_alpha=0.1100002757147358, reg_lambda=0.20423945010551356,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-02-17 19:13:47,900:INFO:create_model() successfully completed......................................
2023-02-17 19:13:48,017:INFO:SubProcess create_model() end ==================================
2023-02-17 19:13:48,017:INFO:choose_better activated
2023-02-17 19:13:48,021:INFO:SubProcess create_model() called ==================================
2023-02-17 19:13:48,021:INFO:Initializing create_model()
2023-02-17 19:13:48,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:13:48,022:INFO:Checking exceptions
2023-02-17 19:13:48,024:INFO:Importing libraries
2023-02-17 19:13:48,024:INFO:Copying training dataset
2023-02-17 19:13:48,032:INFO:Defining folds
2023-02-17 19:13:48,032:INFO:Declaring metric variables
2023-02-17 19:13:48,032:INFO:Importing untrained model
2023-02-17 19:13:48,032:INFO:Declaring custom model
2023-02-17 19:13:48,033:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 19:13:48,033:INFO:Starting cross validation
2023-02-17 19:13:48,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:13:48,487:INFO:Calculating mean and std
2023-02-17 19:13:48,487:INFO:Creating metrics dataframe
2023-02-17 19:13:48,489:INFO:Finalizing model
2023-02-17 19:13:48,505:INFO:Uploading results into container
2023-02-17 19:13:48,506:INFO:Uploading model into container now
2023-02-17 19:13:48,506:INFO:_master_model_container: 17
2023-02-17 19:13:48,506:INFO:_display_container: 4
2023-02-17 19:13:48,507:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 19:13:48,507:INFO:create_model() successfully completed......................................
2023-02-17 19:13:48,620:INFO:SubProcess create_model() end ==================================
2023-02-17 19:13:48,621:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8366
2023-02-17 19:13:48,621:INFO:LGBMClassifier(bagging_fraction=0.47404957304645157, bagging_freq=5,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.5454160450217252, importance_type='split',
               learning_rate=0.0034543364327440295, max_depth=-1,
               min_child_samples=15, min_child_weight=0.001,
               min_split_gain=0.09794868127014156, n_estimators=165, n_jobs=-1,
               num_leaves=149, objective=None, random_state=5963,
               reg_alpha=0.1100002757147358, reg_lambda=0.20423945010551356,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for Recall is 0.8482
2023-02-17 19:13:48,622:INFO:LGBMClassifier(bagging_fraction=0.47404957304645157, bagging_freq=5,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.5454160450217252, importance_type='split',
               learning_rate=0.0034543364327440295, max_depth=-1,
               min_child_samples=15, min_child_weight=0.001,
               min_split_gain=0.09794868127014156, n_estimators=165, n_jobs=-1,
               num_leaves=149, objective=None, random_state=5963,
               reg_alpha=0.1100002757147358, reg_lambda=0.20423945010551356,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) is best model
2023-02-17 19:13:48,622:INFO:choose_better completed
2023-02-17 19:13:48,633:INFO:_master_model_container: 17
2023-02-17 19:13:48,633:INFO:_display_container: 3
2023-02-17 19:13:48,634:INFO:LGBMClassifier(bagging_fraction=0.47404957304645157, bagging_freq=5,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.5454160450217252, importance_type='split',
               learning_rate=0.0034543364327440295, max_depth=-1,
               min_child_samples=15, min_child_weight=0.001,
               min_split_gain=0.09794868127014156, n_estimators=165, n_jobs=-1,
               num_leaves=149, objective=None, random_state=5963,
               reg_alpha=0.1100002757147358, reg_lambda=0.20423945010551356,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-02-17 19:13:48,634:INFO:tune_model() successfully completed......................................
2023-02-17 19:13:48,751:INFO:Initializing tune_model()
2023-02-17 19:13:48,752:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5963, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>)
2023-02-17 19:13:48,752:INFO:Checking exceptions
2023-02-17 19:13:48,752:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-17 19:13:48,776:INFO:Copying training dataset
2023-02-17 19:13:48,782:INFO:Checking base model
2023-02-17 19:13:48,782:INFO:Base model : Gradient Boosting Classifier
2023-02-17 19:13:48,787:INFO:Declaring metric variables
2023-02-17 19:13:48,792:INFO:Defining Hyperparameters
2023-02-17 19:13:48,917:INFO:Tuning with n_jobs=-1
2023-02-17 19:13:48,918:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 19:13:48,918:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 19:13:48,918:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-17 19:13:48,918:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-17 19:13:48,920:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-17 19:17:06,587:INFO:best_params: {'actual_estimator__n_estimators': 176, 'actual_estimator__learning_rate': 0.06927282770029321, 'actual_estimator__subsample': 0.6308251880157458, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__max_depth': 8, 'actual_estimator__min_impurity_decrease': 1.1844674977274064e-09, 'actual_estimator__max_features': 0.7761225141690216}
2023-02-17 19:17:06,587:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-17 19:17:06,588:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-17 19:17:06,589:INFO:Hyperparameter search completed
2023-02-17 19:17:06,589:INFO:SubProcess create_model() called ==================================
2023-02-17 19:17:06,590:INFO:Initializing create_model()
2023-02-17 19:17:06,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5963, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D686628E20>, model_only=True, return_train_score=False, kwargs={'n_estimators': 176, 'learning_rate': 0.06927282770029321, 'subsample': 0.6308251880157458, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 8, 'min_impurity_decrease': 1.1844674977274064e-09, 'max_features': 0.7761225141690216})
2023-02-17 19:17:06,591:INFO:Checking exceptions
2023-02-17 19:17:06,591:INFO:Importing libraries
2023-02-17 19:17:06,591:INFO:Copying training dataset
2023-02-17 19:17:06,598:INFO:Defining folds
2023-02-17 19:17:06,598:INFO:Declaring metric variables
2023-02-17 19:17:06,603:INFO:Importing untrained model
2023-02-17 19:17:06,604:INFO:Declaring custom model
2023-02-17 19:17:06,610:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 19:17:06,620:INFO:Starting cross validation
2023-02-17 19:17:06,621:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:17:07,626:INFO:Calculating mean and std
2023-02-17 19:17:07,627:INFO:Creating metrics dataframe
2023-02-17 19:17:07,635:INFO:Finalizing model
2023-02-17 19:17:11,113:INFO:Uploading results into container
2023-02-17 19:17:11,114:INFO:Uploading model into container now
2023-02-17 19:17:11,115:INFO:_master_model_container: 18
2023-02-17 19:17:11,115:INFO:_display_container: 4
2023-02-17 19:17:11,115:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.06927282770029321, loss='deviance',
                           max_depth=8, max_features=0.7761225141690216,
                           max_leaf_nodes=None,
                           min_impurity_decrease=1.1844674977274064e-09,
                           min_samples_leaf=4, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=176,
                           n_iter_no_change=None, random_state=5963,
                           subsample=0.6308251880157458, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 19:17:11,115:INFO:create_model() successfully completed......................................
2023-02-17 19:17:11,268:INFO:SubProcess create_model() end ==================================
2023-02-17 19:17:11,268:INFO:choose_better activated
2023-02-17 19:17:11,272:INFO:SubProcess create_model() called ==================================
2023-02-17 19:17:11,272:INFO:Initializing create_model()
2023-02-17 19:17:11,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5963, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:17:11,273:INFO:Checking exceptions
2023-02-17 19:17:11,275:INFO:Importing libraries
2023-02-17 19:17:11,275:INFO:Copying training dataset
2023-02-17 19:17:11,281:INFO:Defining folds
2023-02-17 19:17:11,282:INFO:Declaring metric variables
2023-02-17 19:17:11,282:INFO:Importing untrained model
2023-02-17 19:17:11,282:INFO:Declaring custom model
2023-02-17 19:17:11,284:INFO:Gradient Boosting Classifier Imported successfully
2023-02-17 19:17:11,285:INFO:Starting cross validation
2023-02-17 19:17:11,286:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:17:11,859:INFO:Calculating mean and std
2023-02-17 19:17:11,859:INFO:Creating metrics dataframe
2023-02-17 19:17:11,862:INFO:Finalizing model
2023-02-17 19:17:11,886:INFO:Uploading results into container
2023-02-17 19:17:11,886:INFO:Uploading model into container now
2023-02-17 19:17:11,887:INFO:_master_model_container: 19
2023-02-17 19:17:11,887:INFO:_display_container: 5
2023-02-17 19:17:11,887:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5963, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 19:17:11,887:INFO:create_model() successfully completed......................................
2023-02-17 19:17:12,002:INFO:SubProcess create_model() end ==================================
2023-02-17 19:17:12,003:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5963, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Recall is 0.8353
2023-02-17 19:17:12,004:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.06927282770029321, loss='deviance',
                           max_depth=8, max_features=0.7761225141690216,
                           max_leaf_nodes=None,
                           min_impurity_decrease=1.1844674977274064e-09,
                           min_samples_leaf=4, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=176,
                           n_iter_no_change=None, random_state=5963,
                           subsample=0.6308251880157458, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Recall is 0.8397
2023-02-17 19:17:12,005:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.06927282770029321, loss='deviance',
                           max_depth=8, max_features=0.7761225141690216,
                           max_leaf_nodes=None,
                           min_impurity_decrease=1.1844674977274064e-09,
                           min_samples_leaf=4, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=176,
                           n_iter_no_change=None, random_state=5963,
                           subsample=0.6308251880157458, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-02-17 19:17:12,005:INFO:choose_better completed
2023-02-17 19:17:12,016:INFO:_master_model_container: 19
2023-02-17 19:17:12,016:INFO:_display_container: 4
2023-02-17 19:17:12,017:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.06927282770029321, loss='deviance',
                           max_depth=8, max_features=0.7761225141690216,
                           max_leaf_nodes=None,
                           min_impurity_decrease=1.1844674977274064e-09,
                           min_samples_leaf=4, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=176,
                           n_iter_no_change=None, random_state=5963,
                           subsample=0.6308251880157458, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-02-17 19:17:12,018:INFO:tune_model() successfully completed......................................
2023-02-17 19:17:12,139:INFO:Initializing tune_model()
2023-02-17 19:17:12,139:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>)
2023-02-17 19:17:12,139:INFO:Checking exceptions
2023-02-17 19:17:12,139:INFO:Soft dependency imported: optuna: 2.10.1
2023-02-17 19:17:12,163:INFO:Copying training dataset
2023-02-17 19:17:12,171:INFO:Checking base model
2023-02-17 19:17:12,171:INFO:Base model : Extreme Gradient Boosting
2023-02-17 19:17:12,179:INFO:Declaring metric variables
2023-02-17 19:17:12,183:INFO:Defining Hyperparameters
2023-02-17 19:17:12,306:INFO:Tuning with n_jobs=-1
2023-02-17 19:17:12,307:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:263: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 19:17:12,307:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-02-17 19:17:12,307:INFO:Initializing optuna.integration.OptunaSearchCV
2023-02-17 19:17:12,307:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2445: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-02-17 19:17:12,309:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-17 19:17:46,392:INFO:best_params: {'actual_estimator__learning_rate': 3.289248592647836e-05, 'actual_estimator__n_estimators': 149, 'actual_estimator__subsample': 0.663920854641018, 'actual_estimator__max_depth': 1, 'actual_estimator__colsample_bytree': 0.5841799776234919, 'actual_estimator__min_child_weight': 2, 'actual_estimator__reg_alpha': 1.3495598449290276e-10, 'actual_estimator__reg_lambda': 2.2243132559576753e-05, 'actual_estimator__scale_pos_weight': 36.08159647081551}
2023-02-17 19:17:46,392:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-02-17 19:17:46,392:WARNING:Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2674, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-02-17 19:17:46,393:INFO:Hyperparameter search completed
2023-02-17 19:17:46,393:INFO:SubProcess create_model() called ==================================
2023-02-17 19:17:46,396:INFO:Initializing create_model()
2023-02-17 19:17:46,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D69EE6BFA0>, model_only=True, return_train_score=False, kwargs={'learning_rate': 3.289248592647836e-05, 'n_estimators': 149, 'subsample': 0.663920854641018, 'max_depth': 1, 'colsample_bytree': 0.5841799776234919, 'min_child_weight': 2, 'reg_alpha': 1.3495598449290276e-10, 'reg_lambda': 2.2243132559576753e-05, 'scale_pos_weight': 36.08159647081551})
2023-02-17 19:17:46,398:INFO:Checking exceptions
2023-02-17 19:17:46,398:INFO:Importing libraries
2023-02-17 19:17:46,398:INFO:Copying training dataset
2023-02-17 19:17:46,405:INFO:Defining folds
2023-02-17 19:17:46,405:INFO:Declaring metric variables
2023-02-17 19:17:46,408:INFO:Importing untrained model
2023-02-17 19:17:46,409:INFO:Declaring custom model
2023-02-17 19:17:46,418:INFO:Extreme Gradient Boosting Imported successfully
2023-02-17 19:17:46,425:INFO:Starting cross validation
2023-02-17 19:17:46,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:17:46,743:INFO:Calculating mean and std
2023-02-17 19:17:46,744:INFO:Creating metrics dataframe
2023-02-17 19:17:46,752:INFO:Finalizing model
2023-02-17 19:17:46,956:INFO:Uploading results into container
2023-02-17 19:17:46,958:INFO:Uploading model into container now
2023-02-17 19:17:46,959:INFO:_master_model_container: 20
2023-02-17 19:17:46,959:INFO:_display_container: 5
2023-02-17 19:17:46,960:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5841799776234919, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=3.289248592647836e-05,
              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=1, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              n_estimators=149, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-17 19:17:46,960:INFO:create_model() successfully completed......................................
2023-02-17 19:17:47,078:INFO:SubProcess create_model() end ==================================
2023-02-17 19:17:47,078:INFO:choose_better activated
2023-02-17 19:17:47,084:INFO:SubProcess create_model() called ==================================
2023-02-17 19:17:47,085:INFO:Initializing create_model()
2023-02-17 19:17:47,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:17:47,085:INFO:Checking exceptions
2023-02-17 19:17:47,087:INFO:Importing libraries
2023-02-17 19:17:47,087:INFO:Copying training dataset
2023-02-17 19:17:47,093:INFO:Defining folds
2023-02-17 19:17:47,094:INFO:Declaring metric variables
2023-02-17 19:17:47,094:INFO:Importing untrained model
2023-02-17 19:17:47,094:INFO:Declaring custom model
2023-02-17 19:17:47,095:INFO:Extreme Gradient Boosting Imported successfully
2023-02-17 19:17:47,096:INFO:Starting cross validation
2023-02-17 19:17:47,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-17 19:17:47,332:INFO:Calculating mean and std
2023-02-17 19:17:47,333:INFO:Creating metrics dataframe
2023-02-17 19:17:47,335:INFO:Finalizing model
2023-02-17 19:17:47,361:INFO:Uploading results into container
2023-02-17 19:17:47,362:INFO:Uploading model into container now
2023-02-17 19:17:47,364:INFO:_master_model_container: 21
2023-02-17 19:17:47,364:INFO:_display_container: 6
2023-02-17 19:17:47,365:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-17 19:17:47,365:INFO:create_model() successfully completed......................................
2023-02-17 19:17:47,491:INFO:SubProcess create_model() end ==================================
2023-02-17 19:17:47,492:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for Recall is 0.8305
2023-02-17 19:17:47,493:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5841799776234919, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=3.289248592647836e-05,
              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=1, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              n_estimators=149, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) result for Recall is 1.0
2023-02-17 19:17:47,494:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5841799776234919, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=3.289248592647836e-05,
              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=1, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              n_estimators=149, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...) is best model
2023-02-17 19:17:47,494:INFO:choose_better completed
2023-02-17 19:17:47,508:INFO:_master_model_container: 21
2023-02-17 19:17:47,508:INFO:_display_container: 5
2023-02-17 19:17:47,509:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5841799776234919, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=3.289248592647836e-05,
              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=1, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              n_estimators=149, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-02-17 19:17:47,509:INFO:tune_model() successfully completed......................................
2023-02-17 19:17:47,627:INFO:Initializing automl()
2023-02-17 19:17:47,627:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, optimize=AUC, use_holdout=False, turbo=True, return_train_score=False)
2023-02-17 19:17:47,627:INFO:Model Selection Basis : CV Results on Training set
2023-02-17 19:17:47,627:INFO:Checking model 0
2023-02-17 19:17:47,627:INFO:Checking model 1
2023-02-17 19:17:47,627:INFO:Checking model 2
2023-02-17 19:17:47,627:INFO:Checking model 3
2023-02-17 19:17:47,628:INFO:Checking model 4
2023-02-17 19:17:47,628:INFO:Checking model 5
2023-02-17 19:17:47,628:INFO:Checking model 6
2023-02-17 19:17:47,628:INFO:Checking model 7
2023-02-17 19:17:47,628:INFO:Checking model 8
2023-02-17 19:17:47,628:INFO:Checking model 9
2023-02-17 19:17:47,629:INFO:Checking model 10
2023-02-17 19:17:47,629:INFO:Checking model 11
2023-02-17 19:17:47,629:INFO:Checking model 12
2023-02-17 19:17:47,629:INFO:Checking model 13
2023-02-17 19:17:47,629:INFO:Checking model 14
2023-02-17 19:17:47,629:INFO:Checking model 15
2023-02-17 19:17:47,630:INFO:Checking model 16
2023-02-17 19:17:47,630:INFO:Checking model 17
2023-02-17 19:17:47,630:INFO:Checking model 18
2023-02-17 19:17:47,630:INFO:Checking model 19
2023-02-17 19:17:47,632:INFO:Checking model 20
2023-02-17 19:17:47,632:INFO:Initializing create_model()
2023-02-17 19:17:47,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-17 19:17:47,632:INFO:Checking exceptions
2023-02-17 19:17:47,633:INFO:Importing libraries
2023-02-17 19:17:47,633:INFO:Copying training dataset
2023-02-17 19:17:47,639:INFO:Defining folds
2023-02-17 19:17:47,639:INFO:Declaring metric variables
2023-02-17 19:17:47,639:INFO:Importing untrained model
2023-02-17 19:17:47,639:INFO:Declaring custom model
2023-02-17 19:17:47,640:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 19:17:47,641:INFO:Cross validation set to False
2023-02-17 19:17:47,641:INFO:Fitting Model
2023-02-17 19:17:47,649:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 19:17:47,649:INFO:create_model() successfully completed......................................
2023-02-17 19:17:47,879:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 19:17:47,881:INFO:automl() successfully completed......................................
2023-02-17 19:17:47,886:INFO:Initializing finalize_model()
2023-02-17 19:17:47,886:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-02-17 19:17:47,887:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-02-17 19:17:47,889:INFO:Initializing create_model()
2023-02-17 19:17:47,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D69C4A7FA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-02-17 19:17:47,889:INFO:Checking exceptions
2023-02-17 19:17:47,891:INFO:Importing libraries
2023-02-17 19:17:47,891:INFO:Copying training dataset
2023-02-17 19:17:47,891:INFO:Defining folds
2023-02-17 19:17:47,891:INFO:Declaring metric variables
2023-02-17 19:17:47,891:INFO:Importing untrained model
2023-02-17 19:17:47,891:INFO:Declaring custom model
2023-02-17 19:17:47,892:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-17 19:17:47,893:INFO:Cross validation set to False
2023-02-17 19:17:47,893:INFO:Fitting Model
2023-02-17 19:17:48,044:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('actual_estimator',
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5963, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-02-17 19:17:48,044:INFO:create_model() successfully completed......................................
2023-02-17 19:17:48,156:INFO:_master_model_container: 21
2023-02-17 19:17:48,156:INFO:_display_container: 5
2023-02-17 19:17:48,158:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('actual_estimator',
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5963, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-02-17 19:17:48,158:INFO:finalize_model() successfully completed......................................
2023-02-18 00:40:03,412:INFO:Initializing save_model()
2023-02-18 00:40:03,503:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.47404957304645157, bagging_freq=5,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.5454160450217252, importance_type='split',
               learning_rate=0.0034543364327440295, max_depth=-1,
               min_child_samples=15, min_child_weight=0.001,
               min_split_gain=0.09794868127014156, n_estimators=165, n_jobs=-1,
               num_leaves=149, objective=None, random_state=5963,
               reg_alpha=0.1100002757147358, reg_lambda=0.20423945010551356,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), model_name=models/LGBMClassifier_2023-02-18 00:40:03.227619, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-18 00:40:03,503:INFO:Adding model into prep_pipe
2023-02-18 00:40:21,346:INFO:Initializing save_model()
2023-02-18 00:40:21,351:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.47404957304645157, bagging_freq=5,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.5454160450217252, importance_type='split',
               learning_rate=0.0034543364327440295, max_depth=-1,
               min_child_samples=15, min_child_weight=0.001,
               min_split_gain=0.09794868127014156, n_estimators=165, n_jobs=-1,
               num_leaves=149, objective=None, random_state=5963,
               reg_alpha=0.1100002757147358, reg_lambda=0.20423945010551356,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), model_name=LGBMClassifier_2023-02-18 00:40:21.334968, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-18 00:40:21,383:INFO:Adding model into prep_pipe
2023-02-18 00:41:21,117:INFO:Initializing save_model()
2023-02-18 00:41:21,117:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.47404957304645157, bagging_freq=5,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.5454160450217252, importance_type='split',
               learning_rate=0.0034543364327440295, max_depth=-1,
               min_child_samples=15, min_child_weight=0.001,
               min_split_gain=0.09794868127014156, n_estimators=165, n_jobs=-1,
               num_leaves=149, objective=None, random_state=5963,
               reg_alpha=0.1100002757147358, reg_lambda=0.20423945010551356,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), model_name=LGBMClassifier_2023-02-18 00:41:21.104740, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-18 00:41:21,125:INFO:Adding model into prep_pipe
2023-02-18 00:43:15,395:INFO:Initializing save_model()
2023-02-18 00:43:15,401:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.47404957304645157, bagging_freq=5,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.5454160450217252, importance_type='split',
               learning_rate=0.0034543364327440295, max_depth=-1,
               min_child_samples=15, min_child_weight=0.001,
               min_split_gain=0.09794868127014156, n_estimators=165, n_jobs=-1,
               num_leaves=149, objective=None, random_state=5963,
               reg_alpha=0.1100002757147358, reg_lambda=0.20423945010551356,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), model_name=LGBMClassifier_2023-02-18-00-43, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-18 00:43:15,401:INFO:Adding model into prep_pipe
2023-02-18 00:43:18,183:INFO:LGBMClassifier_2023-02-18-00-43.pkl saved in current working directory
2023-02-18 00:43:18,186:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('trained_model',
                 LGBMClassifier(bagging_fraction=0.47404957304645157,
                                bagging_freq=5, boosting_type='gbdt',
                                class_weight=None, colsample_bytree=1.0,
                                feature_fraction=0.5454160450217252,
                                importance_type='split',
                                learning_rate=0.0034543364327440295,
                                max_depth=-1, min_child_samples=15,
                                min_child_weight=0.001,
                                min_split_gain=0.09794868127014156,
                                n_estimators=165, n_jobs=-1, num_leaves=149,
                                objective=None, random_state=5963,
                                reg_alpha=0.1100002757147358,
                                reg_lambda=0.20423945010551356, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-02-18 00:43:18,186:INFO:save_model() successfully completed......................................
2023-02-18 00:43:27,034:INFO:Initializing save_model()
2023-02-18 00:43:27,035:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5963, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=LGBMClassifier_2023-02-18-00-43, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-18 00:43:27,041:INFO:Adding model into prep_pipe
2023-02-18 00:43:27,202:INFO:LGBMClassifier_2023-02-18-00-43.pkl saved in current working directory
2023-02-18 00:43:27,204:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('trained_model',
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5963, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-02-18 00:43:27,204:INFO:save_model() successfully completed......................................
2023-02-18 00:43:27,329:INFO:Initializing save_model()
2023-02-18 00:43:27,329:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5963, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=GradientBoostingClassifier_2023-02-18-00-43, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-18 00:43:27,329:INFO:Adding model into prep_pipe
2023-02-18 00:43:27,601:INFO:GradientBoostingClassifier_2023-02-18-00-43.pkl saved in current working directory
2023-02-18 00:43:27,604:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('trained_model',
                 GradientBoostingClassifier(ccp_alpha=0.0,
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=5963, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-02-18 00:43:27,604:INFO:save_model() successfully completed......................................
2023-02-18 00:43:27,729:INFO:Initializing save_model()
2023-02-18 00:43:27,729:INFO:save_model(model=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), model_name=XGBClassifier_2023-02-18-00-43, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-02-18 00:43:27,729:INFO:Adding model into prep_pipe
2023-02-18 00:43:28,307:INFO:XGBClassifier_2023-02-18-00-43.pkl saved in current working directory
2023-02-18 00:43:28,324:INFO:Pipeline(memory=FastMemory(location=C:\Users\pedro\AppData\Local\Temp\joblib),
         steps=[('placeholder', None),
                ('trained_model',
                 XGBClassifier(base_score=None, booster='gbtree',
                               callbacks=None, colsample_bylevel=None,
                               colsample_bynode=None, colsample_bytree=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=None...
                               grow_policy=None, importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, n_estimators=100,
                               n_jobs=-1, num_parallel_tree=None,
                               objective='binary:logistic', predictor=None, ...))],
         verbose=False)
2023-02-18 00:43:28,324:INFO:save_model() successfully completed......................................
2023-02-18 00:59:17,736:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\trial\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name "num_leaves"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 2, 'high': 80, 'step': 1}
  warnings.warn(

2023-02-18 00:59:30,901:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\trial\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name "num_leaves"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 2, 'high': 80, 'step': 1}
  warnings.warn(

2023-02-18 01:03:24,760:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\trial\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name "num_leaves"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 2, 'high': 11, 'step': 1}
  warnings.warn(

2023-02-18 01:04:06,667:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\trial\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name "num_leaves"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 2, 'high': 10, 'step': 1}
  warnings.warn(

2023-02-18 01:04:31,567:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\trial\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name "num_leaves"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 2, 'high': 10, 'step': 1}
  warnings.warn(

2023-02-18 01:04:56,232:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\trial\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name "num_leaves"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 2, 'high': 5, 'step': 1}
  warnings.warn(

2023-02-18 01:05:41,092:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\trial\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name "num_leaves"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 2, 'high': 7, 'step': 1}
  warnings.warn(

2023-02-18 01:08:42,325:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
5 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 486, in fit
    return super().fit(X, y, sample_weight)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py", line 116, in fit
    X, y = self._validate_data(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\base.py", line 581, in _validate_data
    X, y = check_X_y(X, y, **check_params)
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 964, in check_X_y
    X = check_array(
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-02-18 01:46:55,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-18 01:46:55,406:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-18 01:46:55,406:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-18 01:46:55,406:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-18 01:47:02,440:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-18 03:08:02,020:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-18 03:20:27,402:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:20:27,716:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:20:59,973:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:21:16,486:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:21:49,974:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:22:06,990:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:22:45,865:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:25:46,599:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:26:03,592:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:26:39,867:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:35:50,272:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:36:08,808:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:36:49,209:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:37:13,506:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:37:29,535:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 03:38:07,289:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 05:01:59,124:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-18 05:01:59,125:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-18 05:01:59,125:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-18 05:01:59,125:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-18 05:02:00,817:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-18 05:16:44,839:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-18 05:59:51,691:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 06:00:05,085:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 06:00:12,224:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 06:00:13,970:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 06:00:27,237:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 06:00:33,857:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 09:59:14,960:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-18 10:11:56,366:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 10:12:00,410:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 10:12:04,564:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 10:12:05,694:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 10:12:09,614:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 10:12:13,742:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 10:13:03,834:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-18 14:46:29,846:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 14:47:55,260:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 14:48:57,531:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 14:49:08,619:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 14:50:35,036:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 14:51:40,177:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 15:10:59,884:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-18 16:43:30,081:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 16:44:11,394:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 16:45:14,849:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 16:45:26,299:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 16:46:07,570:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 16:47:15,375:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 16:52:43,842:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 16:53:24,562:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 16:57:30,906:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 16:58:10,454:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 16:59:17,646:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 16:59:30,822:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 17:00:13,196:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-18 17:01:21,040:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 12:47:05,906:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-19 12:59:42,172:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-19 13:52:51,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-19 13:52:51,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-19 13:52:51,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-19 13:52:51,626:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-19 13:52:53,835:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-19 13:57:15,985:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-19 14:03:51,191:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-19 14:47:41,780:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py:746: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  array = np.asarray(array, order=order, dtype=dtype)

2023-02-19 14:49:24,230:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py:746: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  array = np.asarray(array, order=order, dtype=dtype)

2023-02-19 15:00:01,124:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\validation.py:746: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  array = np.asarray(array, order=order, dtype=dtype)

2023-02-19 16:13:18,306:WARNING:C:\Users\pedro\AppData\Local\Temp\ipykernel_18364\3388051328.py:20: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`
  return avg_df.style.background_gradient(cmap=cm).set_precision(2)

2023-02-19 16:13:52,201:WARNING:C:\Users\pedro\AppData\Local\Temp\ipykernel_18364\992710020.py:20: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`
  return avg_df.style.background_gradient(cmap=cm).set_precision(2)

2023-02-19 16:16:51,175:WARNING:C:\Users\pedro\AppData\Local\Temp\ipykernel_18364\2186438748.py:20: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`
  return avg_df.style.background_gradient().set_precision(2)

2023-02-19 16:17:01,216:WARNING:C:\Users\pedro\AppData\Local\Temp\ipykernel_18364\1584092599.py:22: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`
  get_avg_df(results).style.background_gradient().set_precision(2)

2023-02-19 16:42:21,760:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-19 17:10:03,123:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-19 17:10:19,078:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-19 17:24:17,534:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\optuna\study\study.py:393: FutureWarning: `n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.
  warnings.warn(

2023-02-19 18:08:35,744:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 18:08:40,885:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 18:09:08,273:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 18:09:25,702:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-19 18:10:19,629:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-19 18:10:29,133:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-19 18:10:30,624:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-19 18:10:33,597:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-19 18:10:34,797:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-19 18:11:09,486:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-19 18:11:10,856:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-02-19 18:12:59,234:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 18:13:01,006:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 18:13:05,506:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 18:47:58,809:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 18:48:09,378:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 18:48:43,173:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 18:48:50,465:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 18:49:00,889:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 18:49:33,869:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 19:10:36,894:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 19:10:38,106:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 19:10:39,832:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 19:10:42,389:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 19:10:43,690:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 19:10:45,390:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 21:45:24,264:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 21:45:25,643:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 21:45:30,126:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 21:45:37,532:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 21:45:39,046:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 21:45:44,087:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 22:51:46,683:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 22:51:48,665:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 22:51:53,152:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 22:51:59,976:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 22:52:02,078:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 22:52:06,579:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 23:12:59,615:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 23:13:26,893:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 23:13:39,523:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 23:13:43,409:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 23:14:06,051:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

2023-02-19 23:14:18,792:WARNING:c:\Users\pedro\anaconda3\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function plot_precision_recall_curve is deprecated; Function `plot_precision_recall_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: PrecisionRecallDisplay.from_predictions or PrecisionRecallDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)

