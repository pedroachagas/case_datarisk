{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedroachagas/case_datarisk/blob/main/eda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91pYI5yVUHyD"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/pedroachagas/case_datarisk.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xcRaoc8Uk2l"
      },
      "outputs": [],
      "source": [
        "!pip install lazypredict\n",
        "!pip install --pre pycaret\n",
        "!pip install autoviz\n",
        "!pip install pycaret[full]\n",
        "!pip install -U ydata-profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25jUwvTGUaQt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pycaret.classification import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CExqgPYYVezq"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/case_datarisk/treino.csv')\n",
        "test = pd.read_csv('/content/case_datarisk/teste.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45vxgaRUVtvk"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZ2WqiSMU01i"
      },
      "outputs": [],
      "source": [
        "exp_1 = setup(data=train, target='inadimplente', fix_imbalance=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQESHELy9ZDG"
      },
      "outputs": [],
      "source": [
        "top3 = compare_models(n_select = 3)\n",
        "tuned_top3 = [tune_model(i) for i in top3]\n",
        "blender = blend_models(tuned_top3)\n",
        "stacker = stack_models(tuned_top3)\n",
        "best_auc_model = automl(optimize = 'AUC')\n",
        "model = finalize_model(best_auc_model)\n",
        "save_experiment('exp1.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhaHJuyhZfNz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = train.drop('inadimplente', axis=1)\n",
        "y = train.inadimplente\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state =123)\n",
        "\n",
        "metrics = [\n",
        "    'recall_weighted',\n",
        "    # 'recall_micro',\n",
        "    # 'accuracy',\n",
        "    'f1_weighted',\n",
        "    'balanced_accuracy',\n",
        "    'roc_auc',\n",
        "    #  'f1_micro',\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "for i, metric in enumerate(metrics):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(estimator=model, X=X, y=y,\n",
        "                                                            cv=10, train_sizes=np.linspace(0.1, 1.0, 51),\n",
        "                                                            n_jobs=-1, scoring=metric, shuffle=True,\n",
        "                                                            )\n",
        "\n",
        "    # Calculate training and test mean and std\n",
        "    train_mean = np.mean(train_scores, axis=1)\n",
        "    train_std = np.std(train_scores, axis=1)\n",
        "    test_mean = np.mean(test_scores, axis=1)\n",
        "    test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    # Plot the learning curve\n",
        "    plt.subplot(int(len(metrics)/2), 2, i+1)\n",
        "    plt.plot(train_sizes, train_mean,  marker='o',\n",
        "             markersize=5, label=f'Treino - {metric}')\n",
        "    plt.fill_between(train_sizes, train_mean + train_std,\n",
        "                     train_mean - train_std, alpha=0.15)\n",
        "    plt.plot(train_sizes, test_mean,  marker='+', markersize=5,\n",
        "             linestyle='--', label=f'Validação - {metric}')\n",
        "    plt.fill_between(train_sizes, test_mean + test_std,\n",
        "                     test_mean - test_std, alpha=0.15)\n",
        "    plt.ylim([0.2, 1])\n",
        "    plt.title(f'{metric}')\n",
        "    plt.ylabel(f'{metric}')\n",
        "    plt.grid(alpha=0.5)\n",
        "    plt.legend()\n",
        "plt.suptitle('Curvas de aprendizado', fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88Ktglr-WANa"
      },
      "outputs": [],
      "source": [
        "dashboard(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF4f0m3EXyca"
      },
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(train, title=\"Profiling Report\")\n",
        "profile.to_notebook_iframe()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPHCAe5tqsQ4OHOGKIc2Oe+",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "aea149784bd30735ce6bf75b9a5314843328adf2083b944f20623ef50c2ca00d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
